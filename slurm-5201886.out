Container llamafactory already exists.

=============
== PyTorch ==
=============

NVIDIA Release 24.07 (build 100464919)
PyTorch Version 2.4.0a0+3bcc3cd
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

ERROR: This container was built for NVIDIA Driver Release 555.42 or later, but
       version 535.247.01 was detected and compatibility mode is UNAVAILABLE.

       [[]]

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.

Sun Jun 29 12:16:55 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.5     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:CA:00.0 Off |                    0 |
| N/A   39C    P0              66W / 500W |      0MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
==============================================
Starting evaluation for model: InternVL3-8B
Model path: /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf
Template: intern_vl
Batch size: 8
==============================================
[2025-06-29 12:17:03,909] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-29 12:17:07 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-29 12:17:10] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:10,615 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:10,615 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:10,615 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:10,615 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:10,615 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:10,615 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:10,615 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 12:17:11,049 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|processing_utils.py:928] 2025-06-29 12:17:11,049 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/processor_config.json
[INFO|image_processing_base.py:378] 2025-06-29 12:17:11,051 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-29 12:17:11,058 >> Image processor GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:11,059 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:11,059 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:11,059 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:11,059 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:11,059 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:11,059 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:17:11,059 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 12:17:11,476 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-29 12:17:11,477 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-29 12:17:11,477 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-29 12:17:11,477 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-29 12:17:11,481 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

[INFO|video_processing_utils.py:627] 2025-06-29 12:17:11,481 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-29 12:17:11,482 >> Video processor InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-06-29 12:17:11,482 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/processor_config.json
[INFO|processing_utils.py:990] 2025-06-29 12:17:11,982 >> Processor InternVLProcessor:
- image_processor: GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf', vocab_size=151643, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>', '<img>', '</img>', '<IMG_CONTEXT>', '<quad>', '</quad>', '<ref>', '</ref>', '<box>', '</box>'], 'context_image_token': '<IMG_CONTEXT>', 'end_image_token': '</img>', 'start_image_token': '<img>', 'video_token': '<video>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151665: AddedToken("<img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151666: AddedToken("</img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151667: AddedToken("<IMG_CONTEXT>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151668: AddedToken("<quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151669: AddedToken("</quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151670: AddedToken("<ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151671: AddedToken("</ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151672: AddedToken("<box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151673: AddedToken("</box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151674: AddedToken("<video>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}


{
  "image_seq_length": 256,
  "processor_class": "InternVLProcessor"
}

[INFO|2025-06-29 12:17:12] llamafactory.data.template:143 >> Using default system message: You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image..
[INFO|2025-06-29 12:17:12] llamafactory.data.template:143 >> Add <|im_end|> to stop words.
[INFO|2025-06-29 12:17:12] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Converting format of dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   5%|▍         | 105/2108 [00:00<00:02, 920.49 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 2108/2108 [00:00<00:00, 6728.75 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [02:43<40:47,  1.24s/ examples]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [02:51<16:44,  1.84 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [02:53<08:40,  3.29 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [02:53<03:11,  7.56 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 791/2108 [02:54<02:05, 10.52 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 923/2108 [02:57<01:28, 13.41 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1054/2108 [03:00<01:02, 16.81 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▏   | 1317/2108 [03:00<00:25, 30.42 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▍  | 1580/2108 [03:00<00:10, 49.17 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████  | 1712/2108 [03:01<00:06, 61.78 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 1844/2108 [03:01<00:03, 79.82 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [03:01<00:00, 129.96 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [03:01<00:00, 11.61 examples/s] 
[INFO|configuration_utils.py:696] 2025-06-29 12:20:15,350 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-29 12:20:15,357 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

eval example:
input_ids:
[151644, 8948, 198, 2610, 525, 458, 6203, 11900, 16155, 11163, 311, 13382, 323, 23560, 6457, 2168, 6358, 13, 4615, 3476, 374, 311, 10542, 323, 94416, 11900, 5729, 5904, 315, 3151, 18808, 304, 15138, 1599, 29530, 5335, 13, 1446, 686, 387, 3897, 448, 264, 15138, 1599, 29530, 2168, 323, 264, 8457, 829, 13, 4615, 3383, 374, 311, 29257, 94416, 279, 9760, 5537, 1141, 8, 304, 279, 2168, 13, 151645, 198, 151644, 872, 198, 151665, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151666, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image.<|im_end|>
<|im_start|>user
<img><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT></img>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-29 12:20:15] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-29 12:20:15,560 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-06-29 12:20:15,560 >> Instantiating InternVLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-29 12:20:15,563 >> Generate config GenerationConfig {}

[INFO|modeling_utils.py:2241] 2025-06-29 12:20:16,244 >> Instantiating InternVLVisionModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-29 12:20:16,280 >> Instantiating Qwen2Model model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.73s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.53s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:07<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]
[INFO|modeling_utils.py:5131] 2025-06-29 12:20:24,323 >> All model checkpoint weights were used when initializing InternVLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-29 12:20:24,323 >> All the weights of InternVLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use InternVLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-29 12:20:24,329 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-29 12:20:24,329 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|2025-06-29 12:20:24] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-29 12:20:24] llamafactory.model.loader:143 >> all params: 7,944,373,760
[WARNING|2025-06-29 12:20:24] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-29 12:20:24,388 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-29 12:20:24,389 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-29 12:20:24,389 >>   Batch size = 8
  0%|          | 0/264 [00:00<?, ?it/s]  1%|          | 2/264 [00:07<17:15,  3.95s/it]  1%|          | 3/264 [00:15<23:41,  5.45s/it]  2%|▏         | 4/264 [00:23<27:09,  6.27s/it]  2%|▏         | 5/264 [00:30<29:03,  6.73s/it]  2%|▏         | 6/264 [00:38<30:00,  6.98s/it]  3%|▎         | 7/264 [00:47<33:09,  7.74s/it]  3%|▎         | 8/264 [00:58<37:20,  8.75s/it]  3%|▎         | 9/264 [01:08<38:14,  9.00s/it]  4%|▍         | 10/264 [01:15<36:08,  8.54s/it]  4%|▍         | 11/264 [01:24<36:02,  8.55s/it]  5%|▍         | 12/264 [01:31<34:30,  8.22s/it]  5%|▍         | 13/264 [01:41<36:05,  8.63s/it]  5%|▌         | 14/264 [01:48<34:41,  8.33s/it]  6%|▌         | 15/264 [01:56<33:59,  8.19s/it]  6%|▌         | 16/264 [02:06<35:53,  8.68s/it]  6%|▋         | 17/264 [02:15<36:15,  8.81s/it]  7%|▋         | 18/264 [02:26<38:43,  9.45s/it]  7%|▋         | 19/264 [02:33<36:03,  8.83s/it]  8%|▊         | 20/264 [02:43<36:47,  9.05s/it]  8%|▊         | 21/264 [02:51<34:51,  8.61s/it]  8%|▊         | 22/264 [02:58<33:22,  8.27s/it]  9%|▊         | 23/264 [03:11<38:26,  9.57s/it]  9%|▉         | 24/264 [03:20<37:40,  9.42s/it]  9%|▉         | 25/264 [03:29<37:48,  9.49s/it] 10%|▉         | 26/264 [03:38<37:04,  9.35s/it] 10%|█         | 27/264 [03:48<37:19,  9.45s/it] 11%|█         | 28/264 [03:57<36:16,  9.22s/it] 11%|█         | 29/264 [04:06<36:39,  9.36s/it] 11%|█▏        | 30/264 [04:13<33:32,  8.60s/it] 12%|█▏        | 31/264 [04:23<35:15,  9.08s/it] 12%|█▏        | 32/264 [04:35<37:33,  9.71s/it] 12%|█▎        | 33/264 [04:42<35:03,  9.11s/it] 13%|█▎        | 34/264 [04:51<34:21,  8.96s/it] 13%|█▎        | 35/264 [04:59<33:13,  8.70s/it] 14%|█▎        | 36/264 [05:07<31:48,  8.37s/it] 14%|█▍        | 37/264 [05:14<30:50,  8.15s/it] 14%|█▍        | 38/264 [05:22<30:13,  8.03s/it] 15%|█▍        | 39/264 [05:30<30:37,  8.17s/it] 15%|█▌        | 40/264 [05:38<30:18,  8.12s/it] 16%|█▌        | 41/264 [05:49<32:50,  8.84s/it] 16%|█▌        | 42/264 [06:00<35:22,  9.56s/it] 16%|█▋        | 43/264 [06:09<34:31,  9.37s/it] 17%|█▋        | 44/264 [06:18<33:19,  9.09s/it] 17%|█▋        | 45/264 [06:26<31:53,  8.74s/it] 17%|█▋        | 46/264 [06:38<35:42,  9.83s/it] 18%|█▊        | 47/264 [06:46<33:09,  9.17s/it] 18%|█▊        | 48/264 [06:52<30:30,  8.47s/it] 19%|█▊        | 49/264 [07:02<31:33,  8.81s/it] 19%|█▉        | 50/264 [07:11<31:06,  8.72s/it] 19%|█▉        | 51/264 [07:18<29:36,  8.34s/it] 20%|█▉        | 52/264 [07:27<30:12,  8.55s/it] 20%|██        | 53/264 [07:35<29:12,  8.31s/it] 20%|██        | 54/264 [07:45<30:45,  8.79s/it] 21%|██        | 55/264 [07:53<30:10,  8.66s/it] 21%|██        | 56/264 [08:03<31:12,  9.00s/it] 22%|██▏       | 57/264 [08:13<32:17,  9.36s/it] 22%|██▏       | 58/264 [08:22<32:08,  9.36s/it] 22%|██▏       | 59/264 [08:33<33:38,  9.85s/it] 23%|██▎       | 60/264 [08:44<34:23, 10.11s/it] 23%|██▎       | 61/264 [08:52<31:51,  9.42s/it] 23%|██▎       | 62/264 [09:05<35:03, 10.41s/it] 24%|██▍       | 63/264 [09:12<32:16,  9.63s/it] 24%|██▍       | 64/264 [09:21<30:37,  9.19s/it] 25%|██▍       | 65/264 [09:29<29:33,  8.91s/it] 25%|██▌       | 66/264 [09:36<27:25,  8.31s/it] 25%|██▌       | 67/264 [09:44<27:35,  8.40s/it] 26%|██▌       | 68/264 [09:52<26:17,  8.05s/it] 26%|██▌       | 69/264 [09:59<25:25,  7.82s/it] 27%|██▋       | 70/264 [10:07<25:13,  7.80s/it] 27%|██▋       | 71/264 [10:17<27:18,  8.49s/it] 27%|██▋       | 72/264 [10:26<27:41,  8.66s/it] 28%|██▊       | 73/264 [10:35<27:56,  8.78s/it] 28%|██▊       | 74/264 [10:43<27:32,  8.70s/it] 28%|██▊       | 75/264 [10:51<26:37,  8.45s/it] 29%|██▉       | 76/264 [10:59<25:42,  8.21s/it] 29%|██▉       | 77/264 [11:10<28:06,  9.02s/it] 30%|██▉       | 78/264 [11:17<26:25,  8.52s/it] 30%|██▉       | 79/264 [11:24<25:08,  8.15s/it] 30%|███       | 80/264 [11:31<23:48,  7.77s/it] 31%|███       | 81/264 [11:39<23:33,  7.72s/it] 31%|███       | 82/264 [11:47<23:48,  7.85s/it] 31%|███▏      | 83/264 [11:59<27:09,  9.00s/it] 32%|███▏      | 84/264 [12:10<29:15,  9.75s/it] 32%|███▏      | 85/264 [12:20<28:56,  9.70s/it] 33%|███▎      | 86/264 [12:31<29:38,  9.99s/it] 33%|███▎      | 87/264 [12:39<28:01,  9.50s/it] 33%|███▎      | 88/264 [12:47<26:38,  9.08s/it] 34%|███▎      | 89/264 [12:54<24:58,  8.56s/it] 34%|███▍      | 90/264 [13:01<23:33,  8.13s/it] 34%|███▍      | 91/264 [13:10<23:52,  8.28s/it] 35%|███▍      | 92/264 [13:20<24:58,  8.71s/it] 35%|███▌      | 93/264 [13:27<23:49,  8.36s/it] 36%|███▌      | 94/264 [13:35<22:40,  8.00s/it] 36%|███▌      | 95/264 [13:44<23:59,  8.52s/it] 36%|███▋      | 96/264 [13:51<22:47,  8.14s/it] 37%|███▋      | 97/264 [14:02<24:57,  8.97s/it] 37%|███▋      | 98/264 [14:10<24:05,  8.71s/it] 38%|███▊      | 99/264 [14:17<22:30,  8.18s/it] 38%|███▊      | 100/264 [14:25<21:29,  7.87s/it] 38%|███▊      | 101/264 [14:34<22:20,  8.23s/it] 39%|███▊      | 102/264 [14:41<21:09,  7.84s/it] 39%|███▉      | 103/264 [14:48<20:47,  7.75s/it] 39%|███▉      | 104/264 [14:58<22:17,  8.36s/it] 40%|███▉      | 105/264 [15:06<22:01,  8.31s/it] 40%|████      | 106/264 [15:18<24:31,  9.31s/it] 41%|████      | 107/264 [15:26<23:54,  9.14s/it] 41%|████      | 108/264 [15:37<24:41,  9.50s/it] 41%|████▏     | 109/264 [15:46<24:39,  9.55s/it] 42%|████▏     | 110/264 [15:54<22:45,  8.86s/it] 42%|████▏     | 111/264 [16:02<21:49,  8.56s/it] 42%|████▏     | 112/264 [16:10<21:43,  8.57s/it] 43%|████▎     | 113/264 [16:17<20:20,  8.08s/it] 43%|████▎     | 114/264 [16:27<21:37,  8.65s/it] 44%|████▎     | 115/264 [16:35<20:43,  8.34s/it] 44%|████▍     | 116/264 [16:45<21:40,  8.79s/it] 44%|████▍     | 117/264 [16:54<21:52,  8.93s/it] 45%|████▍     | 118/264 [17:06<23:44,  9.76s/it] 45%|████▌     | 119/264 [17:13<22:07,  9.15s/it] 45%|████▌     | 120/264 [17:21<21:13,  8.85s/it] 46%|████▌     | 121/264 [17:31<21:38,  9.08s/it] 46%|████▌     | 122/264 [17:39<20:52,  8.82s/it] 47%|████▋     | 123/264 [17:51<22:51,  9.72s/it] 47%|████▋     | 124/264 [18:00<22:26,  9.62s/it] 47%|████▋     | 125/264 [18:10<22:14,  9.60s/it] 48%|████▊     | 126/264 [18:17<20:14,  8.80s/it] 48%|████▊     | 127/264 [18:28<21:37,  9.47s/it] 48%|████▊     | 128/264 [18:36<20:31,  9.05s/it] 49%|████▉     | 129/264 [18:45<20:28,  9.10s/it] 49%|████▉     | 130/264 [18:57<21:48,  9.77s/it] 50%|████▉     | 131/264 [19:06<21:40,  9.78s/it] 50%|█████     | 132/264 [19:15<20:32,  9.34s/it] 50%|█████     | 133/264 [19:22<18:52,  8.65s/it] 51%|█████     | 134/264 [19:32<19:59,  9.23s/it] 51%|█████     | 135/264 [19:41<19:15,  8.96s/it] 52%|█████▏    | 136/264 [19:52<20:48,  9.75s/it] 52%|█████▏    | 137/264 [20:02<20:25,  9.65s/it] 52%|█████▏    | 138/264 [20:10<19:23,  9.23s/it] 53%|█████▎    | 139/264 [20:19<19:11,  9.21s/it] 53%|█████▎    | 140/264 [20:29<19:35,  9.48s/it] 53%|█████▎    | 141/264 [20:38<19:11,  9.36s/it] 54%|█████▍    | 142/264 [20:47<18:25,  9.06s/it] 54%|█████▍    | 143/264 [20:55<17:43,  8.79s/it] 55%|█████▍    | 144/264 [21:02<16:44,  8.37s/it] 55%|█████▍    | 145/264 [21:10<16:29,  8.32s/it] 55%|█████▌    | 146/264 [21:19<16:29,  8.39s/it] 56%|█████▌    | 147/264 [21:26<15:47,  8.10s/it] 56%|█████▌    | 148/264 [21:34<15:29,  8.02s/it] 56%|█████▋    | 149/264 [21:44<16:11,  8.45s/it] 57%|█████▋    | 150/264 [21:52<16:03,  8.45s/it] 57%|█████▋    | 151/264 [21:59<15:14,  8.10s/it] 58%|█████▊    | 152/264 [22:07<14:46,  7.91s/it] 58%|█████▊    | 153/264 [22:14<14:26,  7.81s/it] 58%|█████▊    | 154/264 [22:22<14:03,  7.66s/it] 59%|█████▊    | 155/264 [22:30<14:15,  7.85s/it] 59%|█████▉    | 156/264 [22:43<16:41,  9.27s/it] 59%|█████▉    | 157/264 [22:54<17:31,  9.82s/it] 60%|█████▉    | 158/264 [23:02<16:35,  9.39s/it] 60%|██████    | 159/264 [23:09<15:14,  8.71s/it] 61%|██████    | 160/264 [23:17<14:52,  8.59s/it] 61%|██████    | 161/264 [23:29<16:19,  9.51s/it] 61%|██████▏   | 162/264 [23:36<14:42,  8.65s/it] 62%|██████▏   | 163/264 [23:44<14:08,  8.40s/it] 62%|██████▏   | 164/264 [23:52<14:06,  8.47s/it] 62%|██████▎   | 165/264 [24:00<13:45,  8.34s/it] 63%|██████▎   | 166/264 [24:08<13:26,  8.23s/it] 63%|██████▎   | 167/264 [24:16<13:07,  8.11s/it] 64%|██████▎   | 168/264 [24:24<12:51,  8.03s/it] 64%|██████▍   | 169/264 [24:31<12:24,  7.84s/it] 64%|██████▍   | 170/264 [24:42<13:41,  8.74s/it] 65%|██████▍   | 171/264 [24:52<14:05,  9.10s/it] 65%|██████▌   | 172/264 [25:00<13:29,  8.80s/it] 66%|██████▌   | 173/264 [25:12<14:33,  9.59s/it] 66%|██████▌   | 174/264 [25:19<13:20,  8.90s/it] 66%|██████▋   | 175/264 [25:29<13:34,  9.15s/it] 67%|██████▋   | 176/264 [25:38<13:42,  9.34s/it] 67%|██████▋   | 177/264 [25:48<13:39,  9.42s/it] 67%|██████▋   | 178/264 [25:59<14:12,  9.91s/it] 68%|██████▊   | 179/264 [26:07<13:11,  9.31s/it] 68%|██████▊   | 180/264 [26:16<12:45,  9.11s/it] 69%|██████▊   | 181/264 [26:25<12:52,  9.30s/it] 69%|██████▉   | 182/264 [26:34<12:17,  9.00s/it] 69%|██████▉   | 183/264 [26:45<13:06,  9.71s/it] 70%|██████▉   | 184/264 [26:53<12:05,  9.07s/it] 70%|███████   | 185/264 [27:01<11:39,  8.86s/it] 70%|███████   | 186/264 [27:08<10:50,  8.34s/it] 71%|███████   | 187/264 [27:19<11:42,  9.13s/it] 71%|███████   | 188/264 [27:26<10:52,  8.59s/it] 72%|███████▏  | 189/264 [27:33<10:03,  8.05s/it] 72%|███████▏  | 190/264 [27:42<10:15,  8.31s/it] 72%|███████▏  | 191/264 [27:49<09:33,  7.85s/it] 73%|███████▎  | 192/264 [28:01<10:52,  9.06s/it] 73%|███████▎  | 193/264 [28:08<10:12,  8.63s/it] 73%|███████▎  | 194/264 [28:18<10:23,  8.90s/it] 74%|███████▍  | 195/264 [28:25<09:42,  8.44s/it] 74%|███████▍  | 196/264 [28:36<10:15,  9.05s/it] 75%|███████▍  | 197/264 [28:46<10:22,  9.29s/it] 75%|███████▌  | 198/264 [28:57<10:54,  9.91s/it] 75%|███████▌  | 199/264 [29:05<09:58,  9.21s/it] 76%|███████▌  | 200/264 [29:14<09:55,  9.30s/it] 76%|███████▌  | 201/264 [29:22<09:12,  8.77s/it] 77%|███████▋  | 202/264 [29:31<09:20,  9.03s/it] 77%|███████▋  | 203/264 [29:40<09:07,  8.97s/it] 77%|███████▋  | 204/264 [29:48<08:31,  8.52s/it] 78%|███████▊  | 205/264 [29:55<08:06,  8.25s/it] 78%|███████▊  | 206/264 [30:06<08:50,  9.15s/it] 78%|███████▊  | 207/264 [30:14<08:14,  8.68s/it] 79%|███████▉  | 208/264 [30:24<08:34,  9.18s/it] 79%|███████▉  | 209/264 [30:34<08:34,  9.35s/it] 80%|███████▉  | 210/264 [30:42<07:54,  8.78s/it] 80%|███████▉  | 211/264 [30:56<09:21, 10.60s/it] 80%|████████  | 212/264 [31:04<08:26,  9.74s/it] 81%|████████  | 213/264 [31:13<08:06,  9.53s/it] 81%|████████  | 214/264 [31:23<07:58,  9.58s/it] 81%|████████▏ | 215/264 [31:31<07:27,  9.12s/it] 82%|████████▏ | 216/264 [31:41<07:25,  9.29s/it] 82%|████████▏ | 217/264 [31:48<06:52,  8.77s/it] 83%|████████▎ | 218/264 [31:57<06:37,  8.65s/it] 83%|████████▎ | 219/264 [32:05<06:28,  8.64s/it] 83%|████████▎ | 220/264 [32:13<06:07,  8.36s/it] 84%|████████▎ | 221/264 [32:24<06:41,  9.33s/it] 84%|████████▍ | 222/264 [32:35<06:50,  9.78s/it] 84%|████████▍ | 223/264 [32:49<07:24, 10.84s/it] 85%|████████▍ | 224/264 [32:56<06:27,  9.69s/it] 85%|████████▌ | 225/264 [33:05<06:08,  9.45s/it] 86%|████████▌ | 226/264 [33:12<05:37,  8.88s/it] 86%|████████▌ | 227/264 [33:23<05:48,  9.43s/it] 86%|████████▋ | 228/264 [33:31<05:21,  8.94s/it] 87%|████████▋ | 229/264 [33:40<05:17,  9.06s/it] 87%|████████▋ | 230/264 [33:47<04:49,  8.51s/it] 88%|████████▊ | 231/264 [33:55<04:30,  8.19s/it] 88%|████████▊ | 232/264 [34:03<04:23,  8.22s/it] 88%|████████▊ | 233/264 [34:10<04:05,  7.93s/it] 89%|████████▊ | 234/264 [34:18<03:54,  7.81s/it] 89%|████████▉ | 235/264 [34:26<03:51,  7.98s/it] 89%|████████▉ | 236/264 [34:36<03:57,  8.50s/it] 90%|████████▉ | 237/264 [34:44<03:47,  8.43s/it] 90%|█████████ | 238/264 [34:52<03:37,  8.37s/it] 91%|█████████ | 239/264 [35:01<03:33,  8.55s/it] 91%|█████████ | 240/264 [35:09<03:18,  8.26s/it] 91%|█████████▏| 241/264 [35:17<03:09,  8.22s/it] 92%|█████████▏| 242/264 [35:24<02:55,  8.00s/it] 92%|█████████▏| 243/264 [35:34<02:56,  8.39s/it] 92%|█████████▏| 244/264 [35:45<03:02,  9.15s/it] 93%|█████████▎| 245/264 [35:54<02:56,  9.31s/it] 93%|█████████▎| 246/264 [36:03<02:44,  9.16s/it] 94%|█████████▎| 247/264 [36:11<02:27,  8.70s/it] 94%|█████████▍| 248/264 [36:18<02:13,  8.36s/it] 94%|█████████▍| 249/264 [36:25<01:57,  7.85s/it] 95%|█████████▍| 250/264 [36:32<01:48,  7.72s/it] 95%|█████████▌| 251/264 [36:46<02:01,  9.38s/it] 95%|█████████▌| 252/264 [36:57<02:01, 10.09s/it] 96%|█████████▌| 253/264 [37:06<01:45,  9.59s/it] 96%|█████████▌| 254/264 [37:14<01:31,  9.18s/it] 97%|█████████▋| 255/264 [37:23<01:22,  9.14s/it] 97%|█████████▋| 256/264 [37:32<01:13,  9.17s/it] 97%|█████████▋| 257/264 [37:40<01:01,  8.74s/it] 98%|█████████▊| 258/264 [37:50<00:53,  8.98s/it] 98%|█████████▊| 259/264 [37:59<00:45,  9.15s/it] 98%|█████████▊| 260/264 [38:07<00:34,  8.75s/it] 99%|█████████▉| 261/264 [38:16<00:26,  8.76s/it] 99%|█████████▉| 262/264 [38:24<00:17,  8.69s/it]100%|█████████▉| 263/264 [38:32<00:08,  8.42s/it]100%|██████████| 264/264 [38:38<00:00,  7.67s/it]Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 0.609 seconds.
Prefix dict has been built successfully.
100%|██████████| 264/264 [38:55<00:00,  8.85s/it]
***** predict metrics *****
  predict_bleu-4                 =    12.7238
  predict_model_preparation_time =     0.0095
  predict_rouge-1                =    22.2886
  predict_rouge-2                =    20.2763
  predict_rouge-l                =    25.4351
  predict_runtime                = 0:39:03.74
  predict_samples_per_second     =      0.899
  predict_steps_per_second       =      0.113
[INFO|2025-06-29 12:59:28] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/results/vinder_adkg_test/InternVL3-8B/generated_predictions.jsonl
✅ InternVL3-8B evaluation completed successfully

==============================================
Starting evaluation for model: Qwen2-VL-7B
Model path: /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct
Template: qwen2_vl
Batch size: 8
==============================================
[2025-06-29 12:59:40,083] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-29 12:59:43 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-29 12:59:46] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,460 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,461 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,461 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,461 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,461 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,461 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,461 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 12:59:46,795 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-06-29 12:59:46,796 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-06-29 12:59:46,828 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-29 12:59:46,857 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,858 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,858 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,859 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,859 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,859 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,859 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 12:59:46,859 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 12:59:47,176 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-29 12:59:47,177 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-29 12:59:47,177 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-29 12:59:47,178 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-29 12:59:47,180 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 152064
  },
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 3584,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 152064
}

[INFO|video_processing_utils.py:627] 2025-06-29 12:59:47,194 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-29 12:59:47,195 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-06-29 12:59:47,706 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|2025-06-29 12:59:47] llamafactory.data.template:143 >> Using default system message: You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image..
[INFO|2025-06-29 12:59:47] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Converting format of dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   5%|▍         | 102/2108 [00:00<00:02, 920.98 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 2108/2108 [00:00<00:00, 7435.21 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [04:07<1:01:45,  1.88s/ examples]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [04:11<24:15,  1.27 examples/s]  Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [04:12<12:18,  2.32 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 527/2108 [04:17<07:20,  3.59 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███       | 658/2108 [04:17<04:19,  5.58 examples/s]Running tokenizer on dataset (num_proc=16):  37%|███▋      | 789/2108 [04:18<02:37,  8.37 examples/s]Running tokenizer on dataset (num_proc=16):  50%|████▉     | 1053/2108 [04:18<01:04, 16.42 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▌    | 1185/2108 [04:18<00:41, 22.06 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▏   | 1317/2108 [04:19<00:27, 28.94 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▊   | 1448/2108 [04:19<00:17, 38.67 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▍  | 1580/2108 [04:20<00:09, 53.34 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████  | 1712/2108 [04:20<00:05, 67.64 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 1844/2108 [04:20<00:02, 92.13 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▎| 1976/2108 [04:21<00:01, 114.41 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [04:21<00:00, 156.88 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [04:21<00:00,  8.06 examples/s] 
[INFO|configuration_utils.py:696] 2025-06-29 13:04:11,102 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-29 13:04:11,110 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 152064
  },
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 3584,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 152064
}

eval example:
input_ids:
[151644, 8948, 198, 2610, 525, 458, 6203, 11900, 16155, 11163, 311, 13382, 323, 23560, 6457, 2168, 6358, 13, 4615, 3476, 374, 311, 10542, 323, 94416, 11900, 5729, 5904, 315, 3151, 18808, 304, 15138, 1599, 29530, 5335, 13, 1446, 686, 387, 3897, 448, 264, 15138, 1599, 29530, 2168, 323, 264, 8457, 829, 13, 4615, 3383, 374, 311, 29257, 94416, 279, 9760, 5537, 1141, 8, 304, 279, 2168, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-29 13:04:11] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-29 13:04:11,279 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-06-29 13:04:11,282 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-29 13:04:11,287 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|modeling_utils.py:2241] 2025-06-29 13:04:11,289 >> Instantiating Qwen2VisionTransformerPretrainedModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-29 13:04:11,325 >> Instantiating Qwen2VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:19,  4.89s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.64s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:09,  4.60s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.59s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.39s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.95s/it]
[INFO|modeling_utils.py:5131] 2025-06-29 13:04:31,130 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-29 13:04:31,130 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-29 13:04:31,135 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-29 13:04:31,136 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

[INFO|2025-06-29 13:04:31] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-29 13:04:31] llamafactory.model.loader:143 >> all params: 8,291,375,616
[WARNING|2025-06-29 13:04:31] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-29 13:04:31,184 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-29 13:04:31,184 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-29 13:04:31,184 >>   Batch size = 8
  0%|          | 0/264 [00:00<?, ?it/s]  1%|          | 2/264 [00:02<05:21,  1.23s/it]  1%|          | 3/264 [00:04<07:35,  1.75s/it]  2%|▏         | 4/264 [00:07<08:45,  2.02s/it]  2%|▏         | 5/264 [00:09<09:24,  2.18s/it]  2%|▏         | 6/264 [00:12<09:53,  2.30s/it]  3%|▎         | 7/264 [00:14<10:03,  2.35s/it]  3%|▎         | 8/264 [00:17<10:11,  2.39s/it]  3%|▎         | 9/264 [00:19<10:13,  2.41s/it]  4%|▍         | 10/264 [00:22<10:19,  2.44s/it]  4%|▍         | 11/264 [00:26<12:10,  2.89s/it]  5%|▍         | 12/264 [00:29<13:11,  3.14s/it]  5%|▍         | 13/264 [00:32<12:18,  2.94s/it]  5%|▌         | 14/264 [00:36<13:13,  3.17s/it]  6%|▌         | 15/264 [00:38<12:26,  3.00s/it]  6%|▌         | 16/264 [00:41<11:41,  2.83s/it]  6%|▋         | 17/264 [00:43<11:15,  2.74s/it]  7%|▋         | 18/264 [00:46<10:53,  2.66s/it]  7%|▋         | 19/264 [00:49<12:09,  2.98s/it]  8%|▊         | 20/264 [00:52<11:27,  2.82s/it]  8%|▊         | 21/264 [00:54<10:57,  2.71s/it]  8%|▊         | 22/264 [00:58<12:03,  2.99s/it]  9%|▊         | 23/264 [01:00<11:26,  2.85s/it]  9%|▉         | 24/264 [01:03<10:54,  2.73s/it]  9%|▉         | 25/264 [01:05<10:31,  2.64s/it] 10%|▉         | 26/264 [01:08<10:26,  2.63s/it] 10%|█         | 27/264 [01:12<11:40,  2.96s/it] 11%|█         | 28/264 [01:15<12:27,  3.17s/it] 11%|█         | 29/264 [01:18<11:38,  2.97s/it] 11%|█▏        | 30/264 [01:20<11:03,  2.83s/it] 12%|█▏        | 31/264 [01:23<10:33,  2.72s/it] 12%|█▏        | 32/264 [01:25<10:11,  2.64s/it] 12%|█▎        | 33/264 [01:28<10:00,  2.60s/it] 13%|█▎        | 34/264 [01:30<09:47,  2.56s/it] 13%|█▎        | 35/264 [01:33<09:39,  2.53s/it] 14%|█▎        | 36/264 [01:35<09:33,  2.52s/it] 14%|█▍        | 37/264 [01:38<09:26,  2.49s/it] 14%|█▍        | 38/264 [01:41<10:45,  2.86s/it] 15%|█▍        | 39/264 [01:44<10:15,  2.73s/it] 15%|█▌        | 40/264 [01:46<10:02,  2.69s/it] 16%|█▌        | 41/264 [01:49<09:52,  2.65s/it] 16%|█▌        | 42/264 [01:53<11:00,  2.97s/it] 16%|█▋        | 43/264 [01:56<11:45,  3.19s/it] 17%|█▋        | 44/264 [01:59<10:52,  2.97s/it] 17%|█▋        | 45/264 [02:01<10:21,  2.84s/it] 17%|█▋        | 46/264 [02:04<09:55,  2.73s/it] 18%|█▊        | 47/264 [02:06<09:33,  2.64s/it] 18%|█▊        | 48/264 [02:10<10:38,  2.95s/it] 19%|█▊        | 49/264 [02:12<10:02,  2.80s/it] 19%|█▉        | 50/264 [02:15<09:38,  2.70s/it] 19%|█▉        | 51/264 [02:17<09:21,  2.64s/it] 20%|█▉        | 52/264 [02:20<09:06,  2.58s/it] 20%|██        | 53/264 [02:22<08:57,  2.55s/it] 20%|██        | 54/264 [02:25<08:55,  2.55s/it] 21%|██        | 55/264 [02:27<08:46,  2.52s/it] 21%|██        | 56/264 [02:30<08:43,  2.52s/it] 22%|██▏       | 57/264 [02:32<08:36,  2.49s/it] 22%|██▏       | 58/264 [02:35<08:30,  2.48s/it] 22%|██▏       | 59/264 [02:37<08:30,  2.49s/it] 23%|██▎       | 60/264 [02:40<08:25,  2.48s/it] 23%|██▎       | 61/264 [02:42<08:28,  2.51s/it] 23%|██▎       | 62/264 [02:45<08:28,  2.52s/it] 24%|██▍       | 63/264 [02:47<08:27,  2.52s/it] 24%|██▍       | 64/264 [02:50<08:27,  2.54s/it] 25%|██▍       | 65/264 [02:52<08:19,  2.51s/it] 25%|██▌       | 66/264 [02:55<08:13,  2.49s/it] 25%|██▌       | 67/264 [02:58<09:14,  2.82s/it] 26%|██▌       | 68/264 [03:01<08:52,  2.71s/it] 26%|██▌       | 69/264 [03:03<08:41,  2.67s/it] 27%|██▋       | 70/264 [03:06<08:30,  2.63s/it] 27%|██▋       | 71/264 [03:08<08:17,  2.58s/it] 27%|██▋       | 72/264 [03:11<08:09,  2.55s/it] 28%|██▊       | 73/264 [03:13<08:04,  2.54s/it] 28%|██▊       | 74/264 [03:17<09:08,  2.89s/it] 28%|██▊       | 75/264 [03:21<09:52,  3.13s/it] 29%|██▉       | 76/264 [03:23<09:10,  2.93s/it] 29%|██▉       | 77/264 [03:26<08:49,  2.83s/it] 30%|██▉       | 78/264 [03:28<08:30,  2.75s/it] 30%|██▉       | 79/264 [03:32<09:21,  3.03s/it] 30%|███       | 80/264 [03:34<08:45,  2.86s/it] 31%|███       | 81/264 [03:37<08:21,  2.74s/it] 31%|███       | 82/264 [03:39<08:06,  2.67s/it] 31%|███▏      | 83/264 [03:44<09:19,  3.09s/it] 32%|███▏      | 84/264 [03:46<08:49,  2.94s/it] 32%|███▏      | 85/264 [03:49<08:19,  2.79s/it] 33%|███▎      | 86/264 [03:51<07:58,  2.69s/it] 33%|███▎      | 87/264 [03:55<08:53,  3.01s/it] 33%|███▎      | 88/264 [03:57<08:25,  2.87s/it] 34%|███▎      | 89/264 [04:00<08:06,  2.78s/it] 34%|███▍      | 90/264 [04:02<07:46,  2.68s/it] 34%|███▍      | 91/264 [04:05<07:40,  2.66s/it] 35%|███▍      | 92/264 [04:07<07:26,  2.59s/it] 35%|███▌      | 93/264 [04:10<07:22,  2.59s/it] 36%|███▌      | 94/264 [04:12<07:15,  2.56s/it] 36%|███▌      | 95/264 [04:15<07:07,  2.53s/it] 36%|███▋      | 96/264 [04:17<07:05,  2.53s/it] 37%|███▋      | 97/264 [04:21<08:01,  2.88s/it] 37%|███▋      | 98/264 [04:24<07:40,  2.77s/it] 38%|███▊      | 99/264 [04:27<08:23,  3.05s/it] 38%|███▊      | 100/264 [04:31<08:49,  3.23s/it] 38%|███▊      | 101/264 [04:35<09:10,  3.37s/it] 39%|███▊      | 102/264 [04:37<08:27,  3.14s/it] 39%|███▉      | 103/264 [04:40<07:51,  2.93s/it] 39%|███▉      | 104/264 [04:42<07:25,  2.78s/it] 40%|███▉      | 105/264 [04:46<08:00,  3.02s/it] 40%|████      | 106/264 [04:49<08:20,  3.17s/it] 41%|████      | 107/264 [04:52<07:44,  2.96s/it] 41%|████      | 108/264 [04:54<07:17,  2.80s/it] 41%|████▏     | 109/264 [04:57<07:04,  2.74s/it] 42%|████▏     | 110/264 [04:59<06:50,  2.67s/it] 42%|████▏     | 111/264 [05:03<07:26,  2.92s/it] 42%|████▏     | 112/264 [05:05<07:06,  2.81s/it] 43%|████▎     | 113/264 [05:08<06:51,  2.73s/it] 43%|████▎     | 114/264 [05:10<06:37,  2.65s/it] 44%|████▎     | 115/264 [05:13<06:25,  2.59s/it] 44%|████▍     | 116/264 [05:15<06:16,  2.55s/it] 44%|████▍     | 117/264 [05:18<06:09,  2.51s/it] 45%|████▍     | 118/264 [05:21<06:58,  2.87s/it] 45%|████▌     | 119/264 [05:24<06:38,  2.75s/it] 45%|████▌     | 120/264 [05:28<07:16,  3.03s/it] 46%|████▌     | 121/264 [05:30<06:53,  2.89s/it] 46%|████▌     | 122/264 [05:33<06:32,  2.77s/it] 47%|████▋     | 123/264 [05:35<06:33,  2.79s/it] 47%|████▋     | 124/264 [05:38<06:18,  2.70s/it] 47%|████▋     | 125/264 [05:40<06:04,  2.62s/it] 48%|████▊     | 126/264 [05:43<05:57,  2.59s/it] 48%|████▊     | 127/264 [05:45<05:48,  2.54s/it] 48%|████▊     | 128/264 [05:48<05:44,  2.53s/it] 49%|████▉     | 129/264 [05:50<05:37,  2.50s/it] 49%|████▉     | 130/264 [05:54<06:20,  2.84s/it] 50%|████▉     | 131/264 [05:56<06:05,  2.75s/it] 50%|█████     | 132/264 [06:00<06:40,  3.04s/it] 50%|█████     | 133/264 [06:03<06:18,  2.89s/it] 51%|█████     | 134/264 [06:05<05:57,  2.75s/it] 51%|█████     | 135/264 [06:08<05:42,  2.66s/it] 52%|█████▏    | 136/264 [06:10<05:30,  2.58s/it] 52%|█████▏    | 137/264 [06:12<05:22,  2.54s/it] 52%|█████▏    | 138/264 [06:15<05:21,  2.55s/it] 53%|█████▎    | 139/264 [06:17<05:14,  2.51s/it] 53%|█████▎    | 140/264 [06:20<05:08,  2.49s/it] 53%|█████▎    | 141/264 [06:22<05:06,  2.50s/it] 54%|█████▍    | 142/264 [06:25<05:03,  2.49s/it] 54%|█████▍    | 143/264 [06:28<05:42,  2.83s/it] 55%|█████▍    | 144/264 [06:31<05:27,  2.73s/it] 55%|█████▍    | 145/264 [06:33<05:18,  2.67s/it] 55%|█████▌    | 146/264 [06:36<05:11,  2.64s/it] 56%|█████▌    | 147/264 [06:40<05:44,  2.94s/it] 56%|█████▌    | 148/264 [06:42<05:24,  2.79s/it] 56%|█████▋    | 149/264 [06:45<05:14,  2.74s/it] 57%|█████▋    | 150/264 [06:47<05:02,  2.65s/it] 57%|█████▋    | 151/264 [06:51<05:35,  2.97s/it] 58%|█████▊    | 152/264 [06:55<05:57,  3.19s/it] 58%|█████▊    | 153/264 [06:57<05:31,  2.99s/it] 58%|█████▊    | 154/264 [07:00<05:10,  2.82s/it] 59%|█████▊    | 155/264 [07:03<05:36,  3.09s/it] 59%|█████▉    | 156/264 [07:06<05:12,  2.90s/it] 59%|█████▉    | 157/264 [07:09<05:37,  3.16s/it] 60%|█████▉    | 158/264 [07:12<05:12,  2.94s/it] 60%|██████    | 159/264 [07:16<05:37,  3.21s/it] 61%|██████    | 160/264 [07:18<05:10,  2.98s/it] 61%|██████    | 161/264 [07:21<04:50,  2.82s/it] 61%|██████▏   | 162/264 [07:23<04:38,  2.73s/it] 62%|██████▏   | 163/264 [07:27<05:05,  3.02s/it] 62%|██████▏   | 164/264 [07:29<04:45,  2.85s/it] 62%|██████▎   | 165/264 [07:33<05:18,  3.22s/it] 63%|██████▎   | 166/264 [07:36<04:52,  2.99s/it] 63%|██████▎   | 167/264 [07:38<04:36,  2.86s/it] 64%|██████▎   | 168/264 [07:41<04:23,  2.74s/it] 64%|██████▍   | 169/264 [07:43<04:11,  2.65s/it] 64%|██████▍   | 170/264 [07:46<04:03,  2.59s/it] 65%|██████▍   | 171/264 [07:48<03:56,  2.55s/it] 65%|██████▌   | 172/264 [07:51<03:52,  2.53s/it] 66%|██████▌   | 173/264 [07:53<03:48,  2.51s/it] 66%|██████▌   | 174/264 [07:56<03:44,  2.49s/it] 66%|██████▋   | 175/264 [07:58<03:40,  2.48s/it] 67%|██████▋   | 176/264 [08:01<03:37,  2.47s/it] 67%|██████▋   | 177/264 [08:03<03:33,  2.46s/it] 67%|██████▋   | 178/264 [08:05<03:32,  2.47s/it] 68%|██████▊   | 179/264 [08:09<04:01,  2.85s/it] 68%|██████▊   | 180/264 [08:12<03:48,  2.72s/it] 69%|██████▊   | 181/264 [08:14<03:39,  2.64s/it] 69%|██████▉   | 182/264 [08:18<04:02,  2.96s/it] 69%|██████▉   | 183/264 [08:20<03:47,  2.81s/it] 70%|██████▉   | 184/264 [08:23<03:39,  2.75s/it] 70%|███████   | 185/264 [08:25<03:29,  2.66s/it] 70%|███████   | 186/264 [08:29<03:51,  2.97s/it] 71%|███████   | 187/264 [08:33<04:05,  3.19s/it] 71%|███████   | 188/264 [08:35<03:47,  2.99s/it] 72%|███████▏  | 189/264 [08:38<03:31,  2.83s/it] 72%|███████▏  | 190/264 [08:41<03:48,  3.09s/it] 72%|███████▏  | 191/264 [08:44<03:31,  2.90s/it] 73%|███████▎  | 192/264 [08:47<03:46,  3.14s/it] 73%|███████▎  | 193/264 [08:50<03:29,  2.95s/it] 73%|███████▎  | 194/264 [08:52<03:16,  2.81s/it] 74%|███████▍  | 195/264 [08:56<03:32,  3.08s/it] 74%|███████▍  | 196/264 [09:00<03:42,  3.27s/it] 75%|███████▍  | 197/264 [09:02<03:23,  3.03s/it] 75%|███████▌  | 198/264 [09:05<03:10,  2.88s/it] 75%|███████▌  | 199/264 [09:07<03:00,  2.78s/it] 76%|███████▌  | 200/264 [09:12<03:22,  3.17s/it] 76%|███████▌  | 201/264 [09:15<03:30,  3.33s/it] 77%|███████▋  | 202/264 [09:18<03:10,  3.07s/it] 77%|███████▋  | 203/264 [09:20<02:57,  2.91s/it] 77%|███████▋  | 204/264 [09:23<02:46,  2.77s/it] 78%|███████▊  | 205/264 [09:26<03:00,  3.05s/it] 78%|███████▊  | 206/264 [09:29<02:47,  2.89s/it] 78%|███████▊  | 207/264 [09:31<02:39,  2.80s/it] 79%|███████▉  | 208/264 [09:34<02:30,  2.69s/it] 79%|███████▉  | 209/264 [09:38<02:44,  3.00s/it] 80%|███████▉  | 210/264 [09:40<02:33,  2.84s/it] 80%|███████▉  | 211/264 [09:43<02:24,  2.72s/it] 80%|████████  | 212/264 [09:45<02:17,  2.64s/it] 81%|████████  | 213/264 [09:47<02:11,  2.58s/it] 81%|████████  | 214/264 [09:51<02:25,  2.92s/it] 81%|████████▏ | 215/264 [09:54<02:17,  2.81s/it] 82%|████████▏ | 216/264 [09:56<02:10,  2.72s/it] 82%|████████▏ | 217/264 [09:59<02:05,  2.67s/it] 83%|████████▎ | 218/264 [10:01<02:01,  2.64s/it] 83%|████████▎ | 219/264 [10:04<01:56,  2.58s/it] 83%|████████▎ | 220/264 [10:06<01:52,  2.56s/it] 84%|████████▎ | 221/264 [10:09<01:49,  2.54s/it] 84%|████████▍ | 222/264 [10:11<01:45,  2.52s/it] 84%|████████▍ | 223/264 [10:15<01:58,  2.90s/it] 85%|████████▍ | 224/264 [10:19<02:05,  3.14s/it] 85%|████████▌ | 225/264 [10:21<01:55,  2.95s/it] 86%|████████▌ | 226/264 [10:24<01:47,  2.82s/it] 86%|████████▌ | 227/264 [10:27<01:54,  3.09s/it] 86%|████████▋ | 228/264 [10:30<01:45,  2.92s/it] 87%|████████▋ | 229/264 [10:33<01:37,  2.79s/it] 87%|████████▋ | 230/264 [10:35<01:31,  2.69s/it] 88%|████████▊ | 231/264 [10:38<01:27,  2.65s/it] 88%|████████▊ | 232/264 [10:40<01:23,  2.60s/it] 88%|████████▊ | 233/264 [10:43<01:19,  2.57s/it] 89%|████████▊ | 234/264 [10:45<01:16,  2.55s/it] 89%|████████▉ | 235/264 [10:48<01:14,  2.56s/it] 89%|████████▉ | 236/264 [10:50<01:10,  2.52s/it] 90%|████████▉ | 237/264 [10:52<01:07,  2.50s/it] 90%|█████████ | 238/264 [10:56<01:14,  2.86s/it] 91%|█████████ | 239/264 [11:00<01:17,  3.12s/it] 91%|█████████ | 240/264 [11:04<01:19,  3.31s/it] 91%|█████████▏| 241/264 [11:07<01:18,  3.43s/it] 92%|█████████▏| 242/264 [11:10<01:08,  3.13s/it] 92%|█████████▏| 243/264 [11:12<01:02,  2.96s/it] 92%|█████████▏| 244/264 [11:15<00:56,  2.83s/it] 93%|█████████▎| 245/264 [11:17<00:51,  2.73s/it] 93%|█████████▎| 246/264 [11:20<00:48,  2.68s/it] 94%|█████████▎| 247/264 [11:22<00:44,  2.63s/it] 94%|█████████▍| 248/264 [11:26<00:47,  2.95s/it] 94%|█████████▍| 249/264 [11:29<00:41,  2.80s/it] 95%|█████████▍| 250/264 [11:32<00:42,  3.05s/it] 95%|█████████▌| 251/264 [11:35<00:37,  2.87s/it] 95%|█████████▌| 252/264 [11:37<00:32,  2.74s/it] 96%|█████████▌| 253/264 [11:40<00:29,  2.67s/it] 96%|█████████▌| 254/264 [11:42<00:26,  2.62s/it] 97%|█████████▋| 255/264 [11:45<00:23,  2.57s/it] 97%|█████████▋| 256/264 [11:47<00:20,  2.54s/it] 97%|█████████▋| 257/264 [11:50<00:17,  2.51s/it] 98%|█████████▊| 258/264 [11:52<00:15,  2.53s/it] 98%|█████████▊| 259/264 [11:55<00:12,  2.52s/it] 98%|█████████▊| 260/264 [11:57<00:10,  2.54s/it] 99%|█████████▉| 261/264 [12:00<00:07,  2.54s/it] 99%|█████████▉| 262/264 [12:02<00:05,  2.55s/it]100%|█████████▉| 263/264 [12:05<00:02,  2.53s/it]100%|██████████| 264/264 [12:07<00:00,  2.33s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.786 seconds.
Prefix dict has been built successfully.
100%|██████████| 264/264 [12:11<00:00,  2.77s/it]
***** predict metrics *****
  predict_bleu-4                 =    28.7029
  predict_model_preparation_time =     0.0088
  predict_rouge-1                =    61.7215
  predict_rouge-2                =    53.8444
  predict_rouge-l                =    61.2414
  predict_runtime                = 0:12:15.28
  predict_samples_per_second     =      2.867
  predict_steps_per_second       =      0.359
[INFO|2025-06-29 13:16:46] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/results/vinder_adkg_test/Qwen2-VL-7B/generated_predictions.jsonl
✅ Qwen2-VL-7B evaluation completed successfully

==============================================
Starting evaluation for model: InternVL3-2B
Model path: /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf
Template: intern_vl
Batch size: 16
==============================================
[2025-06-29 13:16:57,523] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-29 13:17:01 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-29 13:17:03] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,005 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,005 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,005 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,005 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,005 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,005 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,005 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 13:17:04,434 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|processing_utils.py:928] 2025-06-29 13:17:04,436 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/processor_config.json
[INFO|image_processing_base.py:378] 2025-06-29 13:17:04,438 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-29 13:17:04,445 >> Image processor GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,446 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,446 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,446 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,446 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,446 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,446 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:17:04,446 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 13:17:04,864 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-29 13:17:04,865 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-29 13:17:04,866 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-29 13:17:04,866 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-29 13:17:04,869 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

[INFO|video_processing_utils.py:627] 2025-06-29 13:17:04,870 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-29 13:17:04,870 >> Video processor InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-06-29 13:17:04,870 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/processor_config.json
[INFO|processing_utils.py:990] 2025-06-29 13:17:05,377 >> Processor InternVLProcessor:
- image_processor: GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf', vocab_size=151643, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>', '<img>', '</img>', '<IMG_CONTEXT>', '<quad>', '</quad>', '<ref>', '</ref>', '<box>', '</box>'], 'context_image_token': '<IMG_CONTEXT>', 'end_image_token': '</img>', 'start_image_token': '<img>', 'video_token': '<video>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151665: AddedToken("<img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151666: AddedToken("</img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151667: AddedToken("<IMG_CONTEXT>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151668: AddedToken("<quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151669: AddedToken("</quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151670: AddedToken("<ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151671: AddedToken("</ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151672: AddedToken("<box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151673: AddedToken("</box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151674: AddedToken("<video>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}


{
  "image_seq_length": 256,
  "processor_class": "InternVLProcessor"
}

[INFO|2025-06-29 13:17:05] llamafactory.data.template:143 >> Using default system message: You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image..
[INFO|2025-06-29 13:17:05] llamafactory.data.template:143 >> Add <|im_end|> to stop words.
[INFO|2025-06-29 13:17:05] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [02:45<41:16,  1.25s/ examples]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [02:46<16:02,  1.92 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [02:53<08:44,  3.26 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [02:54<04:57,  5.31 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [02:56<03:02,  7.92 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [02:56<01:50, 11.86 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [02:58<01:12, 16.40 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [02:59<00:44, 23.40 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [03:00<00:30, 30.45 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [03:00<00:18, 42.08 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [03:01<00:11, 59.37 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1583/2108 [03:01<00:06, 80.79 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1714/2108 [03:01<00:03, 112.26 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1845/2108 [03:02<00:01, 134.64 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [03:02<00:00, 180.15 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [03:02<00:00, 242.41 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [03:02<00:00, 11.56 examples/s] 
[INFO|configuration_utils.py:696] 2025-06-29 13:20:08,910 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-29 13:20:08,917 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

eval example:
input_ids:
[151644, 8948, 198, 2610, 525, 458, 6203, 11900, 16155, 11163, 311, 13382, 323, 23560, 6457, 2168, 6358, 13, 4615, 3476, 374, 311, 10542, 323, 94416, 11900, 5729, 5904, 315, 3151, 18808, 304, 15138, 1599, 29530, 5335, 13, 1446, 686, 387, 3897, 448, 264, 15138, 1599, 29530, 2168, 323, 264, 8457, 829, 13, 4615, 3383, 374, 311, 29257, 94416, 279, 9760, 5537, 1141, 8, 304, 279, 2168, 13, 151645, 198, 151644, 872, 198, 151665, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151666, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image.<|im_end|>
<|im_start|>user
<img><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT></img>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-29 13:20:08] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-29 13:20:09,119 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/model.safetensors
[INFO|modeling_utils.py:2241] 2025-06-29 13:20:09,130 >> Instantiating InternVLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-29 13:20:09,133 >> Generate config GenerationConfig {}

[INFO|modeling_utils.py:2241] 2025-06-29 13:20:09,848 >> Instantiating InternVLVisionModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-29 13:20:09,883 >> Instantiating Qwen2Model model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:5131] 2025-06-29 13:20:15,508 >> All model checkpoint weights were used when initializing InternVLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-29 13:20:15,508 >> All the weights of InternVLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use InternVLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-29 13:20:15,514 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-29 13:20:15,514 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|2025-06-29 13:20:15] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-29 13:20:15] llamafactory.model.loader:143 >> all params: 2,088,957,440
[WARNING|2025-06-29 13:20:15] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-29 13:20:15,566 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-29 13:20:15,566 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-29 13:20:15,566 >>   Batch size = 16
  0%|          | 0/132 [00:00<?, ?it/s]  2%|▏         | 2/132 [00:01<02:04,  1.04it/s]  2%|▏         | 3/132 [00:03<02:53,  1.34s/it]  3%|▎         | 4/132 [00:05<03:17,  1.54s/it]  4%|▍         | 5/132 [00:07<03:30,  1.66s/it]  5%|▍         | 6/132 [00:09<03:37,  1.73s/it]  5%|▌         | 7/132 [00:11<03:41,  1.78s/it]  6%|▌         | 8/132 [00:13<03:43,  1.81s/it]  7%|▋         | 9/132 [00:15<03:44,  1.83s/it]  8%|▊         | 10/132 [00:16<03:44,  1.84s/it]  8%|▊         | 11/132 [00:18<03:45,  1.86s/it]  9%|▉         | 12/132 [00:20<03:44,  1.87s/it] 10%|▉         | 13/132 [00:22<03:43,  1.88s/it] 11%|█         | 14/132 [00:24<03:41,  1.88s/it] 11%|█▏        | 15/132 [00:26<03:39,  1.88s/it] 12%|█▏        | 16/132 [00:28<03:37,  1.88s/it] 13%|█▎        | 17/132 [00:30<03:35,  1.88s/it] 14%|█▎        | 18/132 [00:31<03:33,  1.87s/it] 14%|█▍        | 19/132 [00:33<03:31,  1.87s/it] 15%|█▌        | 20/132 [00:35<03:29,  1.87s/it] 16%|█▌        | 21/132 [00:37<03:27,  1.87s/it] 17%|█▋        | 22/132 [00:39<03:26,  1.87s/it] 17%|█▋        | 23/132 [00:41<03:24,  1.87s/it] 18%|█▊        | 24/132 [00:43<03:22,  1.88s/it] 19%|█▉        | 25/132 [00:45<03:20,  1.88s/it] 20%|█▉        | 26/132 [00:46<03:18,  1.88s/it] 20%|██        | 27/132 [00:48<03:16,  1.88s/it] 21%|██        | 28/132 [00:50<03:15,  1.88s/it] 22%|██▏       | 29/132 [00:52<03:13,  1.88s/it] 23%|██▎       | 30/132 [00:54<03:11,  1.87s/it] 23%|██▎       | 31/132 [00:56<03:10,  1.88s/it] 24%|██▍       | 32/132 [00:58<03:08,  1.88s/it] 25%|██▌       | 33/132 [01:00<03:05,  1.88s/it] 26%|██▌       | 34/132 [01:01<03:03,  1.88s/it] 27%|██▋       | 35/132 [01:03<03:01,  1.87s/it] 27%|██▋       | 36/132 [01:05<03:00,  1.88s/it] 28%|██▊       | 37/132 [01:07<02:59,  1.89s/it] 29%|██▉       | 38/132 [01:09<02:57,  1.88s/it] 30%|██▉       | 39/132 [01:11<02:55,  1.89s/it] 30%|███       | 40/132 [01:13<02:53,  1.89s/it] 31%|███       | 41/132 [01:15<02:52,  1.89s/it] 32%|███▏      | 42/132 [01:17<02:49,  1.89s/it] 33%|███▎      | 43/132 [01:18<02:47,  1.88s/it] 33%|███▎      | 44/132 [01:20<02:45,  1.88s/it] 34%|███▍      | 45/132 [01:22<02:43,  1.88s/it] 35%|███▍      | 46/132 [01:24<02:42,  1.89s/it] 36%|███▌      | 47/132 [01:26<02:39,  1.88s/it] 36%|███▋      | 48/132 [01:28<02:37,  1.88s/it] 37%|███▋      | 49/132 [01:30<02:35,  1.88s/it] 38%|███▊      | 50/132 [01:32<02:33,  1.87s/it] 39%|███▊      | 51/132 [01:33<02:31,  1.87s/it] 39%|███▉      | 52/132 [01:35<02:29,  1.87s/it] 40%|████      | 53/132 [01:37<02:27,  1.87s/it] 41%|████      | 54/132 [01:39<02:25,  1.87s/it] 42%|████▏     | 55/132 [01:41<02:24,  1.87s/it] 42%|████▏     | 56/132 [01:43<02:22,  1.87s/it] 43%|████▎     | 57/132 [01:45<02:20,  1.87s/it] 44%|████▍     | 58/132 [01:47<02:18,  1.87s/it] 45%|████▍     | 59/132 [01:48<02:16,  1.87s/it] 45%|████▌     | 60/132 [01:50<02:15,  1.88s/it] 46%|████▌     | 61/132 [01:52<02:13,  1.88s/it] 47%|████▋     | 62/132 [01:54<02:11,  1.88s/it] 48%|████▊     | 63/132 [01:56<02:09,  1.87s/it] 48%|████▊     | 64/132 [01:58<02:07,  1.88s/it] 49%|████▉     | 65/132 [02:00<02:05,  1.87s/it] 50%|█████     | 66/132 [02:02<02:03,  1.87s/it] 51%|█████     | 67/132 [02:03<02:02,  1.88s/it] 52%|█████▏    | 68/132 [02:05<02:00,  1.88s/it] 52%|█████▏    | 69/132 [02:07<01:58,  1.88s/it] 53%|█████▎    | 70/132 [02:09<01:56,  1.87s/it] 54%|█████▍    | 71/132 [02:11<01:54,  1.87s/it] 55%|█████▍    | 72/132 [02:13<01:52,  1.87s/it] 55%|█████▌    | 73/132 [02:15<01:50,  1.87s/it] 56%|█████▌    | 74/132 [02:17<01:48,  1.87s/it] 57%|█████▋    | 75/132 [02:18<01:47,  1.88s/it] 58%|█████▊    | 76/132 [02:20<01:45,  1.89s/it] 58%|█████▊    | 77/132 [02:22<01:43,  1.88s/it] 59%|█████▉    | 78/132 [02:24<01:41,  1.88s/it] 60%|█████▉    | 79/132 [02:26<01:39,  1.88s/it] 61%|██████    | 80/132 [02:28<01:37,  1.88s/it] 61%|██████▏   | 81/132 [02:30<01:35,  1.87s/it] 62%|██████▏   | 82/132 [02:32<01:33,  1.87s/it] 63%|██████▎   | 83/132 [02:33<01:31,  1.87s/it] 64%|██████▎   | 84/132 [02:35<01:29,  1.87s/it] 64%|██████▍   | 85/132 [02:37<01:27,  1.87s/it] 65%|██████▌   | 86/132 [02:39<01:26,  1.87s/it] 66%|██████▌   | 87/132 [02:41<01:24,  1.87s/it] 67%|██████▋   | 88/132 [02:43<01:22,  1.87s/it] 67%|██████▋   | 89/132 [02:45<01:20,  1.87s/it] 68%|██████▊   | 90/132 [02:47<01:19,  1.88s/it] 69%|██████▉   | 91/132 [02:48<01:17,  1.88s/it] 70%|██████▉   | 92/132 [02:50<01:15,  1.88s/it] 70%|███████   | 93/132 [02:52<01:13,  1.87s/it] 71%|███████   | 94/132 [02:54<01:11,  1.87s/it] 72%|███████▏  | 95/132 [02:56<01:09,  1.87s/it] 73%|███████▎  | 96/132 [02:58<01:07,  1.87s/it] 73%|███████▎  | 97/132 [03:00<01:05,  1.87s/it] 74%|███████▍  | 98/132 [03:02<01:03,  1.87s/it] 75%|███████▌  | 99/132 [03:03<01:01,  1.87s/it] 76%|███████▌  | 100/132 [03:05<01:00,  1.88s/it] 77%|███████▋  | 101/132 [03:07<00:58,  1.88s/it] 77%|███████▋  | 102/132 [03:09<00:56,  1.88s/it] 78%|███████▊  | 103/132 [03:11<00:54,  1.87s/it] 79%|███████▉  | 104/132 [03:13<00:52,  1.87s/it] 80%|███████▉  | 105/132 [03:15<00:50,  1.87s/it] 80%|████████  | 106/132 [03:17<00:48,  1.87s/it] 81%|████████  | 107/132 [03:18<00:46,  1.87s/it] 82%|████████▏ | 108/132 [03:20<00:44,  1.87s/it] 83%|████████▎ | 109/132 [03:22<00:43,  1.87s/it] 83%|████████▎ | 110/132 [03:25<00:49,  2.24s/it] 84%|████████▍ | 111/132 [03:27<00:44,  2.13s/it] 85%|████████▍ | 112/132 [03:29<00:40,  2.05s/it] 86%|████████▌ | 113/132 [03:31<00:37,  1.99s/it] 86%|████████▋ | 114/132 [03:33<00:35,  1.96s/it] 87%|████████▋ | 115/132 [03:35<00:32,  1.93s/it] 88%|████████▊ | 116/132 [03:37<00:30,  1.91s/it] 89%|████████▊ | 117/132 [03:38<00:28,  1.90s/it] 89%|████████▉ | 118/132 [03:40<00:26,  1.89s/it] 90%|█████████ | 119/132 [03:42<00:24,  1.89s/it] 91%|█████████ | 120/132 [03:44<00:22,  1.89s/it] 92%|█████████▏| 121/132 [03:46<00:20,  1.89s/it] 92%|█████████▏| 122/132 [03:48<00:18,  1.88s/it] 93%|█████████▎| 123/132 [03:50<00:16,  1.88s/it] 94%|█████████▍| 124/132 [03:52<00:15,  1.88s/it] 95%|█████████▍| 125/132 [03:53<00:13,  1.87s/it] 95%|█████████▌| 126/132 [03:55<00:11,  1.87s/it] 96%|█████████▌| 127/132 [03:57<00:09,  1.87s/it] 97%|█████████▋| 128/132 [03:59<00:07,  1.87s/it] 98%|█████████▊| 129/132 [04:01<00:05,  1.87s/it] 98%|█████████▊| 130/132 [04:03<00:03,  1.87s/it] 99%|█████████▉| 131/132 [04:05<00:01,  1.86s/it]100%|██████████| 132/132 [04:06<00:00,  1.79s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.797 seconds.
Prefix dict has been built successfully.
100%|██████████| 132/132 [04:11<00:00,  1.90s/it]
***** predict metrics *****
  predict_bleu-4                 =    48.1489
  predict_model_preparation_time =     0.0093
  predict_rouge-1                =    62.8425
  predict_rouge-2                =     54.979
  predict_rouge-l                =    63.1587
  predict_runtime                = 0:04:14.17
  predict_samples_per_second     =      8.294
  predict_steps_per_second       =      0.519
[INFO|2025-06-29 13:24:29] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/results/vinder_adkg_test/InternVL3-2B/generated_predictions.jsonl
✅ InternVL3-2B evaluation completed successfully

==============================================
Starting evaluation for model: Qwen2-VL-2B
Model path: /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct
Template: qwen2_vl
Batch size: 16
==============================================
[2025-06-29 13:24:40,749] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-29 13:24:44 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-29 13:24:47] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,229 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,229 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,229 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,229 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,229 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,229 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,229 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 13:24:47,566 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-06-29 13:24:47,568 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-06-29 13:24:47,572 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-29 13:24:47,579 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,580 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,580 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,580 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,580 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,580 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,580 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-29 13:24:47,580 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-29 13:24:47,887 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-29 13:24:47,888 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-29 13:24:47,888 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-29 13:24:47,889 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-29 13:24:47,891 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

[INFO|video_processing_utils.py:627] 2025-06-29 13:24:47,892 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-29 13:24:47,893 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-06-29 13:24:48,414 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|2025-06-29 13:24:48] llamafactory.data.template:143 >> Using default system message: You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image..
[INFO|2025-06-29 13:24:48] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [04:02<1:00:30,  1.84s/ examples]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [04:10<24:20,  1.26 examples/s]  Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [04:12<12:30,  2.28 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [04:15<07:14,  3.64 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [04:18<04:23,  5.49 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [04:18<01:46, 11.10 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [04:19<01:10, 14.86 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [04:19<00:45, 20.37 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [04:19<00:18, 35.72 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1583/2108 [04:20<00:11, 44.99 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1714/2108 [04:20<00:06, 56.31 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [04:20<00:00, 114.56 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [04:20<00:00,  8.08 examples/s] 
[INFO|configuration_utils.py:696] 2025-06-29 13:29:10,470 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-29 13:29:10,477 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

eval example:
input_ids:
[151644, 8948, 198, 2610, 525, 458, 6203, 11900, 16155, 11163, 311, 13382, 323, 23560, 6457, 2168, 6358, 13, 4615, 3476, 374, 311, 10542, 323, 94416, 11900, 5729, 5904, 315, 3151, 18808, 304, 15138, 1599, 29530, 5335, 13, 1446, 686, 387, 3897, 448, 264, 15138, 1599, 29530, 2168, 323, 264, 8457, 829, 13, 4615, 3383, 374, 311, 29257, 94416, 279, 9760, 5537, 1141, 8, 304, 279, 2168, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are an expert radiologist committed to accurate and precise medical image analysis. Your role is to identify and localize radiological evidence of specific diseases in chest X-ray images. You will be provided with a chest X-ray image and a disease name. Your task is to accurately localize the relevant region(s) in the image.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-29 13:29:10] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-29 13:29:10,613 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-06-29 13:29:10,615 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-29 13:29:10,619 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|modeling_utils.py:2241] 2025-06-29 13:29:10,620 >> Instantiating Qwen2VisionTransformerPretrainedModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-29 13:29:10,649 >> Instantiating Qwen2VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.84s/it]
[INFO|modeling_utils.py:5131] 2025-06-29 13:29:16,387 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-29 13:29:16,387 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-29 13:29:16,393 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-29 13:29:16,393 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

[INFO|2025-06-29 13:29:16] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-29 13:29:16] llamafactory.model.loader:143 >> all params: 2,208,985,600
[WARNING|2025-06-29 13:29:16] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-29 13:29:16,441 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-29 13:29:16,441 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-29 13:29:16,441 >>   Batch size = 16
  0%|          | 0/132 [00:00<?, ?it/s]  2%|▏         | 2/132 [00:03<04:05,  1.89s/it]  2%|▏         | 3/132 [00:07<05:44,  2.67s/it]  3%|▎         | 4/132 [00:11<06:51,  3.21s/it]  4%|▍         | 5/132 [00:15<07:09,  3.38s/it]  5%|▍         | 6/132 [00:19<07:19,  3.49s/it]  5%|▌         | 7/132 [00:22<07:25,  3.57s/it]  6%|▌         | 8/132 [00:26<07:30,  3.63s/it]  7%|▋         | 9/132 [00:30<07:31,  3.67s/it]  8%|▊         | 10/132 [00:34<07:31,  3.70s/it]  8%|▊         | 11/132 [00:37<07:31,  3.74s/it]  9%|▉         | 12/132 [00:41<07:27,  3.73s/it] 10%|▉         | 13/132 [00:48<09:02,  4.56s/it] 11%|█         | 14/132 [00:51<08:27,  4.30s/it] 11%|█▏        | 15/132 [00:55<08:02,  4.12s/it] 12%|█▏        | 16/132 [00:59<07:43,  4.00s/it] 13%|█▎        | 17/132 [01:02<07:30,  3.92s/it] 14%|█▎        | 18/132 [01:06<07:21,  3.87s/it] 14%|█▍        | 19/132 [01:10<07:24,  3.93s/it] 15%|█▌        | 20/132 [01:14<07:13,  3.87s/it] 16%|█▌        | 21/132 [01:18<07:04,  3.82s/it] 17%|█▋        | 22/132 [01:21<06:58,  3.80s/it] 17%|█▋        | 23/132 [01:28<08:22,  4.61s/it] 18%|█▊        | 24/132 [01:32<07:47,  4.33s/it] 19%|█▉        | 25/132 [01:35<07:25,  4.17s/it] 20%|█▉        | 26/132 [01:39<07:09,  4.05s/it] 20%|██        | 27/132 [01:43<06:56,  3.96s/it] 21%|██        | 28/132 [01:47<06:46,  3.91s/it] 22%|██▏       | 29/132 [01:50<06:36,  3.85s/it] 23%|██▎       | 30/132 [01:57<07:49,  4.61s/it] 23%|██▎       | 31/132 [02:01<07:17,  4.33s/it] 24%|██▍       | 32/132 [02:04<06:56,  4.16s/it] 25%|██▌       | 33/132 [02:08<06:51,  4.16s/it] 26%|██▌       | 34/132 [02:12<06:35,  4.04s/it] 27%|██▋       | 35/132 [02:19<07:42,  4.77s/it] 27%|██▋       | 36/132 [02:22<07:09,  4.47s/it] 28%|██▊       | 37/132 [02:26<06:43,  4.25s/it] 29%|██▉       | 38/132 [02:30<06:26,  4.11s/it] 30%|██▉       | 39/132 [02:34<06:10,  3.99s/it] 30%|███       | 40/132 [02:37<05:59,  3.91s/it] 31%|███       | 41/132 [02:41<05:49,  3.84s/it] 32%|███▏      | 42/132 [02:45<05:43,  3.82s/it] 33%|███▎      | 43/132 [02:49<05:36,  3.78s/it] 33%|███▎      | 44/132 [02:52<05:32,  3.78s/it] 34%|███▍      | 45/132 [02:56<05:28,  3.78s/it] 35%|███▍      | 46/132 [03:00<05:22,  3.74s/it] 36%|███▌      | 47/132 [03:04<05:26,  3.84s/it] 36%|███▋      | 48/132 [03:08<05:20,  3.82s/it] 37%|███▋      | 49/132 [03:11<05:15,  3.81s/it] 38%|███▊      | 50/132 [03:15<05:08,  3.76s/it] 39%|███▊      | 51/132 [03:19<05:05,  3.77s/it] 39%|███▉      | 52/132 [03:23<04:59,  3.75s/it] 40%|████      | 53/132 [03:26<04:54,  3.73s/it] 41%|████      | 54/132 [03:30<04:52,  3.74s/it] 42%|████▏     | 55/132 [03:34<04:48,  3.75s/it] 42%|████▏     | 56/132 [03:38<04:45,  3.76s/it] 43%|████▎     | 57/132 [03:41<04:40,  3.74s/it] 44%|████▍     | 58/132 [03:45<04:35,  3.73s/it] 45%|████▍     | 59/132 [03:49<04:33,  3.74s/it] 45%|████▌     | 60/132 [03:53<04:35,  3.83s/it] 46%|████▌     | 61/132 [04:29<16:05, 13.60s/it] 47%|████▋     | 62/132 [04:33<12:24, 10.63s/it] 48%|████▊     | 63/132 [04:37<09:49,  8.54s/it] 48%|████▊     | 64/132 [04:40<08:03,  7.11s/it] 49%|████▉     | 65/132 [04:44<06:47,  6.09s/it] 50%|█████     | 66/132 [04:48<05:55,  5.39s/it] 51%|█████     | 67/132 [04:52<05:18,  4.90s/it] 52%|█████▏    | 68/132 [04:55<04:51,  4.55s/it] 52%|█████▏    | 69/132 [04:59<04:32,  4.32s/it] 53%|█████▎    | 70/132 [05:03<04:16,  4.13s/it] 54%|█████▍    | 71/132 [05:06<04:05,  4.02s/it] 55%|█████▍    | 72/132 [05:10<03:55,  3.93s/it] 55%|█████▌    | 73/132 [05:47<13:27, 13.68s/it] 56%|█████▌    | 74/132 [05:50<10:20, 10.69s/it] 57%|█████▋    | 75/132 [05:54<08:10,  8.61s/it] 58%|█████▊    | 76/132 [06:01<07:32,  8.09s/it] 58%|█████▊    | 77/132 [06:05<06:13,  6.79s/it] 59%|█████▉    | 78/132 [06:08<05:16,  5.86s/it] 60%|█████▉    | 79/132 [06:12<04:36,  5.21s/it] 61%|██████    | 80/132 [06:16<04:08,  4.78s/it] 61%|██████▏   | 81/132 [06:20<03:47,  4.46s/it] 62%|██████▏   | 82/132 [06:23<03:31,  4.23s/it] 63%|██████▎   | 83/132 [06:35<05:20,  6.55s/it] 64%|██████▎   | 84/132 [06:39<04:34,  5.71s/it] 64%|██████▍   | 85/132 [07:15<11:41, 14.93s/it] 65%|██████▌   | 86/132 [07:19<08:52, 11.57s/it] 66%|██████▌   | 87/132 [07:56<14:16, 19.03s/it] 67%|██████▋   | 88/132 [07:59<10:34, 14.43s/it] 67%|██████▋   | 89/132 [08:03<08:01, 11.19s/it] 68%|██████▊   | 90/132 [08:09<06:50,  9.77s/it] 69%|██████▉   | 91/132 [08:13<05:30,  8.07s/it] 70%|██████▉   | 92/132 [08:17<04:30,  6.76s/it] 70%|███████   | 93/132 [08:21<03:48,  5.86s/it] 71%|███████   | 94/132 [08:25<03:18,  5.21s/it] 72%|███████▏  | 95/132 [08:28<02:56,  4.77s/it] 73%|███████▎  | 96/132 [09:05<08:34, 14.28s/it] 73%|███████▎  | 97/132 [09:09<06:28, 11.11s/it] 74%|███████▍  | 98/132 [09:12<05:02,  8.90s/it] 75%|███████▌  | 99/132 [09:16<04:02,  7.36s/it] 76%|███████▌  | 100/132 [09:20<03:20,  6.28s/it] 77%|███████▋  | 101/132 [09:26<03:16,  6.34s/it] 77%|███████▋  | 102/132 [09:30<02:47,  5.57s/it] 78%|███████▊  | 103/132 [09:34<02:25,  5.01s/it] 79%|███████▉  | 104/132 [09:37<02:09,  4.62s/it] 80%|███████▉  | 105/132 [09:42<02:00,  4.46s/it] 80%|████████  | 106/132 [09:45<01:50,  4.24s/it] 81%|████████  | 107/132 [09:52<02:02,  4.91s/it] 82%|████████▏ | 108/132 [09:55<01:48,  4.54s/it] 83%|████████▎ | 109/132 [09:59<01:39,  4.31s/it] 83%|████████▎ | 110/132 [10:03<01:30,  4.13s/it] 84%|████████▍ | 111/132 [10:07<01:23,  4.00s/it] 85%|████████▍ | 112/132 [10:13<01:34,  4.74s/it] 86%|████████▌ | 113/132 [10:17<01:24,  4.42s/it] 86%|████████▋ | 114/132 [10:20<01:15,  4.20s/it] 87%|████████▋ | 115/132 [10:24<01:09,  4.07s/it] 88%|████████▊ | 116/132 [10:28<01:03,  3.96s/it] 89%|████████▊ | 117/132 [11:04<03:25, 13.70s/it] 89%|████████▉ | 118/132 [11:08<02:29, 10.70s/it] 90%|█████████ | 119/132 [11:12<01:53,  8.72s/it] 91%|█████████ | 120/132 [11:16<01:26,  7.22s/it] 92%|█████████▏| 121/132 [11:20<01:08,  6.19s/it] 92%|█████████▏| 122/132 [11:23<00:54,  5.46s/it] 93%|█████████▎| 123/132 [12:00<02:12, 14.75s/it] 94%|█████████▍| 124/132 [12:04<01:31, 11.44s/it] 95%|█████████▍| 125/132 [12:07<01:03,  9.13s/it] 95%|█████████▌| 126/132 [12:12<00:47,  7.92s/it] 96%|█████████▌| 127/132 [12:16<00:33,  6.66s/it] 97%|█████████▋| 128/132 [12:20<00:23,  5.77s/it] 98%|█████████▊| 129/132 [12:24<00:15,  5.17s/it] 98%|█████████▊| 130/132 [12:27<00:09,  4.73s/it] 99%|█████████▉| 131/132 [13:04<00:14, 14.22s/it]100%|██████████| 132/132 [13:06<00:00, 10.74s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.789 seconds.
Prefix dict has been built successfully.
100%|██████████| 132/132 [13:11<00:00,  6.00s/it]
***** predict metrics *****
  predict_bleu-4                 =     24.356
  predict_model_preparation_time =     0.0089
  predict_rouge-1                =    62.0643
  predict_rouge-2                =    53.2992
  predict_rouge-l                =    60.3701
  predict_runtime                = 0:13:16.32
  predict_samples_per_second     =      2.647
  predict_steps_per_second       =      0.166
[INFO|2025-06-29 13:42:32] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/results/vinder_adkg_test/Qwen2-VL-2B/generated_predictions.jsonl
✅ Qwen2-VL-2B evaluation completed successfully

🎉 All model evaluations completed!
