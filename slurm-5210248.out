Container llamafactory already exists.

=============
== PyTorch ==
=============

NVIDIA Release 24.07 (build 100464919)
PyTorch Version 2.4.0a0+3bcc3cd
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

ERROR: This container was built for NVIDIA Driver Release 555.42 or later, but
       version 535.247.01 was detected and compatibility mode is UNAVAILABLE.

       [[]]

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.

Sat Jul  5 09:46:51 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.5     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |
| N/A   37C    P0              65W / 400W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Checkpoint directory: saves/qwen2_vl-3b/vindr_sft_base
Output directory: ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b
Processing model: qwen2_vl-3b
Running inference on checkpoint: checkpoint-1008
INFO 07-05 09:47:00 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 09:47:02,027 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 09:47:02,076 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,100 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,100 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,100 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,100 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,100 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,100 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,100 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:47:02,495 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:47:02,497 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 09:47:02,503 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:47:02,509 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,510 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,510 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,510 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,510 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,510 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,510 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:02,510 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:47:02,878 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:47:02,881 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:47:03,094 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:47:03,532 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 09:47:03,589 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/config.json
[INFO|configuration_utils.py:696] 2025-07-05 09:47:03,589 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/config.json
[INFO|configuration_utils.py:770] 2025-07-05 09:47:03,591 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 09:47:15 [config.py:689] This model supports multiple tasks: {'generate', 'score', 'reward', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 07-05 09:47:15 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:15,233 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:15,233 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:15,233 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:15,233 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:15,233 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:15,233 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:15,233 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:47:15,563 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 09:47:15,663 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 09:47:15,666 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 09:47:17 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 09:47:17 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 09:47:17 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008...
WARNING 07-05 09:47:17 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 09:47:17 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.23s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.23s/it]

INFO 07-05 09:47:25 [loader.py:458] Loading weights took 7.46 seconds
INFO 07-05 09:47:25 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.705348 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:25,650 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:25,650 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:25,650 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:25,650 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:25,650 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:25,650 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:25,651 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:47:26,067 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:47:26,165 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:47:26,165 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 09:47:26,165 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:47:26,166 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:26,166 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:26,166 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:26,166 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:26,166 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:26,166 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:26,166 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:26,166 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:47:26,923 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:47:26,923 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:47:26,923 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:47:27,384 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 09:47:28,051 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 09:47:28 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 09:47:30,808 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 09:47:31,787 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 09:47:32 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 09:48:10 [worker.py:267] Memory profiling takes 44.86 seconds
INFO 07-05 09:48:10 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 09:48:10 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 09:48:10 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 09:48:10 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 09:48:15 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:18,  1.87it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.93it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.96it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.98it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.99it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.99it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.99it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  2.01it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:12,  2.00it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  2.01it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  2.00it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  2.00it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  2.00it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.00it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.98it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  2.00it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.97it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.98it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  2.00it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  2.00it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.00it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  2.00it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.01it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  2.00it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:02,  2.00it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  2.01it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.01it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.01it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:00,  2.01it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  2.01it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.01it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.99it/s]
INFO 07-05 09:48:33 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 09:48:33 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 67.91 seconds
[INFO|2025-07-05 09:48:33] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:10, 192.86 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 543.68 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:01, 808.96 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:01<00:01, 1021.87 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:01<00:00, 1176.91 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:01<00:00, 1246.67 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:01<00:00, 1465.92 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:01<00:00, 1604.28 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 973.95 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 09:48:38,613 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:48:38,613 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:48:38,614 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:48:38,614 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:48:38,614 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:48:38,614 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:48:38,614 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:48:38,614 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:48:38,614 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:48:39,396 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:48:39,397 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:48:39,397 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:48:39,857 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1008', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.66s/it, est. speed input: 234.69 toks/s, output: 32.50 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 16.92it/s, est. speed input: 5018.18 toks/s, output: 750.50 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.70it/s, est. speed input: 5445.84 toks/s, output: 971.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.86it/s, est. speed input: 5445.84 toks/s, output: 971.80 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:52,  4.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.65 toks/s, output: 42.18 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.83it/s, est. speed input: 5677.12 toks/s, output: 844.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.05it/s, est. speed input: 6517.58 toks/s, output: 1216.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6517.58 toks/s, output: 1216.17 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:43,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.31 toks/s, output: 42.27 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.31it/s, est. speed input: 5221.75 toks/s, output: 780.34 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.67it/s, est. speed input: 6321.67 toks/s, output: 1216.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.82it/s, est. speed input: 5036.16 toks/s, output: 1038.95 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:38,  3.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.09 toks/s, output: 42.24 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.71it/s, est. speed input: 6510.33 toks/s, output: 965.22 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.36it/s, est. speed input: 6744.74 toks/s, output: 1168.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.19it/s, est. speed input: 6744.74 toks/s, output: 1168.34 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:13<03:15,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.29 toks/s, output: 42.13 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6241.33 toks/s, output: 927.77 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 14.11it/s, est. speed input: 5088.12 toks/s, output: 927.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.39it/s, est. speed input: 4472.71 toks/s, output: 897.74 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:17<03:23,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.73 toks/s, output: 42.05 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6482.53 toks/s, output: 956.22 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.48it/s, est. speed input: 5713.83 toks/s, output: 1035.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.56it/s, est. speed input: 5713.83 toks/s, output: 1035.44 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:20<03:13,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.47 toks/s, output: 42.02 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.29it/s, est. speed input: 6690.81 toks/s, output: 989.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7751.28 toks/s, output: 1296.91 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:22<02:55,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.69 toks/s, output: 42.05 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.96it/s, est. speed input: 5994.87 toks/s, output: 894.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 7712.48 toks/s, output: 1375.10 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:24<02:42,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.87 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6733.48 toks/s, output: 995.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7740.24 toks/s, output: 1283.56 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:27<02:32,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.19 toks/s, output: 42.12 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.56it/s, est. speed input: 6758.16 toks/s, output: 1001.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.59it/s, est. speed input: 5728.27 toks/s, output: 998.39 toks/s] 
Processing batched inference:  15%|█▌        | 10/66 [00:30<02:34,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.59 toks/s, output: 42.03 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6472.64 toks/s, output: 954.31 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.32it/s, est. speed input: 6528.42 toks/s, output: 1159.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6528.42 toks/s, output: 1159.74 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:33<02:31,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.02 toks/s, output: 41.96 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5959.70 toks/s, output: 888.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 7703.01 toks/s, output: 1377.98 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:35<02:22,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.07 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6222.40 toks/s, output: 926.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7721.48 toks/s, output: 1352.42 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:37<02:15,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.84 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.82it/s, est. speed input: 6242.22 toks/s, output: 924.10 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.01it/s, est. speed input: 6574.57 toks/s, output: 1141.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6527.61 toks/s, output: 1178.93 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:40<02:15,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.54 toks/s, output: 42.03 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.10it/s, est. speed input: 5449.56 toks/s, output: 811.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.74it/s, est. speed input: 6365.83 toks/s, output: 1187.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.35it/s, est. speed input: 5632.55 toks/s, output: 1109.37 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:43<02:18,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.89 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 6735.91 toks/s, output: 1002.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7743.42 toks/s, output: 1296.41 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:45<02:11,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.04 toks/s, output: 42.49 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6223.62 toks/s, output: 925.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 11.50it/s, est. speed input: 4394.34 toks/s, output: 855.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.55it/s, est. speed input: 4535.93 toks/s, output: 962.70 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:49<02:21,  2.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.14 toks/s, output: 42.11 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 6750.86 toks/s, output: 1001.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7758.37 toks/s, output: 1290.69 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:51<02:11,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6223.33 toks/s, output: 926.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.76it/s, est. speed input: 6334.43 toks/s, output: 1114.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.56it/s, est. speed input: 5717.79 toks/s, output: 1066.31 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:54<02:11,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.81 toks/s, output: 42.45 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.64it/s, est. speed input: 5910.50 toks/s, output: 884.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 7643.44 toks/s, output: 1369.43 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:57<02:02,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.05 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6220.35 toks/s, output: 925.28 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.83it/s, est. speed input: 6578.66 toks/s, output: 1171.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.76it/s, est. speed input: 6578.66 toks/s, output: 1171.40 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:59<01:59,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.35 toks/s, output: 42.00 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.10it/s, est. speed input: 5446.55 toks/s, output: 810.79 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.66it/s, est. speed input: 5884.76 toks/s, output: 1072.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.87it/s, est. speed input: 4661.71 toks/s, output: 1008.02 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:03<02:06,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.31 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6481.19 toks/s, output: 960.36 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 6528.98 toks/s, output: 1135.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6528.98 toks/s, output: 1135.38 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:05<02:00,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.02 toks/s, output: 41.96 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5954.25 toks/s, output: 885.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s, est. speed input: 2942.39 toks/s, output: 623.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.50it/s, est. speed input: 2942.39 toks/s, output: 623.62 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:10<02:24,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.36 toks/s, output: 42.00 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 5957.91 toks/s, output: 885.01 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.10it/s, est. speed input: 6111.05 toks/s, output: 1077.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  6.23it/s, est. speed input: 2444.79 toks/s, output: 576.60 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:16<02:50,  4.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.45 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.75it/s, est. speed input: 6290.53 toks/s, output: 940.34 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.80it/s, est. speed input: 6352.10 toks/s, output: 1100.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.83it/s, est. speed input: 5044.18 toks/s, output: 946.43 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:19<02:34,  3.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.98 toks/s, output: 41.81 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6203.74 toks/s, output: 919.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.73it/s, est. speed input: 6316.52 toks/s, output: 1105.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6520.47 toks/s, output: 1186.57 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:22<02:15,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.45 toks/s, output: 41.88 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 6725.21 toks/s, output: 997.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6523.38 toks/s, output: 1118.02 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:24<02:02,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.96 toks/s, output: 41.95 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.41it/s, est. speed input: 5861.99 toks/s, output: 874.13 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.21it/s, est. speed input: 6110.65 toks/s, output: 1084.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.36it/s, est. speed input: 4070.24 toks/s, output: 839.49 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [01:28<02:04,  3.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.81 toks/s, output: 41.45 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.27it/s, est. speed input: 7557.83 toks/s, output: 1118.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.87it/s, est. speed input: 6625.64 toks/s, output: 1052.06 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:31<01:52,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.50 toks/s, output: 42.02 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6226.27 toks/s, output: 921.65 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.85it/s, est. speed input: 6582.79 toks/s, output: 1166.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6582.79 toks/s, output: 1166.50 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:33<01:42,  2.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.09 toks/s, output: 42.10 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6232.90 toks/s, output: 919.57 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.54it/s, est. speed input: 6528.02 toks/s, output: 1163.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6528.02 toks/s, output: 1163.56 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:36<01:35,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.09 toks/s, output: 41.97 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.39it/s, est. speed input: 5863.05 toks/s, output: 876.84 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.60it/s, est. speed input: 5629.75 toks/s, output: 1057.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.32it/s, est. speed input: 5629.75 toks/s, output: 1057.11 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:39<01:33,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.76 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.19it/s, est. speed input: 6390.63 toks/s, output: 950.48 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.40it/s, est. speed input: 5684.64 toks/s, output: 1018.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.46it/s, est. speed input: 5684.64 toks/s, output: 1018.48 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:41<01:31,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.56 toks/s, output: 42.03 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6484.26 toks/s, output: 961.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 6530.06 toks/s, output: 1133.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6530.06 toks/s, output: 1133.76 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:44<01:25,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.30 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6223.40 toks/s, output: 922.40 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.52it/s, est. speed input: 6519.79 toks/s, output: 1160.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6519.79 toks/s, output: 1160.07 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:47<01:20,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.12 toks/s, output: 42.11 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 6757.77 toks/s, output: 1002.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7791.93 toks/s, output: 1290.68 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:49<01:13,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.10 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.08it/s, est. speed input: 6079.02 toks/s, output: 911.91 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.13it/s, est. speed input: 6560.60 toks/s, output: 1158.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6534.62 toks/s, output: 1198.87 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:51<01:11,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.15 toks/s, output: 41.97 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.58it/s, est. speed input: 4700.87 toks/s, output: 702.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.11it/s, est. speed input: 6293.29 toks/s, output: 1255.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5607.94 toks/s, output: 1174.76 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:54<01:11,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.12 toks/s, output: 41.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.67it/s, est. speed input: 6208.53 toks/s, output: 927.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.46it/s, est. speed input: 6505.84 toks/s, output: 1164.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6505.84 toks/s, output: 1164.57 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:57<01:08,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.03 toks/s, output: 41.96 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.35it/s, est. speed input: 4932.77 toks/s, output: 737.80 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.40it/s, est. speed input: 5921.08 toks/s, output: 1121.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6474.09 toks/s, output: 1351.70 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:59<01:05,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.27 toks/s, output: 41.99 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.95it/s, est. speed input: 5983.69 toks/s, output: 887.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.27it/s, est. speed input: 6383.30 toks/s, output: 1141.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.54it/s, est. speed input: 5707.96 toks/s, output: 1079.86 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:02<01:04,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.35 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 6738.23 toks/s, output: 996.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.79it/s, est. speed input: 4624.47 toks/s, output: 836.05 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:06<01:06,  2.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.52 toks/s, output: 42.16 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.02it/s, est. speed input: 5720.21 toks/s, output: 849.50 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.35it/s, est. speed input: 6111.72 toks/s, output: 1095.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.77it/s, est. speed input: 3830.56 toks/s, output: 820.37 toks/s] 
Processing batched inference:  67%|██████▋   | 44/66 [02:09<01:10,  3.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.39 toks/s, output: 42.01 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6739.93 toks/s, output: 995.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6557.65 toks/s, output: 1142.36 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:12<01:02,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.33 toks/s, output: 42.00 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.09it/s, est. speed input: 5444.99 toks/s, output: 811.10 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 17.76it/s, est. speed input: 5664.57 toks/s, output: 1004.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 17.76it/s, est. speed input: 5441.49 toks/s, output: 1122.38 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.33s/it, est. speed input: 479.80 toks/s, output: 252.37 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 479.80 toks/s, output: 252.37 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:39<03:23, 10.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.70 toks/s, output: 41.80 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6459.38 toks/s, output: 963.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7707.93 toks/s, output: 1321.02 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:41<02:27,  7.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.31 toks/s, output: 42.38 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6204.72 toks/s, output: 921.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 7701.31 toks/s, output: 1344.73 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:43<01:49,  6.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.75 toks/s, output: 41.92 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.38it/s, est. speed input: 5224.05 toks/s, output: 777.89 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.87it/s, est. speed input: 6345.08 toks/s, output: 1206.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6549.52 toks/s, output: 1286.01 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:46<01:25,  5.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.66 toks/s, output: 42.04 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.35it/s, est. speed input: 7276.53 toks/s, output: 1074.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.89it/s, est. speed input: 6627.05 toks/s, output: 1074.59 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:48<01:08,  4.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.76 toks/s, output: 41.92 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.05it/s, est. speed input: 5437.55 toks/s, output: 813.20 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.35it/s, est. speed input: 6473.19 toks/s, output: 1208.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.47it/s, est. speed input: 5681.29 toks/s, output: 1118.71 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:51<00:57,  3.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.40 toks/s, output: 42.40 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.22it/s, est. speed input: 5182.61 toks/s, output: 776.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 7652.19 toks/s, output: 1457.03 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:53<00:47,  3.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.63 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6215.19 toks/s, output: 920.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.80it/s, est. speed input: 6530.62 toks/s, output: 1143.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6526.48 toks/s, output: 1187.90 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:56<00:40,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.36 toks/s, output: 42.00 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7001.93 toks/s, output: 1034.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.92it/s, est. speed input: 5855.93 toks/s, output: 994.25 toks/s] 
Processing batched inference:  82%|████████▏ | 54/66 [02:59<00:36,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.40 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5962.47 toks/s, output: 885.69 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.11it/s, est. speed input: 6112.57 toks/s, output: 1075.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.52it/s, est. speed input: 2952.49 toks/s, output: 673.00 toks/s] 
Processing batched inference:  83%|████████▎ | 55/66 [03:04<00:39,  3.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.26 toks/s, output: 41.85 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.89it/s, est. speed input: 5686.16 toks/s, output: 850.87 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.28it/s, est. speed input: 6090.70 toks/s, output: 1102.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.35it/s, est. speed input: 5639.59 toks/s, output: 1140.65 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:07<00:33,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.23 toks/s, output: 41.99 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5957.98 toks/s, output: 883.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7701.38 toks/s, output: 1367.18 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:09<00:27,  3.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.04 toks/s, output: 42.49 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6220.74 toks/s, output: 921.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7721.67 toks/s, output: 1343.91 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:11<00:22,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.83 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.24it/s, est. speed input: 6674.27 toks/s, output: 986.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7732.04 toks/s, output: 1288.05 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:13<00:18,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.64 toks/s, output: 41.90 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.84it/s, est. speed input: 6240.82 toks/s, output: 924.89 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.75it/s, est. speed input: 6330.88 toks/s, output: 1103.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.84it/s, est. speed input: 5038.17 toks/s, output: 950.97 toks/s] 
Processing batched inference:  91%|█████████ | 60/66 [03:16<00:16,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.55 toks/s, output: 41.89 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5693.40 toks/s, output: 848.11 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.48it/s, est. speed input: 6132.74 toks/s, output: 1111.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6501.25 toks/s, output: 1265.29 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:19<00:13,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.27 toks/s, output: 41.85 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.70it/s, est. speed input: 5643.36 toks/s, output: 843.93 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.84it/s, est. speed input: 6648.49 toks/s, output: 1238.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.92it/s, est. speed input: 6648.49 toks/s, output: 1238.09 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:22<00:10,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.30 toks/s, output: 42.38 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6465.66 toks/s, output: 959.77 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.41it/s, est. speed input: 6537.41 toks/s, output: 1165.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6537.41 toks/s, output: 1165.20 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:24<00:07,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.18 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 5955.11 toks/s, output: 883.52 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.71it/s, est. speed input: 6502.82 toks/s, output: 1184.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6502.82 toks/s, output: 1184.49 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:27<00:05,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.34 toks/s, output: 41.86 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.91it/s, est. speed input: 5689.30 toks/s, output: 848.03 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.89it/s, est. speed input: 6479.62 toks/s, output: 1199.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6479.62 toks/s, output: 1199.02 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:29<00:02,  2.58s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 337.34 toks/s, output: 46.59 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 22.65it/s, est. speed input: 6824.11 toks/s, output: 1013.21 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.83it/s, est. speed input: 7396.30 toks/s, output: 1195.37 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:31<00:00,  2.43s/it]Processing batched inference: 100%|██████████| 66/66 [03:31<00:00,  3.21s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-1008/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 09:52:11.325908457 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1071
INFO 07-05 09:52:24 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 09:52:25,930 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 09:52:25,995 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,018 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,018 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,018 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,018 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,018 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,018 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,018 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:52:26,405 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:52:26,408 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 09:52:26,413 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:52:26,420 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,420 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,420 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,420 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,420 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,420 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,420 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:26,420 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:52:26,791 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:52:26,794 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:52:26,991 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:52:27,428 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 09:52:27,483 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/config.json
[INFO|configuration_utils.py:696] 2025-07-05 09:52:27,483 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/config.json
[INFO|configuration_utils.py:770] 2025-07-05 09:52:27,485 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 09:52:39 [config.py:689] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 07-05 09:52:39 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:39,253 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:39,254 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:39,254 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:39,254 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:39,254 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:39,254 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:39,254 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:52:39,586 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 09:52:39,686 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 09:52:39,689 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 09:52:41 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 09:52:41 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 09:52:41 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071...
WARNING 07-05 09:52:41 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 09:52:41 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.32s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.32s/it]

INFO 07-05 09:52:49 [loader.py:458] Loading weights took 7.53 seconds
INFO 07-05 09:52:49 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.783504 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:49,778 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:49,778 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:49,778 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:49,778 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:49,778 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:49,779 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:49,779 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:52:50,187 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:52:50,284 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:52:50,284 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 09:52:50,284 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:52:50,285 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:50,285 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:50,285 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:50,285 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:50,285 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:50,285 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:50,285 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:52:50,285 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:52:51,033 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:52:51,034 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:52:51,034 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:52:51,494 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 09:52:52,186 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 09:52:52 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 09:52:55,013 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 09:52:56,020 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 09:52:56 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 09:53:34 [worker.py:267] Memory profiling takes 45.02 seconds
INFO 07-05 09:53:34 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 09:53:34 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 09:53:35 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 09:53:35 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 09:53:40 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:21,  1.56it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:19,  1.73it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:18,  1.75it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:17,  1.82it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:16,  1.86it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.83it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:15,  1.84it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.89it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.88it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.90it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:12,  1.89it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:09<00:09,  1.91it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.93it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:10<00:08,  1.91it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:11<00:07,  1.96it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.98it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.98it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.92it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.94it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.92it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.93it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.96it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.98it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.99it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.00it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:00,  2.01it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.99it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.94it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 09:53:58 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 09:53:58 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.98 seconds
[INFO|2025-07-05 09:53:58] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:10, 192.89 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:00<00:04, 382.29 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 562.96 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:01, 1124.75 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:01<00:00, 1053.41 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:01<00:00, 1324.42 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:01<00:00, 1493.63 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:01<00:00, 1374.53 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 979.15 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 09:54:03,344 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:54:03,345 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:54:03,346 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:54:03,346 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:54:03,346 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:54:03,346 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:54:03,346 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:54:03,346 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:54:03,346 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:54:04,141 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:54:04,141 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:54:04,142 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:54:04,596 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1071', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 237.06 toks/s, output: 32.82 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 17.07it/s, est. speed input: 5064.52 toks/s, output: 757.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.07it/s, est. speed input: 6314.17 toks/s, output: 1102.65 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:30,  4.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.09 toks/s, output: 42.10 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.46it/s, est. speed input: 6448.00 toks/s, output: 955.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7746.55 toks/s, output: 1325.91 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:22,  3.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.10 toks/s, output: 42.24 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.31it/s, est. speed input: 5219.87 toks/s, output: 780.06 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.73it/s, est. speed input: 6331.55 toks/s, output: 1218.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.51it/s, est. speed input: 5701.10 toks/s, output: 1153.90 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:17,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.29 toks/s, output: 42.80 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.68it/s, est. speed input: 6781.98 toks/s, output: 1005.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7792.40 toks/s, output: 1290.86 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:56,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.22 toks/s, output: 42.26 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.93it/s, est. speed input: 5990.91 toks/s, output: 890.90 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.18it/s, est. speed input: 6143.06 toks/s, output: 1085.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.98it/s, est. speed input: 4704.33 toks/s, output: 979.80 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:15<03:07,  3.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.20 toks/s, output: 42.26 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.72it/s, est. speed input: 6508.25 toks/s, output: 960.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.71it/s, est. speed input: 5044.88 toks/s, output: 933.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.86it/s, est. speed input: 5044.88 toks/s, output: 933.50 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:18<03:08,  3.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.27 toks/s, output: 42.13 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.29it/s, est. speed input: 6695.53 toks/s, output: 990.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7757.86 toks/s, output: 1297.39 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:21<02:52,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.57 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5969.11 toks/s, output: 892.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.73it/s, est. speed input: 6701.58 toks/s, output: 1217.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.06it/s, est. speed input: 6701.58 toks/s, output: 1217.77 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:24<02:45,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.39 toks/s, output: 41.18 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.16it/s, est. speed input: 6627.97 toks/s, output: 979.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 7623.36 toks/s, output: 1264.17 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:26<02:34,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.93 toks/s, output: 42.22 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.61it/s, est. speed input: 6773.81 toks/s, output: 1001.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7786.26 toks/s, output: 1295.74 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:28<02:26,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.50 toks/s, output: 42.30 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.75it/s, est. speed input: 6513.14 toks/s, output: 959.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 6557.37 toks/s, output: 1141.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6557.37 toks/s, output: 1141.90 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:31<02:25,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.32 toks/s, output: 42.67 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.93it/s, est. speed input: 5983.87 toks/s, output: 895.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 7673.87 toks/s, output: 1372.15 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:33<02:18,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.49 toks/s, output: 42.16 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.44it/s, est. speed input: 6449.55 toks/s, output: 958.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7758.12 toks/s, output: 1331.07 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:36<02:12,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.92 toks/s, output: 42.22 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.73it/s, est. speed input: 6510.05 toks/s, output: 960.92 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.40it/s, est. speed input: 6557.11 toks/s, output: 1138.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6557.11 toks/s, output: 1138.81 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:38<02:11,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.96 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6493.98 toks/s, output: 961.80 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.67it/s, est. speed input: 6606.09 toks/s, output: 1149.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.83it/s, est. speed input: 6606.09 toks/s, output: 1149.65 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:41<02:10,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.14 toks/s, output: 42.11 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6491.37 toks/s, output: 968.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7748.66 toks/s, output: 1325.02 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:43<02:05,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.95 toks/s, output: 42.61 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5966.96 toks/s, output: 887.88 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:02<00:00, 14.99it/s, est. speed input: 5211.67 toks/s, output: 945.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.52it/s, est. speed input: 5703.57 toks/s, output: 1210.97 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:46<02:08,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.39 toks/s, output: 42.15 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.43it/s, est. speed input: 7301.42 toks/s, output: 1080.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 7815.38 toks/s, output: 1242.94 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:49<02:02,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.78 toks/s, output: 42.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5966.89 toks/s, output: 891.48 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.28it/s, est. speed input: 6386.42 toks/s, output: 1149.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6528.94 toks/s, output: 1219.14 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:51<02:02,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.54 toks/s, output: 42.56 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.32it/s, est. speed input: 6698.88 toks/s, output: 999.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7761.18 toks/s, output: 1301.03 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:54<01:55,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.74 toks/s, output: 42.06 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6232.53 toks/s, output: 927.09 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.55it/s, est. speed input: 6528.53 toks/s, output: 1163.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6528.53 toks/s, output: 1163.00 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:56<01:54,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.29 toks/s, output: 41.99 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.51it/s, est. speed input: 4683.39 toks/s, output: 700.55 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:02<00:00, 15.50it/s, est. speed input: 5089.11 toks/s, output: 1013.26 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.39it/s, est. speed input: 5150.72 toks/s, output: 1194.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.12it/s, est. speed input: 5150.72 toks/s, output: 1194.93 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:00<02:00,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 307.84 toks/s, output: 40.25 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.58it/s, est. speed input: 6205.10 toks/s, output: 916.80 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.08it/s, est. speed input: 6167.42 toks/s, output: 1081.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6517.81 toks/s, output: 1233.08 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:02<01:55,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.08 toks/s, output: 41.49 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6226.30 toks/s, output: 922.10 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.30it/s, est. speed input: 3425.75 toks/s, output: 686.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.73it/s, est. speed input: 3425.75 toks/s, output: 686.51 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:06<02:13,  3.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.58 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5961.34 toks/s, output: 885.52 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.42it/s, est. speed input: 6175.54 toks/s, output: 1088.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  6.24it/s, est. speed input: 2450.33 toks/s, output: 577.72 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:12<02:42,  3.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.78 toks/s, output: 42.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.63it/s, est. speed input: 5922.09 toks/s, output: 885.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.00it/s, est. speed input: 6323.98 toks/s, output: 1143.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.59it/s, est. speed input: 2196.64 toks/s, output: 520.60 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:19<03:07,  4.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.02 toks/s, output: 42.09 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6240.40 toks/s, output: 926.00 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.83it/s, est. speed input: 6351.23 toks/s, output: 1112.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6556.30 toks/s, output: 1193.61 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:21<02:37,  4.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.42 toks/s, output: 41.87 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.79it/s, est. speed input: 6572.73 toks/s, output: 976.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7733.51 toks/s, output: 1297.73 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:24<02:14,  3.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.64 toks/s, output: 42.04 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.69it/s, est. speed input: 5359.43 toks/s, output: 802.23 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.99it/s, est. speed input: 5349.17 toks/s, output: 1015.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.14it/s, est. speed input: 5161.64 toks/s, output: 1100.72 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:27<02:05,  3.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.34 toks/s, output: 41.52 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.48it/s, est. speed input: 7034.51 toks/s, output: 1041.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.83it/s, est. speed input: 6607.46 toks/s, output: 1100.18 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:29<01:52,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.33 toks/s, output: 42.14 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 5975.23 toks/s, output: 886.95 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.10it/s, est. speed input: 6583.10 toks/s, output: 1190.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6583.10 toks/s, output: 1190.67 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:32<01:43,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.16 toks/s, output: 42.11 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6235.24 toks/s, output: 919.91 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.55it/s, est. speed input: 6529.59 toks/s, output: 1163.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6529.59 toks/s, output: 1163.83 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:34<01:35,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.67 toks/s, output: 42.05 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.11it/s, est. speed input: 6087.96 toks/s, output: 911.05 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.61it/s, est. speed input: 6467.63 toks/s, output: 1143.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.41it/s, est. speed input: 5664.80 toks/s, output: 1062.79 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:37<01:33,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.95 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.21it/s, est. speed input: 6396.41 toks/s, output: 951.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.43it/s, est. speed input: 5693.37 toks/s, output: 1020.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.49it/s, est. speed input: 5693.37 toks/s, output: 1020.05 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:40<01:31,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.79 toks/s, output: 42.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 6752.50 toks/s, output: 998.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7763.42 toks/s, output: 1289.77 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:42<01:22,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.10 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6222.44 toks/s, output: 922.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7724.57 toks/s, output: 1343.69 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:44<01:16,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.01 toks/s, output: 42.09 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7017.24 toks/s, output: 1039.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 7804.70 toks/s, output: 1264.83 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:47<01:10,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.40 toks/s, output: 42.01 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.10it/s, est. speed input: 6086.42 toks/s, output: 913.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.10it/s, est. speed input: 6787.34 toks/s, output: 1218.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.26it/s, est. speed input: 6787.34 toks/s, output: 1218.26 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:49<01:08,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.85 toks/s, output: 42.07 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.66it/s, est. speed input: 4437.92 toks/s, output: 667.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.43it/s, est. speed input: 6301.40 toks/s, output: 1279.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.30it/s, est. speed input: 5616.63 toks/s, output: 1196.69 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:52<01:09,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.97 toks/s, output: 41.95 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6480.25 toks/s, output: 966.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7735.21 toks/s, output: 1323.74 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:54<01:04,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.10 toks/s, output: 41.97 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 5695.22 toks/s, output: 846.32 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.85it/s, est. speed input: 5969.36 toks/s, output: 1056.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6506.76 toks/s, output: 1284.46 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:57<01:02,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.90 toks/s, output: 41.44 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6476.37 toks/s, output: 958.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.72it/s, est. speed input: 5045.54 toks/s, output: 936.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.85it/s, est. speed input: 5045.54 toks/s, output: 936.06 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:00<01:04,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.13 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6733.19 toks/s, output: 996.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.81it/s, est. speed input: 4632.97 toks/s, output: 837.22 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:03<01:07,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.84 toks/s, output: 42.21 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.93it/s, est. speed input: 5984.50 toks/s, output: 886.25 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.19it/s, est. speed input: 6136.41 toks/s, output: 1076.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.85it/s, est. speed input: 4647.08 toks/s, output: 944.52 toks/s] 
Processing batched inference:  67%|██████▋   | 44/66 [02:07<01:06,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.32 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6739.70 toks/s, output: 995.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6538.90 toks/s, output: 1113.58 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:09<01:00,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.40 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5958.82 toks/s, output: 884.61 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.27it/s, est. speed input: 5907.65 toks/s, output: 1017.75 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:19<00:00, 18.27it/s, est. speed input: 6111.75 toks/s, output: 1098.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.45s/it, est. speed input: 468.48 toks/s, output: 239.25 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.61 toks/s, output: 396.99 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:36<03:20, 10.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.53 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6221.38 toks/s, output: 928.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7720.30 toks/s, output: 1352.61 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:38<02:25,  7.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.82 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6733.48 toks/s, output: 995.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5655.29 toks/s, output: 989.28 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:41<01:51,  6.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.05 toks/s, output: 41.96 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5697.96 toks/s, output: 845.47 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.93it/s, est. speed input: 6400.47 toks/s, output: 1147.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.52it/s, est. speed input: 5697.28 toks/s, output: 1119.12 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:44<01:28,  5.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.62 toks/s, output: 42.04 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 6747.92 toks/s, output: 1000.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.84it/s, est. speed input: 6606.07 toks/s, output: 1119.07 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:46<01:10,  4.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.49 toks/s, output: 42.02 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.22it/s, est. speed input: 5194.89 toks/s, output: 778.56 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.63it/s, est. speed input: 6479.87 toks/s, output: 1234.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.33it/s, est. speed input: 5627.07 toks/s, output: 1129.98 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:49<00:59,  3.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.72 toks/s, output: 41.91 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5696.12 toks/s, output: 848.32 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.18it/s, est. speed input: 6310.15 toks/s, output: 1161.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6513.67 toks/s, output: 1242.32 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:52<00:49,  3.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.57 toks/s, output: 42.42 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6213.19 toks/s, output: 920.70 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.53it/s, est. speed input: 6512.43 toks/s, output: 1162.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6512.43 toks/s, output: 1162.02 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:54<00:41,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6218.95 toks/s, output: 921.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.72it/s, est. speed input: 6555.21 toks/s, output: 1164.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6555.21 toks/s, output: 1164.65 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:57<00:36,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.60 toks/s, output: 42.04 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.87it/s, est. speed input: 5964.30 toks/s, output: 883.80 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.15it/s, est. speed input: 6122.16 toks/s, output: 1079.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  5.07it/s, est. speed input: 1991.51 toks/s, output: 492.32 toks/s] 
Processing batched inference:  83%|████████▎ | 55/66 [03:04<00:46,  4.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.99 toks/s, output: 41.81 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.17it/s, est. speed input: 5176.67 toks/s, output: 776.37 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.71it/s, est. speed input: 6304.47 toks/s, output: 1209.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5611.31 toks/s, output: 1134.48 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:07<00:38,  3.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.14 toks/s, output: 41.97 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5956.17 toks/s, output: 882.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.02it/s, est. speed input: 5025.39 toks/s, output: 950.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.81it/s, est. speed input: 5025.39 toks/s, output: 950.56 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:10<00:33,  3.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.52 toks/s, output: 42.41 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6212.76 toks/s, output: 920.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7710.92 toks/s, output: 1342.04 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:12<00:26,  3.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.53 toks/s, output: 41.89 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.35it/s, est. speed input: 6698.33 toks/s, output: 989.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7730.60 toks/s, output: 1287.19 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:14<00:20,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.88 toks/s, output: 41.94 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.84it/s, est. speed input: 6243.53 toks/s, output: 925.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.77it/s, est. speed input: 6334.89 toks/s, output: 1104.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.86it/s, est. speed input: 5046.07 toks/s, output: 952.06 toks/s] 
Processing batched inference:  91%|█████████ | 60/66 [03:18<00:17,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.75 toks/s, output: 41.78 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.03it/s, est. speed input: 5427.38 toks/s, output: 808.91 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.58it/s, est. speed input: 6330.39 toks/s, output: 1189.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.31it/s, est. speed input: 5623.85 toks/s, output: 1115.10 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:20<00:14,  2.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.30 toks/s, output: 41.86 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.58it/s, est. speed input: 5900.65 toks/s, output: 880.68 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.77it/s, est. speed input: 6499.08 toks/s, output: 1187.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6499.08 toks/s, output: 1187.00 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:23<00:11,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.64 toks/s, output: 41.90 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6728.17 toks/s, output: 997.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.35it/s, est. speed input: 6809.78 toks/s, output: 1157.36 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:26<00:08,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.34 toks/s, output: 41.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6464.34 toks/s, output: 956.33 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.28it/s, est. speed input: 6518.26 toks/s, output: 1138.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6518.26 toks/s, output: 1138.00 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:28<00:05,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.30 toks/s, output: 41.99 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5962.27 toks/s, output: 886.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.56it/s, est. speed input: 5634.72 toks/s, output: 1044.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.35it/s, est. speed input: 5634.72 toks/s, output: 1044.02 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:31<00:02,  2.72s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 336.07 toks/s, output: 46.53 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 22.67it/s, est. speed input: 6825.10 toks/s, output: 1013.36 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.84it/s, est. speed input: 7398.31 toks/s, output: 1195.02 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:33<00:00,  2.55s/it]Processing batched inference: 100%|██████████| 66/66 [03:33<00:00,  3.23s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-1071/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 09:57:37.802015016 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1134
INFO 07-05 09:57:50 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 09:57:52,760 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 09:57:52,801 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:52,826 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:52,826 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:52,826 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:52,826 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:52,826 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:52,826 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:52,826 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:57:53,227 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:57:53,229 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 09:57:53,235 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:57:53,242 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:53,243 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:53,243 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:53,243 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:53,243 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:53,243 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:53,243 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:53,243 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:57:53,619 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:57:53,622 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:57:53,839 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:57:54,284 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 09:57:54,344 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/config.json
[INFO|configuration_utils.py:696] 2025-07-05 09:57:54,345 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/config.json
[INFO|configuration_utils.py:770] 2025-07-05 09:57:54,347 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 09:58:06 [config.py:689] This model supports multiple tasks: {'classify', 'generate', 'score', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 07-05 09:58:06 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:06,079 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:06,080 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:06,080 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:06,080 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:06,080 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:06,080 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:06,080 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:58:06,416 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 09:58:06,517 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 09:58:06,520 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 09:58:07 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 09:58:08 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 09:58:08 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134...
WARNING 07-05 09:58:08 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 09:58:08 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.17s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.17s/it]

INFO 07-05 09:58:15 [loader.py:458] Loading weights took 7.38 seconds
INFO 07-05 09:58:16 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.624176 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,416 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,416 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,416 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,416 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,416 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,416 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,416 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:58:16,852 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:58:16,949 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:58:16,949 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 09:58:16,950 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:58:16,951 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,951 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,951 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,951 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,951 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,951 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,951 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:16,951 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:58:17,718 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:58:17,718 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:58:17,719 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:58:18,176 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 09:58:18,856 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 09:58:19 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 09:58:21,666 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 09:58:22,691 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 09:58:22 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 09:59:01 [worker.py:267] Memory profiling takes 45.11 seconds
INFO 07-05 09:59:01 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 09:59:01 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 09:59:01 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 09:59:01 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 09:59:06 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:18,  1.84it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:16,  1.95it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.98it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  2.00it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.97it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.98it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  2.00it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  2.00it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  2.00it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  2.01it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  2.01it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:10,  2.00it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  2.00it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  2.00it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  2.01it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.01it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.98it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.98it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  2.00it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.98it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.98it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.99it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.98it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.98it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.99it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.00it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.01it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:00,  2.01it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  2.01it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.00it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.99it/s]
INFO 07-05 09:59:24 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 09:59:24 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.15 seconds
[INFO|2025-07-05 09:59:24] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:10, 183.61 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 522.08 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:01, 986.97 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:01<00:01, 955.92 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:01<00:00, 1287.54 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:01<00:00, 1317.86 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:01<00:00, 1396.07 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 965.22 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 09:59:29,114 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:59:29,114 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:59:29,115 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:59:29,115 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:59:29,115 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:59:29,115 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:59:29,115 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:59:29,115 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:59:29,115 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:59:29,891 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:59:29,891 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:59:29,892 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:59:30,349 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1134', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.66s/it, est. speed input: 234.46 toks/s, output: 32.46 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 16.19it/s, est. speed input: 4807.70 toks/s, output: 720.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.88it/s, est. speed input: 6242.45 toks/s, output: 1114.45 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:34,  4.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.53 toks/s, output: 42.30 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6471.55 toks/s, output: 958.39 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.75it/s, est. speed input: 6390.17 toks/s, output: 1098.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6574.21 toks/s, output: 1175.99 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:35,  3.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.62 toks/s, output: 42.32 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.33it/s, est. speed input: 5227.06 toks/s, output: 781.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.20it/s, est. speed input: 5656.56 toks/s, output: 1123.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.39it/s, est. speed input: 5656.56 toks/s, output: 1123.30 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:22,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.73 toks/s, output: 42.33 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.75it/s, est. speed input: 6522.97 toks/s, output: 966.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7780.08 toks/s, output: 1320.42 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:59,  2.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.15 toks/s, output: 42.25 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.84it/s, est. speed input: 6256.40 toks/s, output: 930.01 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.92it/s, est. speed input: 6144.45 toks/s, output: 1085.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.36it/s, est. speed input: 5245.12 toks/s, output: 1052.78 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:15<03:03,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.42 toks/s, output: 42.15 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 6750.14 toks/s, output: 995.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.01it/s, est. speed input: 6673.27 toks/s, output: 1132.23 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:18<02:53,  2.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.18 toks/s, output: 42.26 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.40it/s, est. speed input: 6723.87 toks/s, output: 994.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7790.22 toks/s, output: 1302.81 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:20<02:41,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.98 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.76it/s, est. speed input: 6524.39 toks/s, output: 972.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7754.75 toks/s, output: 1321.55 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:23<02:32,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.65 toks/s, output: 42.18 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.46it/s, est. speed input: 7021.64 toks/s, output: 1037.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7781.00 toks/s, output: 1260.57 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:25<02:24,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 307.59 toks/s, output: 42.26 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.63it/s, est. speed input: 6779.62 toks/s, output: 1001.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.84it/s, est. speed input: 6613.35 toks/s, output: 1124.24 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:28<02:24,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.31 toks/s, output: 42.13 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6492.42 toks/s, output: 957.23 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.07it/s, est. speed input: 5850.39 toks/s, output: 1060.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.91it/s, est. speed input: 5850.39 toks/s, output: 1060.73 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:31<02:28,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.94 toks/s, output: 42.08 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.20it/s, est. speed input: 6964.29 toks/s, output: 1034.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7780.69 toks/s, output: 1274.29 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:33<02:20,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.18 toks/s, output: 42.12 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.32it/s, est. speed input: 6706.55 toks/s, output: 996.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7769.03 toks/s, output: 1302.66 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:35<02:14,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.67 toks/s, output: 42.18 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.60it/s, est. speed input: 6762.65 toks/s, output: 997.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6556.69 toks/s, output: 1114.19 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:38<02:13,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.98 toks/s, output: 42.09 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6237.71 toks/s, output: 926.24 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.10it/s, est. speed input: 6595.00 toks/s, output: 1149.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6546.94 toks/s, output: 1186.79 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:41<02:11,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.14 toks/s, output: 42.11 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6503.80 toks/s, output: 970.75 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 6549.20 toks/s, output: 1145.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6549.20 toks/s, output: 1145.44 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:43<02:10,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.56 toks/s, output: 42.56 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.90it/s, est. speed input: 5970.06 toks/s, output: 889.42 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.15it/s, est. speed input: 6081.79 toks/s, output: 1052.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.51it/s, est. speed input: 3734.94 toks/s, output: 821.83 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [00:47<02:29,  3.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.35 toks/s, output: 42.28 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.47it/s, est. speed input: 7316.13 toks/s, output: 1082.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 7830.23 toks/s, output: 1245.30 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:50<02:16,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.15 toks/s, output: 42.11 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6240.32 toks/s, output: 928.70 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.10it/s, est. speed input: 6408.85 toks/s, output: 1125.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6551.84 toks/s, output: 1196.31 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:52<02:10,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.94 toks/s, output: 42.47 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6428.96 toks/s, output: 959.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 7675.80 toks/s, output: 1317.85 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:55<02:01,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.18 toks/s, output: 42.12 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.56it/s, est. speed input: 6760.52 toks/s, output: 1003.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7770.60 toks/s, output: 1294.58 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:57<01:54,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.37 toks/s, output: 42.01 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.33it/s, est. speed input: 5214.39 toks/s, output: 775.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.75it/s, est. speed input: 6091.12 toks/s, output: 1149.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.64it/s, est. speed input: 4965.14 toks/s, output: 1059.41 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:00<02:01,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.26s/it, est. speed input: 309.35 toks/s, output: 40.45 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.65it/s, est. speed input: 6230.14 toks/s, output: 920.50 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.78it/s, est. speed input: 6589.66 toks/s, output: 1170.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.79it/s, est. speed input: 6589.66 toks/s, output: 1170.06 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:03<01:56,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.71 toks/s, output: 41.44 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6221.19 toks/s, output: 921.34 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.70it/s, est. speed input: 6517.19 toks/s, output: 1136.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.39it/s, est. speed input: 4077.00 toks/s, output: 800.79 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:07<02:06,  3.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.62 toks/s, output: 42.04 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6225.66 toks/s, output: 923.91 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.18it/s, est. speed input: 6182.22 toks/s, output: 1064.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.96it/s, est. speed input: 1555.01 toks/s, output: 414.03 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:15<03:15,  4.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.98 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.30it/s, est. speed input: 6126.08 toks/s, output: 915.07 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.88it/s, est. speed input: 6338.11 toks/s, output: 1122.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s, est. speed input: 2764.90 toks/s, output: 602.96 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:21<03:15,  4.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.27 toks/s, output: 42.13 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6489.09 toks/s, output: 961.08 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 6545.47 toks/s, output: 1194.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6545.47 toks/s, output: 1194.25 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:23<02:43,  4.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.84 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.81it/s, est. speed input: 6580.00 toks/s, output: 977.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.24it/s, est. speed input: 6531.51 toks/s, output: 1121.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6531.51 toks/s, output: 1121.49 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:26<02:21,  3.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.42 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.44it/s, est. speed input: 5871.28 toks/s, output: 874.89 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.24it/s, est. speed input: 6120.15 toks/s, output: 1085.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.37it/s, est. speed input: 4075.30 toks/s, output: 840.21 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [01:29<02:17,  3.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.92 toks/s, output: 41.47 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.48it/s, est. speed input: 7032.63 toks/s, output: 1041.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.84it/s, est. speed input: 6613.72 toks/s, output: 1101.23 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:32<02:00,  3.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.86 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6232.11 toks/s, output: 922.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7792.04 toks/s, output: 1351.62 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:34<01:45,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.14 toks/s, output: 42.11 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6491.30 toks/s, output: 956.52 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.33it/s, est. speed input: 6537.58 toks/s, output: 1140.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6537.58 toks/s, output: 1140.79 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:37<01:37,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.80 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.07it/s, est. speed input: 6075.31 toks/s, output: 909.16 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.67it/s, est. speed input: 6242.15 toks/s, output: 1084.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6534.26 toks/s, output: 1225.92 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:39<01:31,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.15 toks/s, output: 41.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.16it/s, est. speed input: 6381.35 toks/s, output: 949.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.39it/s, est. speed input: 5680.95 toks/s, output: 1018.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.46it/s, est. speed input: 5680.95 toks/s, output: 1018.27 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:42<01:30,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.82 toks/s, output: 42.07 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.38it/s, est. speed input: 7282.58 toks/s, output: 1074.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6572.67 toks/s, output: 1068.91 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:45<01:24,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.21 toks/s, output: 41.43 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.64it/s, est. speed input: 5895.76 toks/s, output: 876.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 7623.61 toks/s, output: 1354.05 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:47<01:18,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.21 toks/s, output: 42.12 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7007.06 toks/s, output: 1037.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7792.48 toks/s, output: 1262.85 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:49<01:12,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.92 toks/s, output: 41.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.48it/s, est. speed input: 6455.07 toks/s, output: 964.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7733.32 toks/s, output: 1330.89 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:52<01:08,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.85 toks/s, output: 42.07 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.67it/s, est. speed input: 4438.85 toks/s, output: 667.14 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.53it/s, est. speed input: 6320.68 toks/s, output: 1283.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.29it/s, est. speed input: 5614.44 toks/s, output: 1196.23 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:54<01:09,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7006.66 toks/s, output: 1042.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7767.32 toks/s, output: 1269.32 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:57<01:03,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.81 toks/s, output: 42.07 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.98it/s, est. speed input: 5708.21 toks/s, output: 848.79 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.82it/s, est. speed input: 6201.33 toks/s, output: 1115.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6511.13 toks/s, output: 1258.37 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:59<01:02,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.74 toks/s, output: 41.55 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6232.11 toks/s, output: 922.07 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.09it/s, est. speed input: 6404.26 toks/s, output: 1120.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6568.62 toks/s, output: 1194.57 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:02<01:00,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.08 toks/s, output: 42.10 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.38it/s, est. speed input: 7286.56 toks/s, output: 1076.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.98it/s, est. speed input: 5876.15 toks/s, output: 973.89 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [02:05<00:59,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.92 toks/s, output: 42.08 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5969.44 toks/s, output: 884.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.42it/s, est. speed input: 5826.88 toks/s, output: 1074.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.85it/s, est. speed input: 5826.88 toks/s, output: 1074.28 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:07<00:58,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.98 toks/s, output: 41.95 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6732.67 toks/s, output: 995.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7739.25 toks/s, output: 1286.58 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:09<00:52,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.95 toks/s, output: 42.08 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.87it/s, est. speed input: 5968.68 toks/s, output: 884.99 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.30it/s, est. speed input: 5304.87 toks/s, output: 954.52 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 15.30it/s, est. speed input: 2889.94 toks/s, output: 630.77 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.40s/it, est. speed input: 480.97 toks/s, output: 258.58 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.97 toks/s, output: 258.58 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:36<03:16,  9.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.96 toks/s, output: 41.98 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6482.19 toks/s, output: 966.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7734.20 toks/s, output: 1324.91 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:39<02:22,  7.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.38 toks/s, output: 42.01 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6481.95 toks/s, output: 959.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7736.99 toks/s, output: 1322.64 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:41<01:46,  5.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.32 toks/s, output: 42.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.17it/s, est. speed input: 5747.82 toks/s, output: 852.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 7690.22 toks/s, output: 1393.65 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:43<01:21,  4.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.78 toks/s, output: 42.06 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.26it/s, est. speed input: 7543.98 toks/s, output: 1113.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.18it/s, est. speed input: 7918.49 toks/s, output: 1223.46 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:45<01:04,  4.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.31 toks/s, output: 42.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 5700.20 toks/s, output: 850.29 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.50it/s, est. speed input: 6370.50 toks/s, output: 1165.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6510.99 toks/s, output: 1234.92 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:48<00:53,  3.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.67 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.81it/s, est. speed input: 5954.18 toks/s, output: 887.68 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.69it/s, est. speed input: 6502.27 toks/s, output: 1189.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6502.27 toks/s, output: 1189.98 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:50<00:45,  3.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.76 toks/s, output: 42.59 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.82it/s, est. speed input: 6234.84 toks/s, output: 923.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7737.36 toks/s, output: 1350.41 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:53<00:39,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.00 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6492.21 toks/s, output: 962.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7748.55 toks/s, output: 1316.82 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:55<00:33,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.26 toks/s, output: 41.99 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 6740.07 toks/s, output: 995.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.10it/s, est. speed input: 3180.37 toks/s, output: 665.19 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:00<00:36,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.02 toks/s, output: 41.96 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.08it/s, est. speed input: 5446.65 toks/s, output: 815.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.52it/s, est. speed input: 6325.87 toks/s, output: 1188.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6509.01 toks/s, output: 1265.76 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:02<00:31,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.74 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6485.40 toks/s, output: 958.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7739.58 toks/s, output: 1316.02 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:04<00:25,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.05 toks/s, output: 42.49 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6222.79 toks/s, output: 922.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7724.45 toks/s, output: 1343.16 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:07<00:21,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.47 toks/s, output: 41.33 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.04it/s, est. speed input: 7175.65 toks/s, output: 1059.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 7680.84 toks/s, output: 1217.74 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:09<00:17,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.91 toks/s, output: 42.08 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.88it/s, est. speed input: 6257.04 toks/s, output: 927.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.09it/s, est. speed input: 6404.08 toks/s, output: 1114.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6547.52 toks/s, output: 1185.28 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:11<00:15,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.70 toks/s, output: 41.91 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5693.90 toks/s, output: 848.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.10it/s, est. speed input: 6527.47 toks/s, output: 1218.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6527.47 toks/s, output: 1218.99 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:14<00:12,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.17 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.63it/s, est. speed input: 5916.19 toks/s, output: 883.00 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.79it/s, est. speed input: 6510.67 toks/s, output: 1189.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6510.67 toks/s, output: 1189.12 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:17<00:10,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.99 toks/s, output: 42.09 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7010.93 toks/s, output: 1039.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6565.51 toks/s, output: 1116.37 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:19<00:07,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.64 toks/s, output: 42.04 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.08it/s, est. speed input: 6642.14 toks/s, output: 982.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7756.31 toks/s, output: 1296.11 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:21<00:04,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.32 toks/s, output: 42.14 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.90it/s, est. speed input: 5979.78 toks/s, output: 889.25 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.78it/s, est. speed input: 6524.39 toks/s, output: 1183.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6524.39 toks/s, output: 1183.41 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:24<00:02,  2.46s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 337.48 toks/s, output: 46.73 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 22.72it/s, est. speed input: 6842.99 toks/s, output: 1016.01 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.89it/s, est. speed input: 7416.39 toks/s, output: 1197.94 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:26<00:00,  2.35s/it]Processing batched inference: 100%|██████████| 66/66 [03:26<00:00,  3.13s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-1134/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:02:56.471770419 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1197
INFO 07-05 10:03:09 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:03:11,200 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:03:11,245 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,268 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,269 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,269 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,269 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,269 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,269 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,269 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:03:11,656 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:03:11,658 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:03:11,663 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:03:11,670 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,671 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,671 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,671 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,671 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,671 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,671 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:11,671 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:03:12,042 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:03:12,044 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:03:12,240 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:03:12,691 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:03:12,739 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:03:12,740 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:03:12,742 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:03:24 [config.py:689] This model supports multiple tasks: {'embed', 'classify', 'generate', 'reward', 'score'}. Defaulting to 'generate'.
INFO 07-05 10:03:24 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:24,370 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:24,370 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:24,370 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:24,370 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:24,370 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:24,370 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:24,370 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:03:24,703 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:03:24,806 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:03:24,809 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:03:26 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:03:26 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:03:26 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197...
WARNING 07-05 10:03:26 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:03:26 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.30s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.30s/it]

INFO 07-05 10:03:34 [loader.py:458] Loading weights took 7.51 seconds
INFO 07-05 10:03:34 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.743018 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:34,848 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:34,848 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:34,848 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:34,848 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:34,848 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:34,848 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:34,848 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:03:35,266 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:03:35,362 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:03:35,362 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:03:35,362 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:03:35,363 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:35,363 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:35,363 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:35,363 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:35,363 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:35,363 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:35,363 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:35,363 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:03:36,121 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:03:36,122 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:03:36,122 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:03:36,583 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:03:37,302 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:03:37 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:03:40,136 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:03:41,112 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:03:41 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:04:19 [worker.py:267] Memory profiling takes 45.13 seconds
INFO 07-05 10:04:19 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:04:19 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:04:20 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:04:20 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:04:25 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:18,  1.89it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:16,  1.97it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.99it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.97it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.98it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.99it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.98it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.98it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.99it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  2.00it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.98it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.99it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.01it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  2.01it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:06,  2.01it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.98it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.98it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  2.00it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  2.01it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.01it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.98it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  2.00it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  2.01it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.01it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.00it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:00,  2.01it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  2.01it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.00it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.99it/s]
INFO 07-05 10:04:43 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:04:43 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.60 seconds
[INFO|2025-07-05 10:04:43] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:10, 192.16 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 547.23 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:01, 822.93 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:01, 900.49 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:01<00:01, 962.54 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:01<00:00, 1351.73 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:01<00:00, 1521.94 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:01<00:00, 1438.10 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:01<00:00, 1425.66 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 971.85 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:04:48,004 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:04:48,004 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:04:48,005 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:04:48,005 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:04:48,005 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:04:48,005 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:04:48,005 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:04:48,005 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:04:48,006 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:04:48,786 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:04:48,787 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:04:48,787 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:04:49,239 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1197', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.63s/it, est. speed input: 239.65 toks/s, output: 33.18 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.94it/s, est. speed input: 5322.20 toks/s, output: 796.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.23it/s, est. speed input: 6379.20 toks/s, output: 1089.15 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:30,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.04 toks/s, output: 42.24 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.64it/s, est. speed input: 6207.69 toks/s, output: 920.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.00it/s, est. speed input: 6383.24 toks/s, output: 1123.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6567.30 toks/s, output: 1200.89 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:39,  3.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.63 toks/s, output: 42.32 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.20it/s, est. speed input: 5484.23 toks/s, output: 819.01 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.49it/s, est. speed input: 5517.09 toks/s, output: 1061.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.54it/s, est. speed input: 2963.09 toks/s, output: 678.68 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:12<04:22,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.94 toks/s, output: 42.08 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 6754.21 toks/s, output: 1000.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.18it/s, est. speed input: 6742.82 toks/s, output: 1142.23 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:14<03:40,  3.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.86 toks/s, output: 42.21 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.93it/s, est. speed input: 5988.49 toks/s, output: 890.54 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.31it/s, est. speed input: 5930.28 toks/s, output: 1028.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.44it/s, est. speed input: 5671.59 toks/s, output: 1139.73 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:17<03:28,  3.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.50 toks/s, output: 42.02 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 6724.16 toks/s, output: 991.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.92it/s, est. speed input: 6639.96 toks/s, output: 1126.57 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:20<03:15,  3.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.00 toks/s, output: 41.82 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.19it/s, est. speed input: 6660.44 toks/s, output: 985.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7716.63 toks/s, output: 1290.50 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:23<02:58,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.76 toks/s, output: 41.92 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.98it/s, est. speed input: 5714.47 toks/s, output: 856.43 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.83it/s, est. speed input: 6666.95 toks/s, output: 1234.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.97it/s, est. speed input: 6666.95 toks/s, output: 1234.82 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:26<02:51,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.85 toks/s, output: 42.07 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7007.24 toks/s, output: 1035.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7765.34 toks/s, output: 1258.03 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:28<02:37,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.26 toks/s, output: 42.08 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 6752.36 toks/s, output: 997.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.76it/s, est. speed input: 6582.68 toks/s, output: 1119.01 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:31<02:34,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.47 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6475.46 toks/s, output: 954.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.09it/s, est. speed input: 5849.19 toks/s, output: 1083.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.91it/s, est. speed input: 5849.19 toks/s, output: 1083.35 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:34<02:35,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.90 toks/s, output: 41.80 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.06it/s, est. speed input: 6922.54 toks/s, output: 1028.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7734.46 toks/s, output: 1266.72 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:36<02:26,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.88 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6439.09 toks/s, output: 957.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7744.95 toks/s, output: 1328.81 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:39<02:18,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.03 toks/s, output: 42.10 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.78it/s, est. speed input: 6516.94 toks/s, output: 962.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 6537.47 toks/s, output: 1133.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6537.47 toks/s, output: 1133.84 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:41<02:16,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.34 toks/s, output: 41.86 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6205.02 toks/s, output: 919.77 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.05it/s, est. speed input: 6380.84 toks/s, output: 1115.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.38it/s, est. speed input: 5643.41 toks/s, output: 1047.71 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:44<02:20,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.21 toks/s, output: 41.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6224.68 toks/s, output: 930.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.50it/s, est. speed input: 6520.50 toks/s, output: 1165.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6520.50 toks/s, output: 1165.83 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:47<02:16,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.43 toks/s, output: 42.54 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6230.46 toks/s, output: 926.15 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.08it/s, est. speed input: 6393.99 toks/s, output: 1171.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.84it/s, est. speed input: 5042.36 toks/s, output: 994.74 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [00:50<02:20,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.74 toks/s, output: 42.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6733.93 toks/s, output: 998.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7740.93 toks/s, output: 1289.63 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:53<02:11,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.30 toks/s, output: 41.86 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.91it/s, est. speed input: 5686.44 toks/s, output: 846.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.47it/s, est. speed input: 6359.47 toks/s, output: 1168.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6501.92 toks/s, output: 1238.40 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:55<02:08,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.75 toks/s, output: 42.45 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6475.77 toks/s, output: 964.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 7669.68 toks/s, output: 1315.58 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:58<01:59,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.94 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 6733.99 toks/s, output: 999.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7741.24 toks/s, output: 1289.69 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:00<01:53,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.32 toks/s, output: 42.00 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.36it/s, est. speed input: 4933.71 toks/s, output: 735.27 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 18.17it/s, est. speed input: 5648.43 toks/s, output: 1061.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.98it/s, est. speed input: 5607.87 toks/s, output: 1259.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5607.87 toks/s, output: 1259.48 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:03<01:56,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.16 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 5957.09 toks/s, output: 884.35 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.51it/s, est. speed input: 6421.11 toks/s, output: 1146.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6585.76 toks/s, output: 1219.71 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:05<01:52,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.80 toks/s, output: 41.45 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 5954.82 toks/s, output: 883.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.90it/s, est. speed input: 6500.97 toks/s, output: 1158.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.88it/s, est. speed input: 2308.43 toks/s, output: 532.63 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:12<02:35,  3.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.95 toks/s, output: 41.95 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.81it/s, est. speed input: 5951.22 toks/s, output: 884.02 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.10it/s, est. speed input: 6108.91 toks/s, output: 1077.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.86it/s, est. speed input: 1908.85 toks/s, output: 486.06 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:19<03:15,  4.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.62 toks/s, output: 41.62 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.14it/s, est. speed input: 6078.55 toks/s, output: 907.97 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.73it/s, est. speed input: 6289.38 toks/s, output: 1113.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.43it/s, est. speed input: 4491.61 toks/s, output: 876.68 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:22<02:55,  4.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.19 toks/s, output: 42.12 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6494.72 toks/s, output: 961.91 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.42it/s, est. speed input: 6557.85 toks/s, output: 1196.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6557.85 toks/s, output: 1196.51 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:25<02:29,  3.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.78 toks/s, output: 41.78 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.75it/s, est. speed input: 6560.46 toks/s, output: 974.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 7713.60 toks/s, output: 1294.39 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:27<02:07,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.59 toks/s, output: 41.48 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.51it/s, est. speed input: 5299.36 toks/s, output: 792.63 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.61it/s, est. speed input: 5829.57 toks/s, output: 1066.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.48it/s, est. speed input: 2939.41 toks/s, output: 705.16 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [01:32<02:22,  3.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.90 toks/s, output: 41.46 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.40it/s, est. speed input: 7301.65 toks/s, output: 1080.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.88it/s, est. speed input: 6628.01 toks/s, output: 1078.28 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:35<02:03,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.90 toks/s, output: 42.08 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6232.59 toks/s, output: 920.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7789.58 toks/s, output: 1352.44 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:37<01:47,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.03 toks/s, output: 42.10 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6231.77 toks/s, output: 919.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7735.04 toks/s, output: 1348.51 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:39<01:35,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.92 toks/s, output: 41.94 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.06it/s, est. speed input: 6073.24 toks/s, output: 908.84 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.68it/s, est. speed input: 6244.33 toks/s, output: 1084.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6536.73 toks/s, output: 1226.38 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:42<01:30,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.36 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.04it/s, est. speed input: 6641.57 toks/s, output: 988.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.21it/s, est. speed input: 5689.52 toks/s, output: 997.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.48it/s, est. speed input: 5689.52 toks/s, output: 997.64 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:45<01:29,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.29 toks/s, output: 41.99 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.36it/s, est. speed input: 7273.92 toks/s, output: 1072.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.73it/s, est. speed input: 6565.06 toks/s, output: 1067.68 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:47<01:24,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.21 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5955.35 toks/s, output: 885.07 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.72it/s, est. speed input: 6503.02 toks/s, output: 1180.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6503.02 toks/s, output: 1180.38 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:50<01:19,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.47 toks/s, output: 42.02 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.39it/s, est. speed input: 7000.76 toks/s, output: 1036.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7786.79 toks/s, output: 1261.92 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:52<01:13,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.39 toks/s, output: 41.87 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.58it/s, est. speed input: 6189.16 toks/s, output: 925.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 7709.94 toks/s, output: 1356.89 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:54<01:08,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.92 toks/s, output: 41.94 toks/s][A
Processed prompts:  53%|█████▎    | 17/32 [00:01<00:01, 13.77it/s, est. speed input: 4175.43 toks/s, output: 630.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.69it/s, est. speed input: 6294.56 toks/s, output: 1301.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.24it/s, est. speed input: 5594.67 toks/s, output: 1212.04 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:57<01:10,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.77 toks/s, output: 41.78 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.30it/s, est. speed input: 6979.64 toks/s, output: 1038.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7739.14 toks/s, output: 1264.72 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:59<01:04,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.76 toks/s, output: 41.92 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 5687.94 toks/s, output: 845.24 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.17it/s, est. speed input: 6302.75 toks/s, output: 1155.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.67it/s, est. speed input: 4975.72 toks/s, output: 983.81 toks/s] 
Processing batched inference:  62%|██████▏   | 41/66 [02:03<01:07,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.05 toks/s, output: 41.46 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6219.31 toks/s, output: 920.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.81it/s, est. speed input: 6579.73 toks/s, output: 1169.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.76it/s, est. speed input: 6579.73 toks/s, output: 1169.35 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:05<01:03,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.10 toks/s, output: 41.97 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.39it/s, est. speed input: 6997.31 toks/s, output: 1034.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.92it/s, est. speed input: 5853.04 toks/s, output: 992.90 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [02:08<01:02,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.73 toks/s, output: 42.05 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6229.70 toks/s, output: 922.34 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.67it/s, est. speed input: 5683.24 toks/s, output: 1009.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.62it/s, est. speed input: 5734.71 toks/s, output: 1078.76 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:11<01:00,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.99 toks/s, output: 41.95 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 6731.00 toks/s, output: 994.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6532.86 toks/s, output: 1112.03 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:13<00:55,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.44 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5959.60 toks/s, output: 883.65 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.13it/s, est. speed input: 6115.68 toks/s, output: 1074.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 19.13it/s, est. speed input: 2545.63 toks/s, output: 565.46 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.40s/it, est. speed input: 481.01 toks/s, output: 260.41 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.01 toks/s, output: 260.41 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:40<03:18,  9.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.37 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6471.94 toks/s, output: 965.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7722.67 toks/s, output: 1322.93 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:42<02:24,  7.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.61 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6469.11 toks/s, output: 957.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.24it/s, est. speed input: 5658.08 toks/s, output: 1033.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5658.08 toks/s, output: 1033.44 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:45<01:51,  6.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.82 toks/s, output: 41.93 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.03it/s, est. speed input: 6000.51 toks/s, output: 888.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7694.07 toks/s, output: 1365.55 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:47<01:24,  4.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.30 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.13it/s, est. speed input: 7793.17 toks/s, output: 1148.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.18it/s, est. speed input: 7918.96 toks/s, output: 1195.15 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:50<01:06,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.96 toks/s, output: 41.95 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.19it/s, est. speed input: 5186.22 toks/s, output: 777.26 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.70it/s, est. speed input: 6257.40 toks/s, output: 1175.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6486.71 toks/s, output: 1302.08 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:52<00:55,  3.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.44 toks/s, output: 41.88 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.79it/s, est. speed input: 5947.25 toks/s, output: 884.76 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.68it/s, est. speed input: 6496.07 toks/s, output: 1188.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6496.07 toks/s, output: 1188.84 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:55<00:46,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.22 toks/s, output: 42.51 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6224.06 toks/s, output: 922.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7724.33 toks/s, output: 1348.14 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:57<00:38,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.37 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6476.34 toks/s, output: 959.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7727.40 toks/s, output: 1313.84 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:59<00:33,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.42 toks/s, output: 41.87 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6722.77 toks/s, output: 993.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.59it/s, est. speed input: 2194.75 toks/s, output: 500.81 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:06<00:42,  3.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.06 toks/s, output: 41.96 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5700.36 toks/s, output: 853.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.28it/s, est. speed input: 6331.12 toks/s, output: 1163.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.35it/s, est. speed input: 5638.32 toks/s, output: 1096.00 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:08<00:35,  3.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.46 toks/s, output: 42.02 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6224.87 toks/s, output: 921.09 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.86it/s, est. speed input: 6583.93 toks/s, output: 1169.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6583.93 toks/s, output: 1169.85 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:11<00:29,  3.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.46 toks/s, output: 42.55 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6227.58 toks/s, output: 922.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7729.89 toks/s, output: 1345.34 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:13<00:23,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.47 toks/s, output: 42.02 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.18it/s, est. speed input: 6950.68 toks/s, output: 1027.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.24it/s, est. speed input: 6766.32 toks/s, output: 1124.48 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:16<00:19,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.13 toks/s, output: 42.11 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.89it/s, est. speed input: 6261.99 toks/s, output: 928.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.80it/s, est. speed input: 6348.47 toks/s, output: 1106.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.60it/s, est. speed input: 5728.31 toks/s, output: 1058.88 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:18<00:16,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.09it/s, est. speed input: 5447.04 toks/s, output: 811.84 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.35it/s, est. speed input: 6529.03 toks/s, output: 1244.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6529.03 toks/s, output: 1244.73 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:21<00:13,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.72 toks/s, output: 42.05 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.64it/s, est. speed input: 5921.82 toks/s, output: 883.84 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.80it/s, est. speed input: 6515.98 toks/s, output: 1190.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6515.98 toks/s, output: 1190.09 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:24<00:10,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.89 toks/s, output: 41.94 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.32it/s, est. speed input: 6982.27 toks/s, output: 1034.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6549.08 toks/s, output: 1113.58 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:26<00:07,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.14 toks/s, output: 42.11 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.86it/s, est. speed input: 6536.28 toks/s, output: 965.69 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.21it/s, est. speed input: 6527.39 toks/s, output: 1138.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6527.39 toks/s, output: 1138.56 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:29<00:05,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.36 toks/s, output: 42.14 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 5977.29 toks/s, output: 888.88 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.78it/s, est. speed input: 6522.42 toks/s, output: 1183.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6522.42 toks/s, output: 1183.05 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:31<00:02,  2.57s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.15s/it, est. speed input: 338.07 toks/s, output: 46.81 toks/s][A
Processed prompts:  93%|█████████▎| 26/28 [00:01<00:00, 22.84it/s, est. speed input: 6937.93 toks/s, output: 1031.81 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.95it/s, est. speed input: 7440.97 toks/s, output: 1171.46 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:33<00:00,  2.46s/it]Processing batched inference: 100%|██████████| 66/66 [03:33<00:00,  3.24s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-1197/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:08:22.810460017 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-126
INFO 07-05 10:08:35 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:08:37,259 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:08:37,306 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,325 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,325 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,325 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,325 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,325 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,325 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,325 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:08:37,712 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:08:37,714 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:08:37,718 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:08:37,725 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,726 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,726 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,726 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,726 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,726 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,726 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:37,726 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:08:38,097 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:08:38,099 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:08:38,296 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:08:38,748 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:08:38,798 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:08:38,798 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:08:38,800 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:08:50 [config.py:689] This model supports multiple tasks: {'score', 'classify', 'embed', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 07-05 10:08:50 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:50,316 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:50,316 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:50,316 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:50,316 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:50,316 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:50,316 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:50,316 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:08:50,652 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:08:50,753 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:08:50,756 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:08:52 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:08:52 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:08:52 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126...
WARNING 07-05 10:08:52 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:08:52 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]

INFO 07-05 10:09:00 [loader.py:458] Loading weights took 7.58 seconds
INFO 07-05 10:09:00 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.809231 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:00,845 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:00,845 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:00,845 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:00,845 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:00,846 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:00,846 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:00,846 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:09:01,261 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:09:01,358 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:09:01,358 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:09:01,359 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:09:01,360 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:01,360 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:01,360 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:01,360 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:01,360 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:01,360 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:01,360 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:09:01,361 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:09:02,129 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:09:02,130 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:09:02,130 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:09:02,575 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:09:03,249 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:09:03 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:09:06,099 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:09:07,077 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:09:07 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:09:45 [worker.py:267] Memory profiling takes 44.90 seconds
INFO 07-05 10:09:45 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:09:45 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:09:45 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:09:45 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:09:51 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.79it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.89it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.93it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.96it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.95it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.97it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.97it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.98it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.97it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.98it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.99it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.98it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.98it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.99it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  2.00it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  2.00it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.97it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.98it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.99it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.99it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  2.00it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.00it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.99it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  2.00it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  2.00it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.01it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.00it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  2.00it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  2.00it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.99it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.98it/s]
INFO 07-05 10:10:09 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:10:09 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.47 seconds
[INFO|2025-07-05 10:10:09] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:10:10,264 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:10:10,264 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:10:10,266 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:10:10,266 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:10:10,266 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:10:10,266 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:10:10,266 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:10:10,266 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:10:10,266 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:10:11,040 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:10:11,041 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:10:11,041 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:10:11,507 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-126', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 236.76 toks/s, output: 32.78 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 19.31it/s, est. speed input: 5709.20 toks/s, output: 853.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.12it/s, est. speed input: 6333.06 toks/s, output: 1032.42 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:32,  4.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.10 toks/s, output: 42.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 25.88it/s, est. speed input: 7813.94 toks/s, output: 1158.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 7813.94 toks/s, output: 1158.99 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:22,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.23 toks/s, output: 42.12 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7022.65 toks/s, output: 1044.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 23.44it/s, est. speed input: 7540.91 toks/s, output: 1209.66 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 481.26 toks/s, output: 231.56 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 481.26 toks/s, output: 231.56 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:33<14:47, 14.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.32 toks/s, output: 42.14 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.17it/s, est. speed input: 7528.42 toks/s, output: 1112.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.45it/s, est. speed input: 8025.80 toks/s, output: 1238.76 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:36<09:48,  9.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.20 toks/s, output: 42.65 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.51it/s, est. speed input: 7027.23 toks/s, output: 1041.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6562.13 toks/s, output: 1092.03 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:38<07:10,  7.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.35 toks/s, output: 42.14 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.47it/s, est. speed input: 7022.84 toks/s, output: 1039.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.13it/s, est. speed input: 7899.46 toks/s, output: 1277.35 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:41<05:29,  5.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.10 toks/s, output: 42.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.96it/s, est. speed input: 8057.34 toks/s, output: 1190.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.52it/s, est. speed input: 8057.34 toks/s, output: 1190.34 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:43<04:24,  4.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.40 toks/s, output: 42.15 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.17it/s, est. speed input: 7819.83 toks/s, output: 1160.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.54it/s, est. speed input: 8069.41 toks/s, output: 1223.66 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:46<03:40,  3.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.60 toks/s, output: 42.18 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.42it/s, est. speed input: 7298.57 toks/s, output: 1078.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 7863.74 toks/s, output: 1243.28 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:48<03:10,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.84 toks/s, output: 42.21 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.32it/s, est. speed input: 7566.93 toks/s, output: 1119.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.09it/s, est. speed input: 7887.10 toks/s, output: 1224.64 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:50<02:50,  3.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.55 toks/s, output: 42.17 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.80it/s, est. speed input: 7440.70 toks/s, output: 1097.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.07it/s, est. speed input: 7874.60 toks/s, output: 1218.85 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:53<02:37,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.25 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.10it/s, est. speed input: 7795.31 toks/s, output: 1156.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7801.78 toks/s, output: 1187.76 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:55<02:26,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.66 toks/s, output: 42.57 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.36it/s, est. speed input: 7276.88 toks/s, output: 1082.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7786.36 toks/s, output: 1243.63 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:58<02:17,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.95 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.78it/s, est. speed input: 6523.33 toks/s, output: 968.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7746.06 toks/s, output: 1306.43 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:00<02:11,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.50 toks/s, output: 42.02 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.23it/s, est. speed input: 7537.06 toks/s, output: 1113.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.90it/s, est. speed input: 6632.69 toks/s, output: 1051.84 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:02<02:10,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.08 toks/s, output: 41.96 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7271.35 toks/s, output: 1080.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7785.03 toks/s, output: 1245.18 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:05<02:05,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.24 toks/s, output: 42.51 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 6741.96 toks/s, output: 1001.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.56it/s, est. speed input: 5718.67 toks/s, output: 997.10 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [01:08<02:08,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.75 toks/s, output: 42.20 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.42it/s, est. speed input: 7302.34 toks/s, output: 1081.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 7811.85 toks/s, output: 1241.13 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:10<02:02,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.69 toks/s, output: 42.58 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.40it/s, est. speed input: 7285.30 toks/s, output: 1083.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7793.07 toks/s, output: 1241.89 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:13<01:57,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.39 toks/s, output: 42.54 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.02it/s, est. speed input: 7483.75 toks/s, output: 1111.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7804.52 toks/s, output: 1219.55 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:15<01:51,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.81 toks/s, output: 41.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.08it/s, est. speed input: 7784.69 toks/s, output: 1152.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.46it/s, est. speed input: 8033.28 toks/s, output: 1215.57 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:17<01:47,  2.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.60 toks/s, output: 42.04 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 5962.43 toks/s, output: 889.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7705.72 toks/s, output: 1372.49 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:19<01:44,  2.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.37 toks/s, output: 42.00 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.37it/s, est. speed input: 7569.20 toks/s, output: 1119.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.48it/s, est. speed input: 8038.13 toks/s, output: 1241.65 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:22<01:40,  2.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.69 toks/s, output: 41.91 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7260.64 toks/s, output: 1072.22 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:17<00:00, 24.30it/s, est. speed input: 7508.64 toks/s, output: 1135.25 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.14s/it, est. speed input: 467.50 toks/s, output: 225.78 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.60 toks/s, output: 383.16 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:49<06:46,  9.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.22it/s, est. speed input: 7817.27 toks/s, output: 1154.27 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 26.22it/s, est. speed input: 7817.27 toks/s, output: 1154.27 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.13s/it, est. speed input: 480.75 toks/s, output: 225.51 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.75 toks/s, output: 225.51 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:15<10:09, 14.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.16 toks/s, output: 41.84 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.12it/s, est. speed input: 7512.70 toks/s, output: 1118.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 25.12it/s, est. speed input: 7532.05 toks/s, output: 1151.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.12s/it, est. speed input: 480.81 toks/s, output: 227.79 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.81 toks/s, output: 227.79 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:42<12:19, 18.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.17 toks/s, output: 41.98 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.21it/s, est. speed input: 7528.83 toks/s, output: 1111.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7791.89 toks/s, output: 1211.39 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:45<08:51, 13.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.00 toks/s, output: 41.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.21it/s, est. speed input: 7869.58 toks/s, output: 1166.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.03it/s, est. speed input: 7869.58 toks/s, output: 1166.53 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:47<06:28, 10.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.35 toks/s, output: 41.86 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.65it/s, est. speed input: 7403.40 toks/s, output: 1099.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 24.65it/s, est. speed input: 7536.62 toks/s, output: 1149.76 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 480.86 toks/s, output: 227.73 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.86 toks/s, output: 227.73 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [03:14<09:23, 15.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.62 toks/s, output: 41.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.41it/s, est. speed input: 7291.23 toks/s, output: 1083.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.24it/s, est. speed input: 7946.24 toks/s, output: 1259.85 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [03:16<06:47, 11.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.66 toks/s, output: 42.04 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.25it/s, est. speed input: 7537.69 toks/s, output: 1109.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 7824.50 toks/s, output: 1211.43 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [03:18<05:00,  8.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.16 toks/s, output: 41.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.08it/s, est. speed input: 7780.90 toks/s, output: 1146.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.00it/s, est. speed input: 7846.72 toks/s, output: 1185.50 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [03:20<03:47,  6.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.81 toks/s, output: 41.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.27it/s, est. speed input: 7609.77 toks/s, output: 1134.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7795.08 toks/s, output: 1192.27 toks/s]
Processing batched inference:  50%|█████     | 33/66 [03:23<02:56,  5.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.54 toks/s, output: 41.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.27it/s, est. speed input: 7261.03 toks/s, output: 1078.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.84it/s, est. speed input: 6617.79 toks/s, output: 1083.04 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [03:25<02:25,  4.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.40 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7004.86 toks/s, output: 1036.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7792.49 toks/s, output: 1262.95 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [03:28<01:59,  3.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.79 toks/s, output: 41.92 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 6991.92 toks/s, output: 1032.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7751.94 toks/s, output: 1260.82 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [03:30<01:41,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.74 toks/s, output: 41.50 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.00it/s, est. speed input: 7460.40 toks/s, output: 1102.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.96it/s, est. speed input: 7832.92 toks/s, output: 1211.39 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [03:32<01:27,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.55 toks/s, output: 41.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.55it/s, est. speed input: 7099.45 toks/s, output: 1060.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7775.97 toks/s, output: 1250.45 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [03:34<01:18,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.09it/s, est. speed input: 7791.76 toks/s, output: 1153.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7796.58 toks/s, output: 1184.15 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:37<01:11,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.86 toks/s, output: 41.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.05it/s, est. speed input: 7557.86 toks/s, output: 1124.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7801.47 toks/s, output: 1191.15 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:39<01:05,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.70 toks/s, output: 42.05 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.35it/s, est. speed input: 7280.47 toks/s, output: 1078.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7793.44 toks/s, output: 1240.07 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [03:41<01:01,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.91 toks/s, output: 41.94 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7262.10 toks/s, output: 1073.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 7829.77 toks/s, output: 1241.88 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [03:43<00:57,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.44 toks/s, output: 42.01 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.26it/s, est. speed input: 7826.60 toks/s, output: 1154.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.50it/s, est. speed input: 8044.67 toks/s, output: 1212.84 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [03:46<00:53,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.67 toks/s, output: 42.05 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.49it/s, est. speed input: 7304.46 toks/s, output: 1076.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.96it/s, est. speed input: 5867.46 toks/s, output: 970.03 toks/s] 
Processing batched inference:  67%|██████▋   | 44/66 [03:48<00:54,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.55 toks/s, output: 42.03 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.12it/s, est. speed input: 7795.36 toks/s, output: 1150.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 7801.36 toks/s, output: 1181.37 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:51<00:49,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.33 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6224.67 toks/s, output: 924.75 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:11<00:00, 20.74it/s, est. speed input: 7241.65 toks/s, output: 1210.11 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.09s/it, est. speed input: 467.42 toks/s, output: 232.98 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.51 toks/s, output: 390.37 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [04:17<03:13,  9.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.89 toks/s, output: 41.94 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.54it/s, est. speed input: 7669.41 toks/s, output: 1140.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7795.93 toks/s, output: 1189.16 toks/s]
Processing batched inference:  71%|███████   | 47/66 [04:20<02:21,  7.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.62 toks/s, output: 42.43 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.22it/s, est. speed input: 7518.10 toks/s, output: 1112.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7778.94 toks/s, output: 1210.32 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [04:22<01:45,  5.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.40 toks/s, output: 42.01 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.47it/s, est. speed input: 7305.63 toks/s, output: 1081.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.13it/s, est. speed input: 7901.15 toks/s, output: 1249.43 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [04:24<01:21,  4.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.63 toks/s, output: 42.04 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 6750.11 toks/s, output: 1001.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.15it/s, est. speed input: 6730.41 toks/s, output: 1138.52 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [04:27<01:05,  4.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.09 toks/s, output: 41.97 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7000.92 toks/s, output: 1039.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7760.45 toks/s, output: 1263.14 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [04:29<00:53,  3.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.48 toks/s, output: 42.41 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.32it/s, est. speed input: 7262.58 toks/s, output: 1079.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7774.36 toks/s, output: 1241.00 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [04:31<00:44,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.24 toks/s, output: 42.51 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.27it/s, est. speed input: 7534.52 toks/s, output: 1116.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.15it/s, est. speed input: 7913.05 toks/s, output: 1229.30 toks/s]
Processing batched inference:  80%|████████  | 53/66 [04:33<00:37,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.57 toks/s, output: 42.42 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.23it/s, est. speed input: 7520.72 toks/s, output: 1112.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.43it/s, est. speed input: 8017.87 toks/s, output: 1238.72 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [04:35<00:31,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.43 toks/s, output: 41.87 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.16it/s, est. speed input: 7511.96 toks/s, output: 1110.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7768.79 toks/s, output: 1204.89 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [04:38<00:28,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.30 toks/s, output: 41.86 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.65it/s, est. speed input: 7402.61 toks/s, output: 1100.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6559.43 toks/s, output: 1051.23 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [04:40<00:25,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.00 toks/s, output: 41.95 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 6994.03 toks/s, output: 1033.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7750.44 toks/s, output: 1257.99 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [04:43<00:22,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.03 toks/s, output: 42.48 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 6999.08 toks/s, output: 1035.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7758.75 toks/s, output: 1260.17 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [04:45<00:19,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.51 toks/s, output: 41.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.35it/s, est. speed input: 7041.39 toks/s, output: 1041.44 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:14<00:00, 23.35it/s, est. speed input: 7041.39 toks/s, output: 1041.44 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:26<00:02,  1.22s/it, est. speed input: 445.74 toks/s, output: 218.82 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.21it/s, est. speed input: 475.50 toks/s, output: 529.00 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [05:12<01:08,  9.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.01 toks/s, output: 42.09 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.51it/s, est. speed input: 7315.12 toks/s, output: 1080.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7792.24 toks/s, output: 1232.50 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [05:14<00:45,  7.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.87 toks/s, output: 41.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.80it/s, est. speed input: 8012.53 toks/s, output: 1187.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 8012.53 toks/s, output: 1187.88 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [05:16<00:29,  5.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.55 toks/s, output: 42.42 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.21it/s, est. speed input: 7521.03 toks/s, output: 1116.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.96it/s, est. speed input: 7840.73 toks/s, output: 1222.48 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [05:19<00:19,  4.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.05 toks/s, output: 41.96 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.18it/s, est. speed input: 7520.94 toks/s, output: 1111.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7780.16 toks/s, output: 1208.32 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [05:21<00:12,  4.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.33 toks/s, output: 42.00 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.84it/s, est. speed input: 8017.34 toks/s, output: 1183.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.42it/s, est. speed input: 8017.34 toks/s, output: 1183.35 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [05:23<00:06,  3.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.23 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.09it/s, est. speed input: 7786.98 toks/s, output: 1149.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.32it/s, est. speed input: 7973.37 toks/s, output: 1204.98 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [05:25<00:03,  3.09s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 337.40 toks/s, output: 46.72 toks/s][A
Processed prompts:  96%|█████████▋| 27/28 [00:01<00:00, 23.59it/s, est. speed input: 7169.47 toks/s, output: 1065.84 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.93it/s, est. speed input: 7435.08 toks/s, output: 1138.08 toks/s]
Processing batched inference: 100%|██████████| 66/66 [05:27<00:00,  2.79s/it]Processing batched inference: 100%|██████████| 66/66 [05:27<00:00,  4.97s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-126/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:15:38.999244675 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1260
INFO 07-05 10:15:52 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:15:53,924 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:15:53,966 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:53,989 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:53,989 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:53,989 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:53,989 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:53,989 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:53,989 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:53,989 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:15:54,397 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:15:54,399 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:15:54,405 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:15:54,411 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:54,412 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:54,412 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:54,412 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:54,412 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:54,412 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:54,412 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:54,412 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:15:54,786 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:15:54,788 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:15:55,025 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:15:55,466 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:15:55,520 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:15:55,521 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:15:55,523 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:16:07 [config.py:689] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 07-05 10:16:07 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:07,211 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:07,211 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:07,211 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:07,211 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:07,211 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:07,211 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:07,211 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:16:07,548 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:16:07,649 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:16:07,652 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:16:09 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:16:09 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:16:09 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260...
WARNING 07-05 10:16:09 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:16:09 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.20s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.20s/it]

INFO 07-05 10:16:17 [loader.py:458] Loading weights took 7.41 seconds
INFO 07-05 10:16:17 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.654473 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:17,647 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:17,647 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:17,647 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:17,647 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:17,647 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:17,647 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:17,647 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:16:18,059 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:16:18,155 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:16:18,155 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:16:18,155 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:16:18,156 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:18,156 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:18,156 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:18,156 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:18,156 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:18,156 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:18,156 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:18,156 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:16:18,925 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:16:18,926 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:16:18,926 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:16:19,374 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:16:20,022 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:16:20 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:16:22,869 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:16:23,879 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:16:24 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:17:02 [worker.py:267] Memory profiling takes 45.12 seconds
INFO 07-05 10:17:02 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:17:02 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:17:02 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:17:02 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:17:07 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:18,  1.84it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.83it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.92it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.92it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.93it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.98it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.99it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.99it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.99it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  2.00it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.01it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  2.00it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.01it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  2.01it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  2.00it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:05,  2.00it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.96it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.95it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.97it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.96it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.93it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.96it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.97it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.98it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.98it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  2.00it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.00it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.97it/s]
INFO 07-05 10:17:25 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:17:25 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.28 seconds
[INFO|2025-07-05 10:17:26] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:10, 192.04 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 545.83 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:01, 798.49 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:01<00:01, 980.35 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:01<00:00, 1140.43 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:01<00:00, 1396.86 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:01<00:00, 1476.87 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:01<00:00, 1510.30 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 997.22 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:17:30,423 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:17:30,423 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:17:30,424 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:17:30,424 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:17:30,424 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:17:30,424 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:17:30,424 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:17:30,424 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:17:30,425 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:17:31,202 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:17:31,203 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:17:31,203 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:17:31,656 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-1260', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it, est. speed input: 233.18 toks/s, output: 32.29 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 16.85it/s, est. speed input: 4994.87 toks/s, output: 747.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.85it/s, est. speed input: 6229.48 toks/s, output: 1087.86 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:31,  4.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 305.90 toks/s, output: 42.35 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6224.18 toks/s, output: 921.97 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.97it/s, est. speed input: 6385.09 toks/s, output: 1123.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.73it/s, est. speed input: 6568.94 toks/s, output: 1200.66 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:36,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.40 toks/s, output: 42.29 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.19it/s, est. speed input: 5481.03 toks/s, output: 818.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.67it/s, est. speed input: 5556.92 toks/s, output: 1068.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.56it/s, est. speed input: 5719.70 toks/s, output: 1156.76 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:23,  3.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.38 toks/s, output: 42.28 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.75it/s, est. speed input: 6519.86 toks/s, output: 965.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7776.96 toks/s, output: 1319.89 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<03:00,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.66 toks/s, output: 42.32 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.97it/s, est. speed input: 6002.44 toks/s, output: 892.62 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.33it/s, est. speed input: 5939.76 toks/s, output: 1030.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.07it/s, est. speed input: 4739.70 toks/s, output: 985.66 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:15<03:10,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.94 toks/s, output: 42.22 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.61it/s, est. speed input: 6767.86 toks/s, output: 998.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7777.99 toks/s, output: 1290.54 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:18<02:53,  2.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.78 toks/s, output: 42.20 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.37it/s, est. speed input: 6716.17 toks/s, output: 993.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7781.29 toks/s, output: 1301.93 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:20<02:42,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.51 toks/s, output: 42.16 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.00it/s, est. speed input: 6009.34 toks/s, output: 897.79 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.74it/s, est. speed input: 6717.77 toks/s, output: 1220.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.10it/s, est. speed input: 6717.77 toks/s, output: 1220.19 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:23<02:38,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.68 toks/s, output: 42.19 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.49it/s, est. speed input: 7029.17 toks/s, output: 1038.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 7818.84 toks/s, output: 1266.07 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:25<02:28,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 307.90 toks/s, output: 42.31 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.65it/s, est. speed input: 6787.17 toks/s, output: 1002.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.83it/s, est. speed input: 6608.09 toks/s, output: 1123.34 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:28<02:27,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.85 toks/s, output: 42.35 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.77it/s, est. speed input: 6521.71 toks/s, output: 961.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.12it/s, est. speed input: 5872.25 toks/s, output: 1087.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.97it/s, est. speed input: 5872.25 toks/s, output: 1087.62 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:31<02:30,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.91 toks/s, output: 42.22 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.48it/s, est. speed input: 6461.74 toks/s, output: 961.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7772.11 toks/s, output: 1332.23 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:33<02:21,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.57 toks/s, output: 42.17 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.46it/s, est. speed input: 6455.46 toks/s, output: 959.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7764.87 toks/s, output: 1332.23 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:36<02:14,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.32 toks/s, output: 42.14 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.59it/s, est. speed input: 6758.43 toks/s, output: 996.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6552.60 toks/s, output: 1113.50 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:38<02:13,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.71 toks/s, output: 42.05 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6491.02 toks/s, output: 961.36 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.44it/s, est. speed input: 6559.26 toks/s, output: 1167.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6559.26 toks/s, output: 1167.09 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:41<02:12,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.78 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6498.90 toks/s, output: 970.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 6545.59 toks/s, output: 1144.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6545.59 toks/s, output: 1144.81 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:44<02:11,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.60 toks/s, output: 42.56 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.82it/s, est. speed input: 6236.25 toks/s, output: 927.01 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.41it/s, est. speed input: 4909.19 toks/s, output: 938.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.90it/s, est. speed input: 5067.27 toks/s, output: 1038.37 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:47<02:17,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.91 toks/s, output: 42.22 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.51it/s, est. speed input: 7037.26 toks/s, output: 1042.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7800.45 toks/s, output: 1269.75 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:49<02:08,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.14 toks/s, output: 42.11 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.13it/s, est. speed input: 5460.36 toks/s, output: 813.83 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.20it/s, est. speed input: 5691.76 toks/s, output: 1105.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.49it/s, est. speed input: 5691.76 toks/s, output: 1105.38 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:52<02:09,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.74 toks/s, output: 42.44 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.39it/s, est. speed input: 6423.35 toks/s, output: 958.40 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.36it/s, est. speed input: 6716.09 toks/s, output: 1177.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.09it/s, est. speed input: 6716.09 toks/s, output: 1177.11 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:55<02:04,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.26 toks/s, output: 41.99 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6482.29 toks/s, output: 963.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7736.50 toks/s, output: 1318.46 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:57<01:57,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.35 toks/s, output: 42.00 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.38it/s, est. speed input: 4937.97 toks/s, output: 735.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.12it/s, est. speed input: 5873.83 toks/s, output: 1121.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.33it/s, est. speed input: 5625.21 toks/s, output: 1241.44 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:00<02:00,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.26 toks/s, output: 42.13 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.81it/s, est. speed input: 6240.08 toks/s, output: 923.88 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.34it/s, est. speed input: 6451.62 toks/s, output: 1128.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.86it/s, est. speed input: 6616.73 toks/s, output: 1201.74 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:03<01:55,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.57 toks/s, output: 41.42 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.79it/s, est. speed input: 5954.96 toks/s, output: 883.21 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.89it/s, est. speed input: 6498.24 toks/s, output: 1158.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.72it/s, est. speed input: 3421.59 toks/s, output: 711.01 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:07<02:13,  3.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.96 toks/s, output: 42.22 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.92it/s, est. speed input: 5986.20 toks/s, output: 889.21 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.05it/s, est. speed input: 6348.08 toks/s, output: 1139.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.59it/s, est. speed input: 1408.16 toks/s, output: 390.62 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:17<03:29,  5.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.79 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.78it/s, est. speed input: 6297.72 toks/s, output: 941.41 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.82it/s, est. speed input: 6359.21 toks/s, output: 1101.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.52it/s, est. speed input: 4527.91 toks/s, output: 866.84 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:20<03:04,  4.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.26 toks/s, output: 42.13 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6499.31 toks/s, output: 962.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.41it/s, est. speed input: 6559.07 toks/s, output: 1196.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6559.07 toks/s, output: 1196.72 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:23<02:35,  3.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.35s/it, est. speed input: 289.58 toks/s, output: 40.09 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.11it/s, est. speed input: 6351.21 toks/s, output: 943.26 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 6343.51 toks/s, output: 1089.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.15it/s, est. speed input: 6343.51 toks/s, output: 1089.21 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:25<02:16,  3.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.14 toks/s, output: 40.86 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.36it/s, est. speed input: 5246.48 toks/s, output: 784.72 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.50it/s, est. speed input: 5780.82 toks/s, output: 1057.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.63it/s, est. speed input: 4568.56 toks/s, output: 1008.04 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:29<02:10,  3.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 299.48 toks/s, output: 40.59 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.10it/s, est. speed input: 6911.17 toks/s, output: 1023.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6520.17 toks/s, output: 1085.65 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:31<01:56,  3.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.31 toks/s, output: 40.89 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.34it/s, est. speed input: 6087.62 toks/s, output: 899.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.40it/s, est. speed input: 7612.17 toks/s, output: 1321.63 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:34<01:43,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.05 toks/s, output: 41.13 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.44it/s, est. speed input: 6116.28 toks/s, output: 902.36 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.30it/s, est. speed input: 6429.81 toks/s, output: 1146.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6429.81 toks/s, output: 1146.05 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:36<01:37,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.07 toks/s, output: 40.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.85it/s, est. speed input: 5991.12 toks/s, output: 895.94 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.40it/s, est. speed input: 6148.38 toks/s, output: 1067.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.38it/s, est. speed input: 6437.96 toks/s, output: 1207.34 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:39<01:31,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.53 toks/s, output: 40.78 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.56it/s, est. speed input: 6484.75 toks/s, output: 964.72 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.01it/s, est. speed input: 5592.82 toks/s, output: 980.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.23it/s, est. speed input: 5592.82 toks/s, output: 980.68 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:42<01:31,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.53 toks/s, output: 41.33 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.05it/s, est. speed input: 7176.48 toks/s, output: 1058.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7682.33 toks/s, output: 1219.40 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:44<01:22,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.89 toks/s, output: 41.80 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 5939.87 toks/s, output: 882.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 7679.18 toks/s, output: 1363.92 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:46<01:16,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.59 toks/s, output: 41.90 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 6988.49 toks/s, output: 1035.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7773.14 toks/s, output: 1259.71 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:49<01:10,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.60 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.92it/s, est. speed input: 6327.08 toks/s, output: 948.43 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.95it/s, est. speed input: 6806.39 toks/s, output: 1194.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.31it/s, est. speed input: 6806.39 toks/s, output: 1194.62 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:51<01:09,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.02 toks/s, output: 41.96 toks/s][A
Processed prompts:  53%|█████▎    | 17/32 [00:01<00:01, 13.78it/s, est. speed input: 4178.55 toks/s, output: 630.91 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.63it/s, est. speed input: 6283.91 toks/s, output: 1300.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.26it/s, est. speed input: 5602.49 toks/s, output: 1214.18 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:54<01:09,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.33 toks/s, output: 41.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 6730.61 toks/s, output: 1003.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7738.26 toks/s, output: 1294.11 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:56<01:04,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.71 toks/s, output: 41.91 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5691.65 toks/s, output: 845.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.19it/s, est. speed input: 6307.38 toks/s, output: 1156.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.68it/s, est. speed input: 4979.85 toks/s, output: 984.63 toks/s] 
Processing batched inference:  62%|██████▏   | 41/66 [01:59<01:07,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.77 toks/s, output: 41.42 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.67it/s, est. speed input: 6211.29 toks/s, output: 918.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.03it/s, est. speed input: 6386.00 toks/s, output: 1117.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6549.88 toks/s, output: 1191.16 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:02<01:03,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.67 toks/s, output: 41.77 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.32it/s, est. speed input: 6972.33 toks/s, output: 1030.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.88it/s, est. speed input: 5837.79 toks/s, output: 990.32 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [02:05<01:02,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.76 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6216.12 toks/s, output: 920.33 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.65it/s, est. speed input: 5673.76 toks/s, output: 1008.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.60it/s, est. speed input: 5725.47 toks/s, output: 1077.02 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:08<01:00,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.36 toks/s, output: 41.73 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.40it/s, est. speed input: 6706.50 toks/s, output: 991.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6511.64 toks/s, output: 1107.90 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:10<00:56,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.89 toks/s, output: 41.94 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 5941.98 toks/s, output: 881.03 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.20it/s, est. speed input: 5888.79 toks/s, output: 1015.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 18.20it/s, est. speed input: 3341.89 toks/s, output: 715.41 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.38s/it, est. speed input: 480.95 toks/s, output: 256.62 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.95 toks/s, output: 256.62 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:37<03:18,  9.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.17 toks/s, output: 41.73 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.51it/s, est. speed input: 6453.97 toks/s, output: 962.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7701.97 toks/s, output: 1319.39 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:39<02:24,  7.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.28 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6464.46 toks/s, output: 956.70 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.16it/s, est. speed input: 5637.19 toks/s, output: 1007.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.36it/s, est. speed input: 5637.19 toks/s, output: 1007.64 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:42<01:51,  6.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.11 toks/s, output: 41.83 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.01it/s, est. speed input: 5992.43 toks/s, output: 887.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7684.36 toks/s, output: 1363.83 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:44<01:24,  5.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.40 toks/s, output: 42.01 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.23it/s, est. speed input: 7533.46 toks/s, output: 1112.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.15it/s, est. speed input: 7907.73 toks/s, output: 1221.80 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:47<01:07,  4.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.85 toks/s, output: 41.93 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.20it/s, est. speed input: 5187.70 toks/s, output: 777.49 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.70it/s, est. speed input: 6256.68 toks/s, output: 1175.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6485.84 toks/s, output: 1301.91 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:49<00:55,  3.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.01 toks/s, output: 41.82 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.67it/s, est. speed input: 6205.27 toks/s, output: 922.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7700.19 toks/s, output: 1349.20 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:51<00:45,  3.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.09 toks/s, output: 42.49 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6222.38 toks/s, output: 922.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7722.68 toks/s, output: 1347.85 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:54<00:38,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.34 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6479.89 toks/s, output: 959.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7727.95 toks/s, output: 1313.94 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:56<00:32,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.48 toks/s, output: 41.88 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6727.65 toks/s, output: 994.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.10it/s, est. speed input: 3179.08 toks/s, output: 664.92 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:00<00:36,  3.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.30 toks/s, output: 41.86 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.04it/s, est. speed input: 5436.40 toks/s, output: 814.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.50it/s, est. speed input: 6317.11 toks/s, output: 1186.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.32it/s, est. speed input: 5628.20 toks/s, output: 1115.96 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:03<00:31,  3.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.03 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6476.23 toks/s, output: 957.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.63it/s, est. speed input: 6588.91 toks/s, output: 1145.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.79it/s, est. speed input: 6588.91 toks/s, output: 1145.55 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:06<00:26,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.66 toks/s, output: 42.43 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6217.07 toks/s, output: 920.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 7716.63 toks/s, output: 1343.03 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:08<00:22,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.36 toks/s, output: 41.87 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.24it/s, est. speed input: 6672.87 toks/s, output: 987.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.17it/s, est. speed input: 6740.04 toks/s, output: 1145.87 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:11<00:18,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.72 toks/s, output: 41.92 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.93it/s, est. speed input: 5976.67 toks/s, output: 886.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.96it/s, est. speed input: 6317.72 toks/s, output: 1126.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.54it/s, est. speed input: 5703.72 toks/s, output: 1076.59 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:13<00:16,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.53 toks/s, output: 41.89 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5694.27 toks/s, output: 848.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.10it/s, est. speed input: 6527.09 toks/s, output: 1218.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6527.09 toks/s, output: 1218.92 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:16<00:13,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.77 toks/s, output: 41.78 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.55it/s, est. speed input: 5892.11 toks/s, output: 879.49 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.84it/s, est. speed input: 6465.36 toks/s, output: 1161.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6504.85 toks/s, output: 1212.37 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:18<00:10,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.57 toks/s, output: 41.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.21it/s, est. speed input: 7242.01 toks/s, output: 1072.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6556.50 toks/s, output: 1089.78 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:21<00:07,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.78 toks/s, output: 41.78 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.78it/s, est. speed input: 6506.12 toks/s, output: 961.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.18it/s, est. speed input: 6505.81 toks/s, output: 1134.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6505.81 toks/s, output: 1134.79 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:24<00:05,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.72 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5954.60 toks/s, output: 885.50 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.73it/s, est. speed input: 6502.16 toks/s, output: 1179.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6502.16 toks/s, output: 1179.38 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:26<00:02,  2.58s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 336.18 toks/s, output: 46.55 toks/s][A
Processed prompts:  93%|█████████▎| 26/28 [00:01<00:00, 22.68it/s, est. speed input: 6891.59 toks/s, output: 1024.92 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.82it/s, est. speed input: 7391.27 toks/s, output: 1163.63 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:28<00:00,  2.44s/it]Processing batched inference: 100%|██████████| 66/66 [03:28<00:00,  3.16s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-1260/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:20:59.124565638 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-189
INFO 07-05 10:21:12 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:21:14,562 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:21:14,603 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:14,630 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:14,631 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:14,631 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:14,631 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:14,631 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:14,631 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:14,631 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:21:15,019 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:21:15,021 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:21:15,026 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:21:15,033 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:15,033 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:15,033 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:15,033 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:15,034 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:15,034 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:15,034 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:15,034 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:21:15,410 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:21:15,412 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:21:15,634 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:21:16,081 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:21:16,137 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:21:16,137 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:21:16,139 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:21:27 [config.py:689] This model supports multiple tasks: {'reward', 'score', 'generate', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 07-05 10:21:27 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:27,752 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:27,752 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:27,752 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:27,752 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:27,752 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:27,753 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:27,753 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:21:28,088 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:21:28,188 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:21:28,191 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:21:29 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:21:29 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:21:30 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189...
WARNING 07-05 10:21:30 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:21:30 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]

INFO 07-05 10:21:37 [loader.py:458] Loading weights took 7.59 seconds
INFO 07-05 10:21:38 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.827818 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,286 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,286 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,286 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,286 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,286 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,286 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,286 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:21:38,693 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:21:38,789 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:21:38,790 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:21:38,791 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:21:38,791 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,791 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,791 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,791 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,791 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,791 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,792 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:38,792 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:21:39,551 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:21:39,551 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:21:39,552 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:21:40,008 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:21:40,698 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:21:41 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:21:43,524 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:21:44,529 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:21:44 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:22:23 [worker.py:267] Memory profiling takes 44.98 seconds
INFO 07-05 10:22:23 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:22:23 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:22:23 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:22:23 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:22:29 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.78it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.89it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.90it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.90it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.92it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.94it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:11,  1.91it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.96it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.90it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.95it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.95it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.96it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.97it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.97it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.91it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.93it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.95it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.95it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.95it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.96it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.96it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.89it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.93it/s]
INFO 07-05 10:22:47 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:22:47 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.57 seconds
[INFO|2025-07-05 10:22:48] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:22:49,012 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:22:49,012 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:22:49,013 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:22:49,013 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:22:49,013 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:22:49,013 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:22:49,013 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:22:49,013 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:22:49,013 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:22:50,072 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:22:50,073 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:22:50,074 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:22:50,609 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-189', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 236.50 toks/s, output: 33.27 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.83it/s, est. speed input: 5279.77 toks/s, output: 792.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.11it/s, est. speed input: 6332.31 toks/s, output: 1080.14 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:03,  4.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.39 toks/s, output: 42.15 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.31it/s, est. speed input: 7561.10 toks/s, output: 1118.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.92it/s, est. speed input: 7824.16 toks/s, output: 1217.79 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:34,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.45 toks/s, output: 42.15 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6507.82 toks/s, output: 969.19 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.44it/s, est. speed input: 6571.23 toks/s, output: 1177.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6571.23 toks/s, output: 1177.42 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:13,  3.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.65 toks/s, output: 42.85 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.69it/s, est. speed input: 6786.08 toks/s, output: 1006.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7796.60 toks/s, output: 1292.18 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:53,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.98 toks/s, output: 42.12 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6501.73 toks/s, output: 964.30 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 21.68it/s, est. speed input: 944.03 toks/s, output: 302.66 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.05s/it, est. speed input: 483.86 toks/s, output: 308.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.86 toks/s, output: 308.03 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:39<11:41, 11.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.30 toks/s, output: 42.13 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6495.31 toks/s, output: 962.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7748.96 toks/s, output: 1313.50 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:41<08:25,  8.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.15 toks/s, output: 42.11 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7020.29 toks/s, output: 1040.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7782.64 toks/s, output: 1266.84 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:44<06:22,  6.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.93 toks/s, output: 42.08 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 6759.93 toks/s, output: 1010.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7762.56 toks/s, output: 1291.38 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:46<05:00,  5.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.45 toks/s, output: 42.68 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.74it/s, est. speed input: 6506.23 toks/s, output: 965.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7762.42 toks/s, output: 1313.82 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:48<04:04,  4.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.09 toks/s, output: 42.13 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 6761.73 toks/s, output: 1002.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7772.74 toks/s, output: 1294.72 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:51<03:26,  3.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.00 toks/s, output: 42.09 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 6749.11 toks/s, output: 996.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7759.79 toks/s, output: 1288.24 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:53<03:01,  3.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.64 toks/s, output: 42.57 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.46it/s, est. speed input: 7015.09 toks/s, output: 1043.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7777.17 toks/s, output: 1271.24 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:55<02:43,  3.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.97 toks/s, output: 41.95 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.32it/s, est. speed input: 7272.88 toks/s, output: 1079.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7787.78 toks/s, output: 1245.72 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:58<02:29,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.38 toks/s, output: 42.14 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.92it/s, est. speed input: 6273.59 toks/s, output: 934.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7745.44 toks/s, output: 1334.71 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:00<02:18,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.89 toks/s, output: 41.94 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5959.61 toks/s, output: 889.38 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.64it/s, est. speed input: 6444.58 toks/s, output: 1146.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s, est. speed input: 756.70 toks/s, output: 284.22 toks/s]  
Processing batched inference:  23%|██▎       | 15/66 [01:18<06:02,  7.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.09 toks/s, output: 41.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6475.99 toks/s, output: 968.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7727.55 toks/s, output: 1320.18 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:20<04:47,  5.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.76 toks/s, output: 41.32 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.35it/s, est. speed input: 6084.47 toks/s, output: 904.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.24it/s, est. speed input: 7554.22 toks/s, output: 1317.74 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:23<03:52,  4.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.59 toks/s, output: 40.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.21it/s, est. speed input: 6354.15 toks/s, output: 944.62 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 6484.77 toks/s, output: 1126.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6484.77 toks/s, output: 1126.30 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:25<03:19,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.38 toks/s, output: 41.41 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.97it/s, est. speed input: 6856.34 toks/s, output: 1019.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.36it/s, est. speed input: 7602.75 toks/s, output: 1241.21 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:28<02:51,  3.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.12 toks/s, output: 41.23 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.94it/s, est. speed input: 6277.34 toks/s, output: 938.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.23it/s, est. speed input: 7556.33 toks/s, output: 1294.93 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:30<02:30,  3.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.56 toks/s, output: 40.65 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.95it/s, est. speed input: 6567.38 toks/s, output: 977.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.24it/s, est. speed input: 7552.25 toks/s, output: 1255.19 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:33<02:16,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.84 toks/s, output: 40.82 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.81it/s, est. speed input: 5347.77 toks/s, output: 799.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.82it/s, est. speed input: 6371.64 toks/s, output: 1207.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.23it/s, est. speed input: 6371.64 toks/s, output: 1207.89 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:35<02:10,  2.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.65 toks/s, output: 40.80 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.26it/s, est. speed input: 6357.14 toks/s, output: 944.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.27it/s, est. speed input: 7562.63 toks/s, output: 1283.21 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:38<01:59,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.43 toks/s, output: 40.77 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.87it/s, est. speed input: 6834.19 toks/s, output: 1011.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.82it/s, est. speed input: 1891.65 toks/s, output: 429.99 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:45<02:54,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.16 toks/s, output: 40.87 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.43it/s, est. speed input: 5829.47 toks/s, output: 867.51 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.82it/s, est. speed input: 6191.23 toks/s, output: 1089.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 19.82it/s, est. speed input: 6257.61 toks/s, output: 1144.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.41s/it, est. speed input: 480.55 toks/s, output: 241.82 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.55 toks/s, output: 241.82 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:12<07:30, 11.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.35s/it, est. speed input: 290.23 toks/s, output: 40.82 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.26it/s, est. speed input: 5771.09 toks/s, output: 864.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.17it/s, est. speed input: 1886.26 toks/s, output: 460.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.80it/s, est. speed input: 1886.26 toks/s, output: 460.54 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:20<06:37,  9.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.01 toks/s, output: 40.85 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.91it/s, est. speed input: 6847.66 toks/s, output: 1015.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.36it/s, est. speed input: 6422.74 toks/s, output: 1069.08 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:22<05:02,  7.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 292.73 toks/s, output: 41.18 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.13it/s, est. speed input: 6316.35 toks/s, output: 942.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.21it/s, est. speed input: 7543.67 toks/s, output: 1286.88 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:25<03:53,  6.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 292.92 toks/s, output: 41.20 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.53it/s, est. speed input: 5558.94 toks/s, output: 831.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:05<00:00,  4.85it/s, est. speed input: 2139.57 toks/s, output: 502.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00,  4.85it/s, est. speed input: 2139.57 toks/s, output: 502.79 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:23<00:00,  1.20s/it, est. speed input: 535.82 toks/s, output: 278.18 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:23<00:00,  1.36it/s, est. speed input: 535.82 toks/s, output: 278.18 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [02:49<07:06, 11.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.77 toks/s, output: 41.32 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.19it/s, est. speed input: 6338.09 toks/s, output: 947.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 6471.10 toks/s, output: 1123.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6471.10 toks/s, output: 1123.32 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:51<05:18,  8.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.35 toks/s, output: 41.17 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.95it/s, est. speed input: 6866.68 toks/s, output: 1015.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.06it/s, est. speed input: 1199.89 toks/s, output: 332.08 toks/s] 
Processing batched inference:  47%|████▋     | 31/66 [03:03<05:34,  9.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.45 toks/s, output: 41.05 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.94it/s, est. speed input: 7140.22 toks/s, output: 1054.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7701.51 toks/s, output: 1221.22 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [03:05<04:10,  7.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.22 toks/s, output: 40.74 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.14it/s, est. speed input: 7243.42 toks/s, output: 1080.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.36it/s, est. speed input: 7611.61 toks/s, output: 1192.65 toks/s]
Processing batched inference:  50%|█████     | 33/66 [03:07<03:12,  5.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.78 toks/s, output: 40.82 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.14it/s, est. speed input: 6335.89 toks/s, output: 944.54 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.14it/s, est. speed input: 7330.26 toks/s, output: 1233.54 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 481.26 toks/s, output: 235.21 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 481.26 toks/s, output: 235.21 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [03:34<06:30, 12.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.75 toks/s, output: 41.37 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.25it/s, est. speed input: 6660.78 toks/s, output: 990.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7708.48 toks/s, output: 1275.12 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [03:36<04:45,  9.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.74 toks/s, output: 41.64 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.71it/s, est. speed input: 5919.46 toks/s, output: 880.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.50it/s, est. speed input: 7653.71 toks/s, output: 1358.78 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [03:39<03:33,  7.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.42 toks/s, output: 42.01 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.37it/s, est. speed input: 7282.57 toks/s, output: 1078.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.15it/s, est. speed input: 7906.99 toks/s, output: 1251.18 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [03:41<02:43,  5.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 303.03 toks/s, output: 41.85 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.56it/s, est. speed input: 7099.43 toks/s, output: 1059.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7776.15 toks/s, output: 1249.86 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [03:43<02:09,  4.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.07 toks/s, output: 41.83 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.03it/s, est. speed input: 5428.73 toks/s, output: 810.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 7654.53 toks/s, output: 1426.27 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:45<01:45,  3.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.32 toks/s, output: 41.72 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.27it/s, est. speed input: 6970.49 toks/s, output: 1038.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7728.37 toks/s, output: 1264.80 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:48<01:28,  3.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.52 toks/s, output: 41.75 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.75it/s, est. speed input: 5933.32 toks/s, output: 883.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 7665.46 toks/s, output: 1364.93 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [03:50<01:16,  3.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.17 toks/s, output: 42.12 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.69it/s, est. speed input: 7074.12 toks/s, output: 1047.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:15<00:00,  2.04it/s, est. speed input: 799.41 toks/s, output: 276.25 toks/s]  
Processing batched inference:  64%|██████▎   | 42/66 [04:06<02:49,  7.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.50 toks/s, output: 41.75 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.29it/s, est. speed input: 6966.65 toks/s, output: 1030.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7780.94 toks/s, output: 1261.70 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [04:09<02:09,  5.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.01 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6492.00 toks/s, output: 962.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.06it/s, est. speed input: 1463.64 toks/s, output: 420.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.73it/s, est. speed input: 1463.64 toks/s, output: 420.75 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [04:18<02:27,  6.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.81 toks/s, output: 42.45 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.40it/s, est. speed input: 7272.95 toks/s, output: 1074.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7786.41 toks/s, output: 1236.77 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [04:20<01:52,  5.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.76 toks/s, output: 41.78 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.01it/s, est. speed input: 5421.63 toks/s, output: 807.62 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:19<00:00, 18.01it/s, est. speed input: 7165.38 toks/s, output: 1285.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.04s/it, est. speed input: 468.10 toks/s, output: 238.90 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.22 toks/s, output: 396.52 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [04:47<03:55, 11.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.70 toks/s, output: 42.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.40it/s, est. speed input: 6700.05 toks/s, output: 998.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7702.80 toks/s, output: 1291.96 toks/s]
Processing batched inference:  71%|███████   | 47/66 [04:49<02:49,  8.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.41 toks/s, output: 41.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.05it/s, est. speed input: 7204.84 toks/s, output: 1066.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7773.82 toks/s, output: 1239.85 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [04:51<02:03,  6.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.52 toks/s, output: 41.89 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6730.93 toks/s, output: 999.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.00it/s, est. speed input: 7850.66 toks/s, output: 1300.21 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [04:53<01:33,  5.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.61 toks/s, output: 42.43 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6217.88 toks/s, output: 925.90 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.92it/s, est. speed input: 6771.58 toks/s, output: 1194.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.26it/s, est. speed input: 6771.58 toks/s, output: 1194.56 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [04:56<01:13,  4.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.84 toks/s, output: 41.79 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.74it/s, est. speed input: 5938.58 toks/s, output: 889.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 7676.77 toks/s, output: 1362.55 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [04:58<00:58,  3.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.65 toks/s, output: 42.43 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6221.04 toks/s, output: 930.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.67it/s, est. speed input: 5706.20 toks/s, output: 1040.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.52it/s, est. speed input: 5706.20 toks/s, output: 1040.21 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [05:01<00:49,  3.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 304.12 toks/s, output: 42.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 5704.27 toks/s, output: 849.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 7692.94 toks/s, output: 1401.44 toks/s]
Processing batched inference:  80%|████████  | 53/66 [05:03<00:41,  3.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.54 toks/s, output: 42.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7006.47 toks/s, output: 1035.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7768.66 toks/s, output: 1262.08 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [05:05<00:34,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.80 toks/s, output: 41.37 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.50it/s, est. speed input: 6147.13 toks/s, output: 913.85 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.37it/s, est. speed input: 6456.59 toks/s, output: 1147.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.45it/s, est. speed input: 6456.59 toks/s, output: 1147.89 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [05:08<00:30,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 299.56 toks/s, output: 42.79 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5684.41 toks/s, output: 853.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.51it/s, est. speed input: 7665.26 toks/s, output: 1397.94 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [05:10<00:26,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.33 toks/s, output: 42.00 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5962.00 toks/s, output: 886.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 7706.27 toks/s, output: 1366.20 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [05:12<00:22,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.00 toks/s, output: 42.34 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6203.29 toks/s, output: 917.80 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.38it/s, est. speed input: 2757.48 toks/s, output: 585.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s, est. speed input: 2757.48 toks/s, output: 585.74 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [05:18<00:26,  3.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.75 toks/s, output: 41.36 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.25it/s, est. speed input: 6656.12 toks/s, output: 983.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.50it/s, est. speed input: 7652.71 toks/s, output: 1271.79 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [05:20<00:21,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.43 toks/s, output: 42.40 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6212.06 toks/s, output: 923.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:15<00:00,  1.69it/s, est. speed input: 829.16 toks/s, output: 289.37 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:15<00:00,  2.11it/s, est. speed input: 829.16 toks/s, output: 289.37 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [05:36<00:41,  6.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.75 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 6733.73 toks/s, output: 1000.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7741.64 toks/s, output: 1297.35 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [05:38<00:27,  5.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.75 toks/s, output: 41.50 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.87it/s, est. speed input: 7153.04 toks/s, output: 1063.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 7715.52 toks/s, output: 1232.41 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [05:40<00:18,  4.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.73 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7262.89 toks/s, output: 1073.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6559.73 toks/s, output: 1069.96 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [05:43<00:11,  3.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.82 toks/s, output: 41.51 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.44it/s, est. speed input: 6423.24 toks/s, output: 953.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 7669.54 toks/s, output: 1306.03 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [05:45<00:06,  3.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.70 toks/s, output: 41.77 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.52it/s, est. speed input: 6454.81 toks/s, output: 959.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7704.03 toks/s, output: 1306.59 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [05:47<00:03,  3.09s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 337.59 toks/s, output: 46.62 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.67it/s, est. speed input: 6539.16 toks/s, output: 974.79 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.80it/s, est. speed input: 7380.69 toks/s, output: 1222.38 toks/s]
Processing batched inference: 100%|██████████| 66/66 [05:50<00:00,  2.79s/it]Processing batched inference: 100%|██████████| 66/66 [05:50<00:00,  5.30s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-189/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:28:39.911440559 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-252
INFO 07-05 10:28:52 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:28:54,412 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:28:54,466 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,486 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,486 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,486 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,486 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,486 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,486 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,486 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:28:54,870 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:28:54,872 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:28:54,877 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:28:54,884 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,885 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,885 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,885 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,885 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,885 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,885 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:28:54,885 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:28:55,261 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:28:55,263 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:28:55,460 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:28:55,891 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:28:55,945 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:28:55,945 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:28:55,947 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:29:07 [config.py:689] This model supports multiple tasks: {'generate', 'embed', 'classify', 'reward', 'score'}. Defaulting to 'generate'.
INFO 07-05 10:29:07 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:07,538 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:07,538 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:07,538 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:07,538 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:07,538 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:07,538 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:07,538 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:29:07,874 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:29:07,974 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:29:07,977 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:29:09 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:29:09 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:29:09 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252...
WARNING 07-05 10:29:09 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:29:09 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.39s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.39s/it]

INFO 07-05 10:29:17 [loader.py:458] Loading weights took 7.61 seconds
INFO 07-05 10:29:17 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.864529 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,177 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,178 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,178 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,178 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,178 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,178 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,178 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:29:18,587 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:29:18,683 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:29:18,683 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:29:18,684 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:29:18,684 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,686 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,686 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,686 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,686 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,686 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,686 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:29:18,686 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:29:19,444 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:29:19,445 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:29:19,445 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:29:19,905 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:29:20,540 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:29:21 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:29:23,311 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:29:24,299 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:29:24 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:30:03 [worker.py:267] Memory profiling takes 45.00 seconds
INFO 07-05 10:30:03 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:30:03 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:30:03 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:30:03 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:30:13 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:21,  1.56it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:19,  1.71it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.81it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.87it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:16,  1.87it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.88it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.90it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.91it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.91it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.92it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:12,  1.90it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.91it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.91it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.92it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.92it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:09<00:09,  1.91it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.92it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:10<00:08,  1.93it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:11<00:07,  1.92it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.93it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.93it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.94it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.94it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.92it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.83it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.85it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.88it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.87it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.89it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.87it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.89it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.84it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.89it/s]
INFO 07-05 10:30:31 [model_runner.py:1598] Graph capturing finished in 19 secs, took 0.33 GiB
INFO 07-05 10:30:31 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 73.93 seconds
[INFO|2025-07-05 10:30:32] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:30:33,363 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:30:33,363 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:33,364 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:33,364 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:33,364 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:33,364 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:33,365 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:33,365 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:33,365 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:30:34,525 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:30:34,525 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:30:34,526 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:30:35,084 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-252', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it, est. speed input: 233.50 toks/s, output: 32.33 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.80it/s, est. speed input: 5843.94 toks/s, output: 870.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.01it/s, est. speed input: 6290.73 toks/s, output: 1005.51 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:15,  4.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.42 toks/s, output: 42.29 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.50it/s, est. speed input: 6466.99 toks/s, output: 959.96 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 21.50it/s, est. speed input: 7535.77 toks/s, output: 1266.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 481.81 toks/s, output: 235.52 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.81 toks/s, output: 235.52 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:31<19:04, 17.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.59 toks/s, output: 42.17 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5979.08 toks/s, output: 891.84 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.32it/s, est. speed input: 6402.72 toks/s, output: 1154.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 20.32it/s, est. speed input: 6402.72 toks/s, output: 1154.80 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.43s/it, est. speed input: 481.91 toks/s, output: 241.18 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.91 toks/s, output: 241.18 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:58<23:09, 22.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.20 toks/s, output: 42.26 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.47it/s, est. speed input: 7656.67 toks/s, output: 1130.39 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 25.47it/s, est. speed input: 7656.67 toks/s, output: 1130.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.13s/it, est. speed input: 481.63 toks/s, output: 226.01 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.63 toks/s, output: 226.01 toks/s]
Processing batched inference:   6%|▌         | 4/66 [01:25<24:47, 24.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.85 toks/s, output: 42.24 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.71it/s, est. speed input: 6515.59 toks/s, output: 967.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 21.71it/s, est. speed input: 7532.65 toks/s, output: 1259.15 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 481.48 toks/s, output: 234.94 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.48 toks/s, output: 234.94 toks/s]
Processing batched inference:   8%|▊         | 5/66 [01:52<25:30, 25.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.46 toks/s, output: 42.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 6757.79 toks/s, output: 997.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 22.57it/s, est. speed input: 7525.44 toks/s, output: 1224.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 481.23 toks/s, output: 232.87 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.23 toks/s, output: 232.87 toks/s]
Processing batched inference:   9%|▉         | 6/66 [02:19<25:44, 25.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.53 toks/s, output: 42.03 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.87it/s, est. speed input: 7170.13 toks/s, output: 1062.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.23it/s, est. speed input: 6766.14 toks/s, output: 1103.00 toks/s]
Processing batched inference:  11%|█         | 7/66 [02:22<17:54, 18.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.08 toks/s, output: 42.10 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.40it/s, est. speed input: 7297.27 toks/s, output: 1083.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 7810.62 toks/s, output: 1245.32 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [02:25<12:44, 13.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.19 toks/s, output: 42.12 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.42it/s, est. speed input: 7295.01 toks/s, output: 1075.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 7806.57 toks/s, output: 1236.73 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [02:27<09:18,  9.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.01 toks/s, output: 42.23 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.86it/s, est. speed input: 7176.25 toks/s, output: 1062.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 7830.63 toks/s, output: 1248.91 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [02:29<07:00,  7.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.58 toks/s, output: 42.03 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.26it/s, est. speed input: 7536.97 toks/s, output: 1108.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7796.00 toks/s, output: 1205.44 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [02:32<05:27,  5.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.38 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5965.28 toks/s, output: 890.42 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.05it/s, est. speed input: 6574.84 toks/s, output: 1201.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.73it/s, est. speed input: 6574.84 toks/s, output: 1201.79 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [02:34<04:27,  4.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.58 toks/s, output: 42.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.48it/s, est. speed input: 6797.68 toks/s, output: 1011.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7770.65 toks/s, output: 1275.74 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [02:37<03:40,  4.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 306.46 toks/s, output: 41.65 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7027.00 toks/s, output: 1036.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7790.22 toks/s, output: 1261.12 toks/s]
Processing batched inference:  21%|██        | 14/66 [02:39<03:07,  3.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.44 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6491.27 toks/s, output: 965.10 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 21.64it/s, est. speed input: 7505.47 toks/s, output: 1249.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 481.26 toks/s, output: 234.52 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.26 toks/s, output: 234.52 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [03:06<09:02, 10.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.90 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.70it/s, est. speed input: 6557.74 toks/s, output: 975.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7744.58 toks/s, output: 1301.54 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [03:08<06:48,  8.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.14 toks/s, output: 41.23 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.17it/s, est. speed input: 6323.71 toks/s, output: 939.13 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:17<00:00, 21.17it/s, est. speed input: 5230.48 toks/s, output: 923.10 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.10s/it, est. speed input: 468.26 toks/s, output: 237.53 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.37 toks/s, output: 395.09 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [03:35<11:15, 13.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 295.14 toks/s, output: 40.76 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.74it/s, est. speed input: 7086.28 toks/s, output: 1047.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.34it/s, est. speed input: 7592.47 toks/s, output: 1208.09 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [03:38<08:21, 10.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.34 toks/s, output: 41.40 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.23it/s, est. speed input: 6348.13 toks/s, output: 946.56 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 21.23it/s, est. speed input: 7344.57 toks/s, output: 1233.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 480.99 toks/s, output: 235.04 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.99 toks/s, output: 235.04 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [04:05<12:07, 15.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 292.11 toks/s, output: 41.73 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.97it/s, est. speed input: 6277.57 toks/s, output: 939.78 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:13<00:00, 20.97it/s, est. speed input: 6019.54 toks/s, output: 1020.35 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.10s/it, est. speed input: 468.69 toks/s, output: 234.46 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.72 toks/s, output: 392.02 toks/s]
Processing batched inference:  30%|███       | 20/66 [04:32<14:29, 18.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:44,  1.43s/it, est. speed input: 273.18 toks/s, output: 37.82 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 22.44it/s, est. speed input: 6722.28 toks/s, output: 996.12 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 22.44it/s, est. speed input: 5950.83 toks/s, output: 929.54 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 479.08 toks/s, output: 228.69 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 479.08 toks/s, output: 228.69 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [04:59<16:02, 21.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.84 toks/s, output: 40.82 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.72it/s, est. speed input: 5321.57 toks/s, output: 790.61 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.19it/s, est. speed input: 5388.30 toks/s, output: 1033.73 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 16.19it/s, est. speed input: 5388.30 toks/s, output: 1033.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.39s/it, est. speed input: 480.50 toks/s, output: 245.93 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.50 toks/s, output: 245.93 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [05:27<17:05, 23.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.47 toks/s, output: 40.77 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.88it/s, est. speed input: 6832.88 toks/s, output: 1009.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7580.93 toks/s, output: 1231.99 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [05:29<12:12, 17.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.24 toks/s, output: 40.88 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.85it/s, est. speed input: 7116.34 toks/s, output: 1051.00 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:17<00:00, 23.85it/s, est. speed input: 7146.88 toks/s, output: 1085.13 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.14s/it, est. speed input: 467.55 toks/s, output: 226.07 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.57 toks/s, output: 383.44 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [05:56<13:59, 19.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.46 toks/s, output: 40.91 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.24it/s, est. speed input: 6695.61 toks/s, output: 993.58 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:12<00:00, 22.24it/s, est. speed input: 7121.54 toks/s, output: 1115.47 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.13s/it, est. speed input: 467.27 toks/s, output: 228.11 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.36 toks/s, output: 385.37 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [06:23<15:04, 22.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.05 toks/s, output: 40.71 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.11it/s, est. speed input: 6381.19 toks/s, output: 953.35 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 21.11it/s, est. speed input: 7328.07 toks/s, output: 1210.61 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 481.11 toks/s, output: 233.67 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 481.11 toks/s, output: 233.67 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [06:50<15:42, 23.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.10 toks/s, output: 40.72 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.78it/s, est. speed input: 7091.06 toks/s, output: 1046.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6432.93 toks/s, output: 1049.79 toks/s]
Processing batched inference:  41%|████      | 27/66 [06:53<11:13, 17.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.14 toks/s, output: 40.87 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.80it/s, est. speed input: 6823.40 toks/s, output: 1011.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 7600.50 toks/s, output: 1243.36 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [06:55<08:07, 12.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.44 toks/s, output: 40.91 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.76it/s, est. speed input: 6248.50 toks/s, output: 929.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 20.76it/s, est. speed input: 7341.54 toks/s, output: 1236.95 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 480.92 toks/s, output: 235.18 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.92 toks/s, output: 235.18 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [07:22<10:30, 17.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.06 toks/s, output: 40.99 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.02it/s, est. speed input: 7165.89 toks/s, output: 1064.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 7811.22 toks/s, output: 1238.44 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [07:24<07:33, 12.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.52 toks/s, output: 41.06 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.99it/s, est. speed input: 6870.96 toks/s, output: 1016.13 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 22.99it/s, est. speed input: 7408.58 toks/s, output: 1176.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.08s/it, est. speed input: 480.67 toks/s, output: 230.73 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.67 toks/s, output: 230.73 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [07:51<09:49, 16.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.63 toks/s, output: 41.21 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.90it/s, est. speed input: 7420.04 toks/s, output: 1092.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7683.70 toks/s, output: 1191.47 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [07:53<07:04, 12.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.54 toks/s, output: 40.78 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.40it/s, est. speed input: 6736.22 toks/s, output: 1003.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.17it/s, est. speed input: 5571.14 toks/s, output: 958.41 toks/s] 
Processing batched inference:  50%|█████     | 33/66 [07:56<05:17,  9.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.80 toks/s, output: 40.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.78it/s, est. speed input: 6256.73 toks/s, output: 932.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.62it/s, est. speed input: 6285.82 toks/s, output: 1084.09 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.62it/s, est. speed input: 6285.82 toks/s, output: 1084.09 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.46s/it, est. speed input: 481.29 toks/s, output: 237.18 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 481.29 toks/s, output: 237.18 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [08:23<07:54, 14.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.01 toks/s, output: 41.12 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.84it/s, est. speed input: 7406.45 toks/s, output: 1092.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 7660.24 toks/s, output: 1185.38 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [08:26<05:43, 11.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:43,  1.41s/it, est. speed input: 276.61 toks/s, output: 38.30 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 20.97it/s, est. speed input: 6247.13 toks/s, output: 923.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 18.34it/s, est. speed input: 7199.93 toks/s, output: 1198.55 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [08:28<04:16,  8.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:43,  1.39s/it, est. speed input: 280.54 toks/s, output: 38.84 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.94it/s, est. speed input: 6823.96 toks/s, output: 1009.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 18.90it/s, est. speed input: 7415.66 toks/s, output: 1172.84 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [08:31<03:14,  6.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:47,  1.53s/it, est. speed input: 255.98 toks/s, output: 36.01 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 19.80it/s, est. speed input: 5873.34 toks/s, output: 877.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.24it/s, est. speed input: 6777.40 toks/s, output: 1139.98 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [08:33<02:34,  5.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:48,  1.56s/it, est. speed input: 250.05 toks/s, output: 34.62 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 15.60it/s, est. speed input: 4643.03 toks/s, output: 690.64 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 18.50it/s, est. speed input: 5551.57 toks/s, output: 1042.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.77it/s, est. speed input: 5016.57 toks/s, output: 994.61 toks/s] 
Processing batched inference:  59%|█████▉    | 39/66 [08:38<02:19,  5.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:43,  1.42s/it, est. speed input: 274.92 toks/s, output: 38.07 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 21.68it/s, est. speed input: 6459.36 toks/s, output: 962.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.60it/s, est. speed input: 6129.55 toks/s, output: 1027.03 toks/s]
Processing batched inference:  61%|██████    | 40/66 [08:41<01:57,  4.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:46,  1.49s/it, est. speed input: 261.72 toks/s, output: 36.24 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 19.30it/s, est. speed input: 5737.77 toks/s, output: 851.72 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 19.55it/s, est. speed input: 6057.55 toks/s, output: 1055.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.43it/s, est. speed input: 6057.55 toks/s, output: 1055.47 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [08:44<01:41,  4.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.99 toks/s, output: 41.67 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.39it/s, est. speed input: 6985.76 toks/s, output: 1032.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7772.72 toks/s, output: 1261.92 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [08:46<01:25,  3.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.66 toks/s, output: 41.35 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.80it/s, est. speed input: 7690.87 toks/s, output: 1134.18 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 25.80it/s, est. speed input: 7690.87 toks/s, output: 1134.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.13s/it, est. speed input: 480.65 toks/s, output: 225.47 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.65 toks/s, output: 225.47 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [09:13<04:03, 10.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.20 toks/s, output: 41.57 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.59it/s, est. speed input: 6169.26 toks/s, output: 912.32 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.73it/s, est. speed input: 6262.62 toks/s, output: 1074.36 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 19.73it/s, est. speed input: 4497.54 toks/s, output: 852.16 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 480.93 toks/s, output: 245.24 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.93 toks/s, output: 245.24 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [09:40<05:39, 15.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.80 toks/s, output: 41.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.01it/s, est. speed input: 7758.52 toks/s, output: 1143.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7765.43 toks/s, output: 1174.70 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [09:42<04:00, 11.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.04 toks/s, output: 42.10 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.87it/s, est. speed input: 5969.01 toks/s, output: 886.66 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:14<00:00, 19.87it/s, est. speed input: 7232.14 toks/s, output: 1238.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.07s/it, est. speed input: 468.36 toks/s, output: 235.33 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.48 toks/s, output: 393.04 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [10:09<05:20, 16.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.89 toks/s, output: 41.55 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.14it/s, est. speed input: 7217.53 toks/s, output: 1073.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7727.96 toks/s, output: 1235.95 toks/s]
Processing batched inference:  71%|███████   | 47/66 [10:11<03:46, 11.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.23 toks/s, output: 42.23 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.31it/s, est. speed input: 6963.57 toks/s, output: 1034.14 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 23.31it/s, est. speed input: 5681.97 toks/s, output: 949.48 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.08s/it, est. speed input: 481.34 toks/s, output: 234.83 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.34 toks/s, output: 234.83 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [10:38<04:54, 16.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.62 toks/s, output: 41.76 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.66it/s, est. speed input: 6196.13 toks/s, output: 920.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7691.79 toks/s, output: 1335.14 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [10:40<03:26, 12.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.32 toks/s, output: 40.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.33it/s, est. speed input: 6400.31 toks/s, output: 947.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 7639.23 toks/s, output: 1294.08 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [10:42<02:27,  9.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.51 toks/s, output: 41.61 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.70it/s, est. speed input: 5918.74 toks/s, output: 882.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 7646.90 toks/s, output: 1361.51 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [10:45<01:46,  7.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.14 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6742.62 toks/s, output: 1003.82 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 22.49it/s, est. speed input: 7508.89 toks/s, output: 1234.83 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 481.83 toks/s, output: 233.73 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.83 toks/s, output: 233.73 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [11:11<03:02, 13.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.37 toks/s, output: 42.39 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.08it/s, est. speed input: 5433.18 toks/s, output: 809.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 18.08it/s, est. speed input: 7419.33 toks/s, output: 1362.70 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.01s/it, est. speed input: 480.87 toks/s, output: 242.33 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.87 toks/s, output: 242.33 toks/s]
Processing batched inference:  80%|████████  | 53/66 [11:38<03:42, 17.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.61 toks/s, output: 41.62 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.19it/s, est. speed input: 7220.32 toks/s, output: 1065.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7731.31 toks/s, output: 1227.69 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [11:40<02:32, 12.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.61 toks/s, output: 41.62 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.61it/s, est. speed input: 6179.24 toks/s, output: 916.48 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.04it/s, est. speed input: 6325.44 toks/s, output: 1085.84 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 20.04it/s, est. speed input: 6293.73 toks/s, output: 1126.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 480.79 toks/s, output: 240.13 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.79 toks/s, output: 240.13 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [12:07<03:06, 16.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 294.98 toks/s, output: 40.84 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.40it/s, est. speed input: 5826.61 toks/s, output: 871.30 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.34it/s, est. speed input: 5543.19 toks/s, output: 1035.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.11it/s, est. speed input: 5543.19 toks/s, output: 1035.18 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [12:10<02:07, 12.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.48 toks/s, output: 41.47 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.43it/s, est. speed input: 6416.24 toks/s, output: 950.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 7660.85 toks/s, output: 1300.80 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [12:12<01:26,  9.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.37 toks/s, output: 41.69 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.85it/s, est. speed input: 5356.03 toks/s, output: 796.17 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:14<00:00, 17.85it/s, est. speed input: 7081.51 toks/s, output: 1274.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:22<00:00,  1.12it/s, est. speed input: 542.12 toks/s, output: 251.07 toks/s]  [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.05s/it, est. speed input: 482.54 toks/s, output: 373.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.54 toks/s, output: 373.85 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [12:39<01:58, 14.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.00 toks/s, output: 41.26 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.54it/s, est. speed input: 7061.23 toks/s, output: 1043.04 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 23.54it/s, est. speed input: 6486.89 toks/s, output: 1031.81 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 481.03 toks/s, output: 231.01 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.03 toks/s, output: 231.01 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [13:06<02:08, 18.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.71 toks/s, output: 41.91 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.59it/s, est. speed input: 6755.53 toks/s, output: 998.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 22.59it/s, est. speed input: 7494.27 toks/s, output: 1218.74 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 480.93 toks/s, output: 232.65 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.93 toks/s, output: 232.65 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [13:33<02:05, 20.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.97 toks/s, output: 41.63 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.69it/s, est. speed input: 5606.93 toks/s, output: 837.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.25it/s, est. speed input: 7565.28 toks/s, output: 1380.91 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [13:35<01:16, 15.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.29 toks/s, output: 41.16 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.06it/s, est. speed input: 6329.56 toks/s, output: 943.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 21.06it/s, est. speed input: 7377.93 toks/s, output: 1241.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 480.84 toks/s, output: 235.05 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.84 toks/s, output: 235.05 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [14:02<01:15, 18.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.32 toks/s, output: 41.30 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.04it/s, est. speed input: 6893.86 toks/s, output: 1021.65 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 23.04it/s, est. speed input: 7406.42 toks/s, output: 1182.97 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 480.69 toks/s, output: 231.12 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.69 toks/s, output: 231.12 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [14:29<01:03, 21.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.15 toks/s, output: 41.42 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.27it/s, est. speed input: 6663.28 toks/s, output: 984.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.98it/s, est. speed input: 6665.85 toks/s, output: 1136.17 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [14:31<00:31, 15.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.11 toks/s, output: 41.69 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.64it/s, est. speed input: 6187.58 toks/s, output: 916.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 7677.47 toks/s, output: 1336.93 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [14:34<00:11, 11.58s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 333.62 toks/s, output: 46.93 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.65it/s, est. speed input: 6224.03 toks/s, output: 928.32 toks/s][A
Processed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.79it/s, est. speed input: 6131.23 toks/s, output: 1069.54 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 15.61it/s, est. speed input: 6131.23 toks/s, output: 1069.54 toks/s]
Processing batched inference: 100%|██████████| 66/66 [14:36<00:00,  8.83s/it]Processing batched inference: 100%|██████████| 66/66 [14:36<00:00, 13.28s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-252/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:45:10.924542083 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-315
INFO 07-05 10:45:23 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:45:25,326 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:45:25,368 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,387 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,387 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,387 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,387 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,387 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,387 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,387 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:45:25,776 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:45:25,777 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:45:25,782 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:45:25,788 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,790 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,790 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,790 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,790 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,790 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,790 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:25,790 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:45:26,162 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:45:26,164 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:45:26,360 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:45:26,796 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:45:26,851 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:45:26,852 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:45:26,854 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:45:38 [config.py:689] This model supports multiple tasks: {'generate', 'score', 'reward', 'embed', 'classify'}. Defaulting to 'generate'.
INFO 07-05 10:45:38 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:38,672 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:38,672 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:38,672 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:38,672 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:38,672 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:38,672 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:38,672 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:45:39,023 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:45:39,109 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:45:39,110 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:45:40 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:45:40 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:45:40 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315...
WARNING 07-05 10:45:41 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:45:41 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.22s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.22s/it]

INFO 07-05 10:45:48 [loader.py:458] Loading weights took 7.44 seconds
INFO 07-05 10:45:48 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.690281 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,104 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,104 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,104 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,104 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,104 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,104 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,104 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:45:49,493 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:45:49,585 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:45:49,585 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:45:49,586 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:45:49,587 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,587 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,587 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,587 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,587 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,587 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,587 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:45:49,587 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:45:50,372 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:45:50,373 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:45:50,373 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:45:50,854 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:45:51,528 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:45:52 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:45:54,359 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:45:55,365 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:45:55 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:46:34 [worker.py:267] Memory profiling takes 45.15 seconds
INFO 07-05 10:46:34 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:46:34 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:46:34 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:46:34 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:46:40 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.75it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.87it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.88it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.91it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.92it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.90it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.92it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.88it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:12,  1.90it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.92it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.92it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.89it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.91it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.91it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.91it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.93it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.90it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.92it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.92it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.91it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.93it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.93it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.92it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.83it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.84it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.88it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.91it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.92it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.93it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.94it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.90it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]
INFO 07-05 10:46:59 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:46:59 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 70.23 seconds
[INFO|2025-07-05 10:46:59] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:47:00,526 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:47:00,526 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:47:00,527 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:47:00,527 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:47:00,527 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:47:00,527 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:47:00,527 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:47:00,527 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:47:00,527 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:47:01,731 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:47:01,732 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:47:01,732 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:47:02,240 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-315', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.63s/it, est. speed input: 239.50 toks/s, output: 33.16 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 19.42it/s, est. speed input: 5750.52 toks/s, output: 860.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.29it/s, est. speed input: 6401.58 toks/s, output: 1044.10 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:04,  4.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.97 toks/s, output: 42.23 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.27it/s, est. speed input: 6982.44 toks/s, output: 1034.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7802.15 toks/s, output: 1275.83 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:35,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.64 toks/s, output: 42.18 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.26it/s, est. speed input: 5207.10 toks/s, output: 778.15 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.73it/s, est. speed input: 6559.31 toks/s, output: 1277.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6559.31 toks/s, output: 1277.53 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:12,  3.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.12 toks/s, output: 42.11 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.41it/s, est. speed input: 7295.18 toks/s, output: 1078.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 7801.61 toks/s, output: 1234.60 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:53,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.59 toks/s, output: 42.17 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6506.38 toks/s, output: 966.26 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 21.69it/s, est. speed input: 6362.95 toks/s, output: 1093.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 481.28 toks/s, output: 237.02 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.28 toks/s, output: 237.02 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:39<11:44, 11.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.53 toks/s, output: 42.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.59it/s, est. speed input: 6762.48 toks/s, output: 999.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7771.73 toks/s, output: 1288.88 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:41<08:26,  8.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.32 toks/s, output: 42.14 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.43it/s, est. speed input: 7299.77 toks/s, output: 1078.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 7816.33 toks/s, output: 1245.58 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:44<06:22,  6.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.85 toks/s, output: 42.07 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.38it/s, est. speed input: 7294.48 toks/s, output: 1085.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7800.39 toks/s, output: 1241.20 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:46<05:05,  5.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.42 toks/s, output: 42.15 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 6760.07 toks/s, output: 999.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7770.86 toks/s, output: 1289.26 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:49<04:08,  4.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.03 toks/s, output: 42.10 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.56it/s, est. speed input: 6756.05 toks/s, output: 999.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.28it/s, est. speed input: 1680.22 toks/s, output: 408.92 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:57<05:11,  5.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.44 toks/s, output: 42.15 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.49it/s, est. speed input: 7020.91 toks/s, output: 1033.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7786.22 toks/s, output: 1265.34 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:59<04:13,  4.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.60 toks/s, output: 42.04 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.65it/s, est. speed input: 7123.77 toks/s, output: 1058.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7803.03 toks/s, output: 1249.40 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [01:02<03:31,  3.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.79 toks/s, output: 42.45 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 6739.94 toks/s, output: 1002.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7750.12 toks/s, output: 1297.64 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:04<03:02,  3.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.92 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.61it/s, est. speed input: 6764.32 toks/s, output: 1004.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.33it/s, est. speed input: 7975.99 toks/s, output: 1314.07 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:06<02:41,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.48 toks/s, output: 41.51 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6751.02 toks/s, output: 1001.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.76it/s, est. speed input: 1084.46 toks/s, output: 325.14 toks/s] 
Processing batched inference:  23%|██▎       | 15/66 [01:19<05:01,  5.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.17 toks/s, output: 41.98 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.62it/s, est. speed input: 7115.13 toks/s, output: 1058.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7792.54 toks/s, output: 1248.24 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:21<04:02,  4.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 299.35 toks/s, output: 42.11 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.51it/s, est. speed input: 6433.47 toks/s, output: 955.43 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:17<00:00, 21.51it/s, est. speed input: 7199.39 toks/s, output: 1182.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.10s/it, est. speed input: 468.40 toks/s, output: 232.07 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.52 toks/s, output: 389.67 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:48<09:21, 11.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.72 toks/s, output: 40.81 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.01it/s, est. speed input: 6584.33 toks/s, output: 976.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.29it/s, est. speed input: 7573.69 toks/s, output: 1258.76 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:51<07:02,  8.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.46 toks/s, output: 41.42 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.97it/s, est. speed input: 6857.20 toks/s, output: 1019.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7607.10 toks/s, output: 1241.92 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:53<05:24,  6.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 292.94 toks/s, output: 41.21 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.66it/s, est. speed input: 6777.89 toks/s, output: 1009.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.34it/s, est. speed input: 6420.00 toks/s, output: 1076.71 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:56<04:19,  5.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.07 toks/s, output: 40.72 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.79it/s, est. speed input: 7094.09 toks/s, output: 1048.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.36it/s, est. speed input: 7601.34 toks/s, output: 1211.32 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:58<03:31,  4.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.56 toks/s, output: 40.65 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.06it/s, est. speed input: 4831.57 toks/s, output: 723.62 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.66it/s, est. speed input: 5958.06 toks/s, output: 1145.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.84it/s, est. speed input: 1114.09 toks/s, output: 363.17 toks/s] 
Processing batched inference:  33%|███▎      | 22/66 [02:11<05:06,  6.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.75 toks/s, output: 40.81 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.03it/s, est. speed input: 6589.53 toks/s, output: 977.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.31it/s, est. speed input: 7579.50 toks/s, output: 1257.71 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [02:13<04:01,  5.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 294.97 toks/s, output: 40.84 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.85it/s, est. speed input: 7113.82 toks/s, output: 1050.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 23.85it/s, est. speed input: 7381.76 toks/s, output: 1144.84 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.68 toks/s, output: 228.98 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.68 toks/s, output: 228.98 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [02:40<08:23, 11.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.04 toks/s, output: 40.57 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.05it/s, est. speed input: 6298.47 toks/s, output: 933.90 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  2.40it/s, est. speed input: 1168.00 toks/s, output: 342.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:10<00:00,  2.98it/s, est. speed input: 1168.00 toks/s, output: 342.32 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:51<08:06, 11.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.57 toks/s, output: 40.79 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.14it/s, est. speed input: 6390.69 toks/s, output: 954.77 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.11it/s, est. speed input: 1498.66 toks/s, output: 389.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.81it/s, est. speed input: 1498.66 toks/s, output: 389.74 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [03:01<07:21, 11.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.47 toks/s, output: 40.91 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.95it/s, est. speed input: 6859.07 toks/s, output: 1016.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.38it/s, est. speed input: 7608.96 toks/s, output: 1236.86 toks/s]
Processing batched inference:  41%|████      | 27/66 [03:03<05:28,  8.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.81 toks/s, output: 40.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.45it/s, est. speed input: 6741.37 toks/s, output: 1000.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.33it/s, est. speed input: 7593.60 toks/s, output: 1244.04 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [03:05<04:11,  6.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.47 toks/s, output: 40.77 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.90it/s, est. speed input: 6901.09 toks/s, output: 1026.88 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 22.90it/s, est. speed input: 6261.58 toks/s, output: 1031.85 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.75it/s, est. speed input: 898.55 toks/s, output: 295.04 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.29it/s, est. speed input: 898.55 toks/s, output: 295.04 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [03:20<05:35,  9.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.37 toks/s, output: 41.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.09it/s, est. speed input: 6898.82 toks/s, output: 1024.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 7676.59 toks/s, output: 1247.04 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [03:22<04:12,  7.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 296.74 toks/s, output: 41.09 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.14it/s, est. speed input: 6619.88 toks/s, output: 979.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.50it/s, est. speed input: 979.37 toks/s, output: 304.98 toks/s] 
Processing batched inference:  47%|████▋     | 31/66 [03:36<05:12,  8.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.39 toks/s, output: 41.41 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.11it/s, est. speed input: 6596.21 toks/s, output: 975.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.34it/s, est. speed input: 7589.11 toks/s, output: 1261.42 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [03:38<03:56,  6.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.41 toks/s, output: 40.76 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.18it/s, est. speed input: 6684.39 toks/s, output: 997.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.17it/s, est. speed input: 5571.90 toks/s, output: 960.31 toks/s]
Processing batched inference:  50%|█████     | 33/66 [03:41<03:10,  5.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.07 toks/s, output: 40.85 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.84it/s, est. speed input: 7118.96 toks/s, output: 1057.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6515.50 toks/s, output: 1066.31 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [03:44<02:35,  4.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.70 toks/s, output: 41.50 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.03it/s, est. speed input: 7466.14 toks/s, output: 1101.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7722.55 toks/s, output: 1195.03 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [03:46<02:06,  4.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.66 toks/s, output: 41.77 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.65it/s, est. speed input: 6195.62 toks/s, output: 919.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.47it/s, est. speed input: 6496.47 toks/s, output: 1154.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6496.47 toks/s, output: 1154.37 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [03:49<01:48,  3.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.94 toks/s, output: 41.67 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.26it/s, est. speed input: 6958.63 toks/s, output: 1030.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7711.75 toks/s, output: 1249.76 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [03:51<01:33,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.83 toks/s, output: 41.61 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.17it/s, est. speed input: 6629.86 toks/s, output: 990.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.82it/s, est. speed input: 1499.98 toks/s, output: 395.50 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [04:00<02:19,  4.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.93 toks/s, output: 41.25 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.71it/s, est. speed input: 5617.35 toks/s, output: 834.22 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.71it/s, est. speed input: 5596.15 toks/s, output: 1067.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.25it/s, est. speed input: 5596.15 toks/s, output: 1067.66 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [04:03<01:57,  4.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.64 toks/s, output: 41.35 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.12it/s, est. speed input: 6921.03 toks/s, output: 1030.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 7676.32 toks/s, output: 1256.89 toks/s]
Processing batched inference:  61%|██████    | 40/66 [04:05<01:36,  3.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.35 toks/s, output: 41.45 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6411.74 toks/s, output: 950.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  2.77it/s, est. speed input: 1332.63 toks/s, output: 373.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.39it/s, est. speed input: 1332.63 toks/s, output: 373.17 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [04:15<02:20,  5.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.33 toks/s, output: 41.72 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 6732.59 toks/s, output: 997.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.62it/s, est. speed input: 1030.23 toks/s, output: 316.89 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [04:28<03:07,  7.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.64 toks/s, output: 40.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.62it/s, est. speed input: 7630.28 toks/s, output: 1124.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7698.41 toks/s, output: 1163.09 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [04:30<02:21,  6.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.51 toks/s, output: 41.75 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.41it/s, est. speed input: 6708.81 toks/s, output: 992.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.09it/s, est. speed input: 6703.38 toks/s, output: 1132.80 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [04:33<01:51,  5.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.26 toks/s, output: 41.44 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.98it/s, est. speed input: 7452.58 toks/s, output: 1098.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6576.45 toks/s, output: 1045.10 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [04:35<01:29,  4.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.61 toks/s, output: 41.62 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.70it/s, est. speed input: 5913.47 toks/s, output: 877.34 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:13<00:00, 19.70it/s, est. speed input: 7167.53 toks/s, output: 1229.39 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.07s/it, est. speed input: 468.00 toks/s, output: 235.27 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.11 toks/s, output: 392.85 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [05:02<03:40, 11.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.59 toks/s, output: 41.51 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.13it/s, est. speed input: 7212.90 toks/s, output: 1072.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 7724.06 toks/s, output: 1235.33 toks/s]
Processing batched inference:  71%|███████   | 47/66 [05:04<02:39,  8.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.30 toks/s, output: 42.24 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.54it/s, est. speed input: 6444.19 toks/s, output: 956.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.58it/s, est. speed input: 6563.36 toks/s, output: 1147.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6563.36 toks/s, output: 1147.08 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [05:07<01:59,  6.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.47 toks/s, output: 41.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.91it/s, est. speed input: 6259.40 toks/s, output: 929.81 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.30it/s, est. speed input: 1109.63 toks/s, output: 332.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.83it/s, est. speed input: 1109.63 toks/s, output: 332.21 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [05:19<02:19,  8.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 299.29 toks/s, output: 40.57 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.03it/s, est. speed input: 7176.71 toks/s, output: 1060.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7764.77 toks/s, output: 1226.30 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [05:21<01:43,  6.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.49 toks/s, output: 41.33 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.59it/s, est. speed input: 5886.46 toks/s, output: 879.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.54it/s, est. speed input: 6624.61 toks/s, output: 1202.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.87it/s, est. speed input: 6624.61 toks/s, output: 1202.16 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [05:24<01:18,  5.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.63 toks/s, output: 42.15 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.75it/s, est. speed input: 5923.19 toks/s, output: 885.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.66it/s, est. speed input: 6475.58 toks/s, output: 1183.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6475.58 toks/s, output: 1183.55 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [05:26<01:02,  4.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.68 toks/s, output: 41.87 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.66it/s, est. speed input: 5888.62 toks/s, output: 875.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.58it/s, est. speed input: 6630.56 toks/s, output: 1207.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.88it/s, est. speed input: 6630.56 toks/s, output: 1207.37 toks/s]
Processing batched inference:  80%|████████  | 53/66 [05:29<00:50,  3.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.64 toks/s, output: 42.15 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.13it/s, est. speed input: 7485.24 toks/s, output: 1107.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 7980.01 toks/s, output: 1232.87 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [05:31<00:40,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.54 toks/s, output: 41.34 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.50it/s, est. speed input: 6145.04 toks/s, output: 911.95 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.17it/s, est. speed input: 1053.12 toks/s, output: 324.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.68it/s, est. speed input: 1053.12 toks/s, output: 324.24 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [05:43<01:07,  6.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.46 toks/s, output: 41.33 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.12it/s, est. speed input: 6916.26 toks/s, output: 1028.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6487.74 toks/s, output: 1088.25 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [05:46<00:50,  5.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.79 toks/s, output: 41.37 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.39it/s, est. speed input: 6401.35 toks/s, output: 945.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 21.39it/s, est. speed input: 7404.10 toks/s, output: 1236.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 480.43 toks/s, output: 234.44 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.43 toks/s, output: 234.44 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [06:13<01:44, 11.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.39 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.58it/s, est. speed input: 6156.38 toks/s, output: 912.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 7643.57 toks/s, output: 1329.71 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [06:15<01:10,  8.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.11 toks/s, output: 41.42 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.92it/s, est. speed input: 6869.05 toks/s, output: 1015.22 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 22.92it/s, est. speed input: 7431.95 toks/s, output: 1182.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.08s/it, est. speed input: 480.86 toks/s, output: 230.94 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.86 toks/s, output: 230.94 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [06:42<01:39, 14.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.00 toks/s, output: 41.54 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.55it/s, est. speed input: 6448.44 toks/s, output: 955.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.02it/s, est. speed input: 1445.54 toks/s, output: 377.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.68it/s, est. speed input: 1445.54 toks/s, output: 377.61 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [06:51<01:16, 12.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 299.32 toks/s, output: 42.10 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.63it/s, est. speed input: 6180.89 toks/s, output: 921.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.92it/s, est. speed input: 6342.98 toks/s, output: 1114.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.35it/s, est. speed input: 1316.90 toks/s, output: 370.99 toks/s] 
Processing batched inference:  92%|█████████▏| 61/66 [07:02<00:59, 12.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 296.71 toks/s, output: 41.08 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.78it/s, est. speed input: 6829.18 toks/s, output: 1015.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 7632.20 toks/s, output: 1248.85 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [07:04<00:36,  9.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.28 toks/s, output: 41.44 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.97it/s, est. speed input: 7450.56 toks/s, output: 1101.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 7710.30 toks/s, output: 1197.47 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [07:06<00:21,  7.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.58 toks/s, output: 41.48 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.31it/s, est. speed input: 6958.45 toks/s, output: 1027.35 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 23.31it/s, est. speed input: 7449.53 toks/s, output: 1189.54 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 480.76 toks/s, output: 231.13 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.76 toks/s, output: 231.13 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [07:33<00:25, 12.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.93 toks/s, output: 41.94 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6217.12 toks/s, output: 923.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.54it/s, est. speed input: 6518.55 toks/s, output: 1158.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6518.55 toks/s, output: 1158.99 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [07:35<00:09,  9.84s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 333.34 toks/s, output: 46.04 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.47it/s, est. speed input: 6473.75 toks/s, output: 965.04 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.61it/s, est. speed input: 7309.35 toks/s, output: 1210.57 toks/s]
Processing batched inference: 100%|██████████| 66/66 [07:38<00:00,  7.53s/it]Processing batched inference: 100%|██████████| 66/66 [07:38<00:00,  6.94s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-315/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:54:39.461101307 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-378
INFO 07-05 10:54:51 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:54:53,857 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:54:53,898 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:53,917 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:53,917 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:53,918 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:53,918 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:53,918 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:53,918 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:53,918 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:54:54,304 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:54:54,305 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:54:54,310 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:54:54,317 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:54,318 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:54,319 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:54,319 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:54,319 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:54,319 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:54,319 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:54:54,319 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:54:54,685 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:54:54,687 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:54:54,891 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:54:55,350 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:54:55,403 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:54:55,403 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:54:55,405 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:55:07 [config.py:689] This model supports multiple tasks: {'classify', 'embed', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 07-05 10:55:07 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:07,006 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:07,006 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:07,006 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:07,006 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:07,006 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:07,006 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:07,006 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:55:07,343 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:55:07,445 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:55:07,448 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:55:08 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:55:09 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:55:09 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378...
WARNING 07-05 10:55:09 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:55:09 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.38s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.38s/it]

INFO 07-05 10:55:17 [loader.py:458] Loading weights took 7.60 seconds
INFO 07-05 10:55:17 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.847378 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:17,649 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:17,649 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:17,649 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:17,649 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:17,649 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:17,649 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:17,649 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:55:18,058 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:55:18,155 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:55:18,156 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:55:18,156 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:55:18,156 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:18,157 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:18,157 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:18,157 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:18,157 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:18,157 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:18,157 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:55:18,157 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:55:18,921 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:55:18,922 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:55:18,922 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:55:19,374 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:55:20,026 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:55:20 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:55:22,878 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:55:23,899 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:55:24 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:56:02 [worker.py:267] Memory profiling takes 45.08 seconds
INFO 07-05 10:56:02 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:56:02 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:56:02 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:56:02 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:56:08 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:21,  1.56it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.78it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.87it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:16,  1.86it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.90it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.91it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.91it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.95it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.93it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.92it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.93it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.90it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.92it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.89it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.91it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.85it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.88it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.91it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.92it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.94it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.95it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]
INFO 07-05 10:56:26 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:56:26 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.39 seconds
[INFO|2025-07-05 10:56:27] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:56:28,243 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:56:28,243 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:56:28,244 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:56:28,244 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:56:28,244 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:56:28,244 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:56:28,244 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:56:28,244 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:56:28,244 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:56:29,382 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:56:29,383 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:56:29,383 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:56:29,958 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-378', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 237.52 toks/s, output: 32.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 20.03it/s, est. speed input: 5920.33 toks/s, output: 883.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.20it/s, est. speed input: 6366.47 toks/s, output: 1015.59 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:01,  4.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.06 toks/s, output: 42.24 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.50it/s, est. speed input: 7095.11 toks/s, output: 1052.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 7830.36 toks/s, output: 1252.40 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:35,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.75 toks/s, output: 42.20 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.98it/s, est. speed input: 6919.83 toks/s, output: 1029.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7791.38 toks/s, output: 1278.93 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:05,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.91 toks/s, output: 42.22 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.36it/s, est. speed input: 7571.57 toks/s, output: 1116.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 7828.37 toks/s, output: 1210.78 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:11<02:48,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.83 toks/s, output: 42.24 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.50it/s, est. speed input: 7038.79 toks/s, output: 1044.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.42it/s, est. speed input: 6839.94 toks/s, output: 1136.62 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:14<02:44,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.46 toks/s, output: 42.29 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.46it/s, est. speed input: 7654.17 toks/s, output: 1127.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.98it/s, est. speed input: 7840.52 toks/s, output: 1185.37 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:16<02:35,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.40 toks/s, output: 42.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 25.92it/s, est. speed input: 7822.76 toks/s, output: 1158.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.92it/s, est. speed input: 7822.76 toks/s, output: 1158.18 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:19<02:29,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.39 toks/s, output: 42.15 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.31it/s, est. speed input: 7563.55 toks/s, output: 1121.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 7821.66 toks/s, output: 1217.20 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:21<02:24,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.45 toks/s, output: 42.15 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7006.95 toks/s, output: 1035.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7795.26 toks/s, output: 1262.26 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:24<02:19,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.18 toks/s, output: 42.12 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.16it/s, est. speed input: 7584.09 toks/s, output: 1122.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 7828.79 toks/s, output: 1189.42 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:26<02:15,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.82 toks/s, output: 42.20 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 6755.72 toks/s, output: 994.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7766.16 toks/s, output: 1292.39 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:28<02:13,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.02 toks/s, output: 42.09 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.38it/s, est. speed input: 7291.46 toks/s, output: 1082.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7805.48 toks/s, output: 1247.30 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:31<02:09,  2.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.47 toks/s, output: 42.02 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.11it/s, est. speed input: 7572.56 toks/s, output: 1125.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 7816.76 toks/s, output: 1191.91 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:33<02:06,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.30 toks/s, output: 42.13 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.56it/s, est. speed input: 7329.34 toks/s, output: 1083.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.52it/s, est. speed input: 8050.19 toks/s, output: 1268.58 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:35<02:02,  2.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.20 toks/s, output: 42.12 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.47it/s, est. speed input: 7022.09 toks/s, output: 1038.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.89it/s, est. speed input: 6629.81 toks/s, output: 1103.64 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:38<02:04,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.49 toks/s, output: 42.02 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6747.08 toks/s, output: 1002.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7756.32 toks/s, output: 1300.42 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:40<02:01,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.60 toks/s, output: 42.56 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.58it/s, est. speed input: 6752.01 toks/s, output: 1001.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.84it/s, est. speed input: 6612.58 toks/s, output: 1127.70 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:43<02:01,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.49 toks/s, output: 42.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.20it/s, est. speed input: 7822.31 toks/s, output: 1156.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.56it/s, est. speed input: 8072.08 toks/s, output: 1220.15 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:45<01:56,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.46 toks/s, output: 42.16 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.42it/s, est. speed input: 7301.77 toks/s, output: 1083.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 7816.31 toks/s, output: 1248.09 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:48<01:52,  2.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.61 toks/s, output: 42.57 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.32it/s, est. speed input: 7325.41 toks/s, output: 1090.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7755.26 toks/s, output: 1214.93 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:50<01:48,  2.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.89 toks/s, output: 41.80 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.27it/s, est. speed input: 7248.95 toks/s, output: 1071.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7762.48 toks/s, output: 1237.00 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:52<01:46,  2.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.44 toks/s, output: 40.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.46it/s, est. speed input: 5835.33 toks/s, output: 865.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.22it/s, est. speed input: 7548.47 toks/s, output: 1348.69 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [00:55<01:46,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.86 toks/s, output: 40.83 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.96it/s, est. speed input: 7138.57 toks/s, output: 1055.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7600.64 toks/s, output: 1203.72 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [00:57<01:43,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.79 toks/s, output: 40.68 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 24.52it/s, est. speed input: 7373.30 toks/s, output: 1089.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00, 24.52it/s, est. speed input: 7373.30 toks/s, output: 1089.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:20<00:00,  1.16it/s, est. speed input: 622.27 toks/s, output: 244.10 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:20<00:00,  1.59it/s, est. speed input: 622.27 toks/s, output: 244.10 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:18<05:36,  8.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.58 toks/s, output: 40.79 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.89it/s, est. speed input: 6896.24 toks/s, output: 1023.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 22.89it/s, est. speed input: 5650.81 toks/s, output: 923.07 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.62 toks/s, output: 232.75 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.62 toks/s, output: 232.75 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:45<09:20, 13.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.77 toks/s, output: 40.81 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.21it/s, est. speed input: 6692.04 toks/s, output: 998.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7592.90 toks/s, output: 1248.98 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:48<06:51, 10.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.93 toks/s, output: 40.97 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.78it/s, est. speed input: 7387.17 toks/s, output: 1089.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 7650.17 toks/s, output: 1188.14 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:50<05:07,  7.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.06 toks/s, output: 40.85 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.85it/s, est. speed input: 7117.81 toks/s, output: 1054.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 7626.89 toks/s, output: 1218.55 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:52<03:56,  6.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.03 toks/s, output: 40.71 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.34it/s, est. speed input: 6428.84 toks/s, output: 956.77 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.88it/s, est. speed input: 938.02 toks/s, output: 300.76 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.39it/s, est. speed input: 938.02 toks/s, output: 300.76 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [02:06<05:17,  8.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.21 toks/s, output: 40.87 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.72it/s, est. speed input: 7374.44 toks/s, output: 1094.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.02it/s, est. speed input: 7861.62 toks/s, output: 1218.28 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:09<04:00,  6.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.29 toks/s, output: 40.89 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.59it/s, est. speed input: 7620.50 toks/s, output: 1121.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 7688.55 toks/s, output: 1160.38 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [02:11<03:07,  5.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.55 toks/s, output: 40.92 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 24.64it/s, est. speed input: 7406.65 toks/s, output: 1093.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 7645.83 toks/s, output: 1158.19 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [02:13<02:30,  4.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.36 toks/s, output: 40.90 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.24it/s, est. speed input: 6701.99 toks/s, output: 1000.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.20it/s, est. speed input: 5583.10 toks/s, output: 962.25 toks/s] 
Processing batched inference:  50%|█████     | 33/66 [02:16<02:11,  3.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.65 toks/s, output: 40.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.63it/s, est. speed input: 6506.34 toks/s, output: 966.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.34it/s, est. speed input: 7598.39 toks/s, output: 1274.95 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [02:19<01:53,  3.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.89 toks/s, output: 41.25 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.76it/s, est. speed input: 7676.59 toks/s, output: 1130.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 7686.79 toks/s, output: 1161.95 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:21<01:37,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.47 toks/s, output: 41.74 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.41it/s, est. speed input: 6708.16 toks/s, output: 992.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 7715.47 toks/s, output: 1284.37 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:23<01:26,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.42 toks/s, output: 42.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.88it/s, est. speed input: 8025.00 toks/s, output: 1181.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.44it/s, est. speed input: 8025.00 toks/s, output: 1181.66 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:25<01:17,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.13 toks/s, output: 41.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.57it/s, est. speed input: 7102.85 toks/s, output: 1060.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7779.25 toks/s, output: 1249.74 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:28<01:11,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.11 toks/s, output: 41.69 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.51it/s, est. speed input: 6445.76 toks/s, output: 956.28 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.44it/s, est. speed input: 6543.97 toks/s, output: 1146.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6543.97 toks/s, output: 1146.45 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:30<01:08,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.91 toks/s, output: 41.80 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.13it/s, est. speed input: 7512.85 toks/s, output: 1116.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7768.54 toks/s, output: 1210.21 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:32<01:03,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.45 toks/s, output: 41.88 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6727.61 toks/s, output: 993.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6530.78 toks/s, output: 1117.13 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:35<01:02,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.97it/s, est. speed input: 8044.33 toks/s, output: 1185.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.49it/s, est. speed input: 8044.33 toks/s, output: 1185.60 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:37<00:57,  2.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.87 toks/s, output: 41.80 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.15it/s, est. speed input: 7505.76 toks/s, output: 1106.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7764.05 toks/s, output: 1202.07 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:39<00:54,  2.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.35 toks/s, output: 42.00 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.37it/s, est. speed input: 7275.90 toks/s, output: 1071.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00, 24.37it/s, est. speed input: 7545.08 toks/s, output: 1167.74 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.79 toks/s, output: 229.00 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.79 toks/s, output: 229.00 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [03:06<03:33,  9.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.79 toks/s, output: 41.51 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.87it/s, est. speed input: 7715.71 toks/s, output: 1137.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7724.59 toks/s, output: 1169.13 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:08<02:36,  7.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.29 toks/s, output: 41.72 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.63it/s, est. speed input: 6187.11 toks/s, output: 917.11 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:12<00:00, 20.63it/s, est. speed input: 7200.42 toks/s, output: 1205.06 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.08s/it, est. speed input: 467.97 toks/s, output: 233.37 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.08 toks/s, output: 390.94 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [03:35<04:24, 13.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.98 toks/s, output: 42.20 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.25it/s, est. speed input: 7235.46 toks/s, output: 1076.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7747.52 toks/s, output: 1239.69 toks/s]
Processing batched inference:  71%|███████   | 47/66 [03:38<03:10, 10.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.22 toks/s, output: 41.39 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.72it/s, est. speed input: 7359.96 toks/s, output: 1089.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.39it/s, est. speed input: 7615.70 toks/s, output: 1184.92 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [03:40<02:20,  7.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.27 toks/s, output: 40.61 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.92it/s, est. speed input: 6554.49 toks/s, output: 970.89 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 21.92it/s, est. speed input: 7298.81 toks/s, output: 1187.86 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.26it/s, est. speed input: 639.63 toks/s, output: 255.31 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.63it/s, est. speed input: 639.63 toks/s, output: 255.31 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [04:01<03:16, 11.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.30 toks/s, output: 40.84 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.66it/s, est. speed input: 7386.64 toks/s, output: 1088.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7759.20 toks/s, output: 1200.08 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [04:03<02:20,  8.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.02 toks/s, output: 41.54 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.32it/s, est. speed input: 6684.27 toks/s, output: 992.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7687.55 toks/s, output: 1281.25 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [04:05<01:42,  6.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.47 toks/s, output: 41.33 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.11it/s, est. speed input: 6914.77 toks/s, output: 1026.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 7671.17 toks/s, output: 1256.86 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [04:07<01:16,  5.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.56 toks/s, output: 41.71 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.21it/s, est. speed input: 6633.67 toks/s, output: 982.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 7625.53 toks/s, output: 1275.06 toks/s]
Processing batched inference:  80%|████████  | 53/66 [04:10<00:59,  4.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.62 toks/s, output: 41.35 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 25.50it/s, est. speed input: 7680.84 toks/s, output: 1134.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 7680.84 toks/s, output: 1134.04 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [04:12<00:47,  3.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.13 toks/s, output: 41.42 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.28it/s, est. speed input: 6662.88 toks/s, output: 983.91 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 22.28it/s, est. speed input: 6291.23 toks/s, output: 1055.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 480.18 toks/s, output: 234.62 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.18 toks/s, output: 234.62 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [04:39<01:59, 10.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.33 toks/s, output: 41.03 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.08it/s, est. speed input: 6614.56 toks/s, output: 986.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.17it/s, est. speed input: 1637.70 toks/s, output: 401.83 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [04:48<01:41, 10.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.26 toks/s, output: 41.71 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.40it/s, est. speed input: 6698.26 toks/s, output: 986.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.24it/s, est. speed input: 1273.21 toks/s, output: 348.62 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [04:59<01:32, 10.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.93 toks/s, output: 42.05 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.49it/s, est. speed input: 6422.24 toks/s, output: 950.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 7668.54 toks/s, output: 1305.35 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [05:01<01:03,  7.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.96 toks/s, output: 41.81 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.68it/s, est. speed input: 7398.45 toks/s, output: 1091.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7773.38 toks/s, output: 1207.04 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [05:03<00:43,  6.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.62 toks/s, output: 41.62 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.34it/s, est. speed input: 6686.57 toks/s, output: 988.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.43it/s, est. speed input: 4486.68 toks/s, output: 813.28 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [05:07<00:32,  5.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.38 toks/s, output: 41.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.24it/s, est. speed input: 6362.17 toks/s, output: 945.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7592.94 toks/s, output: 1301.42 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [05:09<00:22,  4.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 296.62 toks/s, output: 41.07 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.68it/s, est. speed input: 7090.34 toks/s, output: 1053.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 7651.44 toks/s, output: 1223.40 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [05:11<00:15,  3.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.29 toks/s, output: 41.44 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.08it/s, est. speed input: 7191.65 toks/s, output: 1063.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6503.81 toks/s, output: 1060.32 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [05:14<00:10,  3.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.02 toks/s, output: 41.68 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.13it/s, est. speed input: 7268.53 toks/s, output: 1075.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7753.78 toks/s, output: 1207.41 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [05:16<00:06,  3.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.04 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6479.73 toks/s, output: 961.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7735.24 toks/s, output: 1314.35 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [05:18<00:02,  2.83s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.18s/it, est. speed input: 331.69 toks/s, output: 45.93 toks/s][A
Processed prompts:  93%|█████████▎| 26/28 [00:01<00:00, 23.37it/s, est. speed input: 7026.63 toks/s, output: 1042.93 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.66it/s, est. speed input: 7325.87 toks/s, output: 1152.01 toks/s]
Processing batched inference: 100%|██████████| 66/66 [05:20<00:00,  2.62s/it]Processing batched inference: 100%|██████████| 66/66 [05:20<00:00,  4.86s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-378/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:01:49.113830679 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-441
INFO 07-05 11:02:02 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:02:04,275 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:02:04,317 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,341 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,341 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,341 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,341 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,341 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,341 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,341 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:02:04,733 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:02:04,735 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:02:04,741 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:02:04,747 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,748 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,748 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,748 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,748 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,748 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,748 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:04,748 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:02:05,117 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:02:05,119 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:02:05,329 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:02:05,794 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:02:05,845 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:02:05,846 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:02:05,848 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:02:17 [config.py:689] This model supports multiple tasks: {'reward', 'classify', 'generate', 'score', 'embed'}. Defaulting to 'generate'.
INFO 07-05 11:02:17 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:17,685 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:17,685 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:17,685 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:17,685 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:17,685 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:17,685 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:17,685 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:02:18,017 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:02:18,118 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:02:18,120 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:02:19 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:02:19 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:02:19 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441...
WARNING 07-05 11:02:20 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:02:20 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.12s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.12s/it]

INFO 07-05 11:02:27 [loader.py:458] Loading weights took 7.33 seconds
INFO 07-05 11:02:27 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.575059 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:27,987 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:27,987 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:27,987 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:27,987 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:27,987 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:27,987 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:27,987 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:02:28,397 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:02:28,493 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:02:28,494 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:02:28,494 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:02:28,494 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:28,495 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:28,495 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:28,495 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:28,496 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:28,496 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:28,496 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:02:28,496 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:02:29,275 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:02:29,276 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:02:29,276 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:02:29,730 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:02:30,368 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:02:30 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:02:33,196 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:02:34,186 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:02:34 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:03:12 [worker.py:267] Memory profiling takes 44.99 seconds
INFO 07-05 11:03:12 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:03:12 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:03:13 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:03:13 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:03:21 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:21,  1.59it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.76it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.89it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.90it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.91it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.92it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.94it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.93it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.94it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.94it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.86it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.89it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.90it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.92it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.93it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.94it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.84it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]
INFO 07-05 11:03:40 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:03:40 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.48 seconds
[INFO|2025-07-05 11:03:40] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:03:41,666 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:03:41,666 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:41,667 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:41,667 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:41,667 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:41,667 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:41,667 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:41,667 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:41,667 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:03:42,854 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:03:42,856 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:03:42,856 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:03:43,398 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-441', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 237.41 toks/s, output: 32.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 20.05it/s, est. speed input: 5925.21 toks/s, output: 883.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.21it/s, est. speed input: 6371.57 toks/s, output: 1015.90 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:04,  4.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.92 toks/s, output: 42.22 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.38it/s, est. speed input: 6720.56 toks/s, output: 995.04 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 22.38it/s, est. speed input: 5530.57 toks/s, output: 950.91 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 481.51 toks/s, output: 237.13 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.51 toks/s, output: 237.13 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:31<19:00, 17.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.92 toks/s, output: 42.22 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.58it/s, est. speed input: 6773.73 toks/s, output: 1008.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6564.83 toks/s, output: 1126.15 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:34<11:29, 10.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.29 toks/s, output: 42.27 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.44it/s, est. speed input: 7308.39 toks/s, output: 1080.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.07it/s, est. speed input: 7875.52 toks/s, output: 1246.30 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:36<07:49,  7.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.21 toks/s, output: 42.26 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.62it/s, est. speed input: 6779.49 toks/s, output: 1006.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6571.44 toks/s, output: 1120.25 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:39<05:54,  5.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.37 toks/s, output: 42.28 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.85it/s, est. speed input: 7454.21 toks/s, output: 1097.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.96it/s, est. speed input: 7830.88 toks/s, output: 1213.23 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:41<04:39,  4.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.27 toks/s, output: 42.27 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.72it/s, est. speed input: 7716.68 toks/s, output: 1141.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.98it/s, est. speed input: 7843.56 toks/s, output: 1190.60 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:44<03:51,  3.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.59 toks/s, output: 42.17 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.30it/s, est. speed input: 7564.40 toks/s, output: 1121.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 7820.27 toks/s, output: 1215.74 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:46<03:19,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.82 toks/s, output: 42.21 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.33it/s, est. speed input: 7564.74 toks/s, output: 1116.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.40it/s, est. speed input: 8002.26 toks/s, output: 1234.59 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:49<02:55,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.28 toks/s, output: 42.13 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.17it/s, est. speed input: 7813.84 toks/s, output: 1154.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 7819.77 toks/s, output: 1185.56 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:51<02:39,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.95 toks/s, output: 42.22 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.27it/s, est. speed input: 6402.86 toks/s, output: 945.28 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.85it/s, est. speed input: 6807.59 toks/s, output: 1183.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.35it/s, est. speed input: 6807.59 toks/s, output: 1183.31 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:54<02:33,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.90 toks/s, output: 42.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.38it/s, est. speed input: 7636.40 toks/s, output: 1134.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6592.21 toks/s, output: 1030.35 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:56<02:28,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.49 toks/s, output: 42.16 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.15it/s, est. speed input: 7242.19 toks/s, output: 1075.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 7812.75 toks/s, output: 1250.95 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:59<02:19,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.22 toks/s, output: 42.26 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.47it/s, est. speed input: 7314.17 toks/s, output: 1081.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.53it/s, est. speed input: 6874.83 toks/s, output: 1108.55 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:01<02:15,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.88 toks/s, output: 42.21 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.61it/s, est. speed input: 6774.92 toks/s, output: 1003.45 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 22.61it/s, est. speed input: 6627.35 toks/s, output: 1104.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 480.96 toks/s, output: 234.45 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.96 toks/s, output: 234.45 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:28<08:26,  9.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.71 toks/s, output: 42.05 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.10it/s, est. speed input: 7573.14 toks/s, output: 1126.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 7817.32 toks/s, output: 1192.52 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:30<06:23,  7.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.19 toks/s, output: 42.37 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6466.41 toks/s, output: 959.69 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:17<00:00, 21.61it/s, est. speed input: 6300.88 toks/s, output: 1059.05 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.10s/it, est. speed input: 468.13 toks/s, output: 233.66 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 483.24 toks/s, output: 391.17 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:57<10:57, 13.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.57 toks/s, output: 40.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.72it/s, est. speed input: 7373.68 toks/s, output: 1090.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 7632.50 toks/s, output: 1185.30 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [02:00<08:08, 10.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.20 toks/s, output: 41.38 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.08it/s, est. speed input: 6596.89 toks/s, output: 982.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7587.05 toks/s, output: 1267.62 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [02:02<06:10,  7.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.56 toks/s, output: 41.43 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.65it/s, est. speed input: 7071.54 toks/s, output: 1053.65 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:15<00:00, 23.65it/s, est. speed input: 7207.18 toks/s, output: 1102.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.15s/it, est. speed input: 467.25 toks/s, output: 226.28 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.35 toks/s, output: 383.38 toks/s]
Processing batched inference:  30%|███       | 20/66 [02:29<10:24, 13.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.22 toks/s, output: 40.74 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.64it/s, est. speed input: 7345.01 toks/s, output: 1085.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.38it/s, est. speed input: 7607.57 toks/s, output: 1183.24 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [02:32<07:41, 10.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.71 toks/s, output: 40.94 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.75it/s, est. speed input: 5335.45 toks/s, output: 794.25 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 16.65it/s, est. speed input: 5365.63 toks/s, output: 942.19 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 12.62it/s, est. speed input: 4741.93 toks/s, output: 1010.63 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:15<00:00, 12.62it/s, est. speed input: 4741.93 toks/s, output: 1010.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.89s/it, est. speed input: 466.69 toks/s, output: 253.31 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.80 toks/s, output: 410.36 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [02:59<11:12, 15.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.46 toks/s, output: 40.77 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.78it/s, est. speed input: 7093.81 toks/s, output: 1047.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.36it/s, est. speed input: 7599.64 toks/s, output: 1206.59 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [03:01<08:10, 11.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.52 toks/s, output: 40.64 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.72it/s, est. speed input: 7076.76 toks/s, output: 1044.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 23.72it/s, est. speed input: 6415.12 toks/s, output: 1019.70 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.08 toks/s, output: 230.48 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.08 toks/s, output: 230.48 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [03:28<11:16, 16.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.75 toks/s, output: 40.81 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.18it/s, est. speed input: 6677.98 toks/s, output: 990.96 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:19<00:00, 22.18it/s, est. speed input: 7102.51 toks/s, output: 1112.49 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.13s/it, est. speed input: 466.18 toks/s, output: 227.57 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.23 toks/s, output: 384.47 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [03:55<13:13, 19.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.67 toks/s, output: 40.80 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 21.99it/s, est. speed input: 6640.06 toks/s, output: 990.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.31it/s, est. speed input: 7590.20 toks/s, output: 1249.14 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [03:58<09:30, 14.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.98 toks/s, output: 40.98 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.90it/s, est. speed input: 7129.60 toks/s, output: 1051.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.46it/s, est. speed input: 7638.47 toks/s, output: 1216.12 toks/s]
Processing batched inference:  41%|████      | 27/66 [04:00<06:56, 10.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.36 toks/s, output: 40.90 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 24.60it/s, est. speed input: 7405.13 toks/s, output: 1099.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.46it/s, est. speed input: 7644.01 toks/s, output: 1164.10 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [04:02<05:10,  8.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.04 toks/s, output: 40.85 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.85it/s, est. speed input: 6892.48 toks/s, output: 1025.00 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 22.85it/s, est. speed input: 6251.07 toks/s, output: 1029.61 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.54 toks/s, output: 233.24 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.54 toks/s, output: 233.24 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [04:29<08:30, 13.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.47 toks/s, output: 40.91 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.71it/s, est. speed input: 7373.85 toks/s, output: 1092.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 7685.79 toks/s, output: 1192.87 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [04:31<06:11, 10.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.24 toks/s, output: 40.88 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.92it/s, est. speed input: 6849.41 toks/s, output: 1014.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 22.92it/s, est. speed input: 7546.25 toks/s, output: 1194.93 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 479.74 toks/s, output: 230.09 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 479.74 toks/s, output: 230.09 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [04:58<08:55, 15.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.37 toks/s, output: 40.90 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.72it/s, est. speed input: 7367.22 toks/s, output: 1085.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 7625.88 toks/s, output: 1181.28 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [05:00<06:27, 11.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.41 toks/s, output: 40.76 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 23.70it/s, est. speed input: 7142.88 toks/s, output: 1065.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.22it/s, est. speed input: 5588.00 toks/s, output: 920.00 toks/s] 
Processing batched inference:  50%|█████     | 33/66 [05:03<04:52,  8.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.85 toks/s, output: 40.82 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.89it/s, est. speed input: 6902.82 toks/s, output: 1028.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 22.89it/s, est. speed input: 7379.32 toks/s, output: 1157.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.66 toks/s, output: 229.61 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.66 toks/s, output: 229.61 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [05:30<07:38, 14.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.82 toks/s, output: 40.82 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.80it/s, est. speed input: 7104.45 toks/s, output: 1052.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7774.19 toks/s, output: 1229.02 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [05:33<05:31, 10.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.21 toks/s, output: 41.43 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6411.68 toks/s, output: 950.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.51it/s, est. speed input: 7657.30 toks/s, output: 1302.12 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [05:35<04:04,  8.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.69 toks/s, output: 41.63 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.06it/s, est. speed input: 7479.94 toks/s, output: 1104.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.01it/s, est. speed input: 7852.93 toks/s, output: 1213.86 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [05:37<03:04,  6.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.77 toks/s, output: 42.45 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 6736.68 toks/s, output: 1007.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7743.07 toks/s, output: 1301.17 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [05:39<02:24,  5.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.54 toks/s, output: 42.03 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 5704.97 toks/s, output: 849.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.05it/s, est. speed input: 6522.17 toks/s, output: 1217.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6522.17 toks/s, output: 1217.35 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [05:42<01:58,  4.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.52 toks/s, output: 41.89 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.17it/s, est. speed input: 7523.01 toks/s, output: 1116.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7785.74 toks/s, output: 1215.99 toks/s]
Processing batched inference:  61%|██████    | 40/66 [05:44<01:36,  3.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.11 toks/s, output: 41.83 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.55it/s, est. speed input: 6513.82 toks/s, output: 965.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.21it/s, est. speed input: 5657.71 toks/s, output: 1014.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.41it/s, est. speed input: 5657.71 toks/s, output: 1014.17 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [05:47<01:26,  3.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.86 toks/s, output: 41.93 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.44it/s, est. speed input: 7292.91 toks/s, output: 1076.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.61it/s, est. speed input: 5732.21 toks/s, output: 953.46 toks/s] 
Processing batched inference:  64%|██████▎   | 42/66 [05:50<01:18,  3.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.35 toks/s, output: 41.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.92it/s, est. speed input: 7728.02 toks/s, output: 1139.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.80it/s, est. speed input: 4628.81 toks/s, output: 766.43 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [05:53<01:16,  3.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.29 toks/s, output: 41.99 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.23it/s, est. speed input: 7527.70 toks/s, output: 1107.46 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 25.23it/s, est. speed input: 7547.32 toks/s, output: 1140.78 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 480.32 toks/s, output: 227.09 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.32 toks/s, output: 227.09 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [06:20<03:47, 10.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.94 toks/s, output: 41.81 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.00it/s, est. speed input: 7758.79 toks/s, output: 1143.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7766.43 toks/s, output: 1174.85 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [06:22<02:45,  7.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.88 toks/s, output: 41.94 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5954.54 toks/s, output: 885.49 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.99it/s, est. speed input: 6278.23 toks/s, output: 1099.25 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:15<00:00, 19.99it/s, est. speed input: 6278.23 toks/s, output: 1099.25 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.48s/it, est. speed input: 467.56 toks/s, output: 236.66 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.66 toks/s, output: 394.10 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [06:49<04:31, 13.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.06 toks/s, output: 41.85 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.25it/s, est. speed input: 7254.81 toks/s, output: 1079.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7764.52 toks/s, output: 1241.18 toks/s]
Processing batched inference:  71%|███████   | 47/66 [06:51<03:12, 10.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.03 toks/s, output: 41.96 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.37it/s, est. speed input: 7053.69 toks/s, output: 1047.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 23.37it/s, est. speed input: 6560.82 toks/s, output: 1048.45 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.94 toks/s, output: 231.23 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.94 toks/s, output: 231.23 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [07:18<04:32, 15.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.67 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.81it/s, est. speed input: 5949.12 toks/s, output: 883.71 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.99it/s, est. speed input: 6277.11 toks/s, output: 1102.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 19.99it/s, est. speed input: 6305.02 toks/s, output: 1152.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.41s/it, est. speed input: 480.37 toks/s, output: 241.70 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.37 toks/s, output: 241.70 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [07:45<05:17, 18.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.27 toks/s, output: 41.85 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.26it/s, est. speed input: 7251.11 toks/s, output: 1072.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.07it/s, est. speed input: 7874.58 toks/s, output: 1245.52 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [07:47<03:39, 13.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.30 toks/s, output: 41.99 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6485.53 toks/s, output: 965.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7740.77 toks/s, output: 1317.85 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [07:49<02:34, 10.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.25 toks/s, output: 41.85 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 6727.04 toks/s, output: 999.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7733.37 toks/s, output: 1295.96 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [07:52<01:50,  7.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.83 toks/s, output: 41.96 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5699.80 toks/s, output: 847.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 14.21it/s, est. speed input: 5016.35 toks/s, output: 956.61 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 14.21it/s, est. speed input: 5016.35 toks/s, output: 956.61 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.40s/it, est. speed input: 480.54 toks/s, output: 245.41 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.54 toks/s, output: 245.41 toks/s]
Processing batched inference:  80%|████████  | 53/66 [08:19<02:56, 13.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.58 toks/s, output: 42.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7005.52 toks/s, output: 1033.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7767.41 toks/s, output: 1263.74 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [08:21<02:01, 10.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.91 toks/s, output: 42.08 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.56it/s, est. speed input: 6754.47 toks/s, output: 999.61 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 22.56it/s, est. speed input: 6365.56 toks/s, output: 1065.71 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 480.12 toks/s, output: 234.44 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.12 toks/s, output: 234.44 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [08:48<02:46, 15.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.32 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6484.94 toks/s, output: 966.41 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:20<00:00, 21.61it/s, est. speed input: 7497.16 toks/s, output: 1261.32 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 480.82 toks/s, output: 235.00 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.82 toks/s, output: 235.00 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [09:15<03:06, 18.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.84 toks/s, output: 42.07 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.38it/s, est. speed input: 7280.70 toks/s, output: 1073.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7794.17 toks/s, output: 1237.77 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [09:17<02:03, 13.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.56 toks/s, output: 42.56 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.48it/s, est. speed input: 7010.02 toks/s, output: 1035.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7771.75 toks/s, output: 1264.14 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [09:19<01:22, 10.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.53 toks/s, output: 40.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.48it/s, est. speed input: 7315.19 toks/s, output: 1079.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 7628.49 toks/s, output: 1182.71 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [09:21<00:55,  7.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.84 toks/s, output: 42.10 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.58it/s, est. speed input: 7046.02 toks/s, output: 1040.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7780.31 toks/s, output: 1260.36 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [09:24<00:37,  6.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.81 toks/s, output: 41.65 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.35it/s, est. speed input: 6697.85 toks/s, output: 994.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7700.23 toks/s, output: 1289.80 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [09:26<00:25,  5.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.34 toks/s, output: 41.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.34it/s, est. speed input: 6419.60 toks/s, output: 958.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 7721.72 toks/s, output: 1320.01 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [09:28<00:16,  4.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.23 toks/s, output: 41.85 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7246.67 toks/s, output: 1072.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6542.11 toks/s, output: 1064.48 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [09:31<00:11,  3.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.76 toks/s, output: 42.06 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.36it/s, est. speed input: 7283.25 toks/s, output: 1077.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 10.73it/s, est. speed input: 4210.92 toks/s, output: 744.89 toks/s] 
Processing batched inference:  97%|█████████▋| 64/66 [09:34<00:07,  3.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.53 toks/s, output: 42.17 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.60it/s, est. speed input: 6767.87 toks/s, output: 1001.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7779.98 toks/s, output: 1294.07 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [09:36<00:03,  3.22s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 335.91 toks/s, output: 46.51 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 22.76it/s, est. speed input: 6845.41 toks/s, output: 1014.98 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.82it/s, est. speed input: 7389.05 toks/s, output: 1193.53 toks/s]
Processing batched inference: 100%|██████████| 66/66 [09:39<00:00,  2.88s/it]Processing batched inference: 100%|██████████| 66/66 [09:39<00:00,  8.77s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-441/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:13:21.555859598 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-504
INFO 07-05 11:13:34 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:13:36,096 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:13:36,151 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,175 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,175 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,175 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,175 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,175 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,175 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,175 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:13:36,564 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:13:36,565 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:13:36,571 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:13:36,577 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,579 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,579 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,579 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,579 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,579 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,579 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,579 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:13:36,948 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:13:36,950 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:13:37,169 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:13:37,636 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:13:37,687 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:13:37,688 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:13:37,690 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:13:49 [config.py:689] This model supports multiple tasks: {'score', 'generate', 'reward', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 07-05 11:13:49 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:49,326 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:49,326 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:49,326 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:49,326 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:49,326 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:49,326 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:49,326 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:13:49,657 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:13:49,758 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:13:49,761 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:13:51 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:13:51 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:13:51 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504...
WARNING 07-05 11:13:51 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:13:51 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.29s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.29s/it]

INFO 07-05 11:13:59 [loader.py:458] Loading weights took 7.50 seconds
INFO 07-05 11:13:59 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.746208 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:59,820 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:59,821 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:59,821 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:59,821 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:59,821 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:59,821 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:59,821 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:14:00,234 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:14:00,342 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:14:00,342 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:14:00,344 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:14:00,344 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:14:00,344 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:14:00,345 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:14:00,345 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:14:00,345 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:14:00,345 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:14:00,345 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:14:00,345 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:14:01,121 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:14:01,121 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:14:01,122 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:14:01,566 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:14:02,218 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:14:02 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:14:05,044 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:14:06,064 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:14:06 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:14:44 [worker.py:267] Memory profiling takes 45.08 seconds
INFO 07-05 11:14:44 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:14:44 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:14:45 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:14:45 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:14:52 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.75it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.86it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.88it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.88it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.91it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.93it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.92it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.91it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.91it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.93it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.91it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.90it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.91it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.91it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.93it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.93it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.91it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.93it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.87it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.89it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.91it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.93it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.94it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.95it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.94it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.90it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 11:15:11 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:15:11 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 71.48 seconds
[INFO|2025-07-05 11:15:11] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:15:12,501 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:15:12,501 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:15:12,502 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:15:12,502 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:15:12,502 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:15:12,502 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:15:12,502 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:15:12,502 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:15:12,502 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:15:13,696 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:15:13,697 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:15:13,697 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:15:14,291 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-504', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 238.22 toks/s, output: 32.98 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 20.09it/s, est. speed input: 5937.88 toks/s, output: 883.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.25it/s, est. speed input: 6386.67 toks/s, output: 1020.34 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:08,  4.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.18 toks/s, output: 42.25 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.39it/s, est. speed input: 6724.87 toks/s, output: 996.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7790.63 toks/s, output: 1304.32 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:38,  3.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.11 toks/s, output: 42.11 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.73it/s, est. speed input: 5368.33 toks/s, output: 802.41 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.72it/s, est. speed input: 4842.79 toks/s, output: 952.97 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:21<00:00, 13.72it/s, est. speed input: 4842.79 toks/s, output: 952.97 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.38s/it, est. speed input: 481.79 toks/s, output: 248.79 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.79 toks/s, output: 248.79 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:34<14:53, 14.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.78 toks/s, output: 42.20 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.44it/s, est. speed input: 7302.18 toks/s, output: 1077.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 7813.61 toks/s, output: 1238.37 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:36<09:50,  9.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.58 toks/s, output: 42.17 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.58it/s, est. speed input: 6767.22 toks/s, output: 1004.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.86it/s, est. speed input: 1517.09 toks/s, output: 403.39 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:45<09:31,  9.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.62 toks/s, output: 42.18 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6501.00 toks/s, output: 961.21 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.31it/s, est. speed input: 1991.64 toks/s, output: 467.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  5.08it/s, est. speed input: 1991.64 toks/s, output: 467.37 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:52<08:37,  8.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.04 toks/s, output: 42.10 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.99it/s, est. speed input: 6911.32 toks/s, output: 1022.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7782.84 toks/s, output: 1271.84 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:55<06:29,  6.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.69 toks/s, output: 42.05 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6492.64 toks/s, output: 968.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 6541.45 toks/s, output: 1141.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6541.45 toks/s, output: 1141.32 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:58<05:11,  5.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.93 toks/s, output: 42.08 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.56it/s, est. speed input: 6752.28 toks/s, output: 996.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.51it/s, est. speed input: 3730.23 toks/s, output: 705.04 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [01:02<04:43,  4.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.69 toks/s, output: 42.05 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.40it/s, est. speed input: 7350.35 toks/s, output: 1088.38 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 24.40it/s, est. speed input: 7566.52 toks/s, output: 1150.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 481.55 toks/s, output: 227.92 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.55 toks/s, output: 227.92 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [01:29<10:58, 11.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.27 toks/s, output: 42.13 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6234.86 toks/s, output: 919.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7735.31 toks/s, output: 1345.18 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [01:31<08:09,  8.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.81 toks/s, output: 42.07 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7017.18 toks/s, output: 1042.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6564.77 toks/s, output: 1101.26 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [01:34<06:18,  7.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.71 toks/s, output: 42.05 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 7014.71 toks/s, output: 1041.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7779.39 toks/s, output: 1275.31 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:36<04:56,  5.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.58 toks/s, output: 42.17 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.93it/s, est. speed input: 6273.31 toks/s, output: 931.43 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.83it/s, est. speed input: 6359.17 toks/s, output: 1105.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.80it/s, est. speed input: 2275.56 toks/s, output: 518.49 toks/s] 
Processing batched inference:  21%|██        | 14/66 [01:42<05:00,  5.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 305.94 toks/s, output: 41.58 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6228.41 toks/s, output: 924.67 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.65it/s, est. speed input: 5710.90 toks/s, output: 1034.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.55it/s, est. speed input: 5710.90 toks/s, output: 1034.78 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:45<04:10,  4.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.56 toks/s, output: 41.89 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.36it/s, est. speed input: 6992.56 toks/s, output: 1038.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7755.30 toks/s, output: 1270.65 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:48<03:28,  4.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.85 toks/s, output: 42.46 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6478.31 toks/s, output: 962.09 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:07<00:00,  3.74it/s, est. speed input: 1756.24 toks/s, output: 507.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.47it/s, est. speed input: 1756.24 toks/s, output: 507.61 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:55<04:19,  5.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.12 toks/s, output: 41.42 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.14it/s, est. speed input: 6920.63 toks/s, output: 1025.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 7674.48 toks/s, output: 1249.24 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:58<03:31,  4.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.08 toks/s, output: 40.86 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.91it/s, est. speed input: 6847.38 toks/s, output: 1016.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.38it/s, est. speed input: 6433.54 toks/s, output: 1077.45 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [02:01<03:05,  3.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.69 toks/s, output: 41.31 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.70it/s, est. speed input: 6792.79 toks/s, output: 1011.41 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 22.70it/s, est. speed input: 7303.72 toks/s, output: 1172.21 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 480.99 toks/s, output: 231.45 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.99 toks/s, output: 231.45 toks/s]
Processing batched inference:  30%|███       | 20/66 [02:28<08:19, 10.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.89 toks/s, output: 40.69 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.97it/s, est. speed input: 6569.12 toks/s, output: 973.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.36it/s, est. speed input: 6421.25 toks/s, output: 1120.89 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [02:30<06:19,  8.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 294.91 toks/s, output: 40.83 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 16.87it/s, est. speed input: 5076.83 toks/s, output: 758.25 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.68it/s, est. speed input: 5205.12 toks/s, output: 1005.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 15.68it/s, est. speed input: 4271.46 toks/s, output: 904.88 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.35s/it, est. speed input: 480.51 toks/s, output: 255.27 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.51 toks/s, output: 255.27 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [02:58<10:17, 14.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.34 toks/s, output: 40.89 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.30it/s, est. speed input: 6369.32 toks/s, output: 946.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.01it/s, est. speed input: 6416.23 toks/s, output: 1112.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.35it/s, est. speed input: 6416.23 toks/s, output: 1112.70 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [03:00<07:37, 10.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.53 toks/s, output: 40.78 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.82it/s, est. speed input: 7103.33 toks/s, output: 1048.45 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 23.82it/s, est. speed input: 7371.60 toks/s, output: 1143.87 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 480.61 toks/s, output: 228.98 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.61 toks/s, output: 228.98 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [03:27<10:52, 15.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.79 toks/s, output: 40.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 21.99it/s, est. speed input: 6634.62 toks/s, output: 985.13 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:11<00:00, 21.99it/s, est. speed input: 5059.05 toks/s, output: 816.29 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:11<00:01,  1.91it/s, est. speed input: 984.51 toks/s, output: 303.98 toks/s] [A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.38s/it, est. speed input: 465.80 toks/s, output: 295.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.87 toks/s, output: 452.74 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [03:54<12:56, 18.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.47 toks/s, output: 40.77 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.86it/s, est. speed input: 5984.43 toks/s, output: 893.90 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.58it/s, est. speed input: 6217.24 toks/s, output: 1101.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 19.58it/s, est. speed input: 6217.24 toks/s, output: 1101.08 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.45s/it, est. speed input: 480.82 toks/s, output: 239.07 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.82 toks/s, output: 239.07 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [04:21<14:14, 21.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.04 toks/s, output: 40.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.16it/s, est. speed input: 6336.67 toks/s, output: 942.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.27it/s, est. speed input: 7565.02 toks/s, output: 1286.32 toks/s]
Processing batched inference:  41%|████      | 27/66 [04:23<10:09, 15.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.13 toks/s, output: 40.73 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.79it/s, est. speed input: 7097.89 toks/s, output: 1051.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7605.98 toks/s, output: 1215.21 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [04:26<07:22, 11.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.32 toks/s, output: 41.26 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.57it/s, est. speed input: 5567.07 toks/s, output: 830.95 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.02it/s, est. speed input: 5983.19 toks/s, output: 1087.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.02it/s, est. speed input: 5556.01 toks/s, output: 1065.21 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.39s/it, est. speed input: 480.79 toks/s, output: 245.94 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.79 toks/s, output: 245.94 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [04:53<10:00, 16.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:44,  1.44s/it, est. speed input: 271.15 toks/s, output: 37.54 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.43it/s, est. speed input: 6657.34 toks/s, output: 988.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.63it/s, est. speed input: 6135.81 toks/s, output: 997.23 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [04:56<07:19, 12.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:42,  1.38s/it, est. speed input: 283.60 toks/s, output: 39.27 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.72it/s, est. speed input: 5889.32 toks/s, output: 871.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.38it/s, est. speed input: 6112.49 toks/s, output: 1066.40 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 19.38it/s, est. speed input: 6112.49 toks/s, output: 1066.40 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.45s/it, est. speed input: 479.33 toks/s, output: 237.38 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 479.33 toks/s, output: 237.38 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [05:23<09:42, 16.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.79 toks/s, output: 40.95 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.96it/s, est. speed input: 6855.65 toks/s, output: 1010.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.38it/s, est. speed input: 7603.73 toks/s, output: 1237.20 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [05:25<07:00, 12.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.13 toks/s, output: 40.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.73it/s, est. speed input: 6244.21 toks/s, output: 932.71 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.08it/s, est. speed input: 5565.10 toks/s, output: 1001.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.16it/s, est. speed input: 5565.10 toks/s, output: 1001.61 toks/s]
Processing batched inference:  50%|█████     | 33/66 [05:28<05:14,  9.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.48 toks/s, output: 40.91 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.76it/s, est. speed input: 6250.43 toks/s, output: 929.72 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.69it/s, est. speed input: 6295.87 toks/s, output: 1085.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5612.02 toks/s, output: 1027.79 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [05:31<04:02,  7.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.52 toks/s, output: 40.78 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.89it/s, est. speed input: 6836.21 toks/s, output: 1010.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.33it/s, est. speed input: 7584.58 toks/s, output: 1230.46 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [05:33<03:05,  5.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.92 toks/s, output: 41.67 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6211.82 toks/s, output: 921.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 6473.69 toks/s, output: 1150.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6473.69 toks/s, output: 1150.32 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [05:36<02:29,  4.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.77 toks/s, output: 41.64 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.20it/s, est. speed input: 7228.49 toks/s, output: 1069.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.00it/s, est. speed input: 7850.39 toks/s, output: 1242.22 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [05:38<02:00,  4.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.74 toks/s, output: 42.02 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.34it/s, est. speed input: 6683.85 toks/s, output: 997.75 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:20<00:00, 22.34it/s, est. speed input: 4839.36 toks/s, output: 876.77 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 481.87 toks/s, output: 241.47 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.87 toks/s, output: 241.47 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [06:05<05:06, 10.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.17 toks/s, output: 41.70 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.68it/s, est. speed input: 5915.58 toks/s, output: 880.33 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.93it/s, est. speed input: 6297.12 toks/s, output: 1132.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.29it/s, est. speed input: 5612.24 toks/s, output: 1069.40 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [06:08<03:50,  8.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.73 toks/s, output: 41.64 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.47it/s, est. speed input: 6441.56 toks/s, output: 959.76 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 6517.36 toks/s, output: 1192.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6517.36 toks/s, output: 1192.56 toks/s]
Processing batched inference:  61%|██████    | 40/66 [06:10<02:55,  6.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.68 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 5947.34 toks/s, output: 882.81 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.11it/s, est. speed input: 6108.41 toks/s, output: 1076.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.36it/s, est. speed input: 5639.67 toks/s, output: 1093.54 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [06:13<02:19,  5.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.31 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6739.35 toks/s, output: 999.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.61it/s, est. speed input: 5734.46 toks/s, output: 1018.67 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [06:16<01:53,  4.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.80 toks/s, output: 41.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.22it/s, est. speed input: 7529.66 toks/s, output: 1112.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.96it/s, est. speed input: 5869.93 toks/s, output: 949.95 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [06:19<01:36,  4.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.51 toks/s, output: 42.02 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5963.97 toks/s, output: 885.91 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.27it/s, est. speed input: 5543.98 toks/s, output: 1008.49 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 16.27it/s, est. speed input: 5543.98 toks/s, output: 1008.49 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 480.62 toks/s, output: 241.55 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.62 toks/s, output: 241.55 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [06:46<04:01, 10.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.80 toks/s, output: 41.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.09it/s, est. speed input: 7783.52 toks/s, output: 1147.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6569.28 toks/s, output: 1019.90 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [06:48<02:56,  8.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.96 toks/s, output: 41.95 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.06it/s, est. speed input: 5438.14 toks/s, output: 811.68 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.48it/s, est. speed input: 6264.10 toks/s, output: 1146.80 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:20<00:00, 20.48it/s, est. speed input: 6264.10 toks/s, output: 1146.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.45s/it, est. speed input: 467.76 toks/s, output: 240.38 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.87 toks/s, output: 397.89 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [07:15<04:38, 13.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 304.20 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7009.55 toks/s, output: 1043.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7771.13 toks/s, output: 1272.52 toks/s]
Processing batched inference:  71%|███████   | 47/66 [07:17<03:17, 10.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.25 toks/s, output: 42.52 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7002.49 toks/s, output: 1037.75 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00, 23.44it/s, est. speed input: 6368.72 toks/s, output: 1045.75 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.08s/it, est. speed input: 481.28 toks/s, output: 233.46 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.28 toks/s, output: 233.46 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [07:44<04:35, 15.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.79 toks/s, output: 41.92 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.01it/s, est. speed input: 5998.51 toks/s, output: 891.39 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.17it/s, est. speed input: 5896.88 toks/s, output: 1017.61 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 18.17it/s, est. speed input: 5011.47 toks/s, output: 971.72 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.38s/it, est. speed input: 481.01 toks/s, output: 247.23 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.01 toks/s, output: 247.23 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [08:10<05:18, 18.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.14 toks/s, output: 41.50 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.94it/s, est. speed input: 7480.12 toks/s, output: 1102.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.14it/s, est. speed input: 6724.20 toks/s, output: 1064.10 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [08:13<03:42, 13.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.03 toks/s, output: 41.96 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5697.63 toks/s, output: 850.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 18.93it/s, est. speed input: 7441.96 toks/s, output: 1332.95 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.02s/it, est. speed input: 480.78 toks/s, output: 240.16 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.78 toks/s, output: 240.16 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [08:40<04:26, 17.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.82 toks/s, output: 41.79 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.88it/s, est. speed input: 5681.98 toks/s, output: 847.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.88it/s, est. speed input: 6478.72 toks/s, output: 1208.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6478.72 toks/s, output: 1208.86 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [08:42<03:04, 13.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.43 toks/s, output: 42.40 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6729.21 toks/s, output: 997.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.11it/s, est. speed input: 6718.91 toks/s, output: 1145.92 toks/s]
Processing batched inference:  80%|████████  | 53/66 [08:45<02:09,  9.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.57 toks/s, output: 42.03 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 6745.11 toks/s, output: 997.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6561.35 toks/s, output: 1140.66 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [08:47<01:32,  7.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.48 toks/s, output: 42.02 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6224.24 toks/s, output: 921.54 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.93it/s, est. speed input: 6132.19 toks/s, output: 1056.31 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:21<00:00, 18.93it/s, est. speed input: 6336.88 toks/s, output: 1137.48 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 480.99 toks/s, output: 240.50 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.99 toks/s, output: 240.50 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [09:14<02:28, 13.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 300.09 toks/s, output: 42.87 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 5688.62 toks/s, output: 852.31 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.19it/s, est. speed input: 5469.21 toks/s, output: 1027.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5645.71 toks/s, output: 1119.44 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [09:17<01:42, 10.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.77 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6486.92 toks/s, output: 958.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.64it/s, est. speed input: 6596.13 toks/s, output: 1147.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.81it/s, est. speed input: 6596.13 toks/s, output: 1147.33 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [09:20<01:11,  7.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.24 toks/s, output: 42.51 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.99it/s, est. speed input: 5698.92 toks/s, output: 845.70 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.36it/s, est. speed input: 6104.85 toks/s, output: 1101.62 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 19.36it/s, est. speed input: 5657.34 toks/s, output: 1077.80 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.39s/it, est. speed input: 480.94 toks/s, output: 245.60 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.94 toks/s, output: 245.60 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [09:47<01:49, 13.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.99 toks/s, output: 41.95 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.91it/s, est. speed input: 6886.57 toks/s, output: 1019.15 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:12<00:00, 22.91it/s, est. speed input: 6329.43 toks/s, output: 1010.81 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.13s/it, est. speed input: 468.53 toks/s, output: 230.16 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.66 toks/s, output: 387.92 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [10:13<02:02, 17.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.83 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.83it/s, est. speed input: 6240.83 toks/s, output: 924.89 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.07it/s, est. speed input: 6391.94 toks/s, output: 1113.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6535.18 toks/s, output: 1183.57 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [10:16<01:18, 13.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.44 toks/s, output: 41.88 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 5943.81 toks/s, output: 884.43 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.24it/s, est. speed input: 6370.37 toks/s, output: 1148.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6554.65 toks/s, output: 1224.59 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [10:18<00:49,  9.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.44 toks/s, output: 41.88 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.70it/s, est. speed input: 5644.95 toks/s, output: 845.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.93it/s, est. speed input: 6665.92 toks/s, output: 1240.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.97it/s, est. speed input: 6665.92 toks/s, output: 1240.80 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [10:21<00:30,  7.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.30 toks/s, output: 41.99 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 6997.94 toks/s, output: 1037.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:10<00:00,  2.91it/s, est. speed input: 1142.23 toks/s, output: 330.06 toks/s] 
Processing batched inference:  95%|█████████▌| 63/66 [10:32<00:26,  8.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.83 toks/s, output: 41.79 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.27it/s, est. speed input: 7247.94 toks/s, output: 1070.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6550.50 toks/s, output: 1068.54 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [10:35<00:13,  6.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.97 toks/s, output: 41.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.54it/s, est. speed input: 6457.53 toks/s, output: 958.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.17it/s, est. speed input: 5634.90 toks/s, output: 1001.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.36it/s, est. speed input: 5634.90 toks/s, output: 1001.88 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [10:38<00:05,  5.74s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 333.94 toks/s, output: 46.24 toks/s][A
Processed prompts:  96%|█████████▋| 27/28 [00:01<00:00, 23.42it/s, est. speed input: 7112.13 toks/s, output: 1057.32 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.78it/s, est. speed input: 7375.59 toks/s, output: 1128.97 toks/s]
Processing batched inference: 100%|██████████| 66/66 [10:40<00:00,  4.65s/it]Processing batched inference: 100%|██████████| 66/66 [10:40<00:00,  9.70s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-504/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:25:53.837624498 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-567
INFO 07-05 11:26:06 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:26:08,362 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:26:08,405 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,430 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,430 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,431 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,431 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,431 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,431 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,431 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:26:08,818 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:26:08,819 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:26:08,825 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:26:08,831 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,832 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,832 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,832 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,832 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,832 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,832 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,832 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:26:09,206 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:26:09,208 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:26:09,402 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:26:09,847 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:26:09,901 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:26:09,902 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:26:09,904 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:26:21 [config.py:689] This model supports multiple tasks: {'score', 'reward', 'classify', 'generate', 'embed'}. Defaulting to 'generate'.
INFO 07-05 11:26:21 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:21,485 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:21,486 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:21,486 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:21,486 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:21,486 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:21,486 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:21,486 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:26:21,824 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:26:21,925 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:26:21,928 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:26:23 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:26:23 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:26:23 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567...
WARNING 07-05 11:26:23 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:26:23 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.16s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.16s/it]

INFO 07-05 11:26:31 [loader.py:458] Loading weights took 7.37 seconds
INFO 07-05 11:26:31 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.611556 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:31,817 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:31,817 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:31,818 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:31,818 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:31,818 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:31,818 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:31,818 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:26:32,225 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:26:32,322 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:26:32,322 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:26:32,322 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:26:32,323 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:32,323 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:32,323 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:32,323 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:32,323 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:32,323 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:32,323 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:32,323 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:26:33,081 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:26:33,082 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:26:33,082 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:26:33,533 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:26:34,179 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:26:34 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:26:37,013 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:26:37,983 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:26:38 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:27:16 [worker.py:267] Memory profiling takes 44.79 seconds
INFO 07-05 11:27:16 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:27:16 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:27:16 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:27:16 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:27:25 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.74it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.86it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.88it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.91it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.91it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.92it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.92it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.90it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.92it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.96it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.95it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.95it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.90it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.92it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.92it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.93it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.93it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.94it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.88it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.90it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.91it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.93it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.93it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.94it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.94it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.89it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 11:27:43 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:27:43 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.23 seconds
[INFO|2025-07-05 11:27:44] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:27:45,230 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:27:45,231 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:45,231 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:45,231 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:45,232 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:45,232 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:45,232 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:45,232 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:45,232 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:27:46,366 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:27:46,366 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:27:46,367 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:27:46,921 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-567', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 238.42 toks/s, output: 33.01 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.89it/s, est. speed input: 5301.20 toks/s, output: 791.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.19it/s, est. speed input: 6360.64 toks/s, output: 1088.51 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:04,  4.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.37 toks/s, output: 42.28 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.14it/s, est. speed input: 6093.20 toks/s, output: 904.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.85it/s, est. speed input: 6559.44 toks/s, output: 1176.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6559.44 toks/s, output: 1176.48 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:46,  3.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.11 toks/s, output: 42.25 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.18it/s, est. speed input: 5476.93 toks/s, output: 817.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.93it/s, est. speed input: 6187.11 toks/s, output: 1147.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5657.30 toks/s, output: 1145.94 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:28,  3.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.26 toks/s, output: 42.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.74it/s, est. speed input: 6800.85 toks/s, output: 1008.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 7813.30 toks/s, output: 1294.32 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<03:02,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.98 toks/s, output: 42.23 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.93it/s, est. speed input: 5991.43 toks/s, output: 892.70 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.05it/s, est. speed input: 5507.44 toks/s, output: 1011.09 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 16.05it/s, est. speed input: 5507.44 toks/s, output: 1011.09 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 482.00 toks/s, output: 242.86 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.00 toks/s, output: 242.86 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:39<11:49, 11.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.12 toks/s, output: 42.25 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.61it/s, est. speed input: 6770.26 toks/s, output: 999.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.08it/s, est. speed input: 1208.29 toks/s, output: 343.60 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:51<11:30, 11.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.42 toks/s, output: 42.29 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.17it/s, est. speed input: 6674.18 toks/s, output: 987.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7792.76 toks/s, output: 1304.47 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:53<08:23,  8.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.14 toks/s, output: 42.11 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6245.90 toks/s, output: 932.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7750.23 toks/s, output: 1350.38 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:55<06:21,  6.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.74 toks/s, output: 42.19 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.85it/s, est. speed input: 6251.37 toks/s, output: 924.92 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.88it/s, est. speed input: 5042.48 toks/s, output: 932.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.85it/s, est. speed input: 5042.48 toks/s, output: 932.98 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:59<05:15,  5.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.03 toks/s, output: 42.23 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.51it/s, est. speed input: 7038.69 toks/s, output: 1041.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.87it/s, est. speed input: 6622.94 toks/s, output: 1103.20 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [01:01<04:19,  4.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.91 toks/s, output: 42.22 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6496.92 toks/s, output: 956.26 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.35it/s, est. speed input: 6544.92 toks/s, output: 1140.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6544.92 toks/s, output: 1140.26 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [01:04<03:42,  4.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.55 toks/s, output: 42.17 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6493.92 toks/s, output: 966.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7749.93 toks/s, output: 1329.04 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [01:06<03:11,  3.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.98 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.00it/s, est. speed input: 6345.93 toks/s, output: 944.30 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.52it/s, est. speed input: 6545.08 toks/s, output: 1150.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6545.08 toks/s, output: 1150.01 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:09<02:53,  3.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.21 toks/s, output: 42.26 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.75it/s, est. speed input: 6806.06 toks/s, output: 1007.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6569.45 toks/s, output: 1111.65 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:12<02:40,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.22 toks/s, output: 42.12 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.01it/s, est. speed input: 5719.04 toks/s, output: 853.10 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.24it/s, est. speed input: 5495.85 toks/s, output: 1024.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.42it/s, est. speed input: 4089.56 toks/s, output: 851.05 toks/s] 
Processing batched inference:  23%|██▎       | 15/66 [01:16<02:48,  3.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.46 toks/s, output: 42.02 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.71it/s, est. speed input: 6850.59 toks/s, output: 1019.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7772.59 toks/s, output: 1275.33 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:18<02:31,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.58 toks/s, output: 41.44 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.26it/s, est. speed input: 6351.85 toks/s, output: 943.84 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:20<00:00, 21.26it/s, est. speed input: 2045.28 toks/s, output: 487.75 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.05s/it, est. speed input: 482.93 toks/s, output: 268.98 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.93 toks/s, output: 268.98 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:45<08:18, 10.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.55 toks/s, output: 40.78 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.02it/s, est. speed input: 6584.16 toks/s, output: 975.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.30it/s, est. speed input: 7575.65 toks/s, output: 1262.10 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:47<06:18,  7.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.37 toks/s, output: 41.41 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.37it/s, est. speed input: 6094.45 toks/s, output: 909.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.27it/s, est. speed input: 7567.63 toks/s, output: 1322.18 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:50<04:55,  6.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.96 toks/s, output: 41.35 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.84it/s, est. speed input: 6543.16 toks/s, output: 976.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.54it/s, est. speed input: 4927.99 toks/s, output: 901.73 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:53<04:07,  5.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.17 toks/s, output: 40.87 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.43it/s, est. speed input: 5830.94 toks/s, output: 869.84 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.00it/s, est. speed input: 6266.42 toks/s, output: 1120.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.32it/s, est. speed input: 6407.95 toks/s, output: 1188.95 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:56<03:26,  4.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 294.90 toks/s, output: 40.83 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.34it/s, est. speed input: 4331.96 toks/s, output: 650.65 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.29it/s, est. speed input: 5751.19 toks/s, output: 1140.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.08it/s, est. speed input: 5529.10 toks/s, output: 1242.23 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:59<03:02,  4.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.60 toks/s, output: 40.79 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.02it/s, est. speed input: 6584.58 toks/s, output: 975.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.21it/s, est. speed input: 5576.34 toks/s, output: 991.91 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [02:02<02:43,  3.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.41 toks/s, output: 40.76 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.01it/s, est. speed input: 6581.51 toks/s, output: 975.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 22.01it/s, est. speed input: 7333.61 toks/s, output: 1193.43 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 480.64 toks/s, output: 232.51 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.64 toks/s, output: 232.51 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [02:29<07:31, 10.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.36 toks/s, output: 40.76 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.13it/s, est. speed input: 6322.70 toks/s, output: 937.49 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 21.13it/s, est. speed input: 6214.20 toks/s, output: 1089.65 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 480.94 toks/s, output: 238.50 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 480.94 toks/s, output: 238.50 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:56<10:40, 15.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.78 toks/s, output: 40.68 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.27it/s, est. speed input: 6131.06 toks/s, output: 916.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.47it/s, est. speed input: 6218.11 toks/s, output: 1077.25 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.47it/s, est. speed input: 6218.11 toks/s, output: 1077.25 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.46s/it, est. speed input: 481.30 toks/s, output: 237.51 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 481.30 toks/s, output: 237.51 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [03:23<12:40, 19.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.76 toks/s, output: 40.67 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.12it/s, est. speed input: 6318.22 toks/s, output: 937.26 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.06it/s, est. speed input: 5565.92 toks/s, output: 1013.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.18it/s, est. speed input: 5565.92 toks/s, output: 1013.31 toks/s]
Processing batched inference:  41%|████      | 27/66 [03:26<09:13, 14.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.37 toks/s, output: 40.76 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.29it/s, est. speed input: 6079.85 toks/s, output: 905.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.23it/s, est. speed input: 7550.87 toks/s, output: 1319.95 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [03:28<06:44, 10.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.44 toks/s, output: 40.91 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.57it/s, est. speed input: 6203.51 toks/s, output: 923.62 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.47it/s, est. speed input: 6239.72 toks/s, output: 1077.94 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:20<00:00, 19.47it/s, est. speed input: 6239.72 toks/s, output: 1077.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.46s/it, est. speed input: 481.41 toks/s, output: 237.41 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.41 toks/s, output: 237.41 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [03:55<09:33, 15.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.24 toks/s, output: 40.88 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.85it/s, est. speed input: 7402.76 toks/s, output: 1096.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7687.25 toks/s, output: 1192.48 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [03:57<06:55, 11.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.75 toks/s, output: 40.95 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.22it/s, est. speed input: 6351.35 toks/s, output: 942.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.17it/s, est. speed input: 3397.29 toks/s, output: 666.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.66it/s, est. speed input: 3397.29 toks/s, output: 666.14 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [04:02<05:27,  9.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 295.58 toks/s, output: 41.58 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.56it/s, est. speed input: 5852.01 toks/s, output: 866.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.53it/s, est. speed input: 6412.04 toks/s, output: 1164.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.34it/s, est. speed input: 6412.04 toks/s, output: 1164.84 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [04:04<04:09,  7.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.58 toks/s, output: 40.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.87it/s, est. speed input: 5989.13 toks/s, output: 895.74 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.26it/s, est. speed input: 5556.35 toks/s, output: 1022.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5556.35 toks/s, output: 1022.13 toks/s]
Processing batched inference:  50%|█████     | 33/66 [04:07<03:18,  6.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.76 toks/s, output: 40.81 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.89it/s, est. speed input: 5990.35 toks/s, output: 893.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.39it/s, est. speed input: 5584.98 toks/s, output: 1023.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.21it/s, est. speed input: 5584.98 toks/s, output: 1023.72 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [04:10<02:43,  5.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.81 toks/s, output: 41.24 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.92it/s, est. speed input: 7427.84 toks/s, output: 1095.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7684.18 toks/s, output: 1189.09 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [04:12<02:11,  4.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.42 toks/s, output: 41.73 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6220.85 toks/s, output: 922.47 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.46it/s, est. speed input: 6501.07 toks/s, output: 1155.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6501.07 toks/s, output: 1155.18 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [04:15<01:52,  3.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.02 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 6738.66 toks/s, output: 998.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7741.61 toks/s, output: 1284.81 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [04:17<01:35,  3.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.19 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.90it/s, est. speed input: 6318.94 toks/s, output: 945.64 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.72it/s, est. speed input: 6340.00 toks/s, output: 1098.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6544.47 toks/s, output: 1179.35 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [04:20<01:26,  3.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.28 toks/s, output: 41.85 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.46it/s, est. speed input: 4670.24 toks/s, output: 699.65 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.97it/s, est. speed input: 5463.56 toks/s, output: 1112.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.32it/s, est. speed input: 5624.25 toks/s, output: 1200.55 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [04:23<01:21,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.94 toks/s, output: 41.53 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.32it/s, est. speed input: 6688.11 toks/s, output: 997.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6561.72 toks/s, output: 1123.44 toks/s]
Processing batched inference:  61%|██████    | 40/66 [04:25<01:14,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.15 toks/s, output: 42.22 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.17it/s, est. speed input: 5164.85 toks/s, output: 772.46 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.53it/s, est. speed input: 6256.15 toks/s, output: 1193.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.45it/s, est. speed input: 6457.94 toks/s, output: 1273.28 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [04:28<01:09,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.95 toks/s, output: 41.95 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.73it/s, est. speed input: 6503.07 toks/s, output: 963.60 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.71it/s, est. speed input: 6612.26 toks/s, output: 1174.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.85it/s, est. speed input: 6612.26 toks/s, output: 1174.61 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [04:30<01:05,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.40 toks/s, output: 41.87 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 6726.11 toks/s, output: 995.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.78it/s, est. speed input: 3835.54 toks/s, output: 720.92 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [04:34<01:11,  3.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.51 toks/s, output: 42.02 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6227.44 toks/s, output: 922.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.57it/s, est. speed input: 6716.69 toks/s, output: 1187.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.12it/s, est. speed input: 6716.69 toks/s, output: 1187.49 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [04:37<01:03,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.12 toks/s, output: 41.97 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.36it/s, est. speed input: 7274.42 toks/s, output: 1072.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.67it/s, est. speed input: 5759.79 toks/s, output: 982.28 toks/s] 
Processing batched inference:  68%|██████▊   | 45/66 [04:39<00:59,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.56 toks/s, output: 42.03 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 5705.60 toks/s, output: 851.09 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.38it/s, est. speed input: 6070.72 toks/s, output: 1066.65 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 19.38it/s, est. speed input: 3976.96 toks/s, output: 817.36 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.36s/it, est. speed input: 482.14 toks/s, output: 253.26 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.14 toks/s, output: 253.26 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [05:06<03:20, 10.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.66 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6739.20 toks/s, output: 1003.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7746.46 toks/s, output: 1298.67 toks/s]
Processing batched inference:  71%|███████   | 47/66 [05:08<02:26,  7.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.11 toks/s, output: 42.36 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6206.33 toks/s, output: 922.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.08it/s, est. speed input: 6384.18 toks/s, output: 1122.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.87it/s, est. speed input: 5837.70 toks/s, output: 1083.90 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [05:11<01:51,  6.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.63 toks/s, output: 41.90 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.19it/s, est. speed input: 5181.46 toks/s, output: 773.88 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.64it/s, est. speed input: 6289.65 toks/s, output: 1197.33 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 20.64it/s, est. speed input: 6289.65 toks/s, output: 1197.33 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.38s/it, est. speed input: 481.13 toks/s, output: 245.64 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.13 toks/s, output: 245.64 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [05:38<03:30, 12.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.49 toks/s, output: 42.02 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.28it/s, est. speed input: 7545.08 toks/s, output: 1113.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.19it/s, est. speed input: 7920.67 toks/s, output: 1223.80 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [05:40<02:29,  9.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.24 toks/s, output: 41.99 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 5961.79 toks/s, output: 889.36 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.81it/s, est. speed input: 5692.97 toks/s, output: 1056.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.50it/s, est. speed input: 5692.97 toks/s, output: 1056.66 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [05:43<01:50,  7.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.13 toks/s, output: 42.50 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.12it/s, est. speed input: 5449.53 toks/s, output: 816.60 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.38it/s, est. speed input: 3662.58 toks/s, output: 768.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.32it/s, est. speed input: 3662.58 toks/s, output: 768.46 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [05:47<01:29,  6.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.80 toks/s, output: 42.59 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.91it/s, est. speed input: 5971.43 toks/s, output: 888.54 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.79it/s, est. speed input: 6708.96 toks/s, output: 1220.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.08it/s, est. speed input: 6708.96 toks/s, output: 1220.58 toks/s]
Processing batched inference:  80%|████████  | 53/66 [05:50<01:07,  5.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.97 toks/s, output: 42.09 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7015.03 toks/s, output: 1036.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6559.58 toks/s, output: 1091.77 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [05:52<00:52,  4.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.84 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6234.45 toks/s, output: 923.05 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.96it/s, est. speed input: 6140.44 toks/s, output: 1057.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.65it/s, est. speed input: 1824.86 toks/s, output: 458.10 toks/s] 
Processing batched inference:  83%|████████▎ | 55/66 [06:00<00:58,  5.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.23 toks/s, output: 41.99 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.51it/s, est. speed input: 4687.38 toks/s, output: 704.36 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.36it/s, est. speed input: 5871.55 toks/s, output: 1146.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.36it/s, est. speed input: 4070.07 toks/s, output: 964.34 toks/s] 
Processing batched inference:  85%|████████▍ | 56/66 [06:03<00:48,  4.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.59 toks/s, output: 42.03 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6226.37 toks/s, output: 919.15 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.85it/s, est. speed input: 6584.72 toks/s, output: 1172.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6584.72 toks/s, output: 1172.09 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [06:06<00:37,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.27 toks/s, output: 42.38 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6465.59 toks/s, output: 955.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7719.19 toks/s, output: 1315.20 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [06:08<00:28,  3.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.59 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.37it/s, est. speed input: 6418.47 toks/s, output: 950.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:20<00:00, 21.37it/s, est. speed input: 7476.42 toks/s, output: 1249.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 481.15 toks/s, output: 234.83 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.15 toks/s, output: 234.83 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [06:35<01:13, 10.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.15 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.85it/s, est. speed input: 6247.65 toks/s, output: 926.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.85it/s, est. speed input: 6585.77 toks/s, output: 1165.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6585.77 toks/s, output: 1165.46 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [06:37<00:48,  8.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.91 toks/s, output: 41.94 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5695.54 toks/s, output: 847.89 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.49it/s, est. speed input: 6370.10 toks/s, output: 1173.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6554.38 toks/s, output: 1249.56 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [06:40<00:32,  6.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.08 toks/s, output: 42.35 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6211.97 toks/s, output: 928.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.59it/s, est. speed input: 6482.44 toks/s, output: 1159.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5644.41 toks/s, output: 1069.97 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [06:43<00:21,  5.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.81 toks/s, output: 42.07 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.37it/s, est. speed input: 7284.56 toks/s, output: 1077.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.48it/s, est. speed input: 5685.71 toks/s, output: 949.12 toks/s] 
Processing batched inference:  95%|█████████▌| 63/66 [06:46<00:13,  4.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.81 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6215.00 toks/s, output: 920.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 20.73it/s, est. speed input: 7472.87 toks/s, output: 1281.71 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:14<00:00,  1.76it/s, est. speed input: 864.40 toks/s, output: 296.19 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:14<00:00,  2.20it/s, est. speed input: 864.40 toks/s, output: 296.19 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [07:01<00:15,  7.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.48 toks/s, output: 42.16 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.71it/s, est. speed input: 6506.83 toks/s, output: 963.61 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 6555.63 toks/s, output: 1141.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6555.63 toks/s, output: 1141.05 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [07:03<00:06,  6.20s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.15s/it, est. speed input: 338.99 toks/s, output: 46.82 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.77it/s, est. speed input: 6275.30 toks/s, output: 934.79 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.82it/s, est. speed input: 7391.92 toks/s, output: 1257.86 toks/s]
Processing batched inference: 100%|██████████| 66/66 [07:05<00:00,  4.96s/it]Processing batched inference: 100%|██████████| 66/66 [07:05<00:00,  6.45s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-567/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:34:51.049018921 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-63
INFO 07-05 11:35:06 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:35:08,013 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:35:08,036 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,057 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,057 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,057 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,057 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,057 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,057 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,057 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:35:08,443 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:35:08,445 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:35:08,449 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:35:08,457 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,458 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,458 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,458 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,458 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,458 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,458 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:08,458 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:35:08,832 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:35:08,834 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:35:09,033 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:35:09,476 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:35:09,531 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:35:09,531 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:35:09,533 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:35:21 [config.py:689] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.
INFO 07-05 11:35:21 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:21,148 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:21,148 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:21,148 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:21,148 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:21,148 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:21,148 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:21,148 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:35:21,481 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:35:21,583 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:35:21,586 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:35:22 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:35:23 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:35:23 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63...
WARNING 07-05 11:35:23 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:35:23 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.28s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.28s/it]

INFO 07-05 11:35:31 [loader.py:458] Loading weights took 7.49 seconds
INFO 07-05 11:35:31 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.733958 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:31,919 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:31,919 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:31,920 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:31,920 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:31,920 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:31,920 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:31,920 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:35:32,326 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:35:32,422 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:35:32,423 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:35:32,423 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:35:32,423 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:32,424 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:32,424 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:32,424 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:32,424 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:32,424 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:32,424 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:32,424 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:35:33,185 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:35:33,185 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:35:33,186 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:35:33,637 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:35:34,311 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:35:34 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:35:37,161 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:35:38,158 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:35:38 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:36:16 [worker.py:267] Memory profiling takes 45.05 seconds
INFO 07-05 11:36:16 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:36:16 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:36:17 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:36:17 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:36:25 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.74it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.86it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.89it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.84it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.88it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.90it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.91it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.92it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.95it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.92it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.94it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.94it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.88it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.90it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.91it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.93it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.87it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.89it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.90it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.91it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.92it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.93it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.93it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.89it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 11:36:43 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:36:43 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.08 seconds
[INFO|2025-07-05 11:36:44] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:36:45,195 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:36:45,195 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:36:45,196 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:36:45,196 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:36:45,196 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:36:45,196 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:36:45,196 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:36:45,196 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:36:45,196 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:36:46,393 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:36:46,393 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:36:46,393 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:36:46,995 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-63', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 237.38 toks/s, output: 32.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 20.07it/s, est. speed input: 5930.42 toks/s, output: 887.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6537.91 toks/s, output: 1041.38 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:07,  4.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.67 toks/s, output: 42.19 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.36it/s, est. speed input: 7346.01 toks/s, output: 1090.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 7836.54 toks/s, output: 1223.46 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:35,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.10 toks/s, output: 42.11 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7015.44 toks/s, output: 1042.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7779.73 toks/s, output: 1276.40 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:04,  2.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.66 toks/s, output: 42.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.95it/s, est. speed input: 8047.81 toks/s, output: 1184.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.51it/s, est. speed input: 8047.81 toks/s, output: 1184.47 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:11<02:46,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.57 toks/s, output: 42.03 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6230.22 toks/s, output: 924.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7733.40 toks/s, output: 1350.34 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:14<02:39,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.36 toks/s, output: 42.28 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.48it/s, est. speed input: 7313.08 toks/s, output: 1078.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 7820.35 toks/s, output: 1239.64 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:16<02:33,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.07 toks/s, output: 41.13 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.76it/s, est. speed input: 7393.15 toks/s, output: 1094.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 7637.67 toks/s, output: 1185.49 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:19<02:30,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.75 toks/s, output: 42.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6751.35 toks/s, output: 1005.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7760.78 toks/s, output: 1295.41 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:21<02:26,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.59 toks/s, output: 42.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.14it/s, est. speed input: 7804.88 toks/s, output: 1150.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.53it/s, est. speed input: 8053.92 toks/s, output: 1214.33 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:24<02:21,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.02 toks/s, output: 42.10 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7012.91 toks/s, output: 1039.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7773.15 toks/s, output: 1266.96 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:26<02:18,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.11 toks/s, output: 42.11 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.32it/s, est. speed input: 7325.11 toks/s, output: 1078.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.92it/s, est. speed input: 7814.69 toks/s, output: 1212.07 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:29<02:15,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.47 toks/s, output: 42.02 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7279.42 toks/s, output: 1080.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7793.45 toks/s, output: 1246.00 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:31<02:13,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.23 toks/s, output: 41.99 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7278.74 toks/s, output: 1080.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7793.65 toks/s, output: 1247.27 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:33<02:09,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.61 toks/s, output: 42.71 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.41it/s, est. speed input: 5235.52 toks/s, output: 783.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7699.67 toks/s, output: 1443.99 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:36<02:05,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.84 toks/s, output: 41.93 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6478.01 toks/s, output: 962.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7732.09 toks/s, output: 1312.99 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:38<02:03,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.63 toks/s, output: 42.04 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.86it/s, est. speed input: 5969.19 toks/s, output: 890.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7714.82 toks/s, output: 1381.83 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:41<02:00,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.22 toks/s, output: 42.12 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.33it/s, est. speed input: 7336.91 toks/s, output: 1088.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 7826.81 toks/s, output: 1221.41 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:43<01:56,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 296.70 toks/s, output: 41.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 24.69it/s, est. speed input: 7430.46 toks/s, output: 1099.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 7670.05 toks/s, output: 1164.88 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:45<01:54,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 294.96 toks/s, output: 40.84 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.55it/s, est. speed input: 7618.33 toks/s, output: 1128.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 7629.01 toks/s, output: 1159.91 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:48<01:54,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.94 toks/s, output: 41.35 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 25.30it/s, est. speed input: 7611.39 toks/s, output: 1133.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7611.39 toks/s, output: 1133.07 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:50<01:51,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.77 toks/s, output: 40.81 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.83it/s, est. speed input: 7111.64 toks/s, output: 1055.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.39it/s, est. speed input: 7611.03 toks/s, output: 1208.62 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:53<01:49,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.48 toks/s, output: 41.05 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.51it/s, est. speed input: 5852.71 toks/s, output: 870.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.28it/s, est. speed input: 7569.06 toks/s, output: 1350.56 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [00:55<01:48,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.45 toks/s, output: 40.91 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.07it/s, est. speed input: 6602.41 toks/s, output: 980.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 7592.59 toks/s, output: 1259.88 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [00:58<01:44,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.08 toks/s, output: 40.58 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.59it/s, est. speed input: 7328.86 toks/s, output: 1083.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 7640.68 toks/s, output: 1183.20 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:00<01:42,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.10 toks/s, output: 40.86 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.69it/s, est. speed input: 7362.00 toks/s, output: 1087.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 7624.20 toks/s, output: 1185.22 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:02<01:38,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.59 toks/s, output: 40.79 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 23.72it/s, est. speed input: 7149.80 toks/s, output: 1066.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.40it/s, est. speed input: 7626.69 toks/s, output: 1196.32 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:05<01:36,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.19 toks/s, output: 40.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.86it/s, est. speed input: 7120.64 toks/s, output: 1056.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 7620.03 toks/s, output: 1209.54 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:07<01:32,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.03 toks/s, output: 40.71 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.64it/s, est. speed input: 7350.92 toks/s, output: 1091.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.36it/s, est. speed input: 7603.81 toks/s, output: 1182.79 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:09<01:30,  2.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.23 toks/s, output: 40.88 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 23.78it/s, est. speed input: 7163.52 toks/s, output: 1065.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 7641.59 toks/s, output: 1195.59 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:12<01:26,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.25 toks/s, output: 40.88 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.68it/s, est. speed input: 7366.33 toks/s, output: 1093.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.00it/s, est. speed input: 7852.72 toks/s, output: 1216.90 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:14<01:22,  2.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.11 toks/s, output: 40.72 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.85it/s, est. speed input: 6825.44 toks/s, output: 1009.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7598.73 toks/s, output: 1230.94 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:16<01:20,  2.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.40 toks/s, output: 41.41 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.93it/s, est. speed input: 7120.91 toks/s, output: 1050.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 7628.22 toks/s, output: 1210.20 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:19<01:18,  2.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.27 toks/s, output: 40.61 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.11it/s, est. speed input: 7231.01 toks/s, output: 1076.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.34it/s, est. speed input: 7601.59 toks/s, output: 1190.48 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:21<01:16,  2.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.71 toks/s, output: 40.81 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.89it/s, est. speed input: 6842.97 toks/s, output: 1017.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7593.71 toks/s, output: 1245.18 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:23<01:15,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.79 toks/s, output: 41.23 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.48it/s, est. speed input: 7897.25 toks/s, output: 1162.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.12it/s, est. speed input: 7897.25 toks/s, output: 1162.94 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:26<01:11,  2.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.16 toks/s, output: 41.70 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.28it/s, est. speed input: 6964.31 toks/s, output: 1032.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7720.05 toks/s, output: 1253.78 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:28<01:08,  2.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.06 toks/s, output: 41.68 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.19it/s, est. speed input: 7223.90 toks/s, output: 1065.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7732.82 toks/s, output: 1226.70 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:30<01:05,  2.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.37 toks/s, output: 42.39 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.22it/s, est. speed input: 7525.32 toks/s, output: 1121.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7784.22 toks/s, output: 1219.60 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:32<01:03,  2.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.33 toks/s, output: 41.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6725.99 toks/s, output: 996.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7732.04 toks/s, output: 1295.54 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:35<01:01,  2.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.99 toks/s, output: 41.67 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.20it/s, est. speed input: 7236.10 toks/s, output: 1075.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7749.24 toks/s, output: 1241.10 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:37<00:58,  2.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.41 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 6994.33 toks/s, output: 1033.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7757.72 toks/s, output: 1265.88 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:39<00:56,  2.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.17 toks/s, output: 41.98 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.57it/s, est. speed input: 7326.64 toks/s, output: 1083.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7774.55 toks/s, output: 1231.26 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [01:41<00:54,  2.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.38 toks/s, output: 42.53 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.32it/s, est. speed input: 7543.89 toks/s, output: 1115.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.50it/s, est. speed input: 8042.59 toks/s, output: 1241.99 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [01:44<00:52,  2.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.23 toks/s, output: 41.99 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6478.54 toks/s, output: 957.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7734.57 toks/s, output: 1310.14 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [01:46<00:49,  2.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.76 toks/s, output: 41.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.22it/s, est. speed input: 7525.86 toks/s, output: 1110.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7778.48 toks/s, output: 1208.26 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [01:48<00:46,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.30 toks/s, output: 41.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7256.17 toks/s, output: 1073.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7760.90 toks/s, output: 1229.30 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [01:50<00:44,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.51 toks/s, output: 42.41 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 6993.01 toks/s, output: 1039.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7755.43 toks/s, output: 1272.42 toks/s]
Processing batched inference:  71%|███████   | 47/66 [01:52<00:42,  2.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.95 toks/s, output: 41.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.08it/s, est. speed input: 7558.22 toks/s, output: 1120.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7802.05 toks/s, output: 1186.60 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [01:55<00:39,  2.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.08 toks/s, output: 41.96 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.33it/s, est. speed input: 7269.99 toks/s, output: 1074.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 7782.39 toks/s, output: 1235.61 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [01:57<00:37,  2.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.32 toks/s, output: 42.53 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7005.06 toks/s, output: 1037.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7758.22 toks/s, output: 1255.54 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [01:59<00:35,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.12 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6741.28 toks/s, output: 999.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7748.17 toks/s, output: 1293.82 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:01<00:33,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.57 toks/s, output: 41.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.79it/s, est. speed input: 8008.65 toks/s, output: 1187.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.38it/s, est. speed input: 8008.65 toks/s, output: 1187.94 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:03<00:30,  2.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.74 toks/s, output: 42.06 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.90it/s, est. speed input: 7177.32 toks/s, output: 1063.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7803.14 toks/s, output: 1246.38 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:06<00:28,  2.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.31 toks/s, output: 41.72 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7237.58 toks/s, output: 1067.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7747.99 toks/s, output: 1229.11 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:08<00:26,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.53 toks/s, output: 41.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 24.19it/s, est. speed input: 9493.07 toks/s, output: 1366.51 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:10<00:23,  2.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.25 toks/s, output: 41.85 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6211.70 toks/s, output: 923.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7710.19 toks/s, output: 1354.63 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:12<00:21,  2.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.94 toks/s, output: 41.95 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.23it/s, est. speed input: 7530.88 toks/s, output: 1109.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7787.03 toks/s, output: 1203.77 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:14<00:19,  2.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.67 toks/s, output: 42.29 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6193.52 toks/s, output: 916.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 7690.51 toks/s, output: 1339.71 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:17<00:17,  2.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.73 toks/s, output: 41.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.02it/s, est. speed input: 7759.23 toks/s, output: 1143.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7766.85 toks/s, output: 1175.10 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [02:19<00:15,  2.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.65 toks/s, output: 42.29 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6203.31 toks/s, output: 921.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7701.49 toks/s, output: 1334.07 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [02:21<00:13,  2.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.93 toks/s, output: 42.33 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6723.72 toks/s, output: 1000.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7731.59 toks/s, output: 1293.82 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [02:24<00:11,  2.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.92 toks/s, output: 41.80 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.42it/s, est. speed input: 7348.34 toks/s, output: 1091.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7780.37 toks/s, output: 1215.54 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [02:26<00:09,  2.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.05 toks/s, output: 41.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.77it/s, est. speed input: 7993.55 toks/s, output: 1180.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 7993.55 toks/s, output: 1180.38 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [02:28<00:06,  2.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.22 toks/s, output: 41.84 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7258.61 toks/s, output: 1073.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7771.16 toks/s, output: 1235.48 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [02:30<00:04,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.15 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 6738.54 toks/s, output: 994.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7747.00 toks/s, output: 1293.53 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [02:33<00:02,  2.22s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 334.55 toks/s, output: 46.32 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 22.59it/s, est. speed input: 6799.75 toks/s, output: 1010.29 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.77it/s, est. speed input: 7372.51 toks/s, output: 1192.87 toks/s]
Processing batched inference: 100%|██████████| 66/66 [02:35<00:00,  2.18s/it]Processing batched inference: 100%|██████████| 66/66 [02:35<00:00,  2.35s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-63/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:39:21.169777107 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-630
INFO 07-05 11:39:33 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:39:35,462 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:39:35,506 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,529 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,529 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,529 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,529 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,529 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,529 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,530 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:39:35,916 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:39:35,918 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:39:35,923 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:39:35,930 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,931 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,931 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,931 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,931 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,931 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,931 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:35,931 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:39:36,304 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:39:36,307 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:39:36,503 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:39:36,945 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:39:37,000 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:39:37,001 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:39:37,003 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:39:48 [config.py:689] This model supports multiple tasks: {'classify', 'reward', 'embed', 'score', 'generate'}. Defaulting to 'generate'.
INFO 07-05 11:39:48 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:48,657 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:48,657 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:48,657 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:48,657 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:48,657 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:48,657 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:48,657 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:39:48,999 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:39:49,101 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:39:49,104 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:39:50 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:39:50 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:39:50 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630...
WARNING 07-05 11:39:51 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:39:51 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.19s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.19s/it]

INFO 07-05 11:39:58 [loader.py:458] Loading weights took 7.41 seconds
INFO 07-05 11:39:58 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.659491 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,088 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,088 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,088 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,088 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,088 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,088 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,088 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:39:59,498 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:39:59,595 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:39:59,595 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:39:59,596 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:39:59,596 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,597 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,597 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,597 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,597 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,597 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,597 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:59,597 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:40:00,346 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:40:00,346 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:40:00,346 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:40:00,803 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:40:01,457 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:40:01 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:40:04,277 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:40:05,272 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:40:05 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:40:44 [worker.py:267] Memory profiling takes 44.97 seconds
INFO 07-05 11:40:44 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:40:44 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:40:44 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:40:44 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:40:53 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.71it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.81it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.87it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.90it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.91it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.91it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.92it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.92it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.90it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.91it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.91it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.92it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.93it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.92it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.89it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.91it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.92it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.93it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.94it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.94it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.86it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.88it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.90it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.92it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.93it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.93it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.92it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.87it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]
INFO 07-05 11:41:11 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:41:11 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.91 seconds
[INFO|2025-07-05 11:41:12] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:41:13,226 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:41:13,227 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:41:13,227 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:41:13,227 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:41:13,228 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:41:13,228 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:41:13,228 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:41:13,228 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:41:13,228 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:41:14,433 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:41:14,435 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:41:14,435 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:41:15,002 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-630', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.63s/it, est. speed input: 238.74 toks/s, output: 33.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 18.64it/s, est. speed input: 5518.08 toks/s, output: 821.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.22it/s, est. speed input: 6375.05 toks/s, output: 1068.16 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:16,  4.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.24 toks/s, output: 42.26 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.40it/s, est. speed input: 6727.92 toks/s, output: 996.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7792.98 toks/s, output: 1304.71 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:40,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.07 toks/s, output: 42.24 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.90it/s, est. speed input: 5987.05 toks/s, output: 892.49 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.18it/s, est. speed input: 6144.18 toks/s, output: 1089.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6554.37 toks/s, output: 1252.07 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:16,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.72 toks/s, output: 42.33 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.54it/s, est. speed input: 7045.44 toks/s, output: 1040.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 7806.11 toks/s, output: 1267.02 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:55,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.25 toks/s, output: 42.27 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.95it/s, est. speed input: 5996.10 toks/s, output: 892.76 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.19it/s, est. speed input: 6146.03 toks/s, output: 1085.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.32it/s, est. speed input: 6015.29 toks/s, output: 1158.53 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:15<02:54,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.39 toks/s, output: 42.15 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.43it/s, est. speed input: 7294.95 toks/s, output: 1074.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 7803.18 toks/s, output: 1236.91 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:17<02:42,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.02 toks/s, output: 42.09 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.47it/s, est. speed input: 7078.54 toks/s, output: 1048.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 7812.67 toks/s, output: 1248.11 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:20<02:34,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.65 toks/s, output: 42.18 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.48it/s, est. speed input: 7033.85 toks/s, output: 1045.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7796.82 toks/s, output: 1271.03 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:22<02:28,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.29 toks/s, output: 42.13 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6497.07 toks/s, output: 958.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7754.87 toks/s, output: 1318.10 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:25<02:22,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.25 toks/s, output: 42.27 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.76it/s, est. speed input: 7153.53 toks/s, output: 1058.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.96it/s, est. speed input: 7835.80 toks/s, output: 1250.35 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:27<02:17,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.48 toks/s, output: 42.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.59it/s, est. speed input: 6758.44 toks/s, output: 994.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6555.96 toks/s, output: 1116.59 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:30<02:19,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.49 toks/s, output: 42.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.32it/s, est. speed input: 6710.46 toks/s, output: 997.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7772.33 toks/s, output: 1301.97 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:32<02:14,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.19 toks/s, output: 42.12 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.81it/s, est. speed input: 6244.75 toks/s, output: 927.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.57it/s, est. speed input: 6543.05 toks/s, output: 1173.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6543.05 toks/s, output: 1173.60 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:35<02:14,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.79 toks/s, output: 42.20 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.63it/s, est. speed input: 7060.35 toks/s, output: 1043.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6568.54 toks/s, output: 1086.90 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:37<02:13,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 306.05 toks/s, output: 41.59 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7017.27 toks/s, output: 1035.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.76it/s, est. speed input: 6577.34 toks/s, output: 1120.04 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:40<02:11,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.95 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6495.91 toks/s, output: 965.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7753.79 toks/s, output: 1329.60 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:42<02:06,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.58 toks/s, output: 41.30 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.19it/s, est. speed input: 6331.82 toks/s, output: 940.86 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s, est. speed input: 2930.45 toks/s, output: 633.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.46it/s, est. speed input: 2930.45 toks/s, output: 633.38 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:47<02:40,  3.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.08 toks/s, output: 40.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.05it/s, est. speed input: 6594.86 toks/s, output: 978.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7583.86 toks/s, output: 1261.66 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:50<02:26,  3.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.22 toks/s, output: 40.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.32it/s, est. speed input: 6090.79 toks/s, output: 907.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.26it/s, est. speed input: 7563.60 toks/s, output: 1322.67 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:52<02:15,  2.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 293.23 toks/s, output: 41.89 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.04it/s, est. speed input: 6298.31 toks/s, output: 942.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.25it/s, est. speed input: 6442.19 toks/s, output: 1152.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6442.19 toks/s, output: 1152.67 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:55<02:10,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 292.97 toks/s, output: 40.56 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.06it/s, est. speed input: 6303.02 toks/s, output: 936.68 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 6400.87 toks/s, output: 1164.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.30it/s, est. speed input: 6400.87 toks/s, output: 1164.71 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:58<02:07,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.80 toks/s, output: 40.96 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 16.91it/s, est. speed input: 5088.36 toks/s, output: 759.97 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.53it/s, est. speed input: 5992.59 toks/s, output: 1132.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.70it/s, est. speed input: 4592.28 toks/s, output: 974.00 toks/s] 
Processing batched inference:  33%|███▎      | 22/66 [01:01<02:15,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.40 toks/s, output: 40.76 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.89it/s, est. speed input: 6834.36 toks/s, output: 1010.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.23it/s, est. speed input: 5586.32 toks/s, output: 973.67 toks/s] 
Processing batched inference:  35%|███▍      | 23/66 [01:04<02:11,  3.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.45 toks/s, output: 40.77 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.99it/s, est. speed input: 6576.11 toks/s, output: 973.13 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.99it/s, est. speed input: 7327.00 toks/s, output: 1194.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 480.75 toks/s, output: 232.68 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.75 toks/s, output: 232.68 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:31<07:09, 10.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.25 toks/s, output: 40.74 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.66it/s, est. speed input: 5931.75 toks/s, output: 882.11 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.75it/s, est. speed input: 5999.53 toks/s, output: 1063.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 18.75it/s, est. speed input: 5057.12 toks/s, output: 963.22 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.02it/s, est. speed input: 683.08 toks/s, output: 280.51 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.74it/s, est. speed input: 683.08 toks/s, output: 280.51 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:51<08:48, 12.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:42,  1.37s/it, est. speed input: 283.67 toks/s, output: 39.28 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 19.95it/s, est. speed input: 6005.51 toks/s, output: 896.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 19.76it/s, est. speed input: 6248.40 toks/s, output: 1100.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.90it/s, est. speed input: 6248.40 toks/s, output: 1100.84 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:53<06:34,  9.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.37 toks/s, output: 40.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.88it/s, est. speed input: 7123.04 toks/s, output: 1053.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.50it/s, est. speed input: 6478.39 toks/s, output: 1080.41 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:56<04:59,  7.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.50 toks/s, output: 40.78 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.00it/s, est. speed input: 6636.12 toks/s, output: 985.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7586.53 toks/s, output: 1243.49 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:58<03:50,  6.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.23 toks/s, output: 40.88 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.71it/s, est. speed input: 6235.00 toks/s, output: 928.31 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.36it/s, est. speed input: 6225.44 toks/s, output: 1074.45 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 19.36it/s, est. speed input: 6225.44 toks/s, output: 1074.45 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.46s/it, est. speed input: 481.28 toks/s, output: 237.27 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.28 toks/s, output: 237.27 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [02:25<07:35, 12.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.41 toks/s, output: 40.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.99it/s, est. speed input: 7151.06 toks/s, output: 1059.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6514.10 toks/s, output: 1060.27 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:28<05:37,  9.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.00 toks/s, output: 40.85 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.32it/s, est. speed input: 6083.76 toks/s, output: 900.74 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.54it/s, est. speed input: 6417.48 toks/s, output: 1118.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.46it/s, est. speed input: 6458.28 toks/s, output: 1169.13 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [02:30<04:16,  7.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.32 toks/s, output: 41.40 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.50it/s, est. speed input: 5833.56 toks/s, output: 864.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.23it/s, est. speed input: 7547.40 toks/s, output: 1340.44 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [02:32<03:17,  5.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.57 toks/s, output: 40.79 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.70it/s, est. speed input: 6233.50 toks/s, output: 931.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.07it/s, est. speed input: 5559.27 toks/s, output: 1000.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.14it/s, est. speed input: 5559.27 toks/s, output: 1000.56 toks/s]
Processing batched inference:  50%|█████     | 33/66 [02:35<02:43,  4.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.49 toks/s, output: 40.78 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.36it/s, est. speed input: 6436.88 toks/s, output: 957.78 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.07it/s, est. speed input: 5597.26 toks/s, output: 983.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.24it/s, est. speed input: 5597.26 toks/s, output: 983.24 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [02:39<02:21,  4.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.42 toks/s, output: 41.18 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.18it/s, est. speed input: 6637.73 toks/s, output: 985.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.45it/s, est. speed input: 6453.62 toks/s, output: 1093.75 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:41<02:00,  3.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.92 toks/s, output: 41.25 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.47it/s, est. speed input: 6134.05 toks/s, output: 908.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 7617.56 toks/s, output: 1326.29 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:43<01:41,  3.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.21 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6464.93 toks/s, output: 959.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 7715.55 toks/s, output: 1308.14 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:46<01:28,  3.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.27 toks/s, output: 41.71 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.73it/s, est. speed input: 5933.11 toks/s, output: 888.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.64it/s, est. speed input: 6483.36 toks/s, output: 1189.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6483.36 toks/s, output: 1189.98 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:48<01:21,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.63 toks/s, output: 41.90 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5690.84 toks/s, output: 845.58 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.42it/s, est. speed input: 6119.88 toks/s, output: 1108.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6507.55 toks/s, output: 1265.36 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:51<01:15,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.58 toks/s, output: 41.76 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.30it/s, est. speed input: 6976.34 toks/s, output: 1035.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7737.90 toks/s, output: 1265.74 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:53<01:08,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.31 toks/s, output: 42.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5699.28 toks/s, output: 846.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.32it/s, est. speed input: 6335.41 toks/s, output: 1160.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6518.94 toks/s, output: 1238.09 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:56<01:05,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.84 toks/s, output: 41.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.48it/s, est. speed input: 7586.59 toks/s, output: 1119.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.90it/s, est. speed input: 6631.51 toks/s, output: 1051.82 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:58<01:01,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.03 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.33it/s, est. speed input: 6977.52 toks/s, output: 1031.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.80it/s, est. speed input: 4631.74 toks/s, output: 819.29 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [03:02<01:05,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.10 toks/s, output: 41.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6460.99 toks/s, output: 956.38 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.19it/s, est. speed input: 5153.89 toks/s, output: 928.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.14it/s, est. speed input: 5153.89 toks/s, output: 928.85 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [03:05<01:03,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.07 toks/s, output: 41.82 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.18it/s, est. speed input: 7513.34 toks/s, output: 1106.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7775.36 toks/s, output: 1204.67 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:07<00:56,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.46 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6480.39 toks/s, output: 958.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.63it/s, est. speed input: 1119.23 toks/s, output: 337.22 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.05s/it, est. speed input: 483.54 toks/s, output: 298.86 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.54 toks/s, output: 298.86 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [03:33<03:17,  9.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.26 toks/s, output: 41.88 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.34it/s, est. speed input: 6990.23 toks/s, output: 1040.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7749.50 toks/s, output: 1268.98 toks/s]
Processing batched inference:  71%|███████   | 47/66 [03:36<02:24,  7.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.20 toks/s, output: 41.98 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.68it/s, est. speed input: 6840.60 toks/s, output: 1015.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6566.77 toks/s, output: 1122.07 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [03:38<01:49,  6.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 5701.14 toks/s, output: 845.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:07<00:00,  3.54it/s, est. speed input: 1614.76 toks/s, output: 422.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.11it/s, est. speed input: 1614.76 toks/s, output: 422.75 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [03:47<01:54,  6.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.42 toks/s, output: 41.26 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.75it/s, est. speed input: 7139.46 toks/s, output: 1051.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.13it/s, est. speed input: 6720.06 toks/s, output: 1089.67 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [03:49<01:28,  5.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.52 toks/s, output: 42.03 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5705.23 toks/s, output: 852.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 7693.26 toks/s, output: 1397.93 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [03:51<01:07,  4.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.15 toks/s, output: 41.97 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5959.14 toks/s, output: 888.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7702.48 toks/s, output: 1379.61 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [03:54<00:53,  3.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.31 toks/s, output: 42.52 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5962.52 toks/s, output: 886.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7707.05 toks/s, output: 1375.18 toks/s]
Processing batched inference:  80%|████████  | 53/66 [03:56<00:43,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.13 toks/s, output: 42.11 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7017.36 toks/s, output: 1038.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7776.34 toks/s, output: 1262.09 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [03:58<00:36,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.35 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6738.58 toks/s, output: 995.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s, est. speed input: 1057.97 toks/s, output: 326.32 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [04:11<01:04,  5.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.60 toks/s, output: 42.04 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.98it/s, est. speed input: 5712.83 toks/s, output: 854.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.23it/s, est. speed input: 6327.11 toks/s, output: 1164.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.43it/s, est. speed input: 5668.10 toks/s, output: 1102.24 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [04:13<00:49,  4.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.87 toks/s, output: 42.21 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.83it/s, est. speed input: 6248.29 toks/s, output: 924.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.24it/s, est. speed input: 3728.81 toks/s, output: 734.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.50it/s, est. speed input: 3728.81 toks/s, output: 734.12 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [04:17<00:42,  4.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 303.00 toks/s, output: 42.62 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.17it/s, est. speed input: 5457.08 toks/s, output: 811.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7685.46 toks/s, output: 1424.49 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [04:20<00:31,  3.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.57 toks/s, output: 42.17 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.83it/s, est. speed input: 7447.88 toks/s, output: 1099.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 7824.65 toks/s, output: 1214.37 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [04:22<00:24,  3.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.09 toks/s, output: 42.10 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.68it/s, est. speed input: 6782.43 toks/s, output: 1002.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7766.55 toks/s, output: 1288.43 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [04:24<00:18,  3.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.04 toks/s, output: 41.82 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.86it/s, est. speed input: 5676.33 toks/s, output: 845.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.07it/s, est. speed input: 6515.53 toks/s, output: 1216.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6515.53 toks/s, output: 1216.76 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [04:27<00:14,  2.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.67 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.60it/s, est. speed input: 5908.67 toks/s, output: 883.47 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.86it/s, est. speed input: 5668.50 toks/s, output: 1037.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5658.09 toks/s, output: 1095.51 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [04:30<00:11,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.66 toks/s, output: 41.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.43it/s, est. speed input: 7622.94 toks/s, output: 1127.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 7808.09 toks/s, output: 1184.07 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [04:32<00:08,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.20 toks/s, output: 42.12 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.56it/s, est. speed input: 6755.67 toks/s, output: 999.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.86it/s, est. speed input: 6616.85 toks/s, output: 1128.87 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [04:34<00:05,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.18 toks/s, output: 42.12 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6242.00 toks/s, output: 926.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.66it/s, est. speed input: 4984.86 toks/s, output: 924.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.70it/s, est. speed input: 4984.86 toks/s, output: 924.81 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [04:37<00:02,  2.77s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 336.53 toks/s, output: 46.48 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 22.65it/s, est. speed input: 6818.45 toks/s, output: 1011.67 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.82it/s, est. speed input: 7392.00 toks/s, output: 1194.68 toks/s]
Processing batched inference: 100%|██████████| 66/66 [04:40<00:00,  2.57s/it]Processing batched inference: 100%|██████████| 66/66 [04:40<00:00,  4.24s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-630/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:45:53.125476044 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-693
INFO 07-05 11:46:07 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:46:08,838 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:46:08,901 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:08,925 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:08,925 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:08,925 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:08,925 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:08,925 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:08,925 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:08,925 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:46:09,331 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:46:09,333 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:46:09,339 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:46:09,345 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:09,347 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:09,347 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:09,347 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:09,347 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:09,347 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:09,347 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:09,347 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:46:09,722 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:46:09,725 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:46:09,937 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:46:10,378 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:46:10,434 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:46:10,434 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:46:10,436 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:46:22 [config.py:689] This model supports multiple tasks: {'embed', 'classify', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
INFO 07-05 11:46:22 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:22,021 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:22,021 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:22,021 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:22,021 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:22,021 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:22,021 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:22,021 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:46:22,357 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:46:22,457 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:46:22,460 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:46:23 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:46:24 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:46:24 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693...
WARNING 07-05 11:46:24 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:46:24 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.28s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.28s/it]

INFO 07-05 11:46:32 [loader.py:458] Loading weights took 7.49 seconds
INFO 07-05 11:46:32 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.740125 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,471 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,471 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,471 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,471 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,471 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,471 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,471 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:46:32,899 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:46:32,995 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:46:32,996 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:46:32,996 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:46:32,997 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,997 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,997 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,997 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,997 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,997 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,997 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:46:32,997 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:46:33,758 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:46:33,759 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:46:33,759 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:46:34,203 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:46:34,882 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:46:35 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:46:37,690 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:46:38,684 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:46:38 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:47:17 [worker.py:267] Memory profiling takes 45.28 seconds
INFO 07-05 11:47:17 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:47:17 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:47:17 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:47:17 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:47:26 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.72it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.82it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.83it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.87it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.90it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.90it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.89it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.91it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.92it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.92it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:10,  1.89it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.90it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.92it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.92it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:11<00:07,  1.92it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.92it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.93it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.93it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.92it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.89it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.91it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.84it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.87it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.89it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.91it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.92it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.93it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.93it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.88it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.90it/s]
INFO 07-05 11:47:44 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:47:44 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.41 seconds
[INFO|2025-07-05 11:47:45] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:18, 106.31 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 216.06 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 321.35 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 587.21 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:02, 576.23 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 660.80 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:02<00:01, 677.94 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:02<00:00, 895.80 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 924.90 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:02<00:00, 841.99 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:03<00:00, 900.95 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 980.65 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 917.66 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 589.26 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:47:51,940 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:47:51,940 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:47:51,941 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:47:51,941 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:47:51,941 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:47:51,941 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:47:51,941 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:47:51,941 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:47:51,941 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:47:52,715 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:47:52,715 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:47:52,716 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:47:53,177 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-693', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.63s/it, est. speed input: 239.33 toks/s, output: 33.14 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.86it/s, est. speed input: 5302.73 toks/s, output: 793.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.18it/s, est. speed input: 6356.77 toks/s, output: 1085.32 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:30,  4.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.25 toks/s, output: 42.26 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.70it/s, est. speed input: 6853.58 toks/s, output: 1016.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.76it/s, est. speed input: 6581.14 toks/s, output: 1103.39 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:33,  3.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.31 toks/s, output: 42.27 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.19it/s, est. speed input: 5480.99 toks/s, output: 818.52 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.64it/s, est. speed input: 6134.14 toks/s, output: 1139.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.60it/s, est. speed input: 2202.21 toks/s, output: 546.78 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:13<05:01,  4.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.53 toks/s, output: 42.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.80it/s, est. speed input: 6527.16 toks/s, output: 969.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7777.20 toks/s, output: 1316.84 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:15<03:58,  3.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.11 toks/s, output: 42.28 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.63it/s, est. speed input: 6782.75 toks/s, output: 1006.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.51it/s, est. speed input: 5697.80 toks/s, output: 1013.49 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:18<03:36,  3.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.33 toks/s, output: 42.28 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.47it/s, est. speed input: 7309.30 toks/s, output: 1074.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 7826.22 toks/s, output: 1241.19 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:21<03:08,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 291.76 toks/s, output: 40.40 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 21.97it/s, est. speed input: 6610.73 toks/s, output: 978.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.18it/s, est. speed input: 7530.31 toks/s, output: 1231.77 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:23<02:52,  2.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.97 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6500.42 toks/s, output: 968.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7760.21 toks/s, output: 1325.57 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:26<02:40,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.01 toks/s, output: 42.23 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.52it/s, est. speed input: 7037.00 toks/s, output: 1040.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7796.67 toks/s, output: 1263.73 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:28<02:29,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 307.50 toks/s, output: 41.68 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.31it/s, est. speed input: 7575.69 toks/s, output: 1120.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 7832.31 toks/s, output: 1214.26 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:30<02:22,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.44 toks/s, output: 42.15 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.60it/s, est. speed input: 6759.95 toks/s, output: 994.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7772.89 toks/s, output: 1293.51 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:33<02:17,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.85 toks/s, output: 42.21 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.83it/s, est. speed input: 6256.61 toks/s, output: 932.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 7764.12 toks/s, output: 1359.27 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:35<02:13,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.08 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6482.97 toks/s, output: 962.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7738.60 toks/s, output: 1327.72 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:38<02:10,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.49 toks/s, output: 42.69 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.39it/s, est. speed input: 6086.69 toks/s, output: 907.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.70it/s, est. speed input: 6527.07 toks/s, output: 1171.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6527.07 toks/s, output: 1171.56 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:40<02:11,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.59 toks/s, output: 42.20 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.84it/s, est. speed input: 6253.17 toks/s, output: 927.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7759.97 toks/s, output: 1349.23 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:43<02:05,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.45 toks/s, output: 42.15 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.58it/s, est. speed input: 6766.63 toks/s, output: 1005.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7778.67 toks/s, output: 1304.17 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:45<02:01,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.91 toks/s, output: 42.61 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.70it/s, est. speed input: 6495.25 toks/s, output: 963.97 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.58it/s, est. speed input: 5740.28 toks/s, output: 1045.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.62it/s, est. speed input: 5740.28 toks/s, output: 1045.18 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:48<02:06,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.36 toks/s, output: 42.28 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.49it/s, est. speed input: 7321.83 toks/s, output: 1084.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 7832.73 toks/s, output: 1244.45 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:50<02:00,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.46 toks/s, output: 42.69 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.73it/s, est. speed input: 6509.39 toks/s, output: 970.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7768.53 toks/s, output: 1326.99 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:52<01:55,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.98 toks/s, output: 42.62 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.26it/s, est. speed input: 6969.21 toks/s, output: 1037.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7788.03 toks/s, output: 1277.66 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:55<01:50,  2.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.36 toks/s, output: 41.59 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.35it/s, est. speed input: 6692.15 toks/s, output: 994.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7695.58 toks/s, output: 1281.47 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:57<01:47,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.48 toks/s, output: 42.16 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.55it/s, est. speed input: 4700.59 toks/s, output: 705.27 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.15it/s, est. speed input: 6301.58 toks/s, output: 1253.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6505.05 toks/s, output: 1334.65 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:00<01:48,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.85 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 6738.44 toks/s, output: 999.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.46it/s, est. speed input: 5675.54 toks/s, output: 1008.20 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:03<01:51,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.17 toks/s, output: 42.12 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 6759.56 toks/s, output: 1001.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.41it/s, est. speed input: 4086.52 toks/s, output: 756.78 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:06<02:03,  2.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.60 toks/s, output: 42.17 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.92it/s, est. speed input: 6269.27 toks/s, output: 929.20 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.92it/s, est. speed input: 6146.68 toks/s, output: 1062.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.84it/s, est. speed input: 1113.47 toks/s, output: 346.81 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:18<03:52,  5.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.36 toks/s, output: 41.86 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.27it/s, est. speed input: 6116.47 toks/s, output: 913.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.91it/s, est. speed input: 5034.73 toks/s, output: 943.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.81it/s, est. speed input: 5034.73 toks/s, output: 943.86 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:22<03:16,  4.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.67 toks/s, output: 42.18 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.71it/s, est. speed input: 6508.88 toks/s, output: 964.91 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 6556.25 toks/s, output: 1141.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6556.25 toks/s, output: 1141.93 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:24<02:44,  4.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.90 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6497.91 toks/s, output: 966.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7755.08 toks/s, output: 1326.65 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:26<02:17,  3.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.06 toks/s, output: 42.10 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.22it/s, est. speed input: 6397.72 toks/s, output: 952.53 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.02it/s, est. speed input: 6422.44 toks/s, output: 1106.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6566.00 toks/s, output: 1177.71 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:29<02:02,  3.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.97 toks/s, output: 42.09 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.52it/s, est. speed input: 7321.42 toks/s, output: 1084.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.93it/s, est. speed input: 6646.15 toks/s, output: 1082.29 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:31<01:49,  3.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.15 toks/s, output: 42.11 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 6756.95 toks/s, output: 998.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 7826.68 toks/s, output: 1298.41 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:34<01:37,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.15 toks/s, output: 42.11 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.81it/s, est. speed input: 6235.76 toks/s, output: 919.99 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.57it/s, est. speed input: 6534.28 toks/s, output: 1164.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6534.28 toks/s, output: 1164.67 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:36<01:32,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.89 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.98it/s, est. speed input: 6345.24 toks/s, output: 948.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.75it/s, est. speed input: 6357.80 toks/s, output: 1124.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6562.86 toks/s, output: 1205.71 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:39<01:28,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.37 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.05it/s, est. speed input: 6643.20 toks/s, output: 988.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7757.02 toks/s, output: 1301.57 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:41<01:21,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.89 toks/s, output: 42.08 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7017.58 toks/s, output: 1039.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7772.12 toks/s, output: 1258.41 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:43<01:16,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.22 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.18it/s, est. speed input: 6037.12 toks/s, output: 895.85 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.55it/s, est. speed input: 6450.58 toks/s, output: 1148.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6531.84 toks/s, output: 1207.97 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:46<01:15,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.66 toks/s, output: 42.18 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.49it/s, est. speed input: 7031.42 toks/s, output: 1041.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7790.47 toks/s, output: 1263.14 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:48<01:10,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.95 toks/s, output: 41.95 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.74it/s, est. speed input: 6574.97 toks/s, output: 984.40 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.30it/s, est. speed input: 6547.14 toks/s, output: 1150.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6547.14 toks/s, output: 1150.16 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:51<01:09,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.04 toks/s, output: 41.96 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.64it/s, est. speed input: 4426.61 toks/s, output: 663.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.40it/s, est. speed input: 6291.31 toks/s, output: 1280.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5609.33 toks/s, output: 1197.81 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:54<01:10,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.97 toks/s, output: 41.95 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6481.94 toks/s, output: 966.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7736.94 toks/s, output: 1322.81 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:56<01:04,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.91 toks/s, output: 41.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6477.39 toks/s, output: 959.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 6528.96 toks/s, output: 1140.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6528.96 toks/s, output: 1140.73 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:58<01:02,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.69 toks/s, output: 41.91 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 7007.41 toks/s, output: 1037.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7793.15 toks/s, output: 1262.75 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:01<00:58,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.33 toks/s, output: 41.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7259.52 toks/s, output: 1072.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7766.61 toks/s, output: 1230.30 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:03<00:54,  2.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.87 toks/s, output: 41.94 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.84it/s, est. speed input: 6244.31 toks/s, output: 927.12 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.32it/s, est. speed input: 4624.88 toks/s, output: 865.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.79it/s, est. speed input: 4624.88 toks/s, output: 865.94 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:06<00:58,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.88 toks/s, output: 41.94 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7270.08 toks/s, output: 1071.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7780.27 toks/s, output: 1236.41 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:08<00:52,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.31 toks/s, output: 42.00 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.07it/s, est. speed input: 5441.87 toks/s, output: 811.17 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.70it/s, est. speed input: 5886.19 toks/s, output: 1062.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 18.70it/s, est. speed input: 2890.74 toks/s, output: 652.58 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.35s/it, est. speed input: 482.18 toks/s, output: 262.73 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.18 toks/s, output: 262.73 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:35<03:15,  9.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.51 toks/s, output: 42.41 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.39it/s, est. speed input: 6992.93 toks/s, output: 1041.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7752.70 toks/s, output: 1270.12 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:37<02:22,  7.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.11 toks/s, output: 42.50 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7003.26 toks/s, output: 1038.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7765.25 toks/s, output: 1266.91 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:40<01:46,  5.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.45 toks/s, output: 42.54 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.01it/s, est. speed input: 5710.58 toks/s, output: 852.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7700.17 toks/s, output: 1394.23 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:42<01:21,  4.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.18 toks/s, output: 41.50 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7283.07 toks/s, output: 1073.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.14it/s, est. speed input: 6724.18 toks/s, output: 1089.27 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:44<01:06,  4.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.30 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6227.54 toks/s, output: 927.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7729.40 toks/s, output: 1346.06 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:47<00:53,  3.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.92 toks/s, output: 41.94 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6222.55 toks/s, output: 925.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7722.31 toks/s, output: 1354.30 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:49<00:44,  3.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.25 toks/s, output: 42.52 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 5962.26 toks/s, output: 885.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7706.82 toks/s, output: 1375.75 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:51<00:37,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6223.76 toks/s, output: 922.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.55it/s, est. speed input: 6524.40 toks/s, output: 1160.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6524.40 toks/s, output: 1160.22 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:53<00:33,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.90 toks/s, output: 41.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6475.82 toks/s, output: 958.57 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  5.86it/s, est. speed input: 2597.64 toks/s, output: 562.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s, est. speed input: 2597.64 toks/s, output: 562.34 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:59<00:39,  3.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.00 toks/s, output: 43.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.04it/s, est. speed input: 5708.28 toks/s, output: 855.26 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.29it/s, est. speed input: 6323.39 toks/s, output: 1162.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.38it/s, est. speed input: 5649.46 toks/s, output: 1098.16 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:02<00:33,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.41 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.86it/s, est. speed input: 5960.57 toks/s, output: 882.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.31it/s, est. speed input: 6384.84 toks/s, output: 1141.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.80it/s, est. speed input: 6590.60 toks/s, output: 1221.43 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:04<00:28,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.29 toks/s, output: 42.52 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.90it/s, est. speed input: 5961.95 toks/s, output: 882.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7704.87 toks/s, output: 1372.27 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:07<00:22,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.33 toks/s, output: 42.00 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.17it/s, est. speed input: 6948.62 toks/s, output: 1027.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 7761.64 toks/s, output: 1261.46 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:09<00:18,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.92 toks/s, output: 42.08 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.90it/s, est. speed input: 6262.23 toks/s, output: 928.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.88it/s, est. speed input: 6599.58 toks/s, output: 1169.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.82it/s, est. speed input: 6599.58 toks/s, output: 1169.48 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:11<00:15,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.71 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5955.24 toks/s, output: 886.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.92it/s, est. speed input: 6546.94 toks/s, output: 1197.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6546.94 toks/s, output: 1197.63 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:14<00:13,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.88 toks/s, output: 41.94 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.61it/s, est. speed input: 5911.10 toks/s, output: 882.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.01it/s, est. speed input: 6505.46 toks/s, output: 1167.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6523.66 toks/s, output: 1215.36 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:17<00:10,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.72 toks/s, output: 42.05 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7007.57 toks/s, output: 1036.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6556.61 toks/s, output: 1095.02 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:19<00:07,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.06 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6478.93 toks/s, output: 960.21 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 6530.03 toks/s, output: 1140.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6530.03 toks/s, output: 1140.06 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:22<00:05,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.79 toks/s, output: 42.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.87it/s, est. speed input: 5969.96 toks/s, output: 887.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7718.45 toks/s, output: 1369.88 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:24<00:02,  2.45s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 337.17 toks/s, output: 46.68 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.73it/s, est. speed input: 6260.15 toks/s, output: 931.94 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.78it/s, est. speed input: 7374.01 toks/s, output: 1254.81 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:26<00:00,  2.34s/it]Processing batched inference: 100%|██████████| 66/66 [03:26<00:00,  3.13s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-693/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:51:19.260278219 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-756
INFO 07-05 11:51:31 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:51:33,456 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:51:33,498 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,521 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,521 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,521 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,521 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,521 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,522 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,522 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:33,922 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:51:33,924 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:51:33,930 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:51:33,936 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,937 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,937 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,937 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,937 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,937 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,937 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:33,937 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:34,310 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:51:34,313 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:51:34,525 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:51:34,971 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:51:35,029 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:51:35,029 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:51:35,031 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:51:46 [config.py:689] This model supports multiple tasks: {'generate', 'embed', 'score', 'reward', 'classify'}. Defaulting to 'generate'.
INFO 07-05 11:51:46 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:46,585 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:46,585 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:46,585 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:46,585 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:46,585 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:46,585 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:46,585 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:46,925 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:51:47,019 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:51:47,020 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:51:48 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:51:48 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:51:48 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756...
WARNING 07-05 11:51:48 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:51:49 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.20s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.20s/it]

INFO 07-05 11:51:56 [loader.py:458] Loading weights took 7.41 seconds
INFO 07-05 11:51:56 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.656985 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:56,946 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:56,946 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:56,947 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:56,947 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:56,947 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:56,947 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:56,947 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:57,364 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:51:57,457 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:51:57,457 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:51:57,458 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:51:57,458 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:57,459 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:57,459 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:57,459 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:57,459 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:57,459 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:57,459 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:57,459 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:58,237 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:51:58,238 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:51:58,238 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:51:58,725 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:51:59,398 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:51:59 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:52:02,215 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:52:03,200 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:52:03 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:52:41 [worker.py:267] Memory profiling takes 44.91 seconds
INFO 07-05 11:52:41 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:52:41 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:52:42 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:52:42 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:52:50 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.74it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.88it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.91it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.92it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.92it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.91it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.92it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.91it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.91it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.94it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.92it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.91it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.90it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.92it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.85it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.88it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.90it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.91it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.92it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.91it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.91it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.86it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]
INFO 07-05 11:53:09 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:53:09 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.56 seconds
[INFO|2025-07-05 11:53:09] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:17, 110.16 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 215.99 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 339.40 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:03, 462.60 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 574.49 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:02, 636.20 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:02<00:01, 727.50 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:02<00:01, 733.45 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:02<00:01, 657.37 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:02<00:00, 1073.45 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:02<00:00, 1097.99 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 1065.18 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 911.08 examples/s] Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 599.62 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:53:16,431 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:53:16,431 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:53:16,433 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:53:16,433 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:53:16,433 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:53:16,433 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:53:16,433 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:53:16,433 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:53:16,433 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:53:17,212 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:53:17,213 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:53:17,213 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:53:17,679 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-756', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 237.67 toks/s, output: 32.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 16.39it/s, est. speed input: 4868.15 toks/s, output: 729.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 17.38it/s, est. speed input: 5334.46 toks/s, output: 956.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.01it/s, est. speed input: 5506.49 toks/s, output: 1025.10 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:50,  4.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.98 toks/s, output: 42.23 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.11it/s, est. speed input: 6085.53 toks/s, output: 903.30 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.09it/s, est. speed input: 6369.08 toks/s, output: 1123.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6574.70 toks/s, output: 1204.86 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:40,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.80 toks/s, output: 42.06 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.98it/s, est. speed input: 5712.04 toks/s, output: 851.96 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.45it/s, est. speed input: 6136.40 toks/s, output: 1114.09 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.45it/s, est. speed input: 5486.19 toks/s, output: 1056.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.39s/it, est. speed input: 481.62 toks/s, output: 246.71 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.62 toks/s, output: 246.71 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:34<14:55, 14.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.04 toks/s, output: 42.63 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.70it/s, est. speed input: 6494.68 toks/s, output: 963.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7749.31 toks/s, output: 1313.35 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:36<09:54,  9.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.10 toks/s, output: 42.11 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.87it/s, est. speed input: 5973.28 toks/s, output: 888.28 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.15it/s, est. speed input: 6129.42 toks/s, output: 1083.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.30it/s, est. speed input: 4044.55 toks/s, output: 873.93 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:40<07:40,  7.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.05 toks/s, output: 42.10 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.32it/s, est. speed input: 6698.33 toks/s, output: 988.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.79it/s, est. speed input: 6588.04 toks/s, output: 1119.34 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:43<05:54,  5.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.61 toks/s, output: 42.04 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.55it/s, est. speed input: 6178.25 toks/s, output: 915.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7729.88 toks/s, output: 1352.40 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:45<04:42,  4.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.00 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6220.69 toks/s, output: 926.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7719.74 toks/s, output: 1347.52 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:48<03:53,  4.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.93 toks/s, output: 42.61 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.83it/s, est. speed input: 6236.91 toks/s, output: 924.94 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.11it/s, est. speed input: 6398.25 toks/s, output: 1114.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.57it/s, est. speed input: 5715.31 toks/s, output: 1055.65 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:51<03:30,  3.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.19 toks/s, output: 42.12 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.56it/s, est. speed input: 6758.06 toks/s, output: 999.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.75it/s, est. speed input: 3437.48 toks/s, output: 692.14 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:55<03:39,  3.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.96 toks/s, output: 42.09 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.87it/s, est. speed input: 5964.97 toks/s, output: 881.74 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.97it/s, est. speed input: 6510.99 toks/s, output: 1160.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6521.92 toks/s, output: 1207.42 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:58<03:16,  3.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.55 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5966.64 toks/s, output: 890.62 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.73it/s, est. speed input: 6513.90 toks/s, output: 1191.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6513.90 toks/s, output: 1191.17 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [01:01<02:58,  3.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.89 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6440.60 toks/s, output: 957.66 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.37it/s, est. speed input: 6538.11 toks/s, output: 1147.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6538.11 toks/s, output: 1147.75 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:03<02:44,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.79 toks/s, output: 42.20 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.16it/s, est. speed input: 5468.76 toks/s, output: 814.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.25it/s, est. speed input: 6510.87 toks/s, output: 1225.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6510.87 toks/s, output: 1225.71 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:06<02:34,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.74 toks/s, output: 42.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5967.48 toks/s, output: 887.86 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.82it/s, est. speed input: 5694.99 toks/s, output: 1054.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.51it/s, est. speed input: 5694.99 toks/s, output: 1054.12 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:09<02:30,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.09 toks/s, output: 42.10 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6240.67 toks/s, output: 932.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7744.12 toks/s, output: 1354.43 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:11<02:19,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.60 toks/s, output: 42.56 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.01it/s, est. speed input: 5708.82 toks/s, output: 850.94 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.78it/s, est. speed input: 5959.00 toks/s, output: 1059.52 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 18.78it/s, est. speed input: 2049.74 toks/s, output: 535.63 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:23<00:00,  1.25s/it, est. speed input: 525.57 toks/s, output: 289.89 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:23<00:00,  1.34it/s, est. speed input: 525.57 toks/s, output: 289.89 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:36<07:39,  9.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.94 toks/s, output: 42.08 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6233.98 toks/s, output: 926.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7735.73 toks/s, output: 1347.27 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:38<05:49,  7.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.75 toks/s, output: 42.06 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 5708.06 toks/s, output: 850.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 7696.94 toks/s, output: 1406.01 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:41<04:32,  5.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.94 toks/s, output: 42.47 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.54it/s, est. speed input: 6172.38 toks/s, output: 921.45 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.79it/s, est. speed input: 6516.49 toks/s, output: 1147.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6534.04 toks/s, output: 1195.60 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:43<03:42,  4.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.11 toks/s, output: 41.97 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5956.81 toks/s, output: 887.00 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.93it/s, est. speed input: 6502.45 toks/s, output: 1163.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.53it/s, est. speed input: 5704.84 toks/s, output: 1080.29 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:46<03:11,  4.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.63 toks/s, output: 42.04 toks/s][A
Processed prompts:  53%|█████▎    | 17/32 [00:01<00:01, 13.80it/s, est. speed input: 4181.59 toks/s, output: 628.80 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 19.77it/s, est. speed input: 5796.34 toks/s, output: 1158.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.41it/s, est. speed input: 6441.90 toks/s, output: 1445.77 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:49<02:46,  3.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.40 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5959.32 toks/s, output: 884.68 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.63it/s, est. speed input: 6212.77 toks/s, output: 1090.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.38it/s, est. speed input: 5643.69 toks/s, output: 1090.63 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:52<02:31,  3.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.53 toks/s, output: 41.89 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 5947.17 toks/s, output: 883.42 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.22it/s, est. speed input: 6361.04 toks/s, output: 1137.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 20.22it/s, est. speed input: 6361.04 toks/s, output: 1137.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.43s/it, est. speed input: 480.80 toks/s, output: 240.09 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.80 toks/s, output: 240.09 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [02:19<07:22, 10.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.74 toks/s, output: 42.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5962.84 toks/s, output: 885.74 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.22it/s, est. speed input: 6096.80 toks/s, output: 1053.62 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 19.22it/s, est. speed input: 5478.28 toks/s, output: 1069.99 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.44it/s, est. speed input: 919.33 toks/s, output: 325.64 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.34it/s, est. speed input: 919.33 toks/s, output: 325.64 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:33<07:59, 11.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.01 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.30it/s, est. speed input: 6126.81 toks/s, output: 915.18 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.02it/s, est. speed input: 6131.78 toks/s, output: 1066.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 19.02it/s, est. speed input: 6336.16 toks/s, output: 1147.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 481.54 toks/s, output: 241.31 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.54 toks/s, output: 241.31 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [03:00<10:50, 16.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.60 toks/s, output: 41.90 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 5946.07 toks/s, output: 885.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7686.13 toks/s, output: 1366.27 toks/s]
Processing batched inference:  41%|████      | 27/66 [03:02<07:50, 12.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.44 toks/s, output: 41.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6209.73 toks/s, output: 923.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7707.14 toks/s, output: 1349.11 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [03:05<05:46,  9.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.99 toks/s, output: 41.95 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.51it/s, est. speed input: 5600.72 toks/s, output: 837.22 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.52it/s, est. speed input: 5886.23 toks/s, output: 1052.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.57it/s, est. speed input: 1403.89 toks/s, output: 417.30 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [03:14<05:42,  9.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.94 toks/s, output: 41.81 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.39it/s, est. speed input: 7279.71 toks/s, output: 1078.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.85it/s, est. speed input: 6614.14 toks/s, output: 1077.08 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [03:17<04:20,  7.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.57 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5965.11 toks/s, output: 886.53 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.96it/s, est. speed input: 6551.52 toks/s, output: 1184.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6551.52 toks/s, output: 1184.44 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [03:19<03:23,  5.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.86 toks/s, output: 42.60 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.92it/s, est. speed input: 5968.83 toks/s, output: 883.39 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.68it/s, est. speed input: 6452.45 toks/s, output: 1152.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6533.50 toks/s, output: 1211.88 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [03:22<02:44,  4.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.08 toks/s, output: 41.96 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.40it/s, est. speed input: 5863.53 toks/s, output: 876.91 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.23it/s, est. speed input: 6117.42 toks/s, output: 1089.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5647.73 toks/s, output: 1104.49 toks/s]
Processing batched inference:  50%|█████     | 33/66 [03:25<02:20,  4.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.35 toks/s, output: 42.00 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.43it/s, est. speed input: 5870.49 toks/s, output: 875.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7710.74 toks/s, output: 1382.71 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [03:27<01:57,  3.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.88 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6734.29 toks/s, output: 997.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6527.14 toks/s, output: 1108.29 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [03:29<01:43,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.33 toks/s, output: 41.86 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6208.18 toks/s, output: 920.68 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.78it/s, est. speed input: 6328.19 toks/s, output: 1106.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6532.59 toks/s, output: 1187.31 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [03:32<01:33,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.78 toks/s, output: 42.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 6751.29 toks/s, output: 1001.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.17it/s, est. speed input: 6739.32 toks/s, output: 1141.01 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [03:34<01:24,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.67 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.18it/s, est. speed input: 5813.84 toks/s, output: 872.28 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.48it/s, est. speed input: 6110.33 toks/s, output: 1066.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.41it/s, est. speed input: 4092.19 toks/s, output: 892.92 toks/s] 
Processing batched inference:  58%|█████▊    | 38/66 [03:38<01:28,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.13 toks/s, output: 41.97 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.62it/s, est. speed input: 4427.85 toks/s, output: 667.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.39it/s, est. speed input: 6288.35 toks/s, output: 1276.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.47it/s, est. speed input: 6468.59 toks/s, output: 1352.48 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:41<01:20,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.09 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6228.82 toks/s, output: 932.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7729.31 toks/s, output: 1349.16 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:43<01:11,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.48 toks/s, output: 42.02 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5702.33 toks/s, output: 849.53 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.94it/s, est. speed input: 6497.79 toks/s, output: 1207.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6497.79 toks/s, output: 1207.69 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [03:46<01:07,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.75 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.77it/s, est. speed input: 6516.60 toks/s, output: 965.60 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.73it/s, est. speed input: 6622.21 toks/s, output: 1175.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.87it/s, est. speed input: 6622.21 toks/s, output: 1175.85 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [03:48<01:03,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.50 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6483.40 toks/s, output: 959.69 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.30it/s, est. speed input: 6721.99 toks/s, output: 1167.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.13it/s, est. speed input: 6721.99 toks/s, output: 1167.08 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [03:51<01:00,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.85 toks/s, output: 42.07 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.98it/s, est. speed input: 5709.54 toks/s, output: 849.53 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.38it/s, est. speed input: 6071.86 toks/s, output: 1069.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 10.69it/s, est. speed input: 4193.94 toks/s, output: 896.19 toks/s] 
Processing batched inference:  67%|██████▋   | 44/66 [03:54<01:04,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.87 toks/s, output: 42.07 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 7012.03 toks/s, output: 1035.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7774.58 toks/s, output: 1263.98 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:56<00:56,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.81 toks/s, output: 42.07 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 5707.89 toks/s, output: 851.43 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.37it/s, est. speed input: 6069.66 toks/s, output: 1066.46 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.37it/s, est. speed input: 1785.02 toks/s, output: 487.19 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.36s/it, est. speed input: 482.34 toks/s, output: 284.86 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 482.34 toks/s, output: 284.86 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [04:23<03:18,  9.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.45 toks/s, output: 41.91 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6473.27 toks/s, output: 965.12 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.59it/s, est. speed input: 6585.93 toks/s, output: 1153.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.76it/s, est. speed input: 6585.93 toks/s, output: 1153.86 toks/s]
Processing batched inference:  71%|███████   | 47/66 [04:26<02:26,  7.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.22 toks/s, output: 42.51 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 6741.82 toks/s, output: 999.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 7751.67 toks/s, output: 1292.45 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [04:28<01:48,  6.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.76 toks/s, output: 42.45 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.23it/s, est. speed input: 5186.40 toks/s, output: 777.29 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 21.18it/s, est. speed input: 6337.15 toks/s, output: 1187.77 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 21.18it/s, est. speed input: 6463.74 toks/s, output: 1250.66 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.36s/it, est. speed input: 480.44 toks/s, output: 246.74 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 480.44 toks/s, output: 246.74 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [04:55<03:28, 12.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.08 toks/s, output: 41.96 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.32it/s, est. speed input: 7265.92 toks/s, output: 1072.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.96it/s, est. speed input: 7833.50 toks/s, output: 1240.90 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [04:57<02:28,  9.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.25 toks/s, output: 41.99 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.08it/s, est. speed input: 5445.24 toks/s, output: 813.28 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.18it/s, est. speed input: 6676.44 toks/s, output: 1264.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.00it/s, est. speed input: 6676.44 toks/s, output: 1264.71 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [05:00<01:48,  7.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.80 toks/s, output: 41.93 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 5952.89 toks/s, output: 887.49 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.69it/s, est. speed input: 6500.97 toks/s, output: 1189.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6500.97 toks/s, output: 1189.74 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [05:02<01:21,  5.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.21 toks/s, output: 42.51 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.00it/s, est. speed input: 5702.66 toks/s, output: 849.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.56it/s, est. speed input: 5806.03 toks/s, output: 1101.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.79it/s, est. speed input: 5806.03 toks/s, output: 1101.13 toks/s]
Processing batched inference:  80%|████████  | 53/66 [05:05<01:03,  4.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.53 toks/s, output: 42.03 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6482.26 toks/s, output: 961.69 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.31it/s, est. speed input: 6722.81 toks/s, output: 1166.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.13it/s, est. speed input: 6722.81 toks/s, output: 1166.06 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [05:07<00:50,  4.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.75 toks/s, output: 41.92 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5690.89 toks/s, output: 845.68 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.33it/s, est. speed input: 6098.04 toks/s, output: 1098.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.46it/s, est. speed input: 1356.30 toks/s, output: 391.99 toks/s] 
Processing batched inference:  83%|████████▎ | 55/66 [05:17<01:05,  5.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.66 toks/s, output: 41.91 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.19it/s, est. speed input: 5185.08 toks/s, output: 777.62 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.91it/s, est. speed input: 5298.66 toks/s, output: 1024.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.35it/s, est. speed input: 5636.85 toks/s, output: 1205.11 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [05:20<00:50,  5.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.39 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5958.64 toks/s, output: 883.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7702.37 toks/s, output: 1367.35 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [05:22<00:37,  4.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.43 toks/s, output: 42.54 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5958.57 toks/s, output: 881.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 7700.09 toks/s, output: 1370.81 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [05:25<00:28,  3.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.89 toks/s, output: 41.94 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.14it/s, est. speed input: 6938.51 toks/s, output: 1025.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7751.68 toks/s, output: 1261.07 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [05:27<00:22,  3.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.02 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.85it/s, est. speed input: 6245.35 toks/s, output: 925.56 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.78it/s, est. speed input: 6337.38 toks/s, output: 1105.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.85it/s, est. speed input: 5042.41 toks/s, output: 951.77 toks/s] 
Processing batched inference:  91%|█████████ | 60/66 [05:30<00:18,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.19 toks/s, output: 41.84 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.33it/s, est. speed input: 4923.54 toks/s, output: 734.73 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.81it/s, est. speed input: 6276.55 toks/s, output: 1231.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.36it/s, est. speed input: 5642.02 toks/s, output: 1163.57 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [05:33<00:15,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.55 toks/s, output: 41.89 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.48it/s, est. speed input: 6167.02 toks/s, output: 921.09 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.87it/s, est. speed input: 6300.92 toks/s, output: 1087.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.15it/s, est. speed input: 5165.98 toks/s, output: 998.59 toks/s] 
Processing batched inference:  94%|█████████▍| 62/66 [05:36<00:12,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.28 toks/s, output: 41.99 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6737.22 toks/s, output: 997.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.25it/s, est. speed input: 1277.62 toks/s, output: 354.85 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [05:47<00:15,  5.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.04 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.39it/s, est. speed input: 6423.96 toks/s, output: 950.99 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 6525.65 toks/s, output: 1140.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6525.65 toks/s, output: 1140.33 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [05:49<00:08,  4.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.85 toks/s, output: 41.93 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.04it/s, est. speed input: 5432.50 toks/s, output: 809.23 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.40it/s, est. speed input: 6292.92 toks/s, output: 1174.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6496.19 toks/s, output: 1254.85 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [05:52<00:03,  3.89s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 337.57 toks/s, output: 46.74 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.72it/s, est. speed input: 6552.26 toks/s, output: 974.27 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.84it/s, est. speed input: 7396.37 toks/s, output: 1226.33 toks/s]
Processing batched inference: 100%|██████████| 66/66 [05:54<00:00,  3.35s/it]Processing batched inference: 100%|██████████| 66/66 [05:54<00:00,  5.37s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-756/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:59:11.534516981 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-819
INFO 07-05 11:59:23 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:59:25,661 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:59:25,709 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:25,734 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:25,734 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:25,734 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:25,735 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:25,735 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:25,735 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:25,735 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:59:26,138 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:59:26,140 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:59:26,146 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:59:26,152 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:26,153 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:26,153 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:26,153 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:26,153 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:26,153 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:26,153 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:26,153 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:59:26,525 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:59:26,527 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:59:26,738 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:59:27,174 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:59:27,228 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:59:27,228 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:59:27,230 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:59:39 [config.py:689] This model supports multiple tasks: {'embed', 'generate', 'score', 'reward', 'classify'}. Defaulting to 'generate'.
INFO 07-05 11:59:39 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:39,028 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:39,028 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:39,028 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:39,028 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:39,028 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:39,028 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:39,028 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:59:39,360 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:59:39,461 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:59:39,465 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:59:40 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:59:41 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:59:41 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819...
WARNING 07-05 11:59:41 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:59:41 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.08s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.08s/it]

INFO 07-05 11:59:48 [loader.py:458] Loading weights took 7.29 seconds
INFO 07-05 11:59:49 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.534897 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,289 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,289 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,289 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,289 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,289 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,289 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,289 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:59:49,704 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:59:49,800 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:59:49,800 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:59:49,801 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:59:49,801 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,802 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,802 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,802 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,802 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,802 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,802 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:59:49,802 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:59:50,553 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:59:50,554 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:59:50,554 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:59:51,010 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:59:51,665 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:59:52 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:59:54,514 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:59:55,507 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:59:55 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 12:00:34 [worker.py:267] Memory profiling takes 45.16 seconds
INFO 07-05 12:00:34 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 12:00:34 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 12:00:34 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 12:00:34 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 12:00:43 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:23,  1.46it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:19,  1.67it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:18,  1.77it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.83it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:16,  1.86it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.86it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.89it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.92it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.92it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.92it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:09<00:09,  1.93it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.89it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:10<00:08,  1.91it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.92it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:11<00:07,  1.88it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.90it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.91it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.92it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.88it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.90it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.91it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.83it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.84it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:16<00:03,  1.56it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:17<00:02,  1.43it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:18<00:02,  1.24it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:19<00:01,  1.14it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:20<00:00,  1.12it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:20<00:00,  1.15it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:20<00:00,  1.67it/s]
INFO 07-05 12:01:04 [model_runner.py:1598] Graph capturing finished in 21 secs, took 0.33 GiB
INFO 07-05 12:01:04 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 75.47 seconds
[INFO|2025-07-05 12:01:05] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:20, 98.73 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 209.39 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 322.25 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:03, 427.47 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 528.39 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:02<00:02, 621.80 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:02<00:01, 689.38 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 734.39 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:02<00:00, 1036.10 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:02<00:00, 961.57 examples/s] Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 882.48 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:03<00:00, 869.92 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 892.57 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 597.26 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 12:01:11,788 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:01:11,789 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:01:11,790 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:01:11,790 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:01:11,790 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:01:11,790 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:01:11,790 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:01:11,790 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:01:11,790 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:01:12,582 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 12:01:12,582 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 12:01:12,583 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 12:01:13,079 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-819', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 236.74 toks/s, output: 32.78 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.72it/s, est. speed input: 5256.83 toks/s, output: 785.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.04it/s, est. speed input: 6302.61 toks/s, output: 1076.07 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:47,  4.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.88 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.06it/s, est. speed input: 6067.85 toks/s, output: 900.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.00it/s, est. speed input: 6342.86 toks/s, output: 1118.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.76it/s, est. speed input: 1475.82 toks/s, output: 396.93 toks/s] 
Processing batched inference:   3%|▎         | 2/66 [00:13<07:53,  7.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.82 toks/s, output: 42.07 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.41it/s, est. speed input: 5866.69 toks/s, output: 875.26 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.32it/s, est. speed input: 6136.24 toks/s, output: 1090.11 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 19.32it/s, est. speed input: 6320.40 toks/s, output: 1167.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.40s/it, est. speed input: 481.70 toks/s, output: 243.11 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.70 toks/s, output: 243.11 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:40<17:11, 16.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.41 toks/s, output: 42.15 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.58it/s, est. speed input: 6761.86 toks/s, output: 1000.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7771.34 toks/s, output: 1289.23 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:43<11:14, 10.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.17 toks/s, output: 42.12 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 5977.15 toks/s, output: 888.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.57it/s, est. speed input: 5977.65 toks/s, output: 1035.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5662.91 toks/s, output: 1135.73 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:46<08:11,  8.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.38 toks/s, output: 42.01 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.75it/s, est. speed input: 7421.26 toks/s, output: 1092.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.87it/s, est. speed input: 6617.79 toks/s, output: 1050.59 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:49<06:14,  6.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.70 toks/s, output: 42.05 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6233.37 toks/s, output: 923.43 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.55it/s, est. speed input: 6530.54 toks/s, output: 1166.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6530.54 toks/s, output: 1166.99 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:51<05:02,  5.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.51 toks/s, output: 42.02 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5968.18 toks/s, output: 891.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 7713.32 toks/s, output: 1374.02 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:54<04:07,  4.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.09 toks/s, output: 42.63 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.73it/s, est. speed input: 6502.08 toks/s, output: 964.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 7758.80 toks/s, output: 1315.06 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:56<03:29,  3.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.15 toks/s, output: 42.11 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.75it/s, est. speed input: 6858.90 toks/s, output: 1016.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.88it/s, est. speed input: 6627.00 toks/s, output: 1108.10 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:59<03:08,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.46 toks/s, output: 42.16 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6497.20 toks/s, output: 957.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.43it/s, est. speed input: 6559.33 toks/s, output: 1165.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6559.33 toks/s, output: 1165.24 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [01:02<02:54,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.92 toks/s, output: 42.08 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.31it/s, est. speed input: 6702.97 toks/s, output: 996.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6575.01 toks/s, output: 1153.18 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [01:04<02:42,  3.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.89 toks/s, output: 42.08 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.81it/s, est. speed input: 5960.41 toks/s, output: 887.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 7703.47 toks/s, output: 1379.29 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:07<02:29,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.52 toks/s, output: 41.89 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.81it/s, est. speed input: 5950.87 toks/s, output: 886.12 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.74it/s, est. speed input: 6499.64 toks/s, output: 1172.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6499.64 toks/s, output: 1172.33 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:09<02:23,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.47 toks/s, output: 41.54 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6750.21 toks/s, output: 996.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.63it/s, est. speed input: 5743.56 toks/s, output: 1020.12 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:12<02:23,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.85 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 6735.82 toks/s, output: 1003.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6538.77 toks/s, output: 1119.69 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:15<02:19,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.13 toks/s, output: 42.50 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 6742.83 toks/s, output: 1001.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.75it/s, est. speed input: 3437.16 toks/s, output: 678.35 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [01:19<02:40,  3.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.38 toks/s, output: 42.15 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7024.59 toks/s, output: 1042.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7781.53 toks/s, output: 1264.81 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:22<02:23,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 299.36 toks/s, output: 42.11 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.72it/s, est. speed input: 5915.99 toks/s, output: 882.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 7647.31 toks/s, output: 1364.69 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:24<02:12,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.64 toks/s, output: 42.43 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.10it/s, est. speed input: 7213.81 toks/s, output: 1074.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7781.86 toks/s, output: 1245.09 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:26<02:02,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.03 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6737.30 toks/s, output: 1002.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7742.02 toks/s, output: 1287.35 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:29<01:55,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.29 toks/s, output: 41.99 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.22it/s, est. speed input: 5188.69 toks/s, output: 772.82 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.64it/s, est. speed input: 6296.04 toks/s, output: 1206.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.63it/s, est. speed input: 4960.26 toks/s, output: 1020.86 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:32<02:01,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.54 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 5964.68 toks/s, output: 887.10 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.74it/s, est. speed input: 6509.55 toks/s, output: 1181.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6509.55 toks/s, output: 1181.76 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:35<01:56,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.82 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6212.40 toks/s, output: 920.77 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.38it/s, est. speed input: 6448.80 toks/s, output: 1126.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.49it/s, est. speed input: 3724.27 toks/s, output: 746.63 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:39<02:10,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.48 toks/s, output: 41.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.06it/s, est. speed input: 6063.05 toks/s, output: 901.10 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.20it/s, est. speed input: 5299.52 toks/s, output: 961.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.16it/s, est. speed input: 1240.57 toks/s, output: 382.45 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:50<03:42,  5.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.04 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.73it/s, est. speed input: 6283.98 toks/s, output: 939.36 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.10it/s, est. speed input: 1031.88 toks/s, output: 319.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.63it/s, est. speed input: 1031.88 toks/s, output: 319.54 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:02<05:07,  7.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.57 toks/s, output: 42.03 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6231.87 toks/s, output: 924.10 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.81it/s, est. speed input: 6343.85 toks/s, output: 1110.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6548.62 toks/s, output: 1191.69 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:05<03:59,  6.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.21 toks/s, output: 41.98 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.83it/s, est. speed input: 6587.00 toks/s, output: 978.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7750.36 toks/s, output: 1300.56 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:07<03:09,  4.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.18 toks/s, output: 41.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.31it/s, est. speed input: 6127.41 toks/s, output: 914.30 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.99it/s, est. speed input: 6125.79 toks/s, output: 1089.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.90it/s, est. speed input: 2318.10 toks/s, output: 556.48 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [02:13<03:16,  5.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.37 toks/s, output: 42.00 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.36it/s, est. speed input: 7281.07 toks/s, output: 1078.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.90it/s, est. speed input: 6636.06 toks/s, output: 1080.12 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:16<02:40,  4.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.15 toks/s, output: 42.11 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6238.21 toks/s, output: 925.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 7798.67 toks/s, output: 1350.91 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [02:18<02:12,  3.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.64 toks/s, output: 42.04 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5964.62 toks/s, output: 881.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7711.67 toks/s, output: 1373.30 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [02:20<01:53,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.83 toks/s, output: 41.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.22it/s, est. speed input: 6105.41 toks/s, output: 912.41 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.85it/s, est. speed input: 6321.88 toks/s, output: 1118.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5647.58 toks/s, output: 1059.56 toks/s]
Processing batched inference:  50%|█████     | 33/66 [02:23<01:45,  3.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.80 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6212.42 toks/s, output: 924.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.37it/s, est. speed input: 4072.90 toks/s, output: 790.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.36it/s, est. speed input: 4072.90 toks/s, output: 790.61 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [02:27<01:48,  3.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.98 toks/s, output: 41.67 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.37it/s, est. speed input: 6700.18 toks/s, output: 994.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6502.52 toks/s, output: 1102.04 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:30<01:37,  3.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.57 toks/s, output: 41.75 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.75it/s, est. speed input: 5931.12 toks/s, output: 881.47 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.55it/s, est. speed input: 6416.63 toks/s, output: 1144.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6496.84 toks/s, output: 1203.57 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:32<01:28,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.83 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 6993.43 toks/s, output: 1034.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7779.45 toks/s, output: 1260.12 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:34<01:19,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.07 toks/s, output: 41.82 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.67it/s, est. speed input: 6267.98 toks/s, output: 940.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.74it/s, est. speed input: 6330.47 toks/s, output: 1118.36 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 19.74it/s, est. speed input: 6330.47 toks/s, output: 1118.36 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.46s/it, est. speed input: 481.67 toks/s, output: 239.27 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.67 toks/s, output: 239.27 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [03:01<04:39,  9.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.21 toks/s, output: 41.98 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.35it/s, est. speed input: 4934.05 toks/s, output: 737.46 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.06it/s, est. speed input: 6325.93 toks/s, output: 1237.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.31it/s, est. speed input: 5619.84 toks/s, output: 1156.24 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:04<03:31,  7.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.53 toks/s, output: 41.89 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.34it/s, est. speed input: 6993.15 toks/s, output: 1040.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7753.19 toks/s, output: 1267.02 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:06<02:40,  6.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.93 toks/s, output: 41.94 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.06it/s, est. speed input: 5438.11 toks/s, output: 810.07 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.47it/s, est. speed input: 6265.80 toks/s, output: 1153.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.64it/s, est. speed input: 4960.80 toks/s, output: 1017.98 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [03:10<02:11,  5.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.03 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.74it/s, est. speed input: 6791.53 toks/s, output: 1004.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.82it/s, est. speed input: 6601.80 toks/s, output: 1122.28 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [03:12<01:46,  4.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.93 toks/s, output: 41.94 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 6995.14 toks/s, output: 1034.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.82it/s, est. speed input: 4637.55 toks/s, output: 820.32 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [03:15<01:34,  4.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.52 toks/s, output: 42.03 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.98it/s, est. speed input: 5705.86 toks/s, output: 846.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.55it/s, est. speed input: 6377.22 toks/s, output: 1161.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.87it/s, est. speed input: 5833.50 toks/s, output: 1119.19 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [03:18<01:21,  3.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.32 toks/s, output: 41.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7258.35 toks/s, output: 1071.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6556.24 toks/s, output: 1066.95 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:21<01:10,  3.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.97 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6212.52 toks/s, output: 918.72 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.91it/s, est. speed input: 6123.19 toks/s, output: 1052.86 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:18<00:00, 18.91it/s, est. speed input: 6123.19 toks/s, output: 1052.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.50s/it, est. speed input: 468.10 toks/s, output: 235.51 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 483.22 toks/s, output: 393.14 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [03:47<03:27, 10.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.20 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6469.54 toks/s, output: 964.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7719.59 toks/s, output: 1323.02 toks/s]
Processing batched inference:  71%|███████   | 47/66 [03:50<02:30,  7.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.22 toks/s, output: 41.84 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.10it/s, est. speed input: 6927.45 toks/s, output: 1025.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6534.71 toks/s, output: 1093.18 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [03:52<01:53,  6.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.03 toks/s, output: 41.82 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.10it/s, est. speed input: 5731.04 toks/s, output: 854.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.84it/s, est. speed input: 6668.17 toks/s, output: 1229.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.99it/s, est. speed input: 6668.17 toks/s, output: 1229.13 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [03:55<01:27,  5.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.74 toks/s, output: 42.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 6750.84 toks/s, output: 1000.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.06it/s, est. speed input: 6695.07 toks/s, output: 1134.14 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [03:57<01:09,  4.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.72 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6216.78 toks/s, output: 924.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7715.58 toks/s, output: 1345.49 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [03:59<00:55,  3.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.93 toks/s, output: 41.81 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.77it/s, est. speed input: 5941.28 toks/s, output: 885.76 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.00it/s, est. speed input: 6554.21 toks/s, output: 1198.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6554.21 toks/s, output: 1198.96 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [04:02<00:47,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.37 toks/s, output: 42.39 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 5690.53 toks/s, output: 845.97 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.92it/s, est. speed input: 6483.13 toks/s, output: 1206.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6483.13 toks/s, output: 1206.32 toks/s]
Processing batched inference:  80%|████████  | 53/66 [04:04<00:40,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.57 toks/s, output: 41.89 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6724.08 toks/s, output: 995.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7730.40 toks/s, output: 1284.80 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [04:07<00:34,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.01 toks/s, output: 41.82 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.91it/s, est. speed input: 5681.35 toks/s, output: 842.65 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.31it/s, est. speed input: 6090.88 toks/s, output: 1098.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s, est. speed input: 2756.30 toks/s, output: 628.72 toks/s] 
Processing batched inference:  83%|████████▎ | 55/66 [04:12<00:39,  3.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 299.51 toks/s, output: 42.79 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.21it/s, est. speed input: 5172.81 toks/s, output: 777.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.85it/s, est. speed input: 6084.73 toks/s, output: 1149.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.27it/s, est. speed input: 5606.14 toks/s, output: 1153.50 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [04:15<00:33,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.97 toks/s, output: 41.95 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 5952.75 toks/s, output: 881.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.04it/s, est. speed input: 6562.36 toks/s, output: 1191.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6562.36 toks/s, output: 1191.10 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [04:17<00:28,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.54 toks/s, output: 42.42 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 5682.11 toks/s, output: 843.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 7665.87 toks/s, output: 1392.18 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [04:20<00:22,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.51 toks/s, output: 41.89 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.23it/s, est. speed input: 6673.07 toks/s, output: 987.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 7730.53 toks/s, output: 1285.95 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [04:22<00:18,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.77 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 21.06it/s, est. speed input: 6291.84 toks/s, output: 931.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.70it/s, est. speed input: 6332.85 toks/s, output: 1103.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.57it/s, est. speed input: 5717.87 toks/s, output: 1056.50 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [04:25<00:16,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.33 toks/s, output: 41.72 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.75it/s, est. speed input: 5931.85 toks/s, output: 883.19 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.87it/s, est. speed input: 6525.73 toks/s, output: 1193.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6525.73 toks/s, output: 1193.23 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [04:27<00:13,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.73 toks/s, output: 41.78 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.45it/s, est. speed input: 6154.28 toks/s, output: 918.65 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.54it/s, est. speed input: 6694.36 toks/s, output: 1194.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.04it/s, est. speed input: 6694.36 toks/s, output: 1194.98 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [04:30<00:10,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.56 toks/s, output: 41.89 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.33it/s, est. speed input: 6982.35 toks/s, output: 1033.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6535.91 toks/s, output: 1091.04 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [04:32<00:07,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.75 toks/s, output: 40.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.15it/s, est. speed input: 6328.82 toks/s, output: 936.81 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.07it/s, est. speed input: 6420.02 toks/s, output: 1144.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.35it/s, est. speed input: 6420.02 toks/s, output: 1144.36 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [04:35<00:05,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.44 toks/s, output: 41.05 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.40it/s, est. speed input: 6109.05 toks/s, output: 905.01 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.56it/s, est. speed input: 6242.48 toks/s, output: 1093.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.42it/s, est. speed input: 6444.11 toks/s, output: 1172.96 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [04:37<00:02,  2.56s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.15s/it, est. speed input: 338.67 toks/s, output: 45.91 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.58it/s, est. speed input: 6229.73 toks/s, output: 926.72 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.69it/s, est. speed input: 7338.40 toks/s, output: 1248.76 toks/s]
Processing batched inference: 100%|██████████| 66/66 [04:39<00:00,  2.45s/it]Processing batched inference: 100%|██████████| 66/66 [04:39<00:00,  4.24s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-819/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 12:05:52.680398731 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-882
INFO 07-05 12:06:05 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 12:06:07,304 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 12:06:07,345 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,369 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,369 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,370 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,370 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,370 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,370 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,370 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:06:07,757 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 12:06:07,759 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 12:06:07,764 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:06:07,771 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,771 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,771 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,772 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,772 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,772 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,772 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:07,772 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:06:08,147 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 12:06:08,150 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 12:06:08,355 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 12:06:08,820 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 12:06:08,877 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/config.json
[INFO|configuration_utils.py:696] 2025-07-05 12:06:08,878 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/config.json
[INFO|configuration_utils.py:770] 2025-07-05 12:06:08,880 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 12:06:20 [config.py:689] This model supports multiple tasks: {'classify', 'generate', 'embed', 'score', 'reward'}. Defaulting to 'generate'.
INFO 07-05 12:06:20 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:20,431 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:20,431 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:20,431 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:20,431 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:20,431 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:20,431 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:20,431 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:06:20,763 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 12:06:20,863 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 12:06:20,866 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 12:06:22 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 12:06:22 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 12:06:22 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882...
WARNING 07-05 12:06:22 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 12:06:22 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.24s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.24s/it]

INFO 07-05 12:06:30 [loader.py:458] Loading weights took 7.45 seconds
INFO 07-05 12:06:30 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.701093 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:30,879 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:30,879 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:30,879 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:30,879 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:30,879 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:30,879 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:30,879 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:06:31,280 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 12:06:31,375 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:06:31,375 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 12:06:31,376 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:06:31,376 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:31,377 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:31,377 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:31,377 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:31,377 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:31,377 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:31,377 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:06:31,377 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:06:32,177 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 12:06:32,178 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 12:06:32,178 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 12:06:32,634 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 12:06:33,319 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 12:06:33 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 12:06:36,172 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 12:06:37,173 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 12:06:37 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 12:07:16 [worker.py:267] Memory profiling takes 45.44 seconds
INFO 07-05 12:07:16 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 12:07:16 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 12:07:16 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 12:07:16 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 12:07:24 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.73it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.83it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.87it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.89it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.88it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.89it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.91it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.90it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.87it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.90it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:12,  1.91it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.92it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.93it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.93it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.94it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.94it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.94it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.93it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.94it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.86it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.87it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.90it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.91it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.92it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.91it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.92it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.87it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]
INFO 07-05 12:07:43 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 12:07:43 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.65 seconds
[INFO|2025-07-05 12:07:43] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:21, 93.02 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 318.46 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:04, 360.87 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:03, 455.60 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:02<00:02, 546.72 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:02<00:01, 632.20 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 606.30 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:02<00:01, 700.26 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:02<00:00, 982.40 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 1008.97 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:02<00:00, 1050.68 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:03<00:00, 955.80 examples/s] Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 1183.39 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 600.52 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 12:07:50,604 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:07:50,604 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:07:50,606 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:07:50,606 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:07:50,606 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:07:50,606 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:07:50,606 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:07:50,606 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:07:50,606 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:07:51,431 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 12:07:51,432 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 12:07:51,432 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 12:07:51,900 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-882', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.66s/it, est. speed input: 234.69 toks/s, output: 32.50 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.64it/s, est. speed input: 5226.95 toks/s, output: 779.51 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.47it/s, est. speed input: 5446.90 toks/s, output: 952.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.86it/s, est. speed input: 5446.90 toks/s, output: 952.49 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:02,  4.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.52 toks/s, output: 42.03 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.26it/s, est. speed input: 6685.31 toks/s, output: 990.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6529.94 toks/s, output: 1118.71 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:51,  3.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.05 toks/s, output: 42.10 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5707.08 toks/s, output: 851.12 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.26it/s, est. speed input: 6333.81 toks/s, output: 1166.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6517.03 toks/s, output: 1243.38 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:23,  3.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.13 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6221.95 toks/s, output: 924.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 7720.53 toks/s, output: 1336.14 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<03:03,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.47 toks/s, output: 42.16 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.15it/s, est. speed input: 5467.69 toks/s, output: 817.08 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.61it/s, est. speed input: 6118.49 toks/s, output: 1129.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.39it/s, est. speed input: 4471.71 toks/s, output: 980.82 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:16<03:16,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.60 toks/s, output: 41.76 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.51it/s, est. speed input: 6447.24 toks/s, output: 954.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 7694.99 toks/s, output: 1302.51 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:19<02:59,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.32 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.06it/s, est. speed input: 6639.18 toks/s, output: 984.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.22it/s, est. speed input: 6734.71 toks/s, output: 1149.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.15it/s, est. speed input: 6734.71 toks/s, output: 1149.87 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:21<02:51,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.05 toks/s, output: 42.10 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5977.21 toks/s, output: 891.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.86it/s, est. speed input: 6542.23 toks/s, output: 1193.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6542.23 toks/s, output: 1193.51 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:24<02:45,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 298.89 toks/s, output: 41.38 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.36it/s, est. speed input: 6397.24 toks/s, output: 946.93 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.44it/s, est. speed input: 6519.05 toks/s, output: 1130.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6519.05 toks/s, output: 1130.89 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:27<02:41,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 306.38 toks/s, output: 41.53 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 6750.52 toks/s, output: 996.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6590.82 toks/s, output: 1122.50 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:30<02:35,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.32 toks/s, output: 42.14 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6492.50 toks/s, output: 957.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.34it/s, est. speed input: 6732.83 toks/s, output: 1169.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.16it/s, est. speed input: 6732.83 toks/s, output: 1169.77 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:32<02:31,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.34 toks/s, output: 42.00 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 5956.05 toks/s, output: 889.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.69it/s, est. speed input: 6503.36 toks/s, output: 1187.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6503.36 toks/s, output: 1187.69 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:35<02:28,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.86 toks/s, output: 41.69 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.81it/s, est. speed input: 5662.74 toks/s, output: 846.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.82it/s, est. speed input: 6460.02 toks/s, output: 1204.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.44it/s, est. speed input: 6460.02 toks/s, output: 1204.95 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:38<02:26,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.55 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.18it/s, est. speed input: 6038.34 toks/s, output: 895.03 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.95it/s, est. speed input: 6330.80 toks/s, output: 1123.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6535.41 toks/s, output: 1204.82 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:40<02:21,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.29 toks/s, output: 41.99 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 5702.19 toks/s, output: 848.34 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.53it/s, est. speed input: 6374.59 toks/s, output: 1162.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6559.10 toks/s, output: 1239.12 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:43<02:17,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.05 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6481.19 toks/s, output: 965.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 7734.95 toks/s, output: 1325.14 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:45<02:10,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.15 toks/s, output: 42.50 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6227.91 toks/s, output: 925.58 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:04<00:00,  6.20it/s, est. speed input: 2703.57 toks/s, output: 601.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.14it/s, est. speed input: 1625.35 toks/s, output: 494.10 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:54<03:35,  4.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.69 toks/s, output: 42.05 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6490.51 toks/s, output: 966.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 7744.67 toks/s, output: 1318.62 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:56<03:02,  3.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.43 toks/s, output: 42.01 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6225.30 toks/s, output: 926.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.39it/s, est. speed input: 4078.50 toks/s, output: 791.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.38it/s, est. speed input: 4078.50 toks/s, output: 791.10 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:00<02:59,  3.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.59 toks/s, output: 42.42 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.63it/s, est. speed input: 5905.43 toks/s, output: 882.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.80it/s, est. speed input: 6503.92 toks/s, output: 1192.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6503.92 toks/s, output: 1192.16 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:03<02:38,  3.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.24 toks/s, output: 41.99 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5962.80 toks/s, output: 888.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7706.87 toks/s, output: 1371.07 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:05<02:20,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.83 toks/s, output: 41.79 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.28it/s, est. speed input: 4911.12 toks/s, output: 734.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 18.08it/s, est. speed input: 5619.78 toks/s, output: 1054.21 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.43it/s, est. speed input: 5136.77 toks/s, output: 1151.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.08it/s, est. speed input: 5136.77 toks/s, output: 1151.22 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:08<02:18,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.18 toks/s, output: 40.59 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.41it/s, est. speed input: 5817.46 toks/s, output: 865.54 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.61it/s, est. speed input: 6181.19 toks/s, output: 1101.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.25it/s, est. speed input: 6378.14 toks/s, output: 1180.25 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:11<02:11,  3.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.02 toks/s, output: 40.57 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.21it/s, est. speed input: 6051.49 toks/s, output: 898.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.16it/s, est. speed input: 3674.29 toks/s, output: 722.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.36it/s, est. speed input: 3674.29 toks/s, output: 722.86 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:15<02:22,  3.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.84 toks/s, output: 40.69 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.37it/s, est. speed input: 5805.75 toks/s, output: 861.88 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.10it/s, est. speed input: 5208.77 toks/s, output: 943.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 15.10it/s, est. speed input: 4499.81 toks/s, output: 892.19 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:15<00:00,  1.23it/s, est. speed input: 797.64 toks/s, output: 306.15 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s, est. speed input: 797.64 toks/s, output: 306.15 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:32<05:00,  7.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 292.71 toks/s, output: 40.53 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.74it/s, est. speed input: 5949.03 toks/s, output: 888.62 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.64it/s, est. speed input: 5983.61 toks/s, output: 1040.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.55it/s, est. speed input: 2181.11 toks/s, output: 517.44 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:38<04:43,  7.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 295.76 toks/s, output: 40.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.36it/s, est. speed input: 6102.35 toks/s, output: 907.64 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.55it/s, est. speed input: 6236.75 toks/s, output: 1090.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.40it/s, est. speed input: 6438.14 toks/s, output: 1170.05 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:41<03:43,  5.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 293.10 toks/s, output: 40.58 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.08it/s, est. speed input: 6304.99 toks/s, output: 935.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 6385.34 toks/s, output: 1119.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.25it/s, est. speed input: 6385.34 toks/s, output: 1119.26 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:44<03:02,  4.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 294.80 toks/s, output: 40.82 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.02it/s, est. speed input: 5734.72 toks/s, output: 854.54 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.95it/s, est. speed input: 6004.63 toks/s, output: 1065.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.38it/s, est. speed input: 3684.28 toks/s, output: 773.66 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [01:48<02:49,  4.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 297.27 toks/s, output: 41.16 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.11it/s, est. speed input: 7190.13 toks/s, output: 1065.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6545.83 toks/s, output: 1065.43 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:50<02:22,  3.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 296.56 toks/s, output: 41.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.51it/s, est. speed input: 5849.41 toks/s, output: 866.69 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.74it/s, est. speed input: 5609.24 toks/s, output: 1020.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.39it/s, est. speed input: 5646.42 toks/s, output: 1085.12 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:53<02:06,  3.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 295.19 toks/s, output: 41.52 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.04it/s, est. speed input: 6866.46 toks/s, output: 1013.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.43it/s, est. speed input: 6446.59 toks/s, output: 1072.54 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:56<01:52,  3.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 294.18 toks/s, output: 40.73 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.69it/s, est. speed input: 6228.98 toks/s, output: 930.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.31it/s, est. speed input: 6213.49 toks/s, output: 1099.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.15it/s, est. speed input: 5564.30 toks/s, output: 1044.82 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:59<01:45,  3.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 292.70 toks/s, output: 40.53 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.22it/s, est. speed input: 6112.22 toks/s, output: 910.45 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.68it/s, est. speed input: 6249.70 toks/s, output: 1078.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.19it/s, est. speed input: 5576.11 toks/s, output: 1022.10 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [02:02<01:41,  3.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 298.23 toks/s, output: 41.29 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.35it/s, est. speed input: 6392.38 toks/s, output: 947.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.15it/s, est. speed input: 6458.11 toks/s, output: 1121.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.46it/s, est. speed input: 6458.11 toks/s, output: 1121.78 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:04<01:32,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.27 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6464.99 toks/s, output: 956.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 7717.84 toks/s, output: 1314.26 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:07<01:23,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.73 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6731.84 toks/s, output: 997.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 7738.74 toks/s, output: 1284.33 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:09<01:15,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.37 toks/s, output: 41.73 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.59it/s, est. speed input: 6245.40 toks/s, output: 936.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.88it/s, est. speed input: 5735.40 toks/s, output: 1057.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.47it/s, est. speed input: 3724.86 toks/s, output: 781.68 toks/s] 
Processing batched inference:  58%|█████▊    | 38/66 [02:13<01:25,  3.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.51 toks/s, output: 41.88 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.05it/s, est. speed input: 5434.46 toks/s, output: 809.97 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.40it/s, est. speed input: 6298.79 toks/s, output: 1183.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.70it/s, est. speed input: 4988.04 toks/s, output: 1007.60 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:16<01:23,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.71 toks/s, output: 41.91 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6475.41 toks/s, output: 965.98 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.41it/s, est. speed input: 6551.09 toks/s, output: 1172.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6551.09 toks/s, output: 1172.68 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:19<01:15,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.44 toks/s, output: 41.88 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.33it/s, est. speed input: 4923.82 toks/s, output: 734.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.22it/s, est. speed input: 5882.59 toks/s, output: 1116.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6472.61 toks/s, output: 1353.97 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:21<01:10,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.80 toks/s, output: 41.42 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6736.44 toks/s, output: 995.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.61it/s, est. speed input: 5734.40 toks/s, output: 1020.49 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:24<01:07,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.02 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.33it/s, est. speed input: 6976.30 toks/s, output: 1031.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.94it/s, est. speed input: 5861.21 toks/s, output: 1017.16 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:27<01:04,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.96 toks/s, output: 41.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6454.82 toks/s, output: 952.77 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.54it/s, est. speed input: 3530.78 toks/s, output: 702.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.00it/s, est. speed input: 3530.78 toks/s, output: 702.44 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:31<01:10,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.26 toks/s, output: 41.85 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.20it/s, est. speed input: 7518.02 toks/s, output: 1108.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6564.36 toks/s, output: 1044.23 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:33<01:02,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.70 toks/s, output: 41.91 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6212.13 toks/s, output: 920.82 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.11it/s, est. speed input: 5302.96 toks/s, output: 954.18 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 15.11it/s, est. speed input: 3102.81 toks/s, output: 664.99 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.41s/it, est. speed input: 481.97 toks/s, output: 257.28 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.97 toks/s, output: 257.28 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [03:00<03:22, 10.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.53 toks/s, output: 41.78 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.42it/s, est. speed input: 6719.76 toks/s, output: 1000.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 7725.06 toks/s, output: 1294.47 toks/s]
Processing batched inference:  71%|███████   | 47/66 [03:02<02:27,  7.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 301.59 toks/s, output: 42.42 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 6732.14 toks/s, output: 998.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6534.44 toks/s, output: 1116.02 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [03:05<01:51,  6.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.66 toks/s, output: 42.29 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.13it/s, est. speed input: 5728.65 toks/s, output: 853.07 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 19.13it/s, est. speed input: 7423.87 toks/s, output: 1321.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.02s/it, est. speed input: 481.26 toks/s, output: 239.92 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.26 toks/s, output: 239.92 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [03:32<03:30, 12.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.36 toks/s, output: 41.39 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.42it/s, est. speed input: 6730.57 toks/s, output: 996.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 7789.98 toks/s, output: 1288.60 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [03:34<02:29,  9.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.84 toks/s, output: 41.79 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.01it/s, est. speed input: 5424.66 toks/s, output: 811.27 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.34it/s, est. speed input: 6464.22 toks/s, output: 1207.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6544.46 toks/s, output: 1263.67 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [03:37<01:49,  7.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.46 toks/s, output: 41.74 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.64it/s, est. speed input: 6197.18 toks/s, output: 923.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 7691.04 toks/s, output: 1346.98 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [03:39<01:20,  5.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.14 toks/s, output: 41.87 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6209.09 toks/s, output: 920.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7706.68 toks/s, output: 1344.45 toks/s]
Processing batched inference:  80%|████████  | 53/66 [03:41<01:01,  4.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.66 toks/s, output: 41.91 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6469.16 toks/s, output: 959.21 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.29it/s, est. speed input: 6712.47 toks/s, output: 1164.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.10it/s, est. speed input: 6712.47 toks/s, output: 1164.80 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [03:43<00:48,  4.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.18 toks/s, output: 41.84 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 6720.36 toks/s, output: 992.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.75it/s, est. speed input: 3435.88 toks/s, output: 705.50 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:48<00:45,  4.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 298.10 toks/s, output: 42.59 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.15it/s, est. speed input: 5154.40 toks/s, output: 775.68 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.71it/s, est. speed input: 6280.37 toks/s, output: 1202.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.25it/s, est. speed input: 5599.69 toks/s, output: 1129.91 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:51<00:37,  3.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.56 toks/s, output: 41.62 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.49it/s, est. speed input: 6432.67 toks/s, output: 950.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 7679.81 toks/s, output: 1306.47 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:53<00:30,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.55 toks/s, output: 42.28 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6195.53 toks/s, output: 917.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.50it/s, est. speed input: 6687.54 toks/s, output: 1188.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.04it/s, est. speed input: 6687.54 toks/s, output: 1188.41 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:56<00:24,  3.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 299.74 toks/s, output: 41.50 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.07it/s, est. speed input: 6622.29 toks/s, output: 980.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 7671.61 toks/s, output: 1276.15 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:58<00:20,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.17 toks/s, output: 41.84 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6230.34 toks/s, output: 923.33 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.04it/s, est. speed input: 6381.99 toks/s, output: 1111.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6525.07 toks/s, output: 1181.74 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [04:00<00:16,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.40 toks/s, output: 41.73 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.01it/s, est. speed input: 5420.83 toks/s, output: 807.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.30it/s, est. speed input: 6506.72 toks/s, output: 1240.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6506.72 toks/s, output: 1240.99 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [04:03<00:13,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.41 toks/s, output: 41.60 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.37it/s, est. speed input: 6132.59 toks/s, output: 915.85 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.68it/s, est. speed input: 6480.76 toks/s, output: 1139.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.02it/s, est. speed input: 6688.22 toks/s, output: 1217.29 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [04:06<00:10,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.06 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.29it/s, est. speed input: 6969.46 toks/s, output: 1031.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6526.17 toks/s, output: 1089.42 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [04:08<00:07,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.04 toks/s, output: 41.82 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.67it/s, est. speed input: 6198.97 toks/s, output: 918.33 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.46it/s, est. speed input: 6497.95 toks/s, output: 1159.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6497.95 toks/s, output: 1159.27 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [04:11<00:05,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.71 toks/s, output: 41.30 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.64it/s, est. speed input: 6204.40 toks/s, output: 919.40 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.34it/s, est. speed input: 5630.04 toks/s, output: 1021.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.34it/s, est. speed input: 5630.04 toks/s, output: 1021.64 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [04:14<00:02,  2.69s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.15s/it, est. speed input: 338.77 toks/s, output: 46.91 toks/s][A
Processed prompts:  93%|█████████▎| 26/28 [00:01<00:00, 23.77it/s, est. speed input: 7154.41 toks/s, output: 1061.20 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.98it/s, est. speed input: 7454.86 toks/s, output: 1171.62 toks/s]
Processing batched inference: 100%|██████████| 66/66 [04:16<00:00,  2.51s/it]Processing batched inference: 100%|██████████| 66/66 [04:16<00:00,  3.88s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-882/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 12:12:07.788025421 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-945
INFO 07-05 12:12:20 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 12:12:22,368 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 12:12:22,433 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,458 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,458 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,459 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,459 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,459 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,459 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,459 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:12:22,846 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 12:12:22,848 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 12:12:22,853 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:12:22,860 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,861 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,861 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,861 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,861 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,861 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,861 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:22,861 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:12:23,235 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 12:12:23,237 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 12:12:23,434 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 12:12:23,879 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 12:12:23,936 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/config.json
[INFO|configuration_utils.py:696] 2025-07-05 12:12:23,936 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/config.json
[INFO|configuration_utils.py:770] 2025-07-05 12:12:23,938 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 12:12:35 [config.py:689] This model supports multiple tasks: {'reward', 'classify', 'generate', 'embed', 'score'}. Defaulting to 'generate'.
INFO 07-05 12:12:35 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:35,591 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:35,591 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:35,591 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:35,591 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:35,591 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:35,591 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:35,591 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:12:35,934 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 12:12:36,027 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 12:12:36,028 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 12:12:37 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 12:12:37 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 12:12:37 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945...
WARNING 07-05 12:12:37 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 12:12:38 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.32s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.32s/it]

INFO 07-05 12:12:45 [loader.py:458] Loading weights took 7.54 seconds
INFO 07-05 12:12:45 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.793554 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,120 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,120 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,120 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,120 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,120 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,120 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,120 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:12:46,519 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 12:12:46,613 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:12:46,613 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 12:12:46,614 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:12:46,614 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,615 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,615 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,615 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,615 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,615 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,615 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:12:46,615 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:12:47,388 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 12:12:47,388 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 12:12:47,388 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 12:12:47,845 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 12:12:48,505 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 12:12:49 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 12:12:51,333 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 12:12:52,322 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 12:12:52 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 12:13:31 [worker.py:267] Memory profiling takes 45.26 seconds
INFO 07-05 12:13:31 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 12:13:31 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 12:13:31 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 12:13:31 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 12:13:37 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:20,  1.63it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.92it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.94it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.94it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.97it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.98it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.98it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.99it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  2.00it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  2.00it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.93it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.91it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.93it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.90it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.91it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.90it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.92it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.86it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.89it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.91it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.91it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.93it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.94it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.93it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.87it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 12:13:55 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 12:13:55 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.38 seconds
[INFO|2025-07-05 12:13:55] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:18, 108.08 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 223.74 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 340.53 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:03, 454.13 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 550.27 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:02<00:02, 550.48 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 625.74 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:02<00:00, 1046.63 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:02<00:00, 944.08 examples/s] Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:02<00:00, 993.06 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 916.67 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 712.72 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 568.64 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 12:14:02,702 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 12:14:02,702 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:14:02,704 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:14:02,704 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:14:02,704 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:14:02,704 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:14:02,704 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:14:02,704 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 12:14:02,704 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 12:14:03,481 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 12:14:03,482 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 12:14:03,482 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 12:14:03,949 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_base/checkpoint-945', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:52,  1.69s/it, est. speed input: 231.13 toks/s, output: 32.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 18.16it/s, est. speed input: 5370.96 toks/s, output: 802.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.80it/s, est. speed input: 6207.30 toks/s, output: 1035.62 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:32,  4.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.67 toks/s, output: 42.18 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.80it/s, est. speed input: 6586.27 toks/s, output: 977.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.32it/s, est. speed input: 6553.93 toks/s, output: 1123.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6553.93 toks/s, output: 1123.86 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:32,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.73 toks/s, output: 42.19 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.27it/s, est. speed input: 5209.28 toks/s, output: 778.48 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.76it/s, est. speed input: 6333.59 toks/s, output: 1218.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.80it/s, est. speed input: 5030.73 toks/s, output: 1037.03 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:29,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.53 toks/s, output: 42.16 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.49it/s, est. speed input: 7025.10 toks/s, output: 1035.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7786.93 toks/s, output: 1265.77 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<03:04,  2.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.35 toks/s, output: 42.14 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.01it/s, est. speed input: 5720.84 toks/s, output: 852.73 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.51it/s, est. speed input: 4848.55 toks/s, output: 929.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.01it/s, est. speed input: 4716.15 toks/s, output: 980.38 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:16<03:13,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 305.29 toks/s, output: 42.27 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.46it/s, est. speed input: 7305.54 toks/s, output: 1074.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.90it/s, est. speed input: 6630.51 toks/s, output: 1076.38 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:18<03:00,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 306.41 toks/s, output: 41.64 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.31it/s, est. speed input: 6709.68 toks/s, output: 991.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7773.66 toks/s, output: 1300.04 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:21<02:46,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.09 toks/s, output: 42.10 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5972.65 toks/s, output: 894.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.74it/s, est. speed input: 6515.83 toks/s, output: 1184.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6515.83 toks/s, output: 1184.55 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:24<02:41,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.27 toks/s, output: 42.13 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 6759.50 toks/s, output: 999.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 7768.38 toks/s, output: 1288.22 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:26<02:30,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.59 toks/s, output: 42.17 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.23it/s, est. speed input: 6972.04 toks/s, output: 1030.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.54it/s, est. speed input: 5709.50 toks/s, output: 975.13 toks/s] 
Processing batched inference:  15%|█▌        | 10/66 [00:29<02:33,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.04 toks/s, output: 42.10 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6488.95 toks/s, output: 956.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 7746.26 toks/s, output: 1317.47 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:31<02:25,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.52 toks/s, output: 42.16 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6444.56 toks/s, output: 960.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 7693.13 toks/s, output: 1318.69 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:34<02:18,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.93 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6493.21 toks/s, output: 966.47 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.29it/s, est. speed input: 6730.74 toks/s, output: 1177.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.13it/s, est. speed input: 6730.74 toks/s, output: 1177.28 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:36<02:16,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.03 toks/s, output: 42.10 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.67it/s, est. speed input: 6779.89 toks/s, output: 1002.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6547.78 toks/s, output: 1109.02 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:39<02:14,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.50 toks/s, output: 42.05 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.09it/s, est. speed input: 5450.61 toks/s, output: 813.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.16it/s, est. speed input: 6489.78 toks/s, output: 1224.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6489.78 toks/s, output: 1224.99 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:42<02:13,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.65 toks/s, output: 42.04 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7282.24 toks/s, output: 1081.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 7796.06 toks/s, output: 1247.56 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:44<02:07,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.91 toks/s, output: 42.61 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.70it/s, est. speed input: 6496.20 toks/s, output: 965.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.32it/s, est. speed input: 2768.38 toks/s, output: 651.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.05it/s, est. speed input: 2768.38 toks/s, output: 651.01 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:49<02:45,  3.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.06 toks/s, output: 42.10 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7017.74 toks/s, output: 1039.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 7778.12 toks/s, output: 1265.49 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:52<02:26,  3.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.10 toks/s, output: 42.11 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6235.05 toks/s, output: 927.91 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.85it/s, est. speed input: 6591.90 toks/s, output: 1177.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6591.90 toks/s, output: 1177.92 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:54<02:18,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.19 toks/s, output: 42.51 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.19it/s, est. speed input: 6952.76 toks/s, output: 1036.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6551.07 toks/s, output: 1098.70 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:57<02:10,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.64 toks/s, output: 42.04 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 5966.41 toks/s, output: 890.05 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.30it/s, est. speed input: 6385.58 toks/s, output: 1141.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6528.45 toks/s, output: 1211.31 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:59<02:04,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.51 toks/s, output: 42.02 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.51it/s, est. speed input: 4687.03 toks/s, output: 702.70 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.34it/s, est. speed input: 5865.84 toks/s, output: 1141.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.30it/s, est. speed input: 5616.17 toks/s, output: 1236.31 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:02<02:04,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.98 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6492.05 toks/s, output: 962.60 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.44it/s, est. speed input: 6560.15 toks/s, output: 1167.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6560.15 toks/s, output: 1167.44 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:05<01:58,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.62 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6486.99 toks/s, output: 962.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  5.85it/s, est. speed input: 2592.04 toks/s, output: 549.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s, est. speed input: 2592.04 toks/s, output: 549.57 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:10<02:30,  3.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.10 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6215.70 toks/s, output: 922.43 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.88it/s, est. speed input: 6314.77 toks/s, output: 1086.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.56it/s, est. speed input: 1004.16 toks/s, output: 324.75 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:24<04:25,  6.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.12 toks/s, output: 41.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.73it/s, est. speed input: 6283.38 toks/s, output: 939.27 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.80it/s, est. speed input: 5039.00 toks/s, output: 925.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.82it/s, est. speed input: 5039.00 toks/s, output: 925.83 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:27<03:39,  5.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.31 toks/s, output: 42.13 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 5979.13 toks/s, output: 889.69 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.02it/s, est. speed input: 6336.11 toks/s, output: 1133.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6540.67 toks/s, output: 1214.20 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:29<02:59,  4.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.00 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.31it/s, est. speed input: 6122.77 toks/s, output: 909.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.64it/s, est. speed input: 6519.01 toks/s, output: 1169.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6519.01 toks/s, output: 1169.14 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:32<02:32,  4.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.31 toks/s, output: 42.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.56it/s, est. speed input: 5613.12 toks/s, output: 838.98 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.41it/s, est. speed input: 6101.01 toks/s, output: 1109.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.93it/s, est. speed input: 2331.40 toks/s, output: 636.81 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [01:38<02:50,  4.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.57 toks/s, output: 42.03 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.33it/s, est. speed input: 7276.75 toks/s, output: 1078.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.88it/s, est. speed input: 6627.21 toks/s, output: 1079.21 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:41<02:22,  3.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 303.85 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6232.87 toks/s, output: 924.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 7791.91 toks/s, output: 1349.74 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:43<02:00,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.11 toks/s, output: 42.11 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 5968.01 toks/s, output: 881.65 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.75it/s, est. speed input: 6513.91 toks/s, output: 1185.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6513.91 toks/s, output: 1185.42 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:45<01:47,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.21 toks/s, output: 41.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.09it/s, est. speed input: 6081.45 toks/s, output: 910.07 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.67it/s, est. speed input: 6246.24 toks/s, output: 1084.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.38it/s, est. speed input: 5651.60 toks/s, output: 1082.33 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:48<01:41,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.84 toks/s, output: 41.93 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.82it/s, est. speed input: 7160.29 toks/s, output: 1062.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.81it/s, est. speed input: 6607.30 toks/s, output: 1081.86 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:51<01:33,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.90 toks/s, output: 41.80 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7240.56 toks/s, output: 1067.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6539.45 toks/s, output: 1063.51 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:53<01:28,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.15 toks/s, output: 41.97 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 5953.64 toks/s, output: 883.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.70it/s, est. speed input: 6499.43 toks/s, output: 1181.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6499.43 toks/s, output: 1181.28 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:56<01:22,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.44 toks/s, output: 42.01 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 6743.76 toks/s, output: 1000.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7776.43 toks/s, output: 1288.73 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:58<01:15,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.86 toks/s, output: 41.66 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.60it/s, est. speed input: 6187.10 toks/s, output: 925.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 7676.90 toks/s, output: 1349.25 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:00<01:10,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.82 toks/s, output: 41.65 toks/s][A
Processed prompts:  53%|█████▎    | 17/32 [00:01<00:01, 13.71it/s, est. speed input: 4149.16 toks/s, output: 623.39 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.51it/s, est. speed input: 6248.21 toks/s, output: 1296.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.37it/s, est. speed input: 6429.38 toks/s, output: 1371.91 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:03<01:08,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.11 toks/s, output: 41.83 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.43it/s, est. speed input: 6725.55 toks/s, output: 1002.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7731.40 toks/s, output: 1294.20 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:05<01:03,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.94 toks/s, output: 41.81 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.02it/s, est. speed input: 5424.81 toks/s, output: 808.62 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.10it/s, est. speed input: 6466.69 toks/s, output: 1227.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.47it/s, est. speed input: 6466.69 toks/s, output: 1227.13 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:08<01:02,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.90 toks/s, output: 41.43 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6474.20 toks/s, output: 957.70 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.81it/s, est. speed input: 6398.00 toks/s, output: 1094.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.57it/s, est. speed input: 5719.51 toks/s, output: 1039.70 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:11<01:01,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.86 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 6991.54 toks/s, output: 1033.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.90it/s, est. speed input: 5847.48 toks/s, output: 991.96 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [02:14<01:01,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.37 toks/s, output: 41.59 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.36it/s, est. speed input: 6686.88 toks/s, output: 986.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.11it/s, est. speed input: 5141.91 toks/s, output: 908.67 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:17<01:00,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.95 toks/s, output: 41.95 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.32it/s, est. speed input: 7264.56 toks/s, output: 1070.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6557.38 toks/s, output: 1067.65 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:19<00:56,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.42 toks/s, output: 41.73 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.74it/s, est. speed input: 5924.88 toks/s, output: 877.42 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.16it/s, est. speed input: 5872.66 toks/s, output: 1013.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 18.16it/s, est. speed input: 1948.71 toks/s, output: 487.34 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.38s/it, est. speed input: 481.42 toks/s, output: 273.66 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 481.42 toks/s, output: 273.66 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:46<03:18,  9.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.52 toks/s, output: 41.78 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.41it/s, est. speed input: 6717.41 toks/s, output: 1001.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7719.91 toks/s, output: 1292.99 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:48<02:24,  7.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.60 toks/s, output: 41.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.28it/s, est. speed input: 7257.17 toks/s, output: 1072.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 7770.42 toks/s, output: 1238.68 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:50<01:47,  5.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.87 toks/s, output: 41.94 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.05it/s, est. speed input: 5719.38 toks/s, output: 849.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 7681.93 toks/s, output: 1392.76 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:52<01:22,  4.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.53 toks/s, output: 41.89 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.18it/s, est. speed input: 7516.55 toks/s, output: 1109.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.11it/s, est. speed input: 7891.09 toks/s, output: 1219.22 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:55<01:05,  4.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 303.20 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 5960.06 toks/s, output: 888.56 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.25it/s, est. speed input: 6375.93 toks/s, output: 1143.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.85it/s, est. speed input: 5831.43 toks/s, output: 1103.25 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:57<00:55,  3.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.45 toks/s, output: 41.74 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.64it/s, est. speed input: 6195.15 toks/s, output: 922.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 7689.52 toks/s, output: 1347.94 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [03:00<00:45,  3.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 300.43 toks/s, output: 42.26 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.91it/s, est. speed input: 5674.55 toks/s, output: 844.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.83it/s, est. speed input: 5853.35 toks/s, output: 1106.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.91it/s, est. speed input: 5853.35 toks/s, output: 1106.37 toks/s]
Processing batched inference:  80%|████████  | 53/66 [03:03<00:40,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.94 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 6732.06 toks/s, output: 996.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 7736.01 toks/s, output: 1285.11 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [03:05<00:34,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.67 toks/s, output: 41.91 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6468.60 toks/s, output: 955.88 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.55it/s, est. speed input: 2087.38 toks/s, output: 508.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  5.32it/s, est. speed input: 2087.38 toks/s, output: 508.71 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:11<00:43,  3.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 301.48 toks/s, output: 41.74 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.00it/s, est. speed input: 5423.11 toks/s, output: 812.11 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.45it/s, est. speed input: 6302.51 toks/s, output: 1184.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.29it/s, est. speed input: 5616.00 toks/s, output: 1113.99 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:14<00:36,  3.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.64 toks/s, output: 41.90 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 5690.05 toks/s, output: 843.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.24it/s, est. speed input: 6546.60 toks/s, output: 1212.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6546.60 toks/s, output: 1212.75 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:17<00:29,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.00 toks/s, output: 42.48 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6220.60 toks/s, output: 921.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 7720.40 toks/s, output: 1343.69 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:19<00:24,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.81 toks/s, output: 41.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.68it/s, est. speed input: 7404.68 toks/s, output: 1092.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 7776.56 toks/s, output: 1206.91 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:21<00:19,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.15 toks/s, output: 41.84 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6225.70 toks/s, output: 923.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.72it/s, est. speed input: 6318.25 toks/s, output: 1101.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.53it/s, est. speed input: 5700.27 toks/s, output: 1053.70 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:24<00:16,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 302.09 toks/s, output: 41.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6206.67 toks/s, output: 923.69 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.03it/s, est. speed input: 6381.76 toks/s, output: 1123.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6566.29 toks/s, output: 1200.65 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:27<00:13,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.42 toks/s, output: 41.87 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.70it/s, est. speed input: 5643.04 toks/s, output: 843.26 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.85it/s, est. speed input: 6649.91 toks/s, output: 1237.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.93it/s, est. speed input: 6649.91 toks/s, output: 1237.82 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:29<00:10,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.57 toks/s, output: 41.89 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6208.56 toks/s, output: 921.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 7705.35 toks/s, output: 1343.31 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:31<00:07,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 304.76 toks/s, output: 41.42 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.47it/s, est. speed input: 6164.71 toks/s, output: 912.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 7713.08 toks/s, output: 1347.22 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:34<00:04,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 302.64 toks/s, output: 41.90 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6210.64 toks/s, output: 921.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.49it/s, est. speed input: 6507.35 toks/s, output: 1156.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6507.35 toks/s, output: 1156.49 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:36<00:02,  2.48s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 335.56 toks/s, output: 46.46 toks/s][A
Processed prompts:  93%|█████████▎| 26/28 [00:01<00:00, 22.71it/s, est. speed input: 6894.07 toks/s, output: 1025.29 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.83it/s, est. speed input: 7394.92 toks/s, output: 1164.89 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:38<00:00,  2.37s/it]Processing batched inference: 100%|██████████| 66/66 [03:38<00:00,  3.32s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_base_qwen2_vl-3b/checkpoint-945/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 12:17:42.469690941 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
