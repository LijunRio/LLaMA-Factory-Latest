Container llamafactory already exists.

=============
== PyTorch ==
=============

NVIDIA Release 24.07 (build 100464919)
PyTorch Version 2.4.0a0+3bcc3cd
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

ERROR: This container was built for NVIDIA Driver Release 555.42 or later, but
       version 535.247.01 was detected and compatibility mode is UNAVAILABLE.

       [[]]

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.

Fri Jul  4 21:29:08 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.5     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:87:00.0 Off |                    0 |
| N/A   35C    P0              53W / 400W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |
| N/A   34C    P0              56W / 400W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA A100-SXM4-40GB          On  | 00000000:B7:00.0 Off |                    0 |
| N/A   35C    P0              55W / 400W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA A100-SXM4-40GB          On  | 00000000:BD:00.0 Off |                    0 |
| N/A   34C    P0              55W / 400W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
ðŸš€ Running experiment: Experiment 1:Qwen2-VL-2B-Instruct SFT Base
-----------------------------------
Model: /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/
Output Dir: saves/qwen2_vl-3b/vindr_sft_base
Train Dataset: vinder_train_base
Cutoff Length: 1024
Save Steps: 63
Learning Rate: 3.0e-5
Num Train Epochs: 20.0
Logging Steps: 5
Per Device Train Batch Size: 8
Gradient Accumulation Steps: 8
-----------------------------------
[2025-07-04 21:29:19,878] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 07-04 21:29:23 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-07-04 21:29:26] llamafactory.cli:143 >> Initializing 4 distributed tasks at: 127.0.0.1:42629
W0704 21:29:28.707000 2361161 site-packages/torch/distributed/run.py:792] 
W0704 21:29:28.707000 2361161 site-packages/torch/distributed/run.py:792] *****************************************
W0704 21:29:28.707000 2361161 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0704 21:29:28.707000 2361161 site-packages/torch/distributed/run.py:792] *****************************************
[2025-07-04 21:29:38,141] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-04 21:29:38,433] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-04 21:29:38,497] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-04 21:29:38,502] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-04 21:29:42,070] [INFO] [comm.py:669:init_distributed] cdb=None
[INFO|2025-07-04 21:29:42] llamafactory.hparams.parser:406 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[2025-07-04 21:29:42,522] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-04 21:29:42,552] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-04 21:29:42,553] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-07-04 21:29:42,614] [INFO] [comm.py:669:init_distributed] cdb=None
[INFO|2025-07-04 21:29:42] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:42,829 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:42,829 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:42,829 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:42,829 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:42,829 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:42,829 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:42,829 >> loading file chat_template.jinja
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|2025-07-04 21:29:43] llamafactory.hparams.parser:406 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2299] 2025-07-04 21:29:43,152 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-04 21:29:43,153 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-04 21:29:43,157 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-04 21:29:43,164 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:43,165 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:43,165 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:43,165 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:43,165 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:43,165 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:43,165 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-04 21:29:43,165 >> loading file chat_template.jinja
[INFO|2025-07-04 21:29:43] llamafactory.hparams.parser:406 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2299] 2025-07-04 21:29:43,479 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-07-04 21:29:43,481 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-07-04 21:29:43,481 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-07-04 21:29:43,481 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-07-04 21:29:43,483 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

[INFO|video_processing_utils.py:627] 2025-07-04 21:29:43,484 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-04 21:29:43,484 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[rank2]:[W704 21:29:43.939050781 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|processing_utils.py:990] 2025-07-04 21:29:43,972 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|2025-07-04 21:29:43] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/train_vindr_qwen2_len_16087.json...
[rank1]:[W704 21:29:44.629989291 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W704 21:29:44.633397979 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Converting format of dataset (num_proc=16):   0%|          | 0/16087 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   1%|          | 179/16087 [00:00<00:10, 1461.44 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 9558/16087 [00:00<00:00, 50964.01 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16087/16087 [00:00<00:00, 37490.20 examples/s]
[rank0]:[W704 21:29:45.185991612 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Running tokenizer on dataset (num_proc=16):   0%|          | 0/16087 [00:00<?, ? examples/s]