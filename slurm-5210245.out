Container llamafactory already exists.

=============
== PyTorch ==
=============

NVIDIA Release 24.07 (build 100464919)
PyTorch Version 2.4.0a0+3bcc3cd
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

ERROR: This container was built for NVIDIA Driver Release 555.42 or later, but
       version 535.247.01 was detected and compatibility mode is UNAVAILABLE.

       [[]]

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.

Sat Jul  5 09:45:36 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.5     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:87:00.0 Off |                    0 |
| N/A   38C    P0              59W / 400W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Checkpoint directory: saves/qwen2_vl-3b/vindr_sft_def
Output directory: ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b
Processing model: qwen2_vl-3b
Running inference on checkpoint: checkpoint-1008
INFO 07-05 09:46:06 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 09:46:10,379 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 09:46:10,435 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,474 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,474 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,474 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,474 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,474 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,474 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,474 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:46:10,864 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:46:10,866 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 09:46:10,873 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:46:10,882 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,882 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,882 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,882 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,883 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,883 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,883 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:10,883 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:46:11,260 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:46:11,264 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:46:11,452 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:46:11,900 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 09:46:11,955 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/config.json
[INFO|configuration_utils.py:696] 2025-07-05 09:46:11,955 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/config.json
[INFO|configuration_utils.py:770] 2025-07-05 09:46:11,957 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 09:46:24 [config.py:689] This model supports multiple tasks: {'generate', 'reward', 'embed', 'classify', 'score'}. Defaulting to 'generate'.
INFO 07-05 09:46:24 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:24,567 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:24,567 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:24,568 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:24,568 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:24,568 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:24,568 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:24,568 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:46:24,906 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 09:46:25,007 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 09:46:25,010 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 09:46:26 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 09:46:27 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 09:46:27 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008...
WARNING 07-05 09:46:27 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 09:46:27 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.30s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.30s/it]

INFO 07-05 09:46:34 [loader.py:458] Loading weights took 7.52 seconds
INFO 07-05 09:46:35 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.798851 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,297 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,297 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,297 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,297 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,297 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,297 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,297 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:46:35,699 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:46:35,794 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:46:35,795 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 09:46:35,795 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:46:35,795 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,796 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,796 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,796 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,796 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,796 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,796 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:46:35,796 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:46:36,557 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:46:36,558 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:46:36,558 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:46:37,012 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 09:46:37,672 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 09:46:38 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 09:46:40,545 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 09:46:41,544 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 09:46:41 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 09:47:20 [worker.py:267] Memory profiling takes 45.69 seconds
INFO 07-05 09:47:20 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 09:47:20 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 09:47:21 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 09:47:21 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 09:47:26 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:17,  2.00it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:00<00:16,  2.01it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:15,  2.01it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:01<00:15,  2.00it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.99it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:02<00:14,  2.00it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  2.00it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:03<00:13,  2.01it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.99it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:04<00:12,  2.01it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:10,  2.02it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:06<00:10,  2.03it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.04it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:07<00:09,  2.04it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:08,  2.04it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:08<00:08,  2.05it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.05it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:09<00:07,  2.03it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:06,  2.04it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:10<00:06,  2.04it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:05,  2.04it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:11<00:05,  2.04it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.05it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:12<00:04,  2.05it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.05it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:13<00:03,  2.02it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:02,  2.02it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:14<00:02,  2.03it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.04it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:15<00:01,  2.03it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:00,  2.04it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:16<00:00,  2.04it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.02it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.03it/s]
INFO 07-05 09:47:43 [model_runner.py:1598] Graph capturing finished in 17 secs, took 0.33 GiB
INFO 07-05 09:47:43 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.90 seconds
[INFO|2025-07-05 09:47:44] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:13, 145.94 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:02, 655.50 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:01, 860.90 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:01<00:00, 1158.69 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:01<00:00, 1105.70 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:01<00:00, 1298.59 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:01<00:00, 1455.78 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:01<00:00, 1518.26 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 960.27 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 09:47:49,402 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:47:49,402 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:49,404 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:49,404 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:49,404 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:49,404 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:49,404 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:49,404 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:47:49,404 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:47:50,184 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:47:50,185 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:47:50,185 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:47:50,639 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1008', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 253.02 toks/s, output: 32.84 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 17.16it/s, est. speed input: 5376.50 toks/s, output: 759.19 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 18.82it/s, est. speed input: 5993.02 toks/s, output: 1012.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.44it/s, est. speed input: 5993.02 toks/s, output: 1012.37 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:53,  4.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.82 toks/s, output: 42.16 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.69it/s, est. speed input: 6242.80 toks/s, output: 880.48 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.05it/s, est. speed input: 6871.79 toks/s, output: 1171.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6889.59 toks/s, output: 1218.53 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:42,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.42 toks/s, output: 42.11 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.55it/s, est. speed input: 5920.85 toks/s, output: 838.10 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.42it/s, est. speed input: 6442.31 toks/s, output: 1110.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.42it/s, est. speed input: 6656.65 toks/s, output: 1191.27 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.40it/s, est. speed input: 947.15 toks/s, output: 316.14 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.29it/s, est. speed input: 947.15 toks/s, output: 316.14 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:22<09:08,  8.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.54 toks/s, output: 42.00 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7372.02 toks/s, output: 1036.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 8246.02 toks/s, output: 1267.46 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:24<06:26,  6.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.32 toks/s, output: 41.97 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 6005.07 toks/s, output: 849.47 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.33it/s, est. speed input: 6439.58 toks/s, output: 1102.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.26it/s, est. speed input: 5491.60 toks/s, output: 1043.29 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:27<05:14,  5.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.69 toks/s, output: 42.15 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6553.88 toks/s, output: 923.26 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s, est. speed input: 3091.71 toks/s, output: 613.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.52it/s, est. speed input: 3091.71 toks/s, output: 613.03 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:32<05:07,  5.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.53 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.53it/s, est. speed input: 6517.90 toks/s, output: 915.20 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.86it/s, est. speed input: 6697.10 toks/s, output: 1114.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6913.81 toks/s, output: 1195.62 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:35<04:17,  4.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.93 toks/s, output: 42.05 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 7132.21 toks/s, output: 1006.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8205.17 toks/s, output: 1294.41 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:38<03:38,  3.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.62 toks/s, output: 41.88 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 6218.95 toks/s, output: 881.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.39it/s, est. speed input: 6077.53 toks/s, output: 1073.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.81it/s, est. speed input: 6077.53 toks/s, output: 1073.10 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:41<03:19,  3.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.16 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.33it/s, est. speed input: 7354.28 toks/s, output: 1031.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.84it/s, est. speed input: 5308.22 toks/s, output: 900.28 toks/s] 
Processing batched inference:  15%|█▌        | 10/66 [00:44<03:12,  3.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.88 toks/s, output: 42.04 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7094.55 toks/s, output: 991.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8162.25 toks/s, output: 1289.35 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:46<02:52,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.81 toks/s, output: 41.90 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.05it/s, est. speed input: 6356.88 toks/s, output: 906.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.90it/s, est. speed input: 6819.28 toks/s, output: 1144.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6839.88 toks/s, output: 1192.76 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:49<02:41,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.16 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6556.40 toks/s, output: 923.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8144.06 toks/s, output: 1354.47 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:51<02:28,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.93 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.83it/s, est. speed input: 6571.96 toks/s, output: 925.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8136.00 toks/s, output: 1330.79 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:54<02:20,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.28 toks/s, output: 41.44 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.27it/s, est. speed input: 5496.81 toks/s, output: 776.13 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.65it/s, est. speed input: 6596.51 toks/s, output: 1172.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6829.37 toks/s, output: 1299.00 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:57<02:16,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.43 toks/s, output: 41.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 21.18it/s, est. speed input: 6667.75 toks/s, output: 940.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8137.89 toks/s, output: 1349.85 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:59<02:11,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.42 toks/s, output: 42.38 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.08it/s, est. speed input: 5672.52 toks/s, output: 808.55 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.16it/s, est. speed input: 6500.66 toks/s, output: 1145.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.48it/s, est. speed input: 4711.14 toks/s, output: 976.08 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [01:03<02:22,  2.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.95 toks/s, output: 41.79 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.43it/s, est. speed input: 7022.07 toks/s, output: 996.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8090.91 toks/s, output: 1284.85 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:05<02:11,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.98 toks/s, output: 41.80 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.67it/s, est. speed input: 6539.72 toks/s, output: 921.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8127.02 toks/s, output: 1347.25 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:07<02:04,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.16 toks/s, output: 42.31 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.10it/s, est. speed input: 7279.15 toks/s, output: 1032.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.10it/s, est. speed input: 7055.06 toks/s, output: 1125.68 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:10<02:00,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.30 toks/s, output: 41.71 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.73it/s, est. speed input: 6225.44 toks/s, output: 880.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.64it/s, est. speed input: 6798.89 toks/s, output: 1180.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6798.89 toks/s, output: 1180.39 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:13<01:59,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.26 toks/s, output: 41.83 toks/s][A
Processed prompts:  53%|█████▎    | 17/32 [00:01<00:01, 13.76it/s, est. speed input: 4392.38 toks/s, output: 627.03 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 21.83it/s, est. speed input: 6602.62 toks/s, output: 1278.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.22it/s, est. speed input: 5893.27 toks/s, output: 1230.20 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:16<02:01,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.27 toks/s, output: 40.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.51it/s, est. speed input: 6481.97 toks/s, output: 908.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.17it/s, est. speed input: 6759.43 toks/s, output: 1136.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.30it/s, est. speed input: 6759.43 toks/s, output: 1136.16 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:18<01:57,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.92 toks/s, output: 41.92 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.05it/s, est. speed input: 5727.29 toks/s, output: 810.26 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.66it/s, est. speed input: 5811.63 toks/s, output: 1051.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.07it/s, est. speed input: 3320.76 toks/s, output: 706.24 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:23<02:18,  3.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:38,  1.26s/it, est. speed input: 331.15 toks/s, output: 39.80 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.85it/s, est. speed input: 6941.24 toks/s, output: 980.61 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.04it/s, est. speed input: 1991.72 toks/s, output: 462.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.85it/s, est. speed input: 1991.72 toks/s, output: 462.15 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:30<03:04,  4.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.48 toks/s, output: 41.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.11it/s, est. speed input: 6692.96 toks/s, output: 950.61 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 15.69it/s, est. speed input: 5780.78 toks/s, output: 995.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.41it/s, est. speed input: 4297.27 toks/s, output: 830.11 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:34<02:51,  4.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.40 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6815.39 toks/s, output: 956.69 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 6875.32 toks/s, output: 1164.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6875.32 toks/s, output: 1164.97 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:37<02:26,  3.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.22 toks/s, output: 41.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6499.24 toks/s, output: 923.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8091.59 toks/s, output: 1347.98 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:39<02:06,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.16 toks/s, output: 42.21 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.88it/s, est. speed input: 5957.54 toks/s, output: 847.48 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.28it/s, est. speed input: 6360.63 toks/s, output: 1101.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.33it/s, est. speed input: 5892.21 toks/s, output: 1134.47 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:42<01:57,  3.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.50 toks/s, output: 41.86 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6609.62 toks/s, output: 929.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.67it/s, est. speed input: 6895.84 toks/s, output: 1135.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6981.24 toks/s, output: 1193.76 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:44<01:47,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.56 toks/s, output: 41.74 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.74it/s, est. speed input: 6209.71 toks/s, output: 882.32 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.87it/s, est. speed input: 6831.45 toks/s, output: 1177.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6831.45 toks/s, output: 1177.15 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:47<01:40,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.92 toks/s, output: 41.79 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.44it/s, est. speed input: 7063.68 toks/s, output: 990.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6888.83 toks/s, output: 1140.32 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:49<01:34,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.56 toks/s, output: 41.74 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.42it/s, est. speed input: 6171.57 toks/s, output: 876.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.55it/s, est. speed input: 5917.81 toks/s, output: 1053.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5917.81 toks/s, output: 1053.03 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:52<01:33,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.21 toks/s, output: 41.82 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.36it/s, est. speed input: 6171.06 toks/s, output: 871.29 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.07it/s, est. speed input: 6665.21 toks/s, output: 1137.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.46it/s, est. speed input: 6002.14 toks/s, output: 1083.44 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:55<01:31,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.49 toks/s, output: 41.86 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.15it/s, est. speed input: 7895.81 toks/s, output: 1107.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8169.40 toks/s, output: 1202.48 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:58<01:22,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.40 toks/s, output: 41.85 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.90it/s, est. speed input: 6274.79 toks/s, output: 885.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.52it/s, est. speed input: 5911.17 toks/s, output: 1041.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.33it/s, est. speed input: 5911.17 toks/s, output: 1041.61 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:00<01:21,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.18 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7386.39 toks/s, output: 1030.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8192.27 toks/s, output: 1255.74 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:03<01:14,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.71 toks/s, output: 41.76 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.29it/s, est. speed input: 6738.61 toks/s, output: 958.62 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.28it/s, est. speed input: 6853.33 toks/s, output: 1145.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6853.33 toks/s, output: 1145.49 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:05<01:12,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.36 toks/s, output: 41.71 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.12it/s, est. speed input: 5459.97 toks/s, output: 769.43 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.67it/s, est. speed input: 6652.50 toks/s, output: 1204.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.47it/s, est. speed input: 6845.42 toks/s, output: 1280.93 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:08<01:09,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.93 toks/s, output: 41.79 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.25it/s, est. speed input: 7658.89 toks/s, output: 1079.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6921.83 toks/s, output: 1072.86 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:10<01:06,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.93 toks/s, output: 41.92 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.04it/s, est. speed input: 5722.51 toks/s, output: 809.22 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.51it/s, est. speed input: 6646.41 toks/s, output: 1181.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6839.24 toks/s, output: 1258.16 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:13<01:04,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.22 toks/s, output: 41.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6798.50 toks/s, output: 962.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.67it/s, est. speed input: 6917.28 toks/s, output: 1170.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.81it/s, est. speed input: 6917.28 toks/s, output: 1170.29 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:15<01:01,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 318.64 toks/s, output: 41.76 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.41it/s, est. speed input: 7045.79 toks/s, output: 995.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.85it/s, est. speed input: 6112.81 toks/s, output: 1006.96 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:18<01:00,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.44 toks/s, output: 41.72 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.40it/s, est. speed input: 7039.62 toks/s, output: 989.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8098.99 toks/s, output: 1275.94 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:21<00:55,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.71 toks/s, output: 41.89 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.18it/s, est. speed input: 7886.16 toks/s, output: 1108.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8167.40 toks/s, output: 1206.58 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:23<00:51,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.29 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6821.47 toks/s, output: 960.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:05<00:00,  4.62it/s, est. speed input: 2220.29 toks/s, output: 593.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.39it/s, est. speed input: 2220.29 toks/s, output: 593.42 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:29<01:13,  3.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.44 toks/s, output: 41.85 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.99it/s, est. speed input: 6972.83 toks/s, output: 988.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8150.22 toks/s, output: 1297.88 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:32<01:01,  3.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.45 toks/s, output: 42.39 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6801.13 toks/s, output: 960.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8086.20 toks/s, output: 1315.66 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:34<00:52,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.97 toks/s, output: 41.79 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.27it/s, est. speed input: 5157.27 toks/s, output: 734.96 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.54it/s, est. speed input: 6982.82 toks/s, output: 1299.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.88it/s, est. speed input: 6982.82 toks/s, output: 1299.67 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:36<00:47,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.58 toks/s, output: 41.74 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.42it/s, est. speed input: 7075.71 toks/s, output: 994.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.98it/s, est. speed input: 7021.71 toks/s, output: 1127.65 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:39<00:43,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.62 toks/s, output: 41.88 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.03it/s, est. speed input: 5710.94 toks/s, output: 812.43 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.87it/s, est. speed input: 5908.69 toks/s, output: 1083.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5908.69 toks/s, output: 1083.47 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:42<00:41,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.33 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6812.32 toks/s, output: 963.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.55it/s, est. speed input: 6919.30 toks/s, output: 1151.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.73it/s, est. speed input: 6919.30 toks/s, output: 1151.64 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:44<00:37,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 318.66 toks/s, output: 41.87 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6545.79 toks/s, output: 921.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8125.38 toks/s, output: 1344.81 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:47<00:33,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.68 toks/s, output: 41.89 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 7110.70 toks/s, output: 996.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 8047.82 toks/s, output: 1271.94 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:49<00:29,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.52 toks/s, output: 41.74 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.99it/s, est. speed input: 5689.84 toks/s, output: 807.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.48it/s, est. speed input: 6628.52 toks/s, output: 1174.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6820.89 toks/s, output: 1251.46 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:51<00:27,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 314.88 toks/s, output: 42.80 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.35it/s, est. speed input: 5170.37 toks/s, output: 740.58 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.28it/s, est. speed input: 6431.65 toks/s, output: 1180.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5841.87 toks/s, output: 1165.63 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:54<00:26,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.86 toks/s, output: 41.65 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.50it/s, est. speed input: 6748.86 toks/s, output: 950.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 8076.95 toks/s, output: 1308.21 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:57<00:22,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.25 toks/s, output: 42.36 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6219.92 toks/s, output: 880.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.69it/s, est. speed input: 6806.05 toks/s, output: 1178.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6806.05 toks/s, output: 1178.91 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:59<00:20,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.64 toks/s, output: 41.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.49it/s, est. speed input: 6488.52 toks/s, output: 912.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8081.30 toks/s, output: 1341.66 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:02<00:17,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.78 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.71it/s, est. speed input: 6864.94 toks/s, output: 960.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.26it/s, est. speed input: 6881.39 toks/s, output: 1132.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6881.39 toks/s, output: 1132.61 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:04<00:15,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.05 toks/s, output: 41.80 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.54it/s, est. speed input: 6790.01 toks/s, output: 960.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8117.95 toks/s, output: 1321.09 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:06<00:12,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.22 toks/s, output: 41.83 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.69it/s, est. speed input: 5949.20 toks/s, output: 843.28 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.19it/s, est. speed input: 6825.66 toks/s, output: 1191.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.03it/s, est. speed input: 7042.17 toks/s, output: 1269.55 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:09<00:09,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.20 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.30it/s, est. speed input: 7350.67 toks/s, output: 1033.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.79it/s, est. speed input: 6935.78 toks/s, output: 1097.99 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:12<00:07,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.65 toks/s, output: 41.88 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 6258.72 toks/s, output: 883.81 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.70it/s, est. speed input: 6831.20 toks/s, output: 1181.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6831.20 toks/s, output: 1181.44 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:14<00:05,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.26 toks/s, output: 41.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6555.61 toks/s, output: 919.97 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.50it/s, est. speed input: 6878.07 toks/s, output: 1157.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6878.07 toks/s, output: 1157.90 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:17<00:02,  2.50s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 354.75 toks/s, output: 46.61 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.71it/s, est. speed input: 6554.21 toks/s, output: 928.78 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.75it/s, est. speed input: 7729.50 toks/s, output: 1254.31 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:19<00:00,  2.38s/it]Processing batched inference: 100%|██████████| 66/66 [03:19<00:00,  3.02s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-1008/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 09:51:09.409145599 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1071
INFO 07-05 09:51:21 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 09:51:23,880 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 09:51:23,945 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:23,969 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:23,969 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:23,969 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:23,969 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:23,969 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:23,969 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:23,969 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:51:24,361 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:51:24,363 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 09:51:24,368 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:51:24,375 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:24,375 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:24,375 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:24,375 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:24,375 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:24,375 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:24,375 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:24,375 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:51:24,754 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:51:24,757 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:51:24,953 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:51:25,394 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 09:51:25,450 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/config.json
[INFO|configuration_utils.py:696] 2025-07-05 09:51:25,450 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/config.json
[INFO|configuration_utils.py:770] 2025-07-05 09:51:25,452 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 09:51:36 [config.py:689] This model supports multiple tasks: {'classify', 'score', 'generate', 'embed', 'reward'}. Defaulting to 'generate'.
INFO 07-05 09:51:36 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:36,966 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:36,966 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:36,966 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:36,966 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:36,966 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:36,966 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:36,966 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:51:37,315 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 09:51:37,408 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 09:51:37,408 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 09:51:38 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 09:51:39 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 09:51:39 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071...
WARNING 07-05 09:51:39 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 09:51:39 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]

INFO 07-05 09:51:47 [loader.py:458] Loading weights took 7.59 seconds
INFO 07-05 09:51:47 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.826570 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,509 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,509 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,509 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,509 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,509 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,509 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,509 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:51:47,904 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:51:47,996 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:51:47,997 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 09:51:47,997 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:51:47,997 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,998 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,998 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,998 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,998 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,998 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,998 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:51:47,998 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:51:48,779 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:51:48,780 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:51:48,780 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:51:49,263 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 09:51:49,958 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 09:51:50 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 09:51:52,837 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 09:51:53,851 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 09:51:54 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 09:52:33 [worker.py:267] Memory profiling takes 45.67 seconds
INFO 07-05 09:52:33 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 09:52:33 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 09:52:33 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 09:52:33 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 09:52:38 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:17,  1.98it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:00<00:16,  2.01it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.98it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.97it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  2.00it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  2.00it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:13,  2.01it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  2.00it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:12,  2.01it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:04<00:12,  2.02it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.00it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:05<00:11,  2.00it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:10,  2.01it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:06<00:10,  2.02it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.00it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.98it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  2.00it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:08<00:08,  2.01it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.99it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:09<00:07,  2.00it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.96it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  2.00it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.01it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.97it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.97it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.96it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.97it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.98it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.98it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.00it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.99it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  2.01it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.98it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.99it/s]
INFO 07-05 09:52:56 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 09:52:56 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.10 seconds
[INFO|2025-07-05 09:52:56] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:09, 212.55 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:00<00:05, 365.20 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 543.94 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:01, 927.17 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:01<00:00, 1285.54 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:01<00:00, 1263.40 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:01<00:00, 1421.19 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:01<00:00, 1383.64 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 967.83 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 09:53:01,287 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:53:01,287 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:53:01,288 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:53:01,288 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:53:01,288 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:53:01,288 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:53:01,288 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:53:01,288 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:53:01,288 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:53:02,069 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:53:02,070 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:53:02,070 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:53:02,525 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1071', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 254.04 toks/s, output: 32.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 17.23it/s, est. speed input: 5397.14 toks/s, output: 762.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.15it/s, est. speed input: 6699.37 toks/s, output: 1108.99 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:34,  4.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.14 toks/s, output: 42.07 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.67it/s, est. speed input: 6234.62 toks/s, output: 879.33 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.76it/s, est. speed input: 7054.10 toks/s, output: 1220.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.05it/s, est. speed input: 7054.10 toks/s, output: 1220.44 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:34,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.60 toks/s, output: 42.00 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.42it/s, est. speed input: 6188.68 toks/s, output: 875.28 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.23it/s, est. speed input: 6454.84 toks/s, output: 1087.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.25it/s, est. speed input: 1345.86 toks/s, output: 375.97 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:17<07:00,  6.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.76 toks/s, output: 41.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7642.15 toks/s, output: 1071.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8178.17 toks/s, output: 1229.84 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:20<05:09,  4.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.43 toks/s, output: 41.85 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 6266.50 toks/s, output: 885.83 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.07it/s, est. speed input: 6394.66 toks/s, output: 1048.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.95it/s, est. speed input: 6192.02 toks/s, output: 1155.33 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:22<04:19,  4.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.93 toks/s, output: 42.05 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6798.00 toks/s, output: 958.69 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  7.46it/s, est. speed input: 3325.21 toks/s, output: 635.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.08it/s, est. speed input: 3325.21 toks/s, output: 635.08 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:27<04:26,  4.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.22 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.39it/s, est. speed input: 6783.95 toks/s, output: 950.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.63it/s, est. speed input: 6703.11 toks/s, output: 1090.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.47it/s, est. speed input: 6000.77 toks/s, output: 1038.18 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:30<03:55,  4.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.36 toks/s, output: 41.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6842.11 toks/s, output: 965.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8173.21 toks/s, output: 1319.52 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:33<03:22,  3.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.24 toks/s, output: 41.83 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 7034.43 toks/s, output: 991.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8077.47 toks/s, output: 1283.48 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:35<02:59,  3.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.13 toks/s, output: 41.94 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.38it/s, est. speed input: 7435.49 toks/s, output: 1044.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.83it/s, est. speed input: 6955.75 toks/s, output: 1105.02 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:38<02:47,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.00 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6826.22 toks/s, output: 952.90 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.31it/s, est. speed input: 7079.38 toks/s, output: 1165.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.14it/s, est. speed input: 7079.38 toks/s, output: 1165.43 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:40<02:39,  2.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.09 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6519.18 toks/s, output: 931.30 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.75it/s, est. speed input: 6841.69 toks/s, output: 1145.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6861.71 toks/s, output: 1193.97 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:43<02:33,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.82 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 6289.81 toks/s, output: 888.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8135.55 toks/s, output: 1380.66 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:46<02:22,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 320.55 toks/s, output: 42.01 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.87it/s, est. speed input: 6583.70 toks/s, output: 927.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.53it/s, est. speed input: 6879.80 toks/s, output: 1150.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6879.80 toks/s, output: 1150.78 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:48<02:19,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 327.93 toks/s, output: 40.99 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 6030.22 toks/s, output: 848.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8079.86 toks/s, output: 1390.75 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:51<02:11,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 327.88 toks/s, output: 40.98 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.34it/s, est. speed input: 6774.61 toks/s, output: 956.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8157.90 toks/s, output: 1329.14 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:53<02:06,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.31 toks/s, output: 42.37 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 5952.75 toks/s, output: 846.25 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.70it/s, est. speed input: 6462.11 toks/s, output: 1112.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.80it/s, est. speed input: 5253.46 toks/s, output: 1030.44 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:56<02:13,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.00 toks/s, output: 41.54 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.21it/s, est. speed input: 7258.65 toks/s, output: 1028.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8065.70 toks/s, output: 1253.27 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:59<02:05,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.83it/s, est. speed input: 7555.27 toks/s, output: 1061.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8216.52 toks/s, output: 1244.45 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:01<02:00,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.00 toks/s, output: 42.42 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.27it/s, est. speed input: 6996.97 toks/s, output: 993.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 8060.47 toks/s, output: 1290.37 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:03<01:54,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.86 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.00it/s, est. speed input: 6298.93 toks/s, output: 890.93 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.62it/s, est. speed input: 6817.32 toks/s, output: 1181.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6817.32 toks/s, output: 1181.01 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:06<01:55,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.81 toks/s, output: 41.90 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.62it/s, est. speed input: 4675.27 toks/s, output: 662.34 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.38it/s, est. speed input: 6388.11 toks/s, output: 1219.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.81it/s, est. speed input: 6136.07 toks/s, output: 1258.67 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:09<01:57,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.12 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7121.14 toks/s, output: 994.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6902.83 toks/s, output: 1113.44 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:11<01:53,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.12 toks/s, output: 41.94 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 5998.11 toks/s, output: 847.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 11.81it/s, est. speed input: 4616.96 toks/s, output: 852.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.45it/s, est. speed input: 4301.98 toks/s, output: 882.92 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:15<02:04,  2.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it, est. speed input: 331.50 toks/s, output: 39.84 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.86it/s, est. speed input: 6944.93 toks/s, output: 981.13 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.86it/s, est. speed input: 6652.51 toks/s, output: 1085.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:12<00:00,  1.97it/s, est. speed input: 1027.94 toks/s, output: 313.47 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.50it/s, est. speed input: 1027.94 toks/s, output: 313.47 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:29<04:12,  6.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.45 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.31it/s, est. speed input: 6444.32 toks/s, output: 915.88 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.65it/s, est. speed input: 6855.50 toks/s, output: 1174.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6855.50 toks/s, output: 1174.32 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:31<03:24,  5.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.35 toks/s, output: 41.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6818.94 toks/s, output: 961.60 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.29it/s, est. speed input: 6861.19 toks/s, output: 1136.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6861.19 toks/s, output: 1136.07 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:34<02:50,  4.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.21 toks/s, output: 41.95 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7061.79 toks/s, output: 999.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8133.22 toks/s, output: 1297.00 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:36<02:22,  3.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.61 toks/s, output: 42.27 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6497.71 toks/s, output: 922.82 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.70it/s, est. speed input: 6601.08 toks/s, output: 1134.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6816.48 toks/s, output: 1215.58 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:39<02:05,  3.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.22 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.61it/s, est. speed input: 7166.47 toks/s, output: 1003.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8209.77 toks/s, output: 1289.78 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:41<01:49,  3.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.29 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6511.94 toks/s, output: 922.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8088.66 toks/s, output: 1336.63 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:43<01:37,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.82 toks/s, output: 41.90 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7080.05 toks/s, output: 992.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6876.49 toks/s, output: 1112.79 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:46<01:32,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.85 toks/s, output: 41.91 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.48it/s, est. speed input: 6190.96 toks/s, output: 878.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.87it/s, est. speed input: 6334.83 toks/s, output: 1048.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.38it/s, est. speed input: 5957.93 toks/s, output: 1145.56 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:49<01:31,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.28 toks/s, output: 41.96 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 6013.70 toks/s, output: 849.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.83it/s, est. speed input: 5969.97 toks/s, output: 1076.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.39it/s, est. speed input: 5969.97 toks/s, output: 1076.29 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:52<01:30,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.22 toks/s, output: 41.96 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7351.81 toks/s, output: 1033.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6879.87 toks/s, output: 1086.64 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:54<01:24,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.61 toks/s, output: 42.01 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.85it/s, est. speed input: 6554.35 toks/s, output: 927.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.35it/s, est. speed input: 5927.90 toks/s, output: 1023.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5927.90 toks/s, output: 1023.90 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:57<01:23,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.28 toks/s, output: 41.96 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7403.66 toks/s, output: 1033.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8210.54 toks/s, output: 1258.54 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:59<01:15,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.31 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.32it/s, est. speed input: 6748.15 toks/s, output: 959.98 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.30it/s, est. speed input: 6859.98 toks/s, output: 1146.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6859.98 toks/s, output: 1146.60 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:02<01:12,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.10 toks/s, output: 41.81 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.57it/s, est. speed input: 4668.26 toks/s, output: 662.16 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.36it/s, est. speed input: 6391.42 toks/s, output: 1214.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.26it/s, est. speed input: 5926.04 toks/s, output: 1216.76 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:05<01:12,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.47 toks/s, output: 41.86 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.32it/s, est. speed input: 7378.47 toks/s, output: 1041.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6937.11 toks/s, output: 1100.29 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:07<01:08,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.32 toks/s, output: 41.84 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.30it/s, est. speed input: 5176.71 toks/s, output: 733.26 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.37it/s, est. speed input: 6213.89 toks/s, output: 1120.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.45it/s, est. speed input: 6797.23 toks/s, output: 1350.18 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:10<01:05,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.03 toks/s, output: 41.80 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7066.27 toks/s, output: 998.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.57it/s, est. speed input: 5995.96 toks/s, output: 1015.79 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:13<01:04,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 322.45 toks/s, output: 40.80 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.48it/s, est. speed input: 6787.04 toks/s, output: 955.27 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.16it/s, est. speed input: 5408.47 toks/s, output: 930.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.14it/s, est. speed input: 5408.47 toks/s, output: 930.35 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:16<01:05,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.96 toks/s, output: 41.79 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.38it/s, est. speed input: 7036.74 toks/s, output: 988.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8094.79 toks/s, output: 1275.28 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:18<00:58,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.42 toks/s, output: 41.85 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.16it/s, est. speed input: 7878.72 toks/s, output: 1107.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8160.12 toks/s, output: 1205.50 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:20<00:52,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.16 toks/s, output: 41.69 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6533.39 toks/s, output: 921.13 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.82it/s, est. speed input: 6421.71 toks/s, output: 1043.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:15<00:00,  2.12it/s, est. speed input: 874.14 toks/s, output: 328.91 toks/s]  
Processing batched inference:  70%|██████▉   | 46/66 [02:36<02:09,  6.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.34 toks/s, output: 41.97 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.91it/s, est. speed input: 7264.38 toks/s, output: 1026.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8182.09 toks/s, output: 1273.93 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:38<01:38,  5.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.87 toks/s, output: 42.31 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6765.51 toks/s, output: 957.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 6832.50 toks/s, output: 1161.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6832.50 toks/s, output: 1161.48 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:41<01:19,  4.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.88 toks/s, output: 41.78 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.23it/s, est. speed input: 5451.88 toks/s, output: 775.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.27it/s, est. speed input: 6799.41 toks/s, output: 1241.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.44it/s, est. speed input: 6799.41 toks/s, output: 1241.39 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:43<01:05,  3.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.41 toks/s, output: 41.85 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.17it/s, est. speed input: 7926.77 toks/s, output: 1106.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 8251.60 toks/s, output: 1211.04 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:46<00:54,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.35 toks/s, output: 41.84 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.88it/s, est. speed input: 5974.70 toks/s, output: 846.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.51it/s, est. speed input: 8072.85 toks/s, output: 1393.13 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:48<00:45,  3.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 319.89 toks/s, output: 41.25 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.46it/s, est. speed input: 6797.02 toks/s, output: 959.62 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.51it/s, est. speed input: 6910.80 toks/s, output: 1149.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6910.80 toks/s, output: 1149.18 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:50<00:40,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 318.96 toks/s, output: 41.91 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 5994.08 toks/s, output: 845.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 8088.09 toks/s, output: 1397.88 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:53<00:34,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7671.14 toks/s, output: 1072.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8214.63 toks/s, output: 1234.54 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:55<00:30,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.21 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6539.05 toks/s, output: 921.55 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.91it/s, est. speed input: 6442.63 toks/s, output: 1052.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.44it/s, est. speed input: 5963.89 toks/s, output: 1098.29 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:58<00:28,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 314.68 toks/s, output: 42.77 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.49it/s, est. speed input: 4903.29 toks/s, output: 704.21 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.20it/s, est. speed input: 6375.58 toks/s, output: 1193.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5901.62 toks/s, output: 1218.60 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:01<00:27,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.45 toks/s, output: 41.86 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6519.35 toks/s, output: 917.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8097.01 toks/s, output: 1340.91 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:03<00:23,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.97 toks/s, output: 42.46 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.09it/s, est. speed input: 5691.53 toks/s, output: 809.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.18it/s, est. speed input: 6995.24 toks/s, output: 1259.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.98it/s, est. speed input: 6995.24 toks/s, output: 1259.45 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:05<00:20,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.50 toks/s, output: 41.86 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 6261.19 toks/s, output: 881.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 8057.38 toks/s, output: 1365.22 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:08<00:17,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.28 toks/s, output: 41.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.91it/s, est. speed input: 6908.67 toks/s, output: 962.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.17it/s, est. speed input: 6870.75 toks/s, output: 1131.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6870.75 toks/s, output: 1131.89 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:10<00:14,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.56 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.48it/s, est. speed input: 6778.60 toks/s, output: 958.88 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.52it/s, est. speed input: 6912.28 toks/s, output: 1149.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6912.28 toks/s, output: 1149.95 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:13<00:12,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.32 toks/s, output: 41.84 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.69it/s, est. speed input: 5948.91 toks/s, output: 844.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 8072.13 toks/s, output: 1399.73 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:15<00:09,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.07 toks/s, output: 41.81 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7632.53 toks/s, output: 1071.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8159.16 toks/s, output: 1233.65 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:17<00:07,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.37 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6798.61 toks/s, output: 957.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8113.12 toks/s, output: 1315.95 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:20<00:04,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.01 toks/s, output: 41.80 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6549.04 toks/s, output: 919.68 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.47it/s, est. speed input: 6869.77 toks/s, output: 1157.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6869.77 toks/s, output: 1157.03 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:22<00:02,  2.39s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 354.29 toks/s, output: 46.55 toks/s][A
Processed prompts:  79%|███████▊  | 22/28 [00:01<00:00, 19.71it/s, est. speed input: 6243.89 toks/s, output: 888.23 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.68it/s, est. speed input: 7702.05 toks/s, output: 1279.89 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:24<00:00,  2.31s/it]Processing batched inference: 100%|██████████| 66/66 [03:24<00:00,  3.10s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-1071/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 09:56:26.879288737 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1134
INFO 07-05 09:56:39 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 09:56:41,468 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 09:56:41,520 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,545 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,545 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,545 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,545 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,545 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,545 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,545 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:56:41,935 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:56:41,937 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 09:56:41,942 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:56:41,949 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,950 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,950 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,950 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,950 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,950 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,950 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:41,950 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:56:42,324 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:56:42,327 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:56:42,522 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:56:42,966 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 09:56:43,021 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/config.json
[INFO|configuration_utils.py:696] 2025-07-05 09:56:43,021 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/config.json
[INFO|configuration_utils.py:770] 2025-07-05 09:56:43,023 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 09:56:54 [config.py:689] This model supports multiple tasks: {'score', 'generate', 'embed', 'classify', 'reward'}. Defaulting to 'generate'.
INFO 07-05 09:56:54 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:54,634 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:54,634 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:54,634 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:54,634 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:54,634 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:54,634 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:56:54,634 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:56:54,969 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 09:56:55,070 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 09:56:55,073 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 09:56:56 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 09:56:56 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 09:56:56 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134...
WARNING 07-05 09:56:56 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 09:56:57 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.40s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.40s/it]

INFO 07-05 09:57:04 [loader.py:458] Loading weights took 7.61 seconds
INFO 07-05 09:57:04 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.853723 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,205 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,205 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,205 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,205 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,205 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,205 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,205 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:57:05,619 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 09:57:05,716 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:57:05,716 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 09:57:05,716 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:57:05,716 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,717 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,717 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,718 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,718 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,718 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,718 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:57:05,718 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:57:06,477 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:57:06,478 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:57:06,478 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:57:06,929 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 09:57:07,541 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 09:57:08 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 09:57:10,378 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 09:57:11,369 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 09:57:11 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 09:57:50 [worker.py:267] Memory profiling takes 45.28 seconds
INFO 07-05 09:57:50 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 09:57:50 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 09:57:50 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 09:57:50 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 09:57:56 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:17,  1.97it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:16,  1.98it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.95it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.99it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:14,  2.01it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  2.00it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.99it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  2.01it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:12,  2.02it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:04<00:12,  2.02it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.99it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:10,  2.02it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:06<00:10,  2.01it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.01it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.01it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:09<00:07,  2.01it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.99it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.97it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.97it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.99it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  2.00it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.01it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  2.00it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:02,  2.01it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  2.01it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.01it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.02it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:00,  2.03it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:16<00:00,  2.01it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.01it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.00it/s]
INFO 07-05 09:58:13 [model_runner.py:1598] Graph capturing finished in 17 secs, took 0.33 GiB
INFO 07-05 09:58:13 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.62 seconds
[INFO|2025-07-05 09:58:14] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:10, 188.54 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:00<00:04, 380.27 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 563.32 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:01, 952.27 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:01<00:00, 1093.57 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:01<00:00, 1134.38 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:01<00:00, 1431.96 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:01<00:00, 1418.90 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:01<00:00, 1571.94 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 967.44 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 09:58:18,521 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 09:58:18,521 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:18,522 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:18,522 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:18,522 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:18,522 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:18,522 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:18,522 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 09:58:18,522 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 09:58:19,311 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 09:58:19,311 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 09:58:19,312 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 09:58:19,773 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1134', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 253.17 toks/s, output: 32.86 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 17.16it/s, est. speed input: 5376.91 toks/s, output: 759.25 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 18.80it/s, est. speed input: 5990.72 toks/s, output: 1011.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.44it/s, est. speed input: 5990.72 toks/s, output: 1011.98 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:50,  4.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.15 toks/s, output: 42.08 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.26it/s, est. speed input: 6440.49 toks/s, output: 909.38 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.99it/s, est. speed input: 6650.25 toks/s, output: 1089.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.17it/s, est. speed input: 5449.02 toks/s, output: 999.56 toks/s] 
Processing batched inference:   3%|▎         | 2/66 [00:07<04:01,  3.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.27 toks/s, output: 42.09 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.46it/s, est. speed input: 6202.68 toks/s, output: 877.26 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.39it/s, est. speed input: 6246.87 toks/s, output: 1033.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.90it/s, est. speed input: 1202.16 toks/s, output: 357.70 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:19<07:52,  7.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.01 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7087.64 toks/s, output: 997.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8157.25 toks/s, output: 1283.40 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:22<05:41,  5.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.64 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 6281.85 toks/s, output: 887.36 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.12it/s, est. speed input: 6454.76 toks/s, output: 1080.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5970.75 toks/s, output: 1115.85 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:25<04:42,  4.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.31 toks/s, output: 41.97 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.39it/s, est. speed input: 7322.78 toks/s, output: 1032.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8131.04 toks/s, output: 1257.05 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:27<03:53,  3.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.54 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6792.42 toks/s, output: 952.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.64it/s, est. speed input: 6707.44 toks/s, output: 1091.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6924.52 toks/s, output: 1172.43 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:30<03:27,  3.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.12 toks/s, output: 42.07 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 7411.27 toks/s, output: 1041.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8217.67 toks/s, output: 1269.77 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:32<03:03,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:44,  1.45s/it, est. speed input: 287.66 toks/s, output: 37.34 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 19.76it/s, est. speed input: 6154.90 toks/s, output: 870.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.95it/s, est. speed input: 7363.49 toks/s, output: 1195.27 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:35<02:49,  2.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 320.75 toks/s, output: 41.36 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.32it/s, est. speed input: 7428.57 toks/s, output: 1043.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.65it/s, est. speed input: 6054.25 toks/s, output: 1026.36 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:38<02:46,  2.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.84 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6824.03 toks/s, output: 955.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8148.79 toks/s, output: 1315.58 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:40<02:34,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.57 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6511.64 toks/s, output: 930.23 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.73it/s, est. speed input: 6833.62 toks/s, output: 1144.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6853.92 toks/s, output: 1192.61 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:43<02:30,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 321.43 toks/s, output: 41.45 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.55it/s, est. speed input: 6830.31 toks/s, output: 961.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8155.24 toks/s, output: 1325.59 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:45<02:21,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.75 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.74it/s, est. speed input: 6856.28 toks/s, output: 963.88 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.27it/s, est. speed input: 6879.87 toks/s, output: 1128.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6879.87 toks/s, output: 1128.44 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:48<02:19,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 327.81 toks/s, output: 40.98 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.26it/s, est. speed input: 5500.23 toks/s, output: 775.89 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.62it/s, est. speed input: 6885.53 toks/s, output: 1260.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6885.53 toks/s, output: 1260.19 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:51<02:16,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it, est. speed input: 332.23 toks/s, output: 39.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.40it/s, est. speed input: 6507.40 toks/s, output: 917.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8149.48 toks/s, output: 1356.70 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:53<02:09,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.51 toks/s, output: 42.53 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.99it/s, est. speed input: 5971.55 toks/s, output: 848.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.75it/s, est. speed input: 6480.45 toks/s, output: 1115.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.37it/s, est. speed input: 4254.53 toks/s, output: 849.74 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [00:57<02:24,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.84 toks/s, output: 42.04 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 7054.61 toks/s, output: 1001.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8126.99 toks/s, output: 1290.58 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:59<02:13,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.91 toks/s, output: 42.05 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6845.74 toks/s, output: 964.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8177.89 toks/s, output: 1326.72 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:02<02:05,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.84 toks/s, output: 42.40 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.08it/s, est. speed input: 7556.09 toks/s, output: 1071.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8159.47 toks/s, output: 1245.02 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:04<01:57,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.60 toks/s, output: 42.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.10it/s, est. speed input: 6021.08 toks/s, output: 853.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.40it/s, est. speed input: 7995.65 toks/s, output: 1382.10 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:06<01:52,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.24 toks/s, output: 41.96 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.64it/s, est. speed input: 4665.89 toks/s, output: 663.77 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.41it/s, est. speed input: 6397.44 toks/s, output: 1220.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.83it/s, est. speed input: 6143.36 toks/s, output: 1259.70 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:09<01:55,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.99 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.30it/s, est. speed input: 7380.38 toks/s, output: 1030.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6898.09 toks/s, output: 1086.67 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:12<01:52,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.67 toks/s, output: 42.02 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 6294.53 toks/s, output: 883.48 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 11.68it/s, est. speed input: 4625.32 toks/s, output: 838.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.78it/s, est. speed input: 3614.13 toks/s, output: 756.56 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:16<02:11,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:38,  1.26s/it, est. speed input: 331.10 toks/s, output: 39.80 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.19it/s, est. speed input: 6734.57 toks/s, output: 949.22 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.89it/s, est. speed input: 6071.15 toks/s, output: 1032.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.89it/s, est. speed input: 2422.39 toks/s, output: 533.91 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:22<02:45,  4.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.11 toks/s, output: 41.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.10it/s, est. speed input: 6688.25 toks/s, output: 949.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.37it/s, est. speed input: 6842.99 toks/s, output: 1146.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6842.99 toks/s, output: 1146.79 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:25<02:25,  3.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.60 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6560.87 toks/s, output: 924.21 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.53it/s, est. speed input: 6857.69 toks/s, output: 1160.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6857.69 toks/s, output: 1160.42 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:28<02:09,  3.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.31 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.52it/s, est. speed input: 6762.95 toks/s, output: 959.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8089.78 toks/s, output: 1318.26 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:30<01:54,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.60 toks/s, output: 42.41 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6516.55 toks/s, output: 925.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.76it/s, est. speed input: 6620.95 toks/s, output: 1138.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6837.10 toks/s, output: 1219.25 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:33<01:46,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.84 toks/s, output: 41.91 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.49it/s, est. speed input: 7434.64 toks/s, output: 1038.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8217.83 toks/s, output: 1261.43 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:35<01:36,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.93 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6507.54 toks/s, output: 922.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8083.74 toks/s, output: 1336.43 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:37<01:29,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.80 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6800.87 toks/s, output: 953.43 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.26it/s, est. speed input: 5957.61 toks/s, output: 1030.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5957.61 toks/s, output: 1030.32 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:40<01:29,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.14 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.29it/s, est. speed input: 6450.39 toks/s, output: 915.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.67it/s, est. speed input: 5244.55 toks/s, output: 933.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.66it/s, est. speed input: 5244.55 toks/s, output: 933.62 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:43<01:32,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.80 toks/s, output: 41.90 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 6008.61 toks/s, output: 848.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.84it/s, est. speed input: 5969.13 toks/s, output: 1076.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.38it/s, est. speed input: 5969.13 toks/s, output: 1076.13 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:46<01:30,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.24 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7076.07 toks/s, output: 998.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6859.03 toks/s, output: 1106.72 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:49<01:25,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.99 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.81it/s, est. speed input: 6558.19 toks/s, output: 923.62 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.47it/s, est. speed input: 6842.21 toks/s, output: 1157.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6842.21 toks/s, output: 1157.98 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:51<01:20,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.73 toks/s, output: 42.02 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7412.67 toks/s, output: 1034.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8220.54 toks/s, output: 1260.07 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:53<01:13,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.32 toks/s, output: 41.84 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.86it/s, est. speed input: 7244.17 toks/s, output: 1027.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6886.79 toks/s, output: 1102.21 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:56<01:12,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.76 toks/s, output: 41.90 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.61it/s, est. speed input: 4680.87 toks/s, output: 663.95 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.46it/s, est. speed input: 6415.85 toks/s, output: 1219.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.37it/s, est. speed input: 6801.45 toks/s, output: 1371.43 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:59<01:10,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.79 toks/s, output: 41.90 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7385.17 toks/s, output: 1042.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.81it/s, est. speed input: 6980.17 toks/s, output: 1106.60 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:01<01:07,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.40 toks/s, output: 41.85 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.31it/s, est. speed input: 5179.57 toks/s, output: 733.66 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.26it/s, est. speed input: 6440.57 toks/s, output: 1177.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6808.75 toks/s, output: 1327.24 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:04<01:04,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.49 toks/s, output: 41.86 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7335.54 toks/s, output: 1036.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6882.00 toks/s, output: 1090.64 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:06<01:01,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.51 toks/s, output: 41.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6517.06 toks/s, output: 922.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.51it/s, est. speed input: 7028.71 toks/s, output: 1185.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.07it/s, est. speed input: 7028.71 toks/s, output: 1185.58 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:09<00:59,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.13 toks/s, output: 41.81 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 7048.48 toks/s, output: 990.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.91it/s, est. speed input: 6146.22 toks/s, output: 1033.53 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:12<00:57,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.83 toks/s, output: 41.91 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.21it/s, est. speed input: 7908.51 toks/s, output: 1109.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6913.82 toks/s, output: 1072.25 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:14<00:54,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.72 toks/s, output: 41.89 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6560.64 toks/s, output: 924.97 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.87it/s, est. speed input: 6444.17 toks/s, output: 1047.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.14it/s, est. speed input: 1704.41 toks/s, output: 461.49 toks/s] 
Processing batched inference:  70%|██████▉   | 46/66 [02:23<01:26,  4.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.24 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.04it/s, est. speed input: 6990.63 toks/s, output: 990.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8168.02 toks/s, output: 1301.33 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:25<01:10,  3.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.00 toks/s, output: 42.46 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7073.56 toks/s, output: 1000.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8120.01 toks/s, output: 1291.57 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:27<00:58,  3.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.94 toks/s, output: 41.79 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.01it/s, est. speed input: 5696.69 toks/s, output: 808.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 8055.53 toks/s, output: 1413.50 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:29<00:49,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.66 toks/s, output: 41.75 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.13it/s, est. speed input: 7912.49 toks/s, output: 1104.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.92it/s, est. speed input: 8236.13 toks/s, output: 1208.77 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:31<00:44,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.97 toks/s, output: 41.53 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.77it/s, est. speed input: 5935.19 toks/s, output: 842.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.62it/s, est. speed input: 5883.62 toks/s, output: 1058.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.22it/s, est. speed input: 5883.62 toks/s, output: 1058.42 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:35<00:42,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.38 toks/s, output: 41.85 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.44it/s, est. speed input: 7086.14 toks/s, output: 999.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.77it/s, est. speed input: 6934.66 toks/s, output: 1127.99 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:37<00:39,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 318.59 toks/s, output: 41.86 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 6264.20 toks/s, output: 882.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 8098.06 toks/s, output: 1370.25 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:39<00:34,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.67 toks/s, output: 41.75 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7645.35 toks/s, output: 1069.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8188.05 toks/s, output: 1230.55 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:42<00:30,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.23 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6538.18 toks/s, output: 922.51 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.81it/s, est. speed input: 6670.60 toks/s, output: 1109.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5956.41 toks/s, output: 1052.29 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:44<00:28,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.74 toks/s, output: 42.92 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.53it/s, est. speed input: 4918.45 toks/s, output: 706.39 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.67it/s, est. speed input: 6218.62 toks/s, output: 1149.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.26it/s, est. speed input: 5892.85 toks/s, output: 1217.24 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:47<00:26,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.32 toks/s, output: 41.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6807.71 toks/s, output: 957.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8128.32 toks/s, output: 1315.92 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:50<00:23,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.05 toks/s, output: 42.47 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 5959.23 toks/s, output: 845.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8057.65 toks/s, output: 1394.49 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:52<00:19,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.46 toks/s, output: 41.99 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 6005.62 toks/s, output: 847.38 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.69it/s, est. speed input: 7147.40 toks/s, output: 1257.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.37it/s, est. speed input: 7147.40 toks/s, output: 1257.72 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [02:54<00:17,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.28 toks/s, output: 41.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.81it/s, est. speed input: 6584.63 toks/s, output: 921.23 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.75it/s, est. speed input: 6688.12 toks/s, output: 1105.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.84it/s, est. speed input: 5318.27 toks/s, output: 952.80 toks/s] 
Processing batched inference:  91%|█████████ | 60/66 [02:57<00:15,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.35 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6795.60 toks/s, output: 961.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8125.37 toks/s, output: 1322.30 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:00<00:12,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.62 toks/s, output: 41.75 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.54it/s, est. speed input: 6209.01 toks/s, output: 879.41 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.18it/s, est. speed input: 6874.55 toks/s, output: 1174.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.04it/s, est. speed input: 7046.10 toks/s, output: 1244.70 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:02<00:10,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.04 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7366.28 toks/s, output: 1035.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8153.61 toks/s, output: 1260.56 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:05<00:07,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.26 toks/s, output: 41.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6816.23 toks/s, output: 959.49 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.30it/s, est. speed input: 6866.17 toks/s, output: 1139.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6866.17 toks/s, output: 1139.16 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:07<00:04,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.18 toks/s, output: 41.69 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.74it/s, est. speed input: 6258.42 toks/s, output: 881.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.67it/s, est. speed input: 6848.87 toks/s, output: 1176.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.50it/s, est. speed input: 6848.87 toks/s, output: 1176.21 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:10<00:02,  2.50s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.15s/it, est. speed input: 356.59 toks/s, output: 45.98 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.63it/s, est. speed input: 6544.42 toks/s, output: 929.37 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.73it/s, est. speed input: 7719.38 toks/s, output: 1249.33 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:12<00:00,  2.39s/it]Processing batched inference: 100%|██████████| 66/66 [03:12<00:00,  2.91s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-1134/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:01:31.664876896 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1197
INFO 07-05 10:01:45 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:01:47,116 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:01:47,157 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,182 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,182 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,182 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,182 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,182 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,182 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,182 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:01:47,568 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:01:47,570 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:01:47,576 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:01:47,582 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,584 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,584 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,584 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,584 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,584 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,584 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:01:47,584 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:01:47,956 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:01:47,959 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:01:48,154 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:01:48,590 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:01:48,644 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:01:48,644 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:01:48,647 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:02:00 [config.py:689] This model supports multiple tasks: {'embed', 'classify', 'score', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 07-05 10:02:00 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:00,252 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:00,253 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:00,253 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:00,253 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:00,253 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:00,253 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:00,253 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:02:00,589 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:02:00,689 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:02:00,692 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:02:02 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:02:02 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:02:02 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197...
WARNING 07-05 10:02:02 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:02:03 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.36s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]

INFO 07-05 10:02:10 [loader.py:458] Loading weights took 7.57 seconds
INFO 07-05 10:02:11 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.918391 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,271 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,271 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,271 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,271 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,271 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,271 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,271 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:02:11,676 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:02:11,771 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:02:11,771 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:02:11,772 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:02:11,773 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,773 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,773 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,773 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,773 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,773 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,773 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:02:11,773 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:02:12,533 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:02:12,534 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:02:12,534 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:02:12,986 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:02:13,602 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:02:14 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:02:16,502 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:02:17,573 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:02:17 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:02:56 [worker.py:267] Memory profiling takes 45.49 seconds
INFO 07-05 10:02:56 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:02:56 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:02:56 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:02:56 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:03:04 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:17,  1.90it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:16,  1.98it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.91it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.91it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.95it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.99it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.98it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.98it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  2.00it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  2.01it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  2.01it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:10,  2.00it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  2.00it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.98it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:08,  2.00it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  2.02it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.01it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  2.02it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:06,  2.03it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  2.03it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:05,  2.02it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  2.03it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.02it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  2.02it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.02it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  2.00it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:02,  2.01it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:14<00:02,  2.02it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.98it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  2.00it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.98it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  2.00it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.96it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.99it/s]
INFO 07-05 10:03:21 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:03:21 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 70.65 seconds
[INFO|2025-07-05 10:03:22] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:09, 213.20 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:00<00:04, 374.49 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 553.11 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:01, 835.58 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:01<00:00, 1271.31 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:01<00:00, 1139.35 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:01<00:00, 1446.00 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:01<00:00, 1489.56 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 968.66 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:03:26,567 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:03:26,567 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:26,568 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:26,568 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:26,568 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:26,568 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:26,568 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:26,568 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:03:26,568 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:03:27,362 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:03:27,363 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:03:27,363 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:03:27,829 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1197', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 252.52 toks/s, output: 32.78 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 17.15it/s, est. speed input: 5369.74 toks/s, output: 758.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 18.80it/s, est. speed input: 5985.69 toks/s, output: 1011.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5985.69 toks/s, output: 1011.13 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:46,  4.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.84 toks/s, output: 42.04 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.13it/s, est. speed input: 6409.65 toks/s, output: 905.47 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.93it/s, est. speed input: 6871.95 toks/s, output: 1147.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.90it/s, est. speed input: 6161.98 toks/s, output: 1087.04 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:48,  3.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.34 toks/s, output: 42.10 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.47it/s, est. speed input: 6205.46 toks/s, output: 877.66 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.23it/s, est. speed input: 6461.30 toks/s, output: 1088.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.72it/s, est. speed input: 3608.03 toks/s, output: 733.31 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:12<04:14,  4.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.18 toks/s, output: 42.08 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 7108.76 toks/s, output: 1000.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8181.33 toks/s, output: 1287.19 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:14<03:34,  3.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.61 toks/s, output: 42.01 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 6009.70 toks/s, output: 850.94 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.35it/s, est. speed input: 6401.62 toks/s, output: 1075.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 10.77it/s, est. speed input: 4461.97 toks/s, output: 893.80 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:18<03:38,  3.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.22 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6816.82 toks/s, output: 959.00 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.72it/s, est. speed input: 5287.16 toks/s, output: 913.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.85it/s, est. speed input: 5287.16 toks/s, output: 913.79 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:21<03:29,  3.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.08 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.56it/s, est. speed input: 6526.69 toks/s, output: 916.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.88it/s, est. speed input: 6705.21 toks/s, output: 1115.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6922.19 toks/s, output: 1197.07 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:24<03:12,  3.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.33 toks/s, output: 41.84 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 7104.62 toks/s, output: 1000.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8172.87 toks/s, output: 1290.54 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:26<02:53,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.91 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 7037.56 toks/s, output: 991.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8081.15 toks/s, output: 1284.06 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:29<02:39,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 321.61 toks/s, output: 41.47 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.36it/s, est. speed input: 7441.93 toks/s, output: 1044.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.62it/s, est. speed input: 6041.36 toks/s, output: 980.32 toks/s] 
Processing batched inference:  15%|█▌        | 10/66 [00:32<02:39,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.86 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6824.03 toks/s, output: 955.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.31it/s, est. speed input: 7078.04 toks/s, output: 1167.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.13it/s, est. speed input: 7078.04 toks/s, output: 1167.35 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:34<02:34,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.46 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6513.18 toks/s, output: 930.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.75it/s, est. speed input: 6838.03 toks/s, output: 1144.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6858.44 toks/s, output: 1192.88 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:37<02:30,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 321.55 toks/s, output: 41.46 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6837.11 toks/s, output: 962.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8163.97 toks/s, output: 1327.01 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:40<02:20,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 320.02 toks/s, output: 41.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.72it/s, est. speed input: 6848.52 toks/s, output: 961.51 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.29it/s, est. speed input: 6881.24 toks/s, output: 1127.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6881.24 toks/s, output: 1127.63 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:42<02:18,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 327.50 toks/s, output: 40.94 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.25it/s, est. speed input: 5497.01 toks/s, output: 774.80 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.62it/s, est. speed input: 6883.40 toks/s, output: 1259.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6883.40 toks/s, output: 1259.28 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:45<02:15,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 327.01 toks/s, output: 40.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.42it/s, est. speed input: 6488.43 toks/s, output: 916.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8126.63 toks/s, output: 1354.13 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:47<02:09,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.94 toks/s, output: 42.32 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 5946.75 toks/s, output: 845.39 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.60it/s, est. speed input: 6425.72 toks/s, output: 1108.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.62it/s, est. speed input: 4767.99 toks/s, output: 968.26 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [00:51<02:19,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.81 toks/s, output: 41.90 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 7311.49 toks/s, output: 1035.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8123.00 toks/s, output: 1261.56 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:53<02:10,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.52 toks/s, output: 41.99 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7392.99 toks/s, output: 1039.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8202.58 toks/s, output: 1270.15 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:56<02:02,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.36 toks/s, output: 42.47 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.11it/s, est. speed input: 7566.30 toks/s, output: 1073.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8170.53 toks/s, output: 1246.71 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:58<01:55,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.46 toks/s, output: 41.86 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.11it/s, est. speed input: 6018.48 toks/s, output: 852.70 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.84it/s, est. speed input: 6806.60 toks/s, output: 1201.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6806.60 toks/s, output: 1201.85 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:01<01:55,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.80 toks/s, output: 41.90 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.62it/s, est. speed input: 4660.65 toks/s, output: 663.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 18.61it/s, est. speed input: 5941.85 toks/s, output: 1105.00 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 18.62it/s, est. speed input: 6117.47 toks/s, output: 1299.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.76it/s, est. speed input: 6117.47 toks/s, output: 1299.61 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:04<02:00,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 327.00 toks/s, output: 40.87 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.29it/s, est. speed input: 7399.25 toks/s, output: 1031.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6911.81 toks/s, output: 1087.79 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:06<01:56,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.77 toks/s, output: 41.90 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6557.50 toks/s, output: 918.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 11.53it/s, est. speed input: 4623.74 toks/s, output: 821.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.57it/s, est. speed input: 4765.54 toks/s, output: 928.87 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:10<02:03,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:38,  1.26s/it, est. speed input: 330.98 toks/s, output: 39.78 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.97it/s, est. speed input: 6679.80 toks/s, output: 942.13 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.64it/s, est. speed input: 5999.97 toks/s, output: 1022.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.50it/s, est. speed input: 1027.99 toks/s, output: 320.75 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:23<04:10,  6.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.45 toks/s, output: 41.99 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.17it/s, est. speed input: 6711.01 toks/s, output: 953.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.42it/s, est. speed input: 6862.40 toks/s, output: 1150.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6862.40 toks/s, output: 1150.05 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:26<03:22,  5.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.86 toks/s, output: 41.91 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6547.26 toks/s, output: 922.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.50it/s, est. speed input: 6846.40 toks/s, output: 1158.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6846.40 toks/s, output: 1158.51 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:28<02:48,  4.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.33 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6518.17 toks/s, output: 925.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8114.25 toks/s, output: 1351.75 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:31<02:20,  3.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.33 toks/s, output: 42.37 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 5960.21 toks/s, output: 849.38 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.71it/s, est. speed input: 6210.38 toks/s, output: 1057.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.79it/s, est. speed input: 6081.82 toks/s, output: 1170.98 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:34<02:07,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.34 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.61it/s, est. speed input: 7168.26 toks/s, output: 1003.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8210.97 toks/s, output: 1289.97 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:36<01:51,  3.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.85 toks/s, output: 41.91 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6507.38 toks/s, output: 922.74 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.73it/s, est. speed input: 6869.99 toks/s, output: 1160.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6869.99 toks/s, output: 1160.30 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:38<01:42,  2.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.51 toks/s, output: 41.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6794.62 toks/s, output: 952.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.24it/s, est. speed input: 5952.21 toks/s, output: 1029.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5952.21 toks/s, output: 1029.39 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:41<01:39,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.08 toks/s, output: 41.55 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.36it/s, est. speed input: 6149.89 toks/s, output: 873.06 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.70it/s, est. speed input: 6525.87 toks/s, output: 1099.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.62it/s, est. speed input: 5228.63 toks/s, output: 1005.33 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:45<01:39,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.01 toks/s, output: 41.67 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.98it/s, est. speed input: 5711.58 toks/s, output: 807.07 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.33it/s, est. speed input: 6628.22 toks/s, output: 1179.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.36it/s, est. speed input: 5958.78 toks/s, output: 1118.25 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:47<01:36,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.75 toks/s, output: 41.89 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.36it/s, est. speed input: 7344.11 toks/s, output: 1032.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6875.72 toks/s, output: 1085.99 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:50<01:28,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.01 toks/s, output: 41.80 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6544.91 toks/s, output: 921.75 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.33it/s, est. speed input: 5913.93 toks/s, output: 1022.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.34it/s, est. speed input: 5913.93 toks/s, output: 1022.83 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:53<01:25,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.26 toks/s, output: 41.96 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7404.43 toks/s, output: 1033.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8211.70 toks/s, output: 1258.72 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:55<01:17,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.52 toks/s, output: 41.74 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.94it/s, est. speed input: 6956.25 toks/s, output: 988.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.10it/s, est. speed input: 6857.30 toks/s, output: 1122.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6857.30 toks/s, output: 1122.34 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:58<01:14,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.14 toks/s, output: 41.82 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.59it/s, est. speed input: 4672.79 toks/s, output: 662.80 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.49it/s, est. speed input: 6417.34 toks/s, output: 1219.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.37it/s, est. speed input: 6803.40 toks/s, output: 1371.83 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:00<01:11,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.37 toks/s, output: 41.72 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.27it/s, est. speed input: 7358.06 toks/s, output: 1038.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.76it/s, est. speed input: 6957.04 toks/s, output: 1102.94 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:03<01:07,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.90 toks/s, output: 41.91 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.32it/s, est. speed input: 5198.71 toks/s, output: 734.87 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.35it/s, est. speed input: 6459.86 toks/s, output: 1180.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6806.66 toks/s, output: 1325.28 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:05<01:05,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.79 toks/s, output: 41.90 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.71it/s, est. speed input: 7109.99 toks/s, output: 1003.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.73it/s, est. speed input: 6884.93 toks/s, output: 1115.68 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:08<01:01,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.62 toks/s, output: 40.44 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.47it/s, est. speed input: 6467.98 toks/s, output: 913.22 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.33it/s, est. speed input: 6982.61 toks/s, output: 1176.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.96it/s, est. speed input: 6982.61 toks/s, output: 1176.22 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:11<00:59,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.89 toks/s, output: 41.78 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.67it/s, est. speed input: 6507.70 toks/s, output: 917.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8085.06 toks/s, output: 1330.75 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:13<00:54,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.60 toks/s, output: 41.75 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.23it/s, est. speed input: 7604.00 toks/s, output: 1067.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8133.40 toks/s, output: 1231.16 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:15<00:50,  2.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.93 toks/s, output: 41.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6545.88 toks/s, output: 922.89 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.83it/s, est. speed input: 6429.90 toks/s, output: 1045.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.57it/s, est. speed input: 1057.92 toks/s, output: 348.07 toks/s] 
Processing batched inference:  70%|██████▉   | 46/66 [02:28<01:52,  5.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.95 toks/s, output: 41.79 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.10it/s, est. speed input: 6694.22 toks/s, output: 949.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8125.36 toks/s, output: 1323.97 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:30<01:27,  4.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.05 toks/s, output: 42.33 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 7052.72 toks/s, output: 997.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8095.75 toks/s, output: 1287.71 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:33<01:10,  3.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.21 toks/s, output: 41.70 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.98it/s, est. speed input: 5686.42 toks/s, output: 807.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 8041.44 toks/s, output: 1411.03 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:35<00:57,  3.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.76 toks/s, output: 41.77 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.25it/s, est. speed input: 7639.60 toks/s, output: 1069.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 8225.77 toks/s, output: 1235.22 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:37<00:49,  3.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.65 toks/s, output: 41.75 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.99it/s, est. speed input: 5697.10 toks/s, output: 810.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.08it/s, est. speed input: 6809.24 toks/s, output: 1223.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.45it/s, est. speed input: 6809.24 toks/s, output: 1223.40 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:40<00:43,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.12 toks/s, output: 41.81 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.42it/s, est. speed input: 7079.02 toks/s, output: 1000.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6926.67 toks/s, output: 1127.21 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:42<00:39,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 318.53 toks/s, output: 41.85 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 6262.71 toks/s, output: 882.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8090.13 toks/s, output: 1368.91 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:44<00:34,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.62 toks/s, output: 41.88 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7665.54 toks/s, output: 1072.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8209.76 toks/s, output: 1233.81 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:47<00:30,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.83 toks/s, output: 41.78 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.66it/s, est. speed input: 6513.33 toks/s, output: 919.01 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.09it/s, est. speed input: 6674.42 toks/s, output: 1087.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.36it/s, est. speed input: 5932.93 toks/s, output: 1068.34 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:50<00:28,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 315.00 toks/s, output: 42.81 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.33it/s, est. speed input: 5166.57 toks/s, output: 740.04 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.38it/s, est. speed input: 6205.48 toks/s, output: 1123.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.23it/s, est. speed input: 5881.62 toks/s, output: 1194.02 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:53<00:27,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.70 toks/s, output: 41.76 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.66it/s, est. speed input: 6505.28 toks/s, output: 916.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 8081.21 toks/s, output: 1337.07 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:55<00:23,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.95 toks/s, output: 42.32 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.90it/s, est. speed input: 5938.31 toks/s, output: 842.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 8029.27 toks/s, output: 1389.58 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:57<00:19,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.46 toks/s, output: 41.73 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.87it/s, est. speed input: 5976.48 toks/s, output: 843.27 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.60it/s, est. speed input: 7115.71 toks/s, output: 1252.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.29it/s, est. speed input: 7115.71 toks/s, output: 1252.14 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:00<00:17,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.39 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6831.76 toks/s, output: 953.78 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.50it/s, est. speed input: 6027.28 toks/s, output: 1058.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.55it/s, est. speed input: 6027.28 toks/s, output: 1058.44 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:02<00:15,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.50 toks/s, output: 41.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6798.08 toks/s, output: 961.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8128.11 toks/s, output: 1322.74 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:05<00:12,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.12 toks/s, output: 41.81 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.83it/s, est. speed input: 5681.13 toks/s, output: 806.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.61it/s, est. speed input: 6851.73 toks/s, output: 1221.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.98it/s, est. speed input: 7022.81 toks/s, output: 1291.53 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:07<00:10,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.12 toks/s, output: 41.81 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7633.40 toks/s, output: 1070.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8160.66 toks/s, output: 1233.26 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:09<00:07,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.14 toks/s, output: 41.17 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.30it/s, est. speed input: 6709.56 toks/s, output: 944.48 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.20it/s, est. speed input: 6800.39 toks/s, output: 1152.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.47it/s, est. speed input: 6800.39 toks/s, output: 1152.95 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:12<00:04,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.76 toks/s, output: 41.77 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.63it/s, est. speed input: 6537.41 toks/s, output: 917.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.45it/s, est. speed input: 6861.93 toks/s, output: 1155.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6861.93 toks/s, output: 1155.19 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:15<00:02,  2.48s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.15s/it, est. speed input: 356.07 toks/s, output: 45.92 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.62it/s, est. speed input: 6539.21 toks/s, output: 928.64 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.72it/s, est. speed input: 7715.61 toks/s, output: 1249.38 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:17<00:00,  2.37s/it]Processing batched inference: 100%|██████████| 66/66 [03:17<00:00,  2.99s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-1197/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:06:44.623066052 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-126
INFO 07-05 10:06:57 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:06:58,938 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:06:58,962 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:58,982 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:58,982 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:58,982 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:58,982 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:58,982 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:58,982 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:58,982 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:06:59,371 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:06:59,372 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:06:59,377 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:06:59,384 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:59,385 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:59,385 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:59,385 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:59,385 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:59,385 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:59,385 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:06:59,385 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:06:59,763 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:06:59,764 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:06:59,967 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:07:00,428 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:07:00,481 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:07:00,481 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:07:00,483 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:07:12 [config.py:689] This model supports multiple tasks: {'generate', 'embed', 'reward', 'score', 'classify'}. Defaulting to 'generate'.
INFO 07-05 10:07:12 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:12,127 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:12,127 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:12,127 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:12,127 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:12,127 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:12,127 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:12,127 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:07:12,458 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:07:12,559 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:07:12,562 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:07:13 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:07:14 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:07:14 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126...
WARNING 07-05 10:07:14 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:07:14 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.11s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.11s/it]

INFO 07-05 10:07:21 [loader.py:458] Loading weights took 7.32 seconds
INFO 07-05 10:07:22 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.576253 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,436 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,436 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,436 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,436 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,436 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,436 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,436 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:07:22,842 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:07:22,937 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:07:22,937 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:07:22,938 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:07:22,938 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,939 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,939 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,939 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,939 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,939 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,939 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:07:22,939 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:07:23,716 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:07:23,717 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:07:23,717 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:07:24,170 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:07:24,809 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:07:25 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:07:27,715 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:07:28,713 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:07:28 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:08:08 [worker.py:267] Memory profiling takes 45.68 seconds
INFO 07-05 10:08:08 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:08:08 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:08:08 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:08:08 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:08:13 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.73it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.93it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.93it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.93it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.96it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.97it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.97it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.98it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.98it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.99it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.99it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.99it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.99it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  2.00it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.99it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:08,  1.15it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:14<00:06,  1.30it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:05,  1.45it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:15<00:04,  1.57it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.66it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:16<00:02,  1.72it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:17<00:02,  1.79it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:17<00:01,  1.85it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:18<00:01,  1.88it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:18<00:00,  1.90it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:19<00:00,  1.90it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:19<00:00,  1.84it/s]
INFO 07-05 10:08:32 [model_runner.py:1598] Graph capturing finished in 19 secs, took 0.33 GiB
INFO 07-05 10:08:32 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 70.31 seconds
[INFO|2025-07-05 10:08:32] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:08:33,731 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:08:33,731 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:33,732 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:33,732 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:33,732 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:33,732 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:33,732 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:33,732 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:08:33,732 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:08:34,500 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:08:34,501 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:08:34,501 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:08:34,957 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-126', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:54,  1.75s/it, est. speed input: 237.64 toks/s, output: 30.85 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:02<00:00, 18.33it/s, est. speed input: 5704.66 toks/s, output: 808.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.34it/s, est. speed input: 6366.37 toks/s, output: 983.38 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:31,  4.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.44 toks/s, output: 42.11 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.10it/s, est. speed input: 8213.94 toks/s, output: 1154.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 8216.61 toks/s, output: 1185.05 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:21,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.52 toks/s, output: 42.12 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.09it/s, est. speed input: 7023.77 toks/s, output: 991.10 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.18it/s, est. speed input: 1138.93 toks/s, output: 322.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.75it/s, est. speed input: 1138.93 toks/s, output: 322.03 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:19<07:49,  7.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.38 toks/s, output: 41.98 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7365.36 toks/s, output: 1035.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 8231.03 toks/s, output: 1264.53 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:21<05:38,  5.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.77 toks/s, output: 42.01 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7666.46 toks/s, output: 1075.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.44it/s, est. speed input: 5981.21 toks/s, output: 945.87 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:24<04:40,  4.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.44 toks/s, output: 42.11 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7360.37 toks/s, output: 1036.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.97it/s, est. speed input: 8213.65 toks/s, output: 1268.57 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:27<03:51,  3.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.49 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.11it/s, est. speed input: 8231.01 toks/s, output: 1152.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.17it/s, est. speed input: 8365.41 toks/s, output: 1199.55 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:29<03:19,  3.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.06 toks/s, output: 42.06 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.07it/s, est. speed input: 8231.65 toks/s, output: 1156.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.47it/s, est. speed input: 8496.79 toks/s, output: 1219.49 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:31<02:57,  3.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.82 toks/s, output: 42.57 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.60it/s, est. speed input: 7071.19 toks/s, output: 1001.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 8178.46 toks/s, output: 1295.17 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:34<02:42,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.22 toks/s, output: 42.09 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.37it/s, est. speed input: 7664.98 toks/s, output: 1077.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.01it/s, est. speed input: 8270.59 toks/s, output: 1248.86 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:36<02:30,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.09 toks/s, output: 41.94 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.20it/s, est. speed input: 7916.47 toks/s, output: 1108.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.13it/s, est. speed input: 8317.13 toks/s, output: 1220.69 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:39<02:23,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.96 toks/s, output: 42.05 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.12it/s, est. speed input: 8178.93 toks/s, output: 1159.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 8373.30 toks/s, output: 1214.79 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:41<02:16,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.20 toks/s, output: 42.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.13it/s, est. speed input: 8238.50 toks/s, output: 1157.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 8244.23 toks/s, output: 1189.01 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:43<02:10,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.12 toks/s, output: 41.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6815.71 toks/s, output: 962.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8144.92 toks/s, output: 1303.94 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:46<02:06,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.02 toks/s, output: 42.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7110.95 toks/s, output: 1002.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.82it/s, est. speed input: 6949.34 toks/s, output: 1119.92 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:48<02:07,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.44 toks/s, output: 41.98 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.21it/s, est. speed input: 7932.91 toks/s, output: 1121.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.99it/s, est. speed input: 8269.34 toks/s, output: 1222.99 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:51<02:03,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.66 toks/s, output: 42.55 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.46it/s, est. speed input: 7355.50 toks/s, output: 1038.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 23.46it/s, est. speed input: 828.66 toks/s, output: 401.26 toks/s]  [A
Processed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.27it/s, est. speed input: 683.26 toks/s, output: 476.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s, est. speed input: 683.26 toks/s, output: 476.25 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:11<06:19,  7.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.35 toks/s, output: 41.97 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.22it/s, est. speed input: 7884.89 toks/s, output: 1115.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.15it/s, est. speed input: 8286.33 toks/s, output: 1225.22 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:13<04:53,  6.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 318.15 toks/s, output: 42.57 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.30it/s, est. speed input: 7965.79 toks/s, output: 1122.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.17it/s, est. speed input: 8366.33 toks/s, output: 1231.83 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:15<03:54,  4.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 317.87 toks/s, output: 42.54 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.02it/s, est. speed input: 7852.00 toks/s, output: 1112.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.86it/s, est. speed input: 8191.00 toks/s, output: 1219.42 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:18<03:12,  4.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.33 toks/s, output: 42.10 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.28it/s, est. speed input: 7922.52 toks/s, output: 1118.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 8197.16 toks/s, output: 1211.85 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:20<02:43,  3.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.96 toks/s, output: 42.05 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.99it/s, est. speed input: 6021.59 toks/s, output: 850.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8123.34 toks/s, output: 1403.50 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:22<02:22,  3.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.33 toks/s, output: 42.10 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 7148.42 toks/s, output: 1002.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8202.16 toks/s, output: 1289.02 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:25<02:07,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.97 toks/s, output: 42.05 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 7344.87 toks/s, output: 1035.43 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 23.37it/s, est. speed input: 7895.77 toks/s, output: 1195.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 503.01 toks/s, output: 230.26 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.01 toks/s, output: 230.26 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:52<07:06, 10.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.63 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.52it/s, est. speed input: 7378.57 toks/s, output: 1041.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 23.52it/s, est. speed input: 7944.34 toks/s, output: 1205.96 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 502.29 toks/s, output: 230.39 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 502.29 toks/s, output: 230.39 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:18<10:22, 15.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.27it/s, est. speed input: 7639.55 toks/s, output: 1082.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8167.62 toks/s, output: 1246.99 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:21<07:35, 11.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.15 toks/s, output: 41.95 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7348.58 toks/s, output: 1037.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8153.73 toks/s, output: 1260.59 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:23<05:38,  8.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.34 toks/s, output: 41.97 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.06it/s, est. speed input: 8174.23 toks/s, output: 1154.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.14it/s, est. speed input: 8308.70 toks/s, output: 1200.97 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:26<04:16,  6.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.50 toks/s, output: 41.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.01it/s, est. speed input: 7908.12 toks/s, output: 1121.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 25.01it/s, est. speed input: 7908.12 toks/s, output: 1121.67 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.13s/it, est. speed input: 502.75 toks/s, output: 225.65 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 502.75 toks/s, output: 225.65 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [02:52<07:53, 12.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.20 toks/s, output: 41.82 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.27it/s, est. speed input: 7990.12 toks/s, output: 1118.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.40it/s, est. speed input: 8488.04 toks/s, output: 1240.44 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:55<05:46,  9.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.03 toks/s, output: 41.93 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6816.58 toks/s, output: 959.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8131.91 toks/s, output: 1317.21 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [02:57<04:18,  7.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.12 toks/s, output: 41.94 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7367.85 toks/s, output: 1033.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8168.19 toks/s, output: 1259.44 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [02:59<03:18,  5.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.52 toks/s, output: 42.40 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 7376.95 toks/s, output: 1044.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8161.97 toks/s, output: 1270.74 toks/s]
Processing batched inference:  50%|█████     | 33/66 [03:01<02:37,  4.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.93 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7677.76 toks/s, output: 1082.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 8274.72 toks/s, output: 1250.01 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [03:04<02:08,  4.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.96 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7083.82 toks/s, output: 998.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8138.29 toks/s, output: 1282.32 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [03:06<01:47,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.05 toks/s, output: 41.93 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6812.22 toks/s, output: 958.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8122.97 toks/s, output: 1315.67 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [03:08<01:33,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.77 toks/s, output: 41.90 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.36it/s, est. speed input: 7396.57 toks/s, output: 1037.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 8322.24 toks/s, output: 1273.16 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [03:10<01:22,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.18 toks/s, output: 41.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 25.67it/s, est. speed input: 8165.16 toks/s, output: 1157.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8165.16 toks/s, output: 1157.02 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [03:13<01:14,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.82 toks/s, output: 41.64 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.07it/s, est. speed input: 7919.84 toks/s, output: 1113.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.33it/s, est. speed input: 8447.49 toks/s, output: 1238.91 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:15<01:09,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:43,  1.40s/it, est. speed input: 297.05 toks/s, output: 38.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 24.16it/s, est. speed input: 7668.76 toks/s, output: 1080.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 18.47it/s, est. speed input: 7668.76 toks/s, output: 1080.10 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:17<01:05,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.80 toks/s, output: 41.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7636.83 toks/s, output: 1075.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8179.97 toks/s, output: 1236.89 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [03:19<01:00,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.60 toks/s, output: 41.88 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.41it/s, est. speed input: 7645.14 toks/s, output: 1076.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 8202.60 toks/s, output: 1241.37 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [03:22<00:56,  2.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.16 toks/s, output: 41.82 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.25it/s, est. speed input: 7604.68 toks/s, output: 1070.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 8196.36 toks/s, output: 1238.19 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [03:24<00:54,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.15 toks/s, output: 41.95 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6806.68 toks/s, output: 959.68 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 21.61it/s, est. speed input: 7870.44 toks/s, output: 1244.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 503.88 toks/s, output: 233.68 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.88 toks/s, output: 233.68 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [03:51<03:33,  9.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.72 toks/s, output: 41.76 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.99it/s, est. speed input: 8138.01 toks/s, output: 1142.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8147.59 toks/s, output: 1173.99 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:53<02:36,  7.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.96 toks/s, output: 41.92 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 5986.55 toks/s, output: 849.09 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:16<00:00, 18.92it/s, est. speed input: 7579.82 toks/s, output: 1259.32 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.06s/it, est. speed input: 491.59 toks/s, output: 236.57 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.69 toks/s, output: 393.97 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [04:20<04:24, 13.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.74 toks/s, output: 42.29 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7363.95 toks/s, output: 1038.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:17<00:00,  1.79it/s, est. speed input: 742.39 toks/s, output: 263.34 toks/s]  
Processing batched inference:  71%|███████   | 47/66 [04:38<04:41, 14.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.37 toks/s, output: 42.38 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.32it/s, est. speed input: 7626.34 toks/s, output: 1074.18 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 24.32it/s, est. speed input: 7897.47 toks/s, output: 1173.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 502.91 toks/s, output: 228.87 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 502.91 toks/s, output: 228.87 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [05:05<05:31, 18.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.82 toks/s, output: 42.30 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6522.37 toks/s, output: 924.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8106.09 toks/s, output: 1331.71 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [05:07<03:50, 13.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.93 toks/s, output: 42.32 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7067.06 toks/s, output: 997.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.97it/s, est. speed input: 8258.97 toks/s, output: 1296.39 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [05:10<02:43, 10.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7089.98 toks/s, output: 1000.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8160.48 toks/s, output: 1290.53 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [05:12<01:57,  7.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.73 toks/s, output: 42.42 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7353.61 toks/s, output: 1041.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8159.97 toks/s, output: 1267.47 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [05:14<01:26,  6.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.96 toks/s, output: 42.42 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6566.63 toks/s, output: 925.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8132.31 toks/s, output: 1344.73 toks/s]
Processing batched inference:  80%|████████  | 53/66 [05:16<01:04,  4.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.07 toks/s, output: 42.43 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.35it/s, est. speed input: 7669.24 toks/s, output: 1074.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8205.97 toks/s, output: 1230.14 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [05:19<00:49,  4.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.71 toks/s, output: 41.89 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7349.49 toks/s, output: 1037.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8147.06 toks/s, output: 1256.23 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [05:21<00:39,  3.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.19 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.31it/s, est. speed input: 7340.72 toks/s, output: 1042.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8140.84 toks/s, output: 1264.26 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [05:23<00:31,  3.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.48 toks/s, output: 41.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 7084.65 toks/s, output: 996.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8186.27 toks/s, output: 1291.19 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [05:25<00:26,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.22 toks/s, output: 42.49 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7063.10 toks/s, output: 996.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8128.93 toks/s, output: 1288.41 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [05:28<00:21,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.88 toks/s, output: 41.91 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.93it/s, est. speed input: 7818.27 toks/s, output: 1100.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8155.02 toks/s, output: 1205.87 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [05:30<00:17,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.61 toks/s, output: 41.88 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.48it/s, est. speed input: 7397.15 toks/s, output: 1036.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8175.84 toks/s, output: 1255.58 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [05:32<00:14,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.17 toks/s, output: 41.82 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.01it/s, est. speed input: 8176.82 toks/s, output: 1152.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 8247.57 toks/s, output: 1191.39 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [05:35<00:12,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.57 toks/s, output: 41.74 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.16it/s, est. speed input: 7019.44 toks/s, output: 990.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 22.16it/s, est. speed input: 7880.47 toks/s, output: 1226.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:16<00:00,  1.46it/s, est. speed input: 780.27 toks/s, output: 271.13 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s, est. speed input: 780.27 toks/s, output: 271.13 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [05:52<00:27,  6.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.51 toks/s, output: 41.86 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.21it/s, est. speed input: 8282.68 toks/s, output: 1163.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 8282.68 toks/s, output: 1163.36 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [05:54<00:16,  5.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.33 toks/s, output: 41.97 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.08it/s, est. speed input: 8185.02 toks/s, output: 1148.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8193.36 toks/s, output: 1180.13 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [05:57<00:09,  4.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.23 toks/s, output: 41.83 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.27it/s, est. speed input: 7664.30 toks/s, output: 1075.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.22it/s, est. speed input: 8388.94 toks/s, output: 1255.55 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [05:59<00:03,  3.83s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 354.01 toks/s, output: 46.51 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.62it/s, est. speed input: 6837.06 toks/s, output: 972.56 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.75it/s, est. speed input: 7730.42 toks/s, output: 1219.63 toks/s]
Processing batched inference: 100%|██████████| 66/66 [06:01<00:00,  3.31s/it]Processing batched inference: 100%|██████████| 66/66 [06:01<00:00,  5.47s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-126/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:14:35.944095885 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-1260
INFO 07-05 10:14:48 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:14:50,621 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:14:50,668 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:50,692 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:50,692 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:50,692 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:50,692 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:50,692 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:50,692 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:50,692 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:14:51,076 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:14:51,077 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:14:51,083 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:14:51,089 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:51,091 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:51,091 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:51,091 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:51,091 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:51,091 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:51,091 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:14:51,091 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:14:51,465 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:14:51,468 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:14:51,664 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:14:52,110 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:14:52,160 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:14:52,161 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:14:52,163 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:15:03 [config.py:689] This model supports multiple tasks: {'classify', 'reward', 'generate', 'score', 'embed'}. Defaulting to 'generate'.
INFO 07-05 10:15:03 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:03,693 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:03,693 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:03,693 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:03,693 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:03,693 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:03,693 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:03,693 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:15:04,024 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:15:04,128 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:15:04,131 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:15:05 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:15:05 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:15:05 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260...
WARNING 07-05 10:15:06 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:15:06 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.20s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.20s/it]

INFO 07-05 10:15:13 [loader.py:458] Loading weights took 7.42 seconds
INFO 07-05 10:15:13 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.659419 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,082 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,082 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,082 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,082 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,082 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,082 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,082 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:15:14,490 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:15:14,587 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:15:14,587 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:15:14,588 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:15:14,588 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,589 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,589 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,589 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,589 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,589 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,589 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:15:14,589 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:15:15,346 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:15:15,346 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:15:15,347 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:15:15,790 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:15:16,410 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:15:16 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:15:19,225 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:15:20,240 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:15:20 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:15:59 [worker.py:267] Memory profiling takes 45.36 seconds
INFO 07-05 10:15:59 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:15:59 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:15:59 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:15:59 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:16:05 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:17,  2.00it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:00<00:16,  2.02it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:15,  2.00it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:01<00:15,  2.01it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:14,  2.02it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:02<00:14,  2.03it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:13,  2.02it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:03<00:13,  2.02it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  2.00it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:04<00:12,  2.02it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.02it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:05<00:11,  2.02it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:10,  2.03it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:06<00:10,  2.04it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.04it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:07<00:09,  2.04it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:08,  2.03it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:08<00:08,  2.03it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.04it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:09<00:07,  2.04it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:06,  2.04it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:10<00:06,  2.00it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:05,  2.00it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:11<00:05,  2.01it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.02it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:12<00:04,  2.03it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.03it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:13<00:03,  2.01it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:02,  2.02it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:14<00:02,  2.02it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.01it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:15<00:01,  1.99it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.97it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:16<00:00,  1.99it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.98it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.02it/s]
INFO 07-05 10:16:22 [model_runner.py:1598] Graph capturing finished in 17 secs, took 0.33 GiB
INFO 07-05 10:16:22 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.56 seconds
[INFO|2025-07-05 10:16:22] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:09, 214.03 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:00<00:05, 365.44 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:00<00:03, 544.16 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:01, 1062.15 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:01<00:00, 1182.85 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:01<00:00, 1258.46 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:01<00:00, 1297.62 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:01<00:00, 1383.92 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:01<00:00, 1465.04 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:02<00:00, 966.65 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:16:27,399 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:16:27,399 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:27,400 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:27,400 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:27,400 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:27,400 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:27,400 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:27,400 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:16:27,400 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:16:28,173 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:16:28,173 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:16:28,174 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:16:28,650 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-1260', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 252.58 toks/s, output: 32.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 17.15it/s, est. speed input: 5372.04 toks/s, output: 758.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 18.81it/s, est. speed input: 5989.08 toks/s, output: 1011.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.43it/s, est. speed input: 5989.08 toks/s, output: 1011.70 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:44,  4.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.04 toks/s, output: 42.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.15it/s, est. speed input: 6112.77 toks/s, output: 864.70 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.27it/s, est. speed input: 6633.86 toks/s, output: 1114.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.79it/s, est. speed input: 4875.25 toks/s, output: 930.03 toks/s] 
Processing batched inference:   3%|▎         | 2/66 [00:07<04:11,  3.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.16 toks/s, output: 42.08 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.78it/s, est. speed input: 5976.59 toks/s, output: 846.53 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.54it/s, est. speed input: 6234.59 toks/s, output: 1054.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s, est. speed input: 2909.50 toks/s, output: 643.84 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:13<04:49,  4.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.95 toks/s, output: 42.05 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 7105.63 toks/s, output: 999.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8178.32 toks/s, output: 1286.72 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:15<03:51,  3.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.34 toks/s, output: 41.97 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 6278.74 toks/s, output: 888.37 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.10it/s, est. speed input: 6406.46 toks/s, output: 1049.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.30it/s, est. speed input: 5507.55 toks/s, output: 1044.66 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:19<03:36,  3.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.08 toks/s, output: 42.07 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7075.63 toks/s, output: 996.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8133.26 toks/s, output: 1287.05 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:21<03:10,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.93 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.38it/s, est. speed input: 6782.76 toks/s, output: 951.24 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.61it/s, est. speed input: 6697.74 toks/s, output: 1089.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6914.50 toks/s, output: 1170.73 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:24<02:58,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.49 toks/s, output: 41.99 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 7124.95 toks/s, output: 1003.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8194.98 toks/s, output: 1294.03 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:26<02:44,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:49,  1.60s/it, est. speed input: 259.25 toks/s, output: 33.65 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 18.22it/s, est. speed input: 5645.11 toks/s, output: 796.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6763.28 toks/s, output: 1098.36 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:29<02:38,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 322.08 toks/s, output: 41.53 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.38it/s, est. speed input: 7450.53 toks/s, output: 1045.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.56it/s, est. speed input: 6018.73 toks/s, output: 977.55 toks/s] 
Processing batched inference:  15%|█▌        | 10/66 [00:32<02:38,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.07 toks/s, output: 42.07 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6827.58 toks/s, output: 955.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.32it/s, est. speed input: 7081.44 toks/s, output: 1167.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.14it/s, est. speed input: 7081.44 toks/s, output: 1167.91 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:34<02:33,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.65 toks/s, output: 42.01 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6504.55 toks/s, output: 929.21 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.71it/s, est. speed input: 6827.89 toks/s, output: 1143.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6847.56 toks/s, output: 1191.50 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:37<02:29,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 321.49 toks/s, output: 41.46 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6834.76 toks/s, output: 961.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8161.32 toks/s, output: 1326.58 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:39<02:20,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 320.36 toks/s, output: 41.99 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.74it/s, est. speed input: 6854.07 toks/s, output: 962.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.29it/s, est. speed input: 6884.34 toks/s, output: 1128.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6884.34 toks/s, output: 1128.14 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:42<02:17,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 326.83 toks/s, output: 40.85 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.94it/s, est. speed input: 6024.98 toks/s, output: 847.78 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.14it/s, est. speed input: 6888.52 toks/s, output: 1210.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6888.52 toks/s, output: 1210.71 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:45<02:15,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 327.22 toks/s, output: 40.90 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.53it/s, est. speed input: 6226.37 toks/s, output: 878.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 8105.62 toks/s, output: 1380.01 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:47<02:08,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.78 toks/s, output: 42.57 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 6236.61 toks/s, output: 887.32 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.87it/s, est. speed input: 6560.20 toks/s, output: 1101.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.39it/s, est. speed input: 4263.08 toks/s, output: 834.89 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [00:51<02:24,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.07 toks/s, output: 42.07 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 7332.09 toks/s, output: 1038.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8144.84 toks/s, output: 1264.95 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:53<02:12,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.63 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7394.91 toks/s, output: 1040.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8204.71 toks/s, output: 1271.10 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:56<02:04,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 317.67 toks/s, output: 42.51 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.13it/s, est. speed input: 7573.36 toks/s, output: 1074.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 8177.81 toks/s, output: 1247.82 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:58<01:56,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.35 toks/s, output: 41.97 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.28it/s, est. speed input: 5765.45 toks/s, output: 818.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.10it/s, est. speed input: 6812.36 toks/s, output: 1226.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6812.36 toks/s, output: 1226.63 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:01<01:55,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.94 toks/s, output: 42.05 toks/s][A
Processed prompts:  53%|█████▎    | 17/32 [00:01<00:01, 13.81it/s, est. speed input: 4410.34 toks/s, output: 629.59 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.78it/s, est. speed input: 6177.06 toks/s, output: 1187.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.07it/s, est. speed input: 5417.73 toks/s, output: 1168.93 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:04<02:01,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.50 toks/s, output: 41.86 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.36it/s, est. speed input: 7389.97 toks/s, output: 1031.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6905.53 toks/s, output: 1087.85 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:06<01:56,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.77 toks/s, output: 41.90 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6558.63 toks/s, output: 919.11 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.45it/s, est. speed input: 5163.70 toks/s, output: 898.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.77it/s, est. speed input: 3610.49 toks/s, output: 730.04 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:11<02:14,  3.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it, est. speed input: 331.49 toks/s, output: 39.84 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.64it/s, est. speed input: 6892.62 toks/s, output: 973.74 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:07<00:00,  3.68it/s, est. speed input: 1830.10 toks/s, output: 430.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.45it/s, est. speed input: 1830.10 toks/s, output: 430.91 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:19<03:08,  4.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.50 toks/s, output: 41.99 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.17it/s, est. speed input: 6711.39 toks/s, output: 953.23 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.67it/s, est. speed input: 6669.49 toks/s, output: 1098.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6885.21 toks/s, output: 1179.41 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:21<02:40,  4.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.55 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6557.88 toks/s, output: 923.79 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.53it/s, est. speed input: 6856.29 toks/s, output: 1160.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6856.29 toks/s, output: 1160.18 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:24<02:20,  3.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.09 toks/s, output: 42.07 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6800.51 toks/s, output: 965.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8135.52 toks/s, output: 1325.10 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:26<02:01,  3.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.81 toks/s, output: 42.57 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.90it/s, est. speed input: 6256.97 toks/s, output: 889.41 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.15it/s, est. speed input: 6418.14 toks/s, output: 1084.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.55it/s, est. speed input: 5982.87 toks/s, output: 1111.01 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:29<01:54,  3.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.74 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.74it/s, est. speed input: 6904.61 toks/s, output: 968.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8206.20 toks/s, output: 1317.57 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:31<01:41,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.94 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6510.42 toks/s, output: 923.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.74it/s, est. speed input: 6873.38 toks/s, output: 1160.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6873.38 toks/s, output: 1160.87 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:34<01:35,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.97 toks/s, output: 41.92 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6809.00 toks/s, output: 954.57 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.27it/s, est. speed input: 5962.11 toks/s, output: 1031.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.43it/s, est. speed input: 5962.11 toks/s, output: 1031.10 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:37<01:34,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.37 toks/s, output: 41.85 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.36it/s, est. speed input: 6158.71 toks/s, output: 874.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.80it/s, est. speed input: 6555.19 toks/s, output: 1105.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.39it/s, est. speed input: 5960.69 toks/s, output: 1124.51 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:40<01:32,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.40 toks/s, output: 41.85 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.04it/s, est. speed input: 5731.82 toks/s, output: 809.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.39it/s, est. speed input: 6648.82 toks/s, output: 1183.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5975.19 toks/s, output: 1121.32 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:42<01:30,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.10 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7074.32 toks/s, output: 997.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6866.63 toks/s, output: 1107.95 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:45<01:25,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.83 toks/s, output: 41.91 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.83it/s, est. speed input: 6561.15 toks/s, output: 924.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.48it/s, est. speed input: 6844.62 toks/s, output: 1158.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6844.62 toks/s, output: 1158.39 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:48<01:20,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.37 toks/s, output: 41.85 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 7114.33 toks/s, output: 994.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8179.36 toks/s, output: 1282.07 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:50<01:13,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.13 toks/s, output: 41.81 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.97it/s, est. speed input: 6965.25 toks/s, output: 989.41 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.12it/s, est. speed input: 6864.34 toks/s, output: 1123.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6864.34 toks/s, output: 1123.49 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:52<01:12,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.76 toks/s, output: 41.77 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.57it/s, est. speed input: 4667.31 toks/s, output: 662.03 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.47it/s, est. speed input: 6411.57 toks/s, output: 1218.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.22it/s, est. speed input: 5908.05 toks/s, output: 1212.62 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:55<01:12,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.54 toks/s, output: 41.87 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.32it/s, est. speed input: 7378.93 toks/s, output: 1041.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6952.28 toks/s, output: 1102.71 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:58<01:08,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.15 toks/s, output: 41.95 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.20it/s, est. speed input: 5457.61 toks/s, output: 772.37 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.16it/s, est. speed input: 6477.06 toks/s, output: 1158.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6824.16 toks/s, output: 1303.91 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:00<01:05,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.79 toks/s, output: 41.90 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 7076.71 toks/s, output: 999.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8134.43 toks/s, output: 1289.12 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:03<01:00,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 322.70 toks/s, output: 40.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6542.57 toks/s, output: 921.48 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.39it/s, est. speed input: 7024.70 toks/s, output: 1184.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.06it/s, est. speed input: 7024.70 toks/s, output: 1184.37 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:05<00:58,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.59 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6787.44 toks/s, output: 955.32 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.94it/s, est. speed input: 6980.06 toks/s, output: 1149.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.93it/s, est. speed input: 6980.06 toks/s, output: 1149.40 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:08<00:55,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.74 toks/s, output: 41.76 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.13it/s, est. speed input: 7884.02 toks/s, output: 1105.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6875.00 toks/s, output: 1041.20 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:10<00:52,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.04 toks/s, output: 41.93 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.83it/s, est. speed input: 6568.20 toks/s, output: 926.04 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.88it/s, est. speed input: 6448.27 toks/s, output: 1048.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 18.88it/s, est. speed input: 3048.81 toks/s, output: 608.47 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.03s/it, est. speed input: 686.03 toks/s, output: 288.15 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s, est. speed input: 686.03 toks/s, output: 288.15 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:30<02:34,  7.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.69 toks/s, output: 41.89 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.14it/s, est. speed input: 6708.20 toks/s, output: 951.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8142.81 toks/s, output: 1326.81 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:32<01:55,  6.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.40 toks/s, output: 42.52 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 7080.13 toks/s, output: 1001.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8126.30 toks/s, output: 1292.57 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:35<01:28,  4.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.99 toks/s, output: 41.93 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.16it/s, est. speed input: 5736.81 toks/s, output: 813.76 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.43it/s, est. speed input: 6890.97 toks/s, output: 1233.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6890.97 toks/s, output: 1233.63 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:37<01:11,  4.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.12 toks/s, output: 41.68 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.27it/s, est. speed input: 7340.65 toks/s, output: 1028.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8191.45 toks/s, output: 1259.16 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:39<00:57,  3.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.29 toks/s, output: 41.83 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.89it/s, est. speed input: 5973.55 toks/s, output: 847.60 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.69it/s, est. speed input: 5913.42 toks/s, output: 1063.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.29it/s, est. speed input: 5913.42 toks/s, output: 1063.79 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:42<00:50,  3.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.66 toks/s, output: 41.88 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 7092.23 toks/s, output: 1002.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.79it/s, est. speed input: 6941.37 toks/s, output: 1129.60 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:45<00:43,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.31 toks/s, output: 41.95 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 6275.24 toks/s, output: 885.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8115.69 toks/s, output: 1372.63 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:47<00:37,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.32 toks/s, output: 41.97 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7391.61 toks/s, output: 1035.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8196.27 toks/s, output: 1260.20 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:49<00:31,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.40 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6262.91 toks/s, output: 885.57 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.44it/s, est. speed input: 6452.79 toks/s, output: 1055.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.41it/s, est. speed input: 5952.83 toks/s, output: 1136.78 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:52<00:29,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 315.33 toks/s, output: 42.86 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.37it/s, est. speed input: 5176.95 toks/s, output: 741.53 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.42it/s, est. speed input: 6218.58 toks/s, output: 1125.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.26it/s, est. speed input: 5892.16 toks/s, output: 1196.16 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:55<00:27,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.23 toks/s, output: 41.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6788.30 toks/s, output: 954.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8105.06 toks/s, output: 1312.15 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:57<00:23,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.67 toks/s, output: 42.42 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.95it/s, est. speed input: 5953.92 toks/s, output: 844.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8050.38 toks/s, output: 1393.23 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:59<00:20,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.35 toks/s, output: 41.84 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.91it/s, est. speed input: 5989.81 toks/s, output: 845.15 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.65it/s, est. speed input: 7130.93 toks/s, output: 1254.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.33it/s, est. speed input: 7130.93 toks/s, output: 1254.82 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:02<00:17,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.62 toks/s, output: 41.88 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.55it/s, est. speed input: 6824.29 toks/s, output: 952.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.72it/s, est. speed input: 5313.87 toks/s, output: 952.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.83it/s, est. speed input: 5313.87 toks/s, output: 952.41 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:05<00:16,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.60 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6800.09 toks/s, output: 961.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8130.50 toks/s, output: 1323.13 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:07<00:12,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.64 toks/s, output: 41.88 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.70it/s, est. speed input: 5954.30 toks/s, output: 844.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.42it/s, est. speed input: 6872.61 toks/s, output: 1199.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.03it/s, est. speed input: 7043.80 toks/s, output: 1269.31 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:10<00:10,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.24 toks/s, output: 41.83 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.25it/s, est. speed input: 7636.54 toks/s, output: 1071.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8163.47 toks/s, output: 1233.68 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:12<00:07,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.11 toks/s, output: 41.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6795.55 toks/s, output: 956.58 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.26it/s, est. speed input: 6848.42 toks/s, output: 1136.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.59it/s, est. speed input: 6848.42 toks/s, output: 1136.21 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:15<00:04,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.53 toks/s, output: 40.70 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.24it/s, est. speed input: 6401.38 toks/s, output: 898.32 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.18it/s, est. speed input: 6745.61 toks/s, output: 1135.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.26it/s, est. speed input: 6745.61 toks/s, output: 1135.61 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:17<00:02,  2.50s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 353.11 toks/s, output: 45.53 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.44it/s, est. speed input: 6791.91 toks/s, output: 961.03 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.61it/s, est. speed input: 7673.04 toks/s, output: 1211.91 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:19<00:00,  2.38s/it]Processing batched inference: 100%|██████████| 66/66 [03:19<00:00,  3.03s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-1260/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:19:47.068338696 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-189
INFO 07-05 10:20:00 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:20:02,491 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:20:02,533 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,553 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,553 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,553 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,553 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,553 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,553 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,553 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:20:02,942 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:20:02,943 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:20:02,948 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:20:02,955 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,955 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,955 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,956 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,956 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,956 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,956 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:02,956 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:20:03,332 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:20:03,334 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:20:03,530 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:20:03,961 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:20:04,014 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:20:04,015 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:20:04,016 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:20:15 [config.py:689] This model supports multiple tasks: {'classify', 'embed', 'reward', 'score', 'generate'}. Defaulting to 'generate'.
INFO 07-05 10:20:15 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:15,618 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:15,618 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:15,618 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:15,618 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:15,618 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:15,618 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:15,618 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:20:15,951 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:20:16,056 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:20:16,059 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:20:17 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:20:17 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:20:17 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189...
WARNING 07-05 10:20:17 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:20:18 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.39s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.39s/it]

INFO 07-05 10:20:25 [loader.py:458] Loading weights took 7.60 seconds
INFO 07-05 10:20:25 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.852219 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,206 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,206 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,206 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,206 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,206 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,206 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,206 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:20:26,615 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:20:26,710 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:20:26,710 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:20:26,710 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:20:26,711 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,712 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,712 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,712 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,712 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,712 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,712 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:20:26,712 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:20:27,462 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:20:27,462 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:20:27,463 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:20:27,917 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:20:28,580 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:20:29 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:20:31,366 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:20:32,405 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:20:32 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:21:11 [worker.py:267] Memory profiling takes 45.32 seconds
INFO 07-05 10:21:11 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:21:11 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:21:11 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:21:11 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:21:17 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:18,  1.88it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.87it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.83it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.88it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.93it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.96it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.98it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.97it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.99it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.99it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:06,  2.00it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.99it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  2.00it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.01it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  2.00it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  2.00it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.97it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.95it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.97it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.98it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.96it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.98it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  1.96it/s]
INFO 07-05 10:21:35 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:21:35 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.50 seconds
[INFO|2025-07-05 10:21:35] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:21:36,788 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:21:36,788 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:36,789 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:36,789 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:36,789 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:36,789 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:36,789 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:36,789 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:21:36,790 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:21:37,715 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:21:37,717 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:21:37,717 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:21:38,211 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-189', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 252.33 toks/s, output: 32.75 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 18.52it/s, est. speed input: 5787.15 toks/s, output: 822.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.12it/s, est. speed input: 6687.07 toks/s, output: 1056.08 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:43,  4.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 316.80 toks/s, output: 42.71 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.54it/s, est. speed input: 7406.98 toks/s, output: 1045.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8206.03 toks/s, output: 1269.71 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:26,  3.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.00 toks/s, output: 42.46 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6836.91 toks/s, output: 967.72 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.65it/s, est. speed input: 7909.22 toks/s, output: 1259.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 507.30 toks/s, output: 235.29 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 507.30 toks/s, output: 235.29 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:33<14:48, 14.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.70 toks/s, output: 42.56 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7369.47 toks/s, output: 1037.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.92it/s, est. speed input: 8237.08 toks/s, output: 1264.22 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:36<09:48,  9.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.20 toks/s, output: 42.08 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7399.89 toks/s, output: 1039.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8208.58 toks/s, output: 1268.38 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:38<07:03,  6.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.23 toks/s, output: 42.09 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7060.78 toks/s, output: 1001.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 8196.39 toks/s, output: 1292.68 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:41<05:23,  5.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 316.07 toks/s, output: 42.61 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.49it/s, est. speed input: 7406.69 toks/s, output: 1043.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.96it/s, est. speed input: 8278.41 toks/s, output: 1273.16 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:43<04:20,  4.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.03 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 7390.21 toks/s, output: 1044.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8192.90 toks/s, output: 1261.62 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:45<03:39,  3.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.51 toks/s, output: 42.40 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7306.18 toks/s, output: 1035.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 8158.09 toks/s, output: 1261.49 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:48<03:10,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.19 toks/s, output: 42.08 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7393.25 toks/s, output: 1039.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8188.60 toks/s, output: 1267.45 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:50<02:50,  3.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.72 toks/s, output: 42.15 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6817.80 toks/s, output: 958.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8152.43 toks/s, output: 1313.71 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:53<02:37,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 316.08 toks/s, output: 42.61 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.33it/s, est. speed input: 7909.42 toks/s, output: 1123.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 8249.57 toks/s, output: 1225.65 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:55<02:26,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.63 toks/s, output: 42.41 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7663.50 toks/s, output: 1080.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8204.10 toks/s, output: 1241.37 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:57<02:17,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.50 toks/s, output: 42.53 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 6271.45 toks/s, output: 891.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8124.80 toks/s, output: 1355.96 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:00<02:11,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.39 toks/s, output: 40.69 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.28it/s, est. speed input: 6721.88 toks/s, output: 949.54 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 21.28it/s, est. speed input: 7785.83 toks/s, output: 1230.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 505.74 toks/s, output: 234.29 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.74 toks/s, output: 234.29 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:27<08:25,  9.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.61 toks/s, output: 40.97 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.87it/s, est. speed input: 7504.67 toks/s, output: 1061.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 8044.84 toks/s, output: 1220.18 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:29<06:25,  7.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 308.95 toks/s, output: 41.65 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.20it/s, est. speed input: 6959.11 toks/s, output: 984.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 22.20it/s, est. speed input: 1443.62 toks/s, output: 361.58 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.06s/it, est. speed input: 505.56 toks/s, output: 280.52 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 505.56 toks/s, output: 280.52 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:56<11:00, 13.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 312.04 toks/s, output: 41.00 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.98it/s, est. speed input: 7182.90 toks/s, output: 1019.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8040.29 toks/s, output: 1245.04 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:59<08:10, 10.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 310.32 toks/s, output: 41.53 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.94it/s, est. speed input: 7529.88 toks/s, output: 1061.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 8067.68 toks/s, output: 1217.65 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [02:01<06:11,  7.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 309.30 toks/s, output: 41.39 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.73it/s, est. speed input: 7137.03 toks/s, output: 1014.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 7981.95 toks/s, output: 1246.36 toks/s]
Processing batched inference:  30%|███       | 20/66 [02:04<04:48,  6.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.96 toks/s, output: 41.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.97it/s, est. speed input: 7199.65 toks/s, output: 1022.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.39it/s, est. speed input: 7993.48 toks/s, output: 1236.28 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [02:06<03:51,  5.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 310.94 toks/s, output: 40.85 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.71it/s, est. speed input: 5613.22 toks/s, output: 797.21 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.53it/s, est. speed input: 6803.94 toks/s, output: 1201.34 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.53it/s, est. speed input: 6803.94 toks/s, output: 1201.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.40s/it, est. speed input: 506.56 toks/s, output: 243.12 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 506.56 toks/s, output: 243.12 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [02:34<08:37, 11.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.77 toks/s, output: 40.99 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.98it/s, est. speed input: 7248.03 toks/s, output: 1019.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.39it/s, est. speed input: 8040.01 toks/s, output: 1233.84 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [02:36<06:26,  8.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.59 toks/s, output: 40.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.22it/s, est. speed input: 6661.76 toks/s, output: 941.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 21.22it/s, est. speed input: 7721.95 toks/s, output: 1225.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 503.93 toks/s, output: 234.24 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.93 toks/s, output: 234.24 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [03:03<10:05, 14.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.40 toks/s, output: 40.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.19it/s, est. speed input: 6640.44 toks/s, output: 943.03 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 21.19it/s, est. speed input: 7696.19 toks/s, output: 1228.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 502.48 toks/s, output: 234.26 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 502.48 toks/s, output: 234.26 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [03:30<12:25, 18.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 305.87 toks/s, output: 41.23 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.28it/s, est. speed input: 6379.26 toks/s, output: 909.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.19it/s, est. speed input: 7921.12 toks/s, output: 1322.68 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [03:32<08:56, 13.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.87 toks/s, output: 41.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.06it/s, est. speed input: 6932.17 toks/s, output: 981.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 7987.39 toks/s, output: 1262.08 toks/s]
Processing batched inference:  41%|████      | 27/66 [03:35<06:33, 10.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.56 toks/s, output: 40.96 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.95it/s, est. speed input: 7194.19 toks/s, output: 1020.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.38it/s, est. speed input: 7993.39 toks/s, output: 1240.78 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [03:37<04:54,  7.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 304.63 toks/s, output: 41.07 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.96it/s, est. speed input: 6879.26 toks/s, output: 974.26 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.96it/s, est. speed input: 7658.76 toks/s, output: 1200.87 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 501.76 toks/s, output: 232.49 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 501.76 toks/s, output: 232.49 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [04:04<08:20, 13.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 310.19 toks/s, output: 41.51 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.12it/s, est. speed input: 7000.89 toks/s, output: 987.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 8111.52 toks/s, output: 1270.08 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [04:06<06:05, 10.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.92 toks/s, output: 40.75 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.09it/s, est. speed input: 6629.83 toks/s, output: 936.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.36it/s, est. speed input: 7962.04 toks/s, output: 1287.28 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [04:08<04:32,  7.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 308.32 toks/s, output: 41.56 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.06it/s, est. speed input: 7232.91 toks/s, output: 1015.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 8031.64 toks/s, output: 1238.39 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [04:11<03:28,  6.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.88 toks/s, output: 40.74 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 24.75it/s, est. speed input: 7838.01 toks/s, output: 1109.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.21it/s, est. speed input: 5887.97 toks/s, output: 898.05 toks/s] 
Processing batched inference:  50%|█████     | 33/66 [04:14<02:49,  5.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.07 toks/s, output: 41.26 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.16it/s, est. speed input: 6694.67 toks/s, output: 945.84 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 6825.62 toks/s, output: 1130.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.45it/s, est. speed input: 6825.62 toks/s, output: 1130.31 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [04:16<02:20,  4.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.17 toks/s, output: 40.91 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.95it/s, est. speed input: 7200.71 toks/s, output: 1018.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.96it/s, est. speed input: 8237.50 toks/s, output: 1265.53 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [04:18<01:56,  3.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 310.45 toks/s, output: 41.85 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.72it/s, est. speed input: 6189.78 toks/s, output: 877.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7991.66 toks/s, output: 1347.68 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [04:21<01:39,  3.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.59 toks/s, output: 41.35 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.07it/s, est. speed input: 7600.30 toks/s, output: 1064.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 8259.63 toks/s, output: 1234.99 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [04:23<01:27,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 309.69 toks/s, output: 41.75 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.10it/s, est. speed input: 7267.85 toks/s, output: 1031.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 8063.63 toks/s, output: 1257.08 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [04:25<01:18,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 310.77 toks/s, output: 41.89 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.20it/s, est. speed input: 5154.17 toks/s, output: 731.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.26it/s, est. speed input: 8001.65 toks/s, output: 1466.00 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [04:28<01:12,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.66 toks/s, output: 41.23 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.87it/s, est. speed input: 7846.05 toks/s, output: 1105.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8117.72 toks/s, output: 1197.73 toks/s]
Processing batched inference:  61%|██████    | 40/66 [04:30<01:06,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.08 toks/s, output: 41.68 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.38it/s, est. speed input: 7045.98 toks/s, output: 995.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8111.65 toks/s, output: 1284.24 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [04:32<01:01,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.61 toks/s, output: 41.75 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7349.20 toks/s, output: 1036.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.51it/s, est. speed input: 5972.48 toks/s, output: 966.46 toks/s] 
Processing batched inference:  64%|██████▎   | 42/66 [04:35<01:02,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.86 toks/s, output: 41.78 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.29it/s, est. speed input: 7313.35 toks/s, output: 1031.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 23.29it/s, est. speed input: 5974.96 toks/s, output: 945.79 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.08s/it, est. speed input: 504.61 toks/s, output: 234.40 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 504.61 toks/s, output: 234.40 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [05:02<03:46,  9.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.03 toks/s, output: 42.33 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.81it/s, est. speed input: 6523.31 toks/s, output: 923.37 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 20.81it/s, est. speed input: 7833.25 toks/s, output: 1266.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.04s/it, est. speed input: 505.06 toks/s, output: 235.95 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 505.06 toks/s, output: 235.95 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [05:29<05:29, 14.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.33 toks/s, output: 42.37 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.33it/s, est. speed input: 7623.46 toks/s, output: 1071.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.85it/s, est. speed input: 6944.94 toks/s, output: 1074.44 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [05:31<03:55, 11.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 312.33 toks/s, output: 42.10 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.84it/s, est. speed input: 5942.88 toks/s, output: 843.43 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:18<00:00, 18.84it/s, est. speed input: 7530.97 toks/s, output: 1251.21 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.05s/it, est. speed input: 493.17 toks/s, output: 237.33 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 508.31 toks/s, output: 395.24 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [05:58<05:17, 15.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.66 toks/s, output: 41.78 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6799.81 toks/s, output: 963.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8125.27 toks/s, output: 1321.50 toks/s]
Processing batched inference:  71%|███████   | 47/66 [06:00<03:43, 11.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.88 toks/s, output: 42.31 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.19it/s, est. speed input: 7878.83 toks/s, output: 1110.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8140.02 toks/s, output: 1207.61 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [06:02<02:40,  8.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.94 toks/s, output: 42.01 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6810.24 toks/s, output: 963.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8197.56 toks/s, output: 1315.76 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [06:05<01:57,  6.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.40 toks/s, output: 41.72 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.41it/s, est. speed input: 7071.88 toks/s, output: 994.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8184.98 toks/s, output: 1286.62 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [06:07<01:28,  5.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.26 toks/s, output: 42.32 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.90it/s, est. speed input: 5969.34 toks/s, output: 851.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.51it/s, est. speed input: 8073.41 toks/s, output: 1388.95 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [06:09<01:08,  4.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.83 toks/s, output: 41.77 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.65it/s, est. speed input: 6529.96 toks/s, output: 924.82 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00, 20.65it/s, est. speed input: 7855.78 toks/s, output: 1283.28 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.04s/it, est. speed input: 506.38 toks/s, output: 237.04 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 506.38 toks/s, output: 237.04 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [06:36<02:37, 11.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.40 toks/s, output: 42.34 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7083.31 toks/s, output: 996.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8144.64 toks/s, output: 1289.58 toks/s]
Processing batched inference:  80%|████████  | 53/66 [06:38<01:50,  8.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.05 toks/s, output: 42.43 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7381.79 toks/s, output: 1034.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8185.15 toks/s, output: 1257.25 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [06:40<01:19,  6.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.87 toks/s, output: 42.45 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6543.71 toks/s, output: 925.03 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 20.76it/s, est. speed input: 7881.15 toks/s, output: 1277.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.04s/it, est. speed input: 506.18 toks/s, output: 236.45 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.18 toks/s, output: 236.45 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [07:07<02:19, 12.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.82 toks/s, output: 42.65 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6761.24 toks/s, output: 963.81 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.26it/s, est. speed input: 6830.76 toks/s, output: 1134.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6830.76 toks/s, output: 1134.66 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [07:10<01:36,  9.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.87 toks/s, output: 42.31 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.05it/s, est. speed input: 5701.92 toks/s, output: 810.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 8038.98 toks/s, output: 1411.69 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [07:12<01:07,  7.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.86 toks/s, output: 42.44 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7055.57 toks/s, output: 994.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8125.53 toks/s, output: 1289.72 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [07:14<00:47,  5.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.55 toks/s, output: 41.87 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.34it/s, est. speed input: 7327.96 toks/s, output: 1031.41 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 23.34it/s, est. speed input: 6671.53 toks/s, output: 1035.66 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 503.87 toks/s, output: 232.63 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.87 toks/s, output: 232.63 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [07:41<01:25, 12.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.39 toks/s, output: 42.38 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6278.55 toks/s, output: 884.30 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 19.83it/s, est. speed input: 7872.82 toks/s, output: 1296.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.03s/it, est. speed input: 507.08 toks/s, output: 237.79 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 507.08 toks/s, output: 237.79 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [08:08<01:39, 16.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.52 toks/s, output: 42.36 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7631.05 toks/s, output: 1078.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8173.81 toks/s, output: 1238.17 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [08:10<01:01, 12.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.07 toks/s, output: 41.94 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.14it/s, est. speed input: 7308.87 toks/s, output: 1032.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.16it/s, est. speed input: 7095.95 toks/s, output: 1126.44 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [08:13<00:37,  9.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.08 toks/s, output: 41.94 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.19it/s, est. speed input: 7916.30 toks/s, output: 1113.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.12it/s, est. speed input: 8315.05 toks/s, output: 1224.51 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [08:15<00:21,  7.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.70 toks/s, output: 41.89 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 7080.90 toks/s, output: 1001.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.49it/s, est. speed input: 4742.00 toks/s, output: 817.61 toks/s] 
Processing batched inference:  97%|█████████▋| 64/66 [08:19<00:12,  6.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.27 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6572.63 toks/s, output: 925.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8162.87 toks/s, output: 1339.77 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [08:21<00:04,  4.91s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 349.73 toks/s, output: 47.14 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.70it/s, est. speed input: 6848.81 toks/s, output: 974.92 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.78it/s, est. speed input: 7743.10 toks/s, output: 1221.63 toks/s]
Processing batched inference: 100%|██████████| 66/66 [08:23<00:00,  4.07s/it]Processing batched inference: 100%|██████████| 66/66 [08:23<00:00,  7.63s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-189/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:30:00.014193183 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-252
INFO 07-05 10:30:13 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:30:15,517 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:30:15,540 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,559 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,559 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,559 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,559 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,559 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,559 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,559 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:30:15,947 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:30:15,948 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:30:15,953 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:30:15,959 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,960 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,960 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,961 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,961 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,961 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,961 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:15,961 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:30:16,335 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:30:16,337 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:30:16,531 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:30:16,972 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:30:17,026 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:30:17,026 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:30:17,028 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:30:28 [config.py:689] This model supports multiple tasks: {'reward', 'classify', 'embed', 'generate', 'score'}. Defaulting to 'generate'.
INFO 07-05 10:30:28 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:28,646 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:28,646 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:28,646 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:28,647 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:28,647 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:28,647 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:28,647 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:30:28,981 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:30:29,083 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:30:29,086 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:30:30 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:30:30 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:30:30 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252...
WARNING 07-05 10:30:31 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:30:31 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.31s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.31s/it]

INFO 07-05 10:30:38 [loader.py:458] Loading weights took 7.54 seconds
INFO 07-05 10:30:38 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.795001 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,198 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,198 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,198 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,198 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,198 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,198 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,198 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:30:39,606 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:30:39,702 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:30:39,702 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:30:39,703 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:30:39,703 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,704 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,704 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,704 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,704 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,704 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,704 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:30:39,704 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:30:40,456 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:30:40,456 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:30:40,457 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:30:40,933 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:30:41,557 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:30:42 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:30:44,402 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:30:45,417 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:30:45 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:31:24 [worker.py:267] Memory profiling takes 45.37 seconds
INFO 07-05 10:31:24 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:31:24 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:31:24 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:31:24 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:31:30 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:22,  1.50it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.75it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.83it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.85it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.89it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.92it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.92it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.93it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.96it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.96it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.95it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.95it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.96it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.92it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.94it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.95it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.96it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.93it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.87it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.90it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.92it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.94it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.95it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.96it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.92it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.88it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 10:31:48 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:31:48 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.68 seconds
[INFO|2025-07-05 10:31:49] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:31:50,123 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:31:50,123 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:31:50,124 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:31:50,124 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:31:50,124 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:31:50,124 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:31:50,124 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:31:50,124 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:31:50,124 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:31:51,294 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:31:51,294 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:31:51,294 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:31:51,863 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-252', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 252.33 toks/s, output: 32.75 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 18.46it/s, est. speed input: 5781.62 toks/s, output: 815.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.08it/s, est. speed input: 6671.20 toks/s, output: 1058.60 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:02,  4.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.66 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.19it/s, est. speed input: 7322.74 toks/s, output: 1030.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8180.74 toks/s, output: 1269.50 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:33,  3.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.57 toks/s, output: 41.74 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.08it/s, est. speed input: 6704.93 toks/s, output: 946.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.35it/s, est. speed input: 6852.90 toks/s, output: 1142.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6852.90 toks/s, output: 1142.92 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:14,  3.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.21 toks/s, output: 42.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.14it/s, est. speed input: 8216.96 toks/s, output: 1148.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 8288.16 toks/s, output: 1187.50 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:55,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.39 toks/s, output: 41.85 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6546.53 toks/s, output: 924.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  2.88it/s, est. speed input: 1441.79 toks/s, output: 372.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.48it/s, est. speed input: 1441.79 toks/s, output: 372.90 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:22<05:31,  5.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.67 toks/s, output: 42.14 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7361.51 toks/s, output: 1034.84 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 23.45it/s, est. speed input: 7970.26 toks/s, output: 1205.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 503.07 toks/s, output: 230.34 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.07 toks/s, output: 230.34 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:49<12:47, 12.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.41 toks/s, output: 41.98 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.83it/s, est. speed input: 7566.29 toks/s, output: 1060.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.20it/s, est. speed input: 7133.58 toks/s, output: 1100.86 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:52<09:19,  9.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.19 toks/s, output: 42.08 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.26it/s, est. speed input: 7975.63 toks/s, output: 1120.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 8248.39 toks/s, output: 1214.27 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:54<06:59,  7.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.75 toks/s, output: 41.90 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7046.43 toks/s, output: 993.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.11it/s, est. speed input: 1685.50 toks/s, output: 403.40 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [01:03<07:16,  7.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.44 toks/s, output: 41.98 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.62it/s, est. speed input: 7478.31 toks/s, output: 1052.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 8196.51 toks/s, output: 1243.26 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [01:05<05:37,  6.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.90 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6821.37 toks/s, output: 956.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8148.64 toks/s, output: 1315.56 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [01:07<04:31,  4.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.22 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.80it/s, est. speed input: 6888.89 toks/s, output: 981.37 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.22it/s, est. speed input: 7043.94 toks/s, output: 1151.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.11it/s, est. speed input: 7043.94 toks/s, output: 1151.87 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [01:10<03:48,  4.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.75 toks/s, output: 42.02 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 7118.65 toks/s, output: 1002.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8186.83 toks/s, output: 1301.71 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:12<03:14,  3.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.22 toks/s, output: 41.31 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.62it/s, est. speed input: 6490.26 toks/s, output: 911.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 8042.39 toks/s, output: 1320.95 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:15<02:50,  3.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.45 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6567.79 toks/s, output: 925.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 20.76it/s, est. speed input: 7890.57 toks/s, output: 1277.96 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.05s/it, est. speed input: 504.82 toks/s, output: 235.78 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 504.82 toks/s, output: 235.78 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:42<08:51, 10.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.21 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6556.34 toks/s, output: 926.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8131.47 toks/s, output: 1354.32 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:44<06:40,  8.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.22 toks/s, output: 42.49 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 6249.92 toks/s, output: 886.78 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.27it/s, est. speed input: 6202.65 toks/s, output: 1024.77 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:14<00:00, 18.27it/s, est. speed input: 5617.10 toks/s, output: 989.94 toks/s] [A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.45s/it, est. speed input: 490.10 toks/s, output: 241.28 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 505.22 toks/s, output: 398.85 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [02:11<11:09, 13.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.07 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7069.91 toks/s, output: 997.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8110.87 toks/s, output: 1291.72 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [02:13<08:13, 10.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 309.70 toks/s, output: 41.44 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.25it/s, est. speed input: 6697.97 toks/s, output: 945.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.31it/s, est. speed input: 8008.33 toks/s, output: 1297.40 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [02:16<06:12,  7.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 308.25 toks/s, output: 41.25 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.81it/s, est. speed input: 6846.46 toks/s, output: 973.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.31it/s, est. speed input: 6728.13 toks/s, output: 1100.02 toks/s]
Processing batched inference:  30%|███       | 20/66 [02:19<04:52,  6.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.00 toks/s, output: 40.76 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.88it/s, est. speed input: 7178.39 toks/s, output: 1011.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5921.61 toks/s, output: 985.43 toks/s] 
Processing batched inference:  32%|███▏      | 21/66 [02:22<04:02,  5.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.82 toks/s, output: 40.87 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.20it/s, est. speed input: 4833.30 toks/s, output: 685.55 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 18.16it/s, est. speed input: 5854.13 toks/s, output: 1065.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 18.16it/s, est. speed input: 5642.42 toks/s, output: 1175.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.29s/it, est. speed input: 505.71 toks/s, output: 258.31 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.71 toks/s, output: 258.31 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [02:49<08:46, 11.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.20 toks/s, output: 40.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.08it/s, est. speed input: 6971.43 toks/s, output: 976.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 8020.64 toks/s, output: 1262.91 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [02:51<06:31,  9.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.59 toks/s, output: 40.84 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.88it/s, est. speed input: 7178.75 toks/s, output: 1009.00 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 22.88it/s, est. speed input: 7713.71 toks/s, output: 1168.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.09s/it, est. speed input: 503.12 toks/s, output: 230.38 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.12 toks/s, output: 230.38 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [03:18<10:08, 14.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.33 toks/s, output: 40.80 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.29it/s, est. speed input: 6372.83 toks/s, output: 904.29 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:12<00:00, 20.29it/s, est. speed input: 7182.78 toks/s, output: 1128.24 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:26<00:02,  1.15s/it, est. speed input: 467.63 toks/s, output: 225.89 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.21it/s, est. speed input: 497.35 toks/s, output: 535.65 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [03:46<12:31, 18.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.26 toks/s, output: 40.66 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.83it/s, est. speed input: 6279.87 toks/s, output: 892.51 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 19.83it/s, est. speed input: 7679.78 toks/s, output: 1263.58 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.05s/it, est. speed input: 503.90 toks/s, output: 236.67 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.90 toks/s, output: 236.67 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [04:13<13:58, 20.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.46 toks/s, output: 40.56 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.57it/s, est. speed input: 7694.05 toks/s, output: 1080.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.41it/s, est. speed input: 6774.07 toks/s, output: 1051.39 toks/s]
Processing batched inference:  41%|████      | 27/66 [04:16<10:03, 15.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.73 toks/s, output: 40.85 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.62it/s, est. speed input: 6810.68 toks/s, output: 964.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7969.40 toks/s, output: 1272.08 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [04:18<07:19, 11.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.60 toks/s, output: 40.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.75it/s, est. speed input: 6534.81 toks/s, output: 929.43 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.39it/s, est. speed input: 6533.70 toks/s, output: 1075.64 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.39it/s, est. speed input: 6533.70 toks/s, output: 1075.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.47s/it, est. speed input: 502.35 toks/s, output: 236.57 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 502.35 toks/s, output: 236.57 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [04:45<09:59, 16.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.82 toks/s, output: 40.87 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.04it/s, est. speed input: 7284.42 toks/s, output: 1022.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6879.56 toks/s, output: 1079.77 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [04:48<07:15, 12.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.48 toks/s, output: 40.95 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.09it/s, est. speed input: 6921.28 toks/s, output: 977.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 7992.25 toks/s, output: 1264.22 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [04:50<05:20,  9.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.02 toks/s, output: 40.89 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.96it/s, est. speed input: 7212.36 toks/s, output: 1010.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.38it/s, est. speed input: 8007.89 toks/s, output: 1236.54 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [04:52<04:01,  7.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.36 toks/s, output: 40.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.77it/s, est. speed input: 6589.31 toks/s, output: 934.58 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.08it/s, est. speed input: 5868.33 toks/s, output: 1002.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.16it/s, est. speed input: 5868.33 toks/s, output: 1002.17 toks/s]
Processing batched inference:  50%|█████     | 33/66 [04:55<03:13,  5.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.44 toks/s, output: 40.82 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.34it/s, est. speed input: 5541.75 toks/s, output: 783.87 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.43it/s, est. speed input: 6586.29 toks/s, output: 1173.52 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 20.43it/s, est. speed input: 6586.29 toks/s, output: 1173.52 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.40s/it, est. speed input: 506.40 toks/s, output: 243.76 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 506.40 toks/s, output: 243.76 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [05:22<06:31, 12.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.37 toks/s, output: 40.94 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.75it/s, est. speed input: 7753.38 toks/s, output: 1088.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 8026.99 toks/s, output: 1180.91 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [05:24<04:46,  9.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.95 toks/s, output: 41.01 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.39it/s, est. speed input: 6419.67 toks/s, output: 904.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7970.49 toks/s, output: 1321.77 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [05:27<03:34,  7.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.87 toks/s, output: 41.65 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.19it/s, est. speed input: 7642.87 toks/s, output: 1067.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8182.19 toks/s, output: 1225.25 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [05:29<02:44,  5.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.20 toks/s, output: 41.82 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.61it/s, est. speed input: 7182.13 toks/s, output: 1020.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8152.81 toks/s, output: 1274.68 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [05:31<02:10,  4.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.60 toks/s, output: 41.36 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.87it/s, est. speed input: 5686.03 toks/s, output: 798.85 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.44it/s, est. speed input: 6640.91 toks/s, output: 1179.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6811.93 toks/s, output: 1251.61 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [05:34<01:48,  4.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.73 toks/s, output: 41.63 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.46it/s, est. speed input: 7465.83 toks/s, output: 1051.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8176.79 toks/s, output: 1240.92 toks/s]
Processing batched inference:  61%|██████    | 40/66 [05:36<01:30,  3.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.84 toks/s, output: 41.91 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6537.36 toks/s, output: 920.77 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.88it/s, est. speed input: 6440.08 toks/s, output: 1058.36 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 18.88it/s, est. speed input: 6656.06 toks/s, output: 1139.30 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 505.18 toks/s, output: 240.32 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.18 toks/s, output: 240.32 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [06:03<04:22, 10.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.87 toks/s, output: 41.91 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.48it/s, est. speed input: 7373.27 toks/s, output: 1036.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 8185.24 toks/s, output: 1269.21 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [06:05<03:12,  8.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.06 toks/s, output: 40.77 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.54it/s, est. speed input: 5854.32 toks/s, output: 829.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.14it/s, est. speed input: 7880.12 toks/s, output: 1358.51 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [06:08<02:26,  6.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.42 toks/s, output: 41.20 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.46it/s, est. speed input: 6454.01 toks/s, output: 903.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.39it/s, est. speed input: 7993.54 toks/s, output: 1319.32 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [06:10<01:52,  5.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.52 toks/s, output: 41.48 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.12it/s, est. speed input: 7580.82 toks/s, output: 1062.81 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 24.12it/s, est. speed input: 7852.44 toks/s, output: 1161.31 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 503.65 toks/s, output: 228.72 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.65 toks/s, output: 228.72 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [06:37<04:04, 11.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.94 toks/s, output: 41.01 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.62it/s, est. speed input: 5890.48 toks/s, output: 831.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:12<00:00, 18.62it/s, est. speed input: 7448.84 toks/s, output: 1241.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.06s/it, est. speed input: 491.77 toks/s, output: 236.89 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.88 toks/s, output: 394.35 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [07:04<05:23, 16.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 311.34 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.33it/s, est. speed input: 7029.66 toks/s, output: 994.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 8088.60 toks/s, output: 1287.45 toks/s]
Processing batched inference:  71%|███████   | 47/66 [07:06<03:47, 12.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 311.52 toks/s, output: 41.99 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.31it/s, est. speed input: 7001.90 toks/s, output: 990.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6858.83 toks/s, output: 1116.48 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [07:08<02:44,  9.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.58 toks/s, output: 41.61 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.71it/s, est. speed input: 6224.71 toks/s, output: 882.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.50it/s, est. speed input: 8063.05 toks/s, output: 1355.10 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [07:10<02:00,  7.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.05 toks/s, output: 40.39 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.36it/s, est. speed input: 7414.40 toks/s, output: 1034.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 8033.86 toks/s, output: 1211.26 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [07:13<01:30,  5.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.53 toks/s, output: 41.22 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.56it/s, est. speed input: 6177.48 toks/s, output: 875.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.49it/s, est. speed input: 6768.04 toks/s, output: 1168.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.35it/s, est. speed input: 6768.04 toks/s, output: 1168.46 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [07:15<01:11,  4.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.50 toks/s, output: 41.21 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.69it/s, est. speed input: 5917.14 toks/s, output: 840.23 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.31it/s, est. speed input: 6626.11 toks/s, output: 1156.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6775.57 toks/s, output: 1225.54 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [07:18<00:57,  4.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.92 toks/s, output: 42.01 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.83it/s, est. speed input: 5950.45 toks/s, output: 842.10 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 18.83it/s, est. speed input: 7781.67 toks/s, output: 1325.54 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.02s/it, est. speed input: 505.16 toks/s, output: 239.61 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.16 toks/s, output: 239.61 toks/s]
Processing batched inference:  80%|████████  | 53/66 [07:45<02:22, 10.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.55 toks/s, output: 41.48 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.11it/s, est. speed input: 7603.37 toks/s, output: 1062.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8143.99 toks/s, output: 1223.31 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [07:47<01:39,  8.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.74 toks/s, output: 41.24 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.45it/s, est. speed input: 6449.91 toks/s, output: 910.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 20.45it/s, est. speed input: 7769.74 toks/s, output: 1260.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.05s/it, est. speed input: 504.20 toks/s, output: 235.64 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 504.20 toks/s, output: 235.64 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [08:14<02:32, 13.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.93 toks/s, output: 40.75 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.68it/s, est. speed input: 5594.39 toks/s, output: 796.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.09it/s, est. speed input: 7890.56 toks/s, output: 1400.20 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [08:16<01:44, 10.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.57 toks/s, output: 40.96 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.23it/s, est. speed input: 6674.91 toks/s, output: 940.74 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.23it/s, est. speed input: 6631.85 toks/s, output: 1075.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 503.85 toks/s, output: 235.59 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.85 toks/s, output: 235.59 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [08:43<02:18, 15.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 307.40 toks/s, output: 41.44 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.48it/s, est. speed input: 6105.66 toks/s, output: 864.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.21it/s, est. speed input: 7913.43 toks/s, output: 1341.91 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [08:46<01:31, 11.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.07 toks/s, output: 41.29 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.00it/s, est. speed input: 6935.11 toks/s, output: 976.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:13<00:00, 22.00it/s, est. speed input: 7537.32 toks/s, output: 1144.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.11s/it, est. speed input: 491.61 toks/s, output: 229.99 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 506.73 toks/s, output: 387.62 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [09:12<01:52, 16.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.86 toks/s, output: 41.13 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.55it/s, est. speed input: 6192.81 toks/s, output: 869.20 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 19.55it/s, est. speed input: 7732.98 toks/s, output: 1275.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.03s/it, est. speed input: 505.70 toks/s, output: 237.26 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.70 toks/s, output: 237.26 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [09:39<01:55, 19.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.77 toks/s, output: 40.73 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.26it/s, est. speed input: 6380.73 toks/s, output: 903.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.20it/s, est. speed input: 7940.52 toks/s, output: 1320.41 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [09:42<01:11, 14.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.78 toks/s, output: 40.86 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.23it/s, est. speed input: 6107.80 toks/s, output: 865.69 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.79it/s, est. speed input: 6518.16 toks/s, output: 1092.47 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:17<00:00, 19.79it/s, est. speed input: 6518.16 toks/s, output: 1092.47 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:26<00:01,  1.48s/it, est. speed input: 492.04 toks/s, output: 237.06 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 507.69 toks/s, output: 394.18 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [10:09<01:12, 18.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.53 toks/s, output: 40.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.03it/s, est. speed input: 7887.03 toks/s, output: 1108.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8082.66 toks/s, output: 1164.61 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [10:11<00:39, 13.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.40 toks/s, output: 41.20 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.40it/s, est. speed input: 7081.97 toks/s, output: 996.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 8043.98 toks/s, output: 1249.94 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [10:13<00:19,  9.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 318.99 toks/s, output: 41.41 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6771.34 toks/s, output: 946.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.50it/s, est. speed input: 8088.83 toks/s, output: 1304.47 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [10:15<00:07,  7.65s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.18s/it, est. speed input: 351.50 toks/s, output: 45.63 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.40it/s, est. speed input: 6443.51 toks/s, output: 914.17 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.45it/s, est. speed input: 7605.31 toks/s, output: 1236.14 toks/s]
Processing batched inference: 100%|██████████| 66/66 [10:17<00:00,  5.99s/it]Processing batched inference: 100%|██████████| 66/66 [10:17<00:00,  9.36s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-252/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:42:08.928406810 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-315
INFO 07-05 10:42:21 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:42:23,346 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:42:23,394 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,413 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,413 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,413 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,413 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,413 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,413 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,413 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:42:23,806 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:42:23,807 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:42:23,812 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:42:23,818 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,819 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,819 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,819 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,819 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,819 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,819 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:23,819 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:42:24,192 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:42:24,194 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:42:24,385 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:42:24,830 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:42:24,880 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:42:24,881 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:42:24,882 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:42:36 [config.py:689] This model supports multiple tasks: {'score', 'embed', 'reward', 'classify', 'generate'}. Defaulting to 'generate'.
INFO 07-05 10:42:36 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:36,363 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:36,363 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:36,363 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:36,364 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:36,364 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:36,364 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:36,364 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:42:36,694 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:42:36,795 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:42:36,798 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:42:38 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:42:38 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:42:38 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315...
WARNING 07-05 10:42:38 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:42:38 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.38s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.38s/it]

INFO 07-05 10:42:46 [loader.py:458] Loading weights took 7.59 seconds
INFO 07-05 10:42:46 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.825575 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:46,908 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:46,908 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:46,908 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:46,908 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:46,908 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:46,908 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:46,908 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:42:47,324 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:42:47,421 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:42:47,421 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:42:47,421 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:42:47,422 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:47,423 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:47,423 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:47,423 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:47,423 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:47,423 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:47,423 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:42:47,423 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:42:48,192 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:42:48,192 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:42:48,193 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:42:48,652 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:42:49,288 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:42:49 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:42:52,119 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:42:53,111 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:42:53 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:43:32 [worker.py:267] Memory profiling takes 45.29 seconds
INFO 07-05 10:43:32 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:43:32 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:43:32 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:43:32 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:43:38 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.75it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.90it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.89it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.91it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.94it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.98it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.89it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.91it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.95it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.95it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.94it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.95it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.92it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.94it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.87it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.90it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.92it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.94it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.95it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.96it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.93it/s]
INFO 07-05 10:43:56 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:43:56 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.72 seconds
[INFO|2025-07-05 10:43:56] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:43:57,867 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:43:57,867 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:43:57,868 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:43:57,868 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:43:57,868 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:43:57,868 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:43:57,868 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:43:57,868 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:43:57,868 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:43:59,057 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:43:59,057 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:43:59,058 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:43:59,621 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-315', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.66s/it, est. speed input: 250.26 toks/s, output: 32.48 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 18.39it/s, est. speed input: 5740.91 toks/s, output: 814.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.00it/s, est. speed input: 6639.95 toks/s, output: 1050.15 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:13,  4.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.68 toks/s, output: 42.15 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.56it/s, est. speed input: 7480.80 toks/s, output: 1053.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 8226.57 toks/s, output: 1248.02 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:40,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.34 toks/s, output: 42.10 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 6020.84 toks/s, output: 851.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8112.09 toks/s, output: 1411.11 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:07,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.24 toks/s, output: 41.96 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.23it/s, est. speed input: 7931.52 toks/s, output: 1110.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8205.20 toks/s, output: 1204.14 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:50,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.01 toks/s, output: 42.06 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6571.58 toks/s, output: 926.90 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.27it/s, est. speed input: 1159.98 toks/s, output: 332.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.80it/s, est. speed input: 1159.98 toks/s, output: 332.49 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:24<06:16,  6.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.95 toks/s, output: 42.05 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.27it/s, est. speed input: 7901.29 toks/s, output: 1110.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 8242.62 toks/s, output: 1215.44 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:26<04:54,  4.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.88 toks/s, output: 41.91 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7110.99 toks/s, output: 996.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8178.31 toks/s, output: 1293.51 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:29<04:02,  4.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.51 toks/s, output: 41.99 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.33it/s, est. speed input: 7685.15 toks/s, output: 1082.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8225.03 toks/s, output: 1238.70 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:31<03:26,  3.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.93 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 7034.90 toks/s, output: 995.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8096.04 toks/s, output: 1284.58 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:34<03:01,  3.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.25 toks/s, output: 42.09 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7394.90 toks/s, output: 1038.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6907.17 toks/s, output: 1096.78 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:36<02:48,  3.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.79 toks/s, output: 42.03 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7092.24 toks/s, output: 992.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6887.64 toks/s, output: 1113.54 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:39<02:40,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.87 toks/s, output: 42.04 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.24it/s, est. speed input: 7901.07 toks/s, output: 1119.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 8182.18 toks/s, output: 1219.37 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:41<02:28,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.95 toks/s, output: 42.05 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 7121.23 toks/s, output: 1003.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8189.38 toks/s, output: 1302.12 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:44<02:19,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.64 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.96it/s, est. speed input: 6296.96 toks/s, output: 892.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8132.59 toks/s, output: 1358.50 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:46<02:12,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.01 toks/s, output: 42.06 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 7095.56 toks/s, output: 1002.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8170.58 toks/s, output: 1291.39 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:48<02:06,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.77 toks/s, output: 42.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7378.39 toks/s, output: 1041.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8188.41 toks/s, output: 1274.73 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:51<02:02,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.46 toks/s, output: 41.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.78it/s, est. speed input: 6863.70 toks/s, output: 975.38 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.29it/s, est. speed input: 5945.14 toks/s, output: 1082.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.48it/s, est. speed input: 5945.14 toks/s, output: 1082.82 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:54<02:06,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.00 toks/s, output: 42.06 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7334.67 toks/s, output: 1038.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8147.95 toks/s, output: 1265.43 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:56<02:00,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.11 toks/s, output: 42.44 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 7105.09 toks/s, output: 1002.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8177.42 toks/s, output: 1294.60 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:58<01:56,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 307.42 toks/s, output: 41.14 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.39it/s, est. speed input: 7640.77 toks/s, output: 1083.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.20it/s, est. speed input: 5855.81 toks/s, output: 915.26 toks/s] 
Processing batched inference:  30%|███       | 20/66 [01:01<02:00,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.40 toks/s, output: 40.81 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.03it/s, est. speed input: 6918.40 toks/s, output: 976.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.50it/s, est. speed input: 6799.30 toks/s, output: 1105.20 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:04<01:59,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 316.06 toks/s, output: 41.03 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.09it/s, est. speed input: 5108.18 toks/s, output: 724.26 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.78it/s, est. speed input: 6326.31 toks/s, output: 1154.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5856.08 toks/s, output: 1161.05 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:07<02:02,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.56 toks/s, output: 40.83 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.04it/s, est. speed input: 6955.44 toks/s, output: 978.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 8010.81 toks/s, output: 1258.95 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:09<01:53,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.84 toks/s, output: 40.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.19it/s, est. speed input: 6663.84 toks/s, output: 940.16 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:19<00:00, 21.19it/s, est. speed input: 7470.27 toks/s, output: 1161.32 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.09s/it, est. speed input: 492.89 toks/s, output: 232.22 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 508.04 toks/s, output: 390.16 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:36<06:55,  9.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 313.99 toks/s, output: 40.76 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.26it/s, est. speed input: 6348.99 toks/s, output: 901.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.91it/s, est. speed input: 5235.16 toks/s, output: 911.22 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 13.91it/s, est. speed input: 5235.16 toks/s, output: 911.22 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.44s/it, est. speed input: 502.96 toks/s, output: 241.56 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 502.96 toks/s, output: 241.56 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:03<10:15, 15.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.57 toks/s, output: 40.70 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.11it/s, est. speed input: 6707.64 toks/s, output: 953.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:07<00:00,  3.67it/s, est. speed input: 1828.16 toks/s, output: 419.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.43it/s, est. speed input: 1828.16 toks/s, output: 419.30 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:11<08:38, 12.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.42 toks/s, output: 40.81 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.69it/s, est. speed input: 7736.60 toks/s, output: 1086.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 8015.35 toks/s, output: 1184.58 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:14<06:20,  9.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.62 toks/s, output: 40.84 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.46it/s, est. speed input: 7072.76 toks/s, output: 1000.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.37it/s, est. speed input: 6754.73 toks/s, output: 1078.70 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:16<04:50,  7.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.46 toks/s, output: 41.31 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.19it/s, est. speed input: 6632.08 toks/s, output: 943.97 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.11it/s, est. speed input: 6727.96 toks/s, output: 1148.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.36it/s, est. speed input: 6727.96 toks/s, output: 1148.67 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [02:19<03:46,  6.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 316.32 toks/s, output: 41.06 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.12it/s, est. speed input: 7314.72 toks/s, output: 1027.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8141.00 toks/s, output: 1245.96 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:21<02:58,  4.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.99 toks/s, output: 41.15 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.06it/s, est. speed input: 7222.41 toks/s, output: 1019.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 8039.00 toks/s, output: 1242.91 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [02:23<02:24,  4.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.79 toks/s, output: 40.73 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.01it/s, est. speed input: 6919.80 toks/s, output: 969.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.16it/s, est. speed input: 5852.82 toks/s, output: 968.82 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [02:26<02:07,  3.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.56 toks/s, output: 40.70 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.16it/s, est. speed input: 7034.59 toks/s, output: 997.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.15it/s, est. speed input: 5860.65 toks/s, output: 958.86 toks/s]
Processing batched inference:  50%|█████     | 33/66 [02:29<01:55,  3.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.23 toks/s, output: 40.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.29it/s, est. speed input: 6416.51 toks/s, output: 904.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.22it/s, est. speed input: 7974.21 toks/s, output: 1324.12 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [02:32<01:42,  3.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.00 toks/s, output: 41.15 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.17it/s, est. speed input: 6960.54 toks/s, output: 983.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 8021.52 toks/s, output: 1264.53 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:34<01:31,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.11 toks/s, output: 41.42 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6728.09 toks/s, output: 950.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.19it/s, est. speed input: 6806.32 toks/s, output: 1126.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.50it/s, est. speed input: 6806.32 toks/s, output: 1126.64 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:36<01:24,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.60 toks/s, output: 41.75 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7656.80 toks/s, output: 1069.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8197.74 toks/s, output: 1227.58 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:39<01:16,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 312.24 toks/s, output: 42.09 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.19it/s, est. speed input: 7299.39 toks/s, output: 1035.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.31it/s, est. speed input: 5925.23 toks/s, output: 968.89 toks/s] 
Processing batched inference:  58%|█████▊    | 38/66 [02:42<01:16,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.66 toks/s, output: 41.88 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.04it/s, est. speed input: 5741.15 toks/s, output: 809.10 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.63it/s, est. speed input: 6459.95 toks/s, output: 1130.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.36it/s, est. speed input: 5965.70 toks/s, output: 1140.10 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:44<01:14,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.54 toks/s, output: 42.00 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7404.98 toks/s, output: 1042.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8212.20 toks/s, output: 1271.02 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:47<01:07,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.02 toks/s, output: 41.93 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 7081.34 toks/s, output: 995.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5947.55 toks/s, output: 989.30 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:50<01:06,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.70 toks/s, output: 42.02 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.64it/s, est. speed input: 7104.37 toks/s, output: 1003.40 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 22.64it/s, est. speed input: 7889.79 toks/s, output: 1223.97 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 504.82 toks/s, output: 232.99 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 504.82 toks/s, output: 232.99 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [03:16<03:57,  9.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.81 toks/s, output: 41.51 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.16it/s, est. speed input: 7272.36 toks/s, output: 1022.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 8056.89 toks/s, output: 1247.70 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [03:19<02:55,  7.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.27 toks/s, output: 41.57 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.23it/s, est. speed input: 7290.70 toks/s, output: 1025.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8086.81 toks/s, output: 1243.36 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [03:21<02:12,  6.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.55 toks/s, output: 41.61 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.96it/s, est. speed input: 8122.55 toks/s, output: 1140.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8133.84 toks/s, output: 1172.01 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:23<01:42,  4.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.76 toks/s, output: 41.77 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.65it/s, est. speed input: 6513.30 toks/s, output: 917.84 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.08it/s, est. speed input: 5572.36 toks/s, output: 951.87 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:16<00:00, 15.08it/s, est. speed input: 5572.36 toks/s, output: 951.87 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.49s/it, est. speed input: 493.82 toks/s, output: 239.88 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.24it/s, est. speed input: 508.99 toks/s, output: 398.00 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [03:50<03:47, 11.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 310.97 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.12it/s, est. speed input: 7579.28 toks/s, output: 1070.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8119.33 toks/s, output: 1232.91 toks/s]
Processing batched inference:  71%|███████   | 47/66 [03:52<02:44,  8.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 310.53 toks/s, output: 41.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.10it/s, est. speed input: 7538.80 toks/s, output: 1063.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6879.79 toks/s, output: 1071.84 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [03:54<02:02,  6.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.19 toks/s, output: 41.30 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6785.47 toks/s, output: 957.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.46it/s, est. speed input: 8046.72 toks/s, output: 1293.98 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [03:57<01:32,  5.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 311.55 toks/s, output: 40.44 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.53it/s, est. speed input: 7694.05 toks/s, output: 1077.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8086.72 toks/s, output: 1185.01 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [03:59<01:12,  4.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 310.31 toks/s, output: 40.28 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.22it/s, est. speed input: 6062.67 toks/s, output: 861.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 18.99it/s, est. speed input: 7859.36 toks/s, output: 1325.42 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [04:01<00:57,  3.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.11 toks/s, output: 41.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.17it/s, est. speed input: 6991.76 toks/s, output: 985.76 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 22.17it/s, est. speed input: 6617.34 toks/s, output: 1057.78 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 506.85 toks/s, output: 235.54 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.85 toks/s, output: 235.54 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [04:28<02:30, 10.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 312.23 toks/s, output: 41.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.21it/s, est. speed input: 6697.34 toks/s, output: 943.68 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.06it/s, est. speed input: 3187.34 toks/s, output: 615.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.70it/s, est. speed input: 3187.34 toks/s, output: 615.61 toks/s]
Processing batched inference:  80%|████████  | 53/66 [04:33<01:56,  8.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.79 toks/s, output: 41.25 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.79it/s, est. speed input: 8117.88 toks/s, output: 1134.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.21it/s, est. speed input: 8379.77 toks/s, output: 1196.83 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [04:35<01:22,  6.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.13 toks/s, output: 41.17 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.30it/s, est. speed input: 6714.15 toks/s, output: 943.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 21.30it/s, est. speed input: 7773.24 toks/s, output: 1234.72 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 505.73 toks/s, output: 234.67 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.73 toks/s, output: 234.67 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [05:02<02:21, 12.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.83 toks/s, output: 40.74 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.27it/s, est. speed input: 6395.94 toks/s, output: 907.60 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.48it/s, est. speed input: 6552.14 toks/s, output: 1095.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 19.48it/s, est. speed input: 6552.14 toks/s, output: 1095.67 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.44s/it, est. speed input: 506.43 toks/s, output: 239.01 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.43 toks/s, output: 239.01 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [05:29<02:51, 17.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.77 toks/s, output: 40.73 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.87it/s, est. speed input: 7166.41 toks/s, output: 1007.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.31it/s, est. speed input: 7964.12 toks/s, output: 1230.81 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [05:31<01:54, 12.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.36 toks/s, output: 41.30 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.21it/s, est. speed input: 6629.35 toks/s, output: 935.78 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.03it/s, est. speed input: 6721.79 toks/s, output: 1116.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.32it/s, est. speed input: 6721.79 toks/s, output: 1116.38 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [05:34<01:17,  9.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.53 toks/s, output: 41.48 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.31it/s, est. speed input: 7017.90 toks/s, output: 987.33 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:15<00:00, 22.31it/s, est. speed input: 7568.52 toks/s, output: 1148.01 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.11s/it, est. speed input: 493.20 toks/s, output: 230.65 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.24it/s, est. speed input: 508.36 toks/s, output: 388.79 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [06:00<01:43, 14.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.19 toks/s, output: 41.17 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.55it/s, est. speed input: 6494.70 toks/s, output: 911.24 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 20.55it/s, est. speed input: 7788.58 toks/s, output: 1255.08 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.04s/it, est. speed input: 507.26 toks/s, output: 236.12 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 507.26 toks/s, output: 236.12 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [06:27<01:50, 18.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 306.95 toks/s, output: 41.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.09it/s, est. speed input: 6624.64 toks/s, output: 938.70 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.16it/s, est. speed input: 7925.71 toks/s, output: 1288.01 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [06:30<01:07, 13.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 305.59 toks/s, output: 41.19 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.29it/s, est. speed input: 6394.38 toks/s, output: 905.35 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.46it/s, est. speed input: 6531.17 toks/s, output: 1114.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.30it/s, est. speed input: 6743.08 toks/s, output: 1194.23 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [06:32<00:41, 10.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.80 toks/s, output: 40.86 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.68it/s, est. speed input: 7758.19 toks/s, output: 1088.92 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 24.68it/s, est. speed input: 7899.31 toks/s, output: 1136.12 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 506.27 toks/s, output: 227.50 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.27 toks/s, output: 227.50 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [06:59<00:45, 15.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.68 toks/s, output: 40.98 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.10it/s, est. speed input: 6938.46 toks/s, output: 977.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6767.39 toks/s, output: 1098.18 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [07:02<00:22, 11.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.57 toks/s, output: 41.48 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.79it/s, est. speed input: 5963.40 toks/s, output: 841.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 8052.69 toks/s, output: 1381.74 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [07:04<00:08,  8.69s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.18s/it, est. speed input: 348.39 toks/s, output: 45.77 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.49it/s, est. speed input: 6779.59 toks/s, output: 963.01 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.52it/s, est. speed input: 7633.57 toks/s, output: 1203.03 toks/s]
Processing batched inference: 100%|██████████| 66/66 [07:06<00:00,  6.73s/it]Processing batched inference: 100%|██████████| 66/66 [07:06<00:00,  6.46s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-315/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:51:05.254181866 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-378
INFO 07-05 10:51:17 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:51:19,523 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:51:19,566 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,585 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,585 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,585 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,585 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,585 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,585 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,585 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:51:19,974 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:51:19,975 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:51:19,980 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:51:19,986 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,987 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,987 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,987 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,987 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,987 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,987 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:19,988 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:51:20,359 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:51:20,361 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:51:20,555 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:51:21,006 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:51:21,056 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:51:21,056 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:51:21,058 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:51:32 [config.py:689] This model supports multiple tasks: {'embed', 'reward', 'score', 'classify', 'generate'}. Defaulting to 'generate'.
INFO 07-05 10:51:32 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:32,598 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:32,598 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:32,598 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:32,598 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:32,598 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:32,598 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:32,599 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:51:32,932 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:51:33,033 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:51:33,036 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:51:34 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:51:34 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:51:34 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378...
WARNING 07-05 10:51:34 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:51:35 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.36s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.36s/it]

INFO 07-05 10:51:42 [loader.py:458] Loading weights took 7.57 seconds
INFO 07-05 10:51:42 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.804085 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,131 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,131 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,131 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,131 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,131 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,131 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,131 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:51:43,541 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:51:43,637 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:51:43,637 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:51:43,637 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:51:43,638 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,639 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,639 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,639 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,639 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,639 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,639 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:51:43,639 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:51:44,397 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:51:44,398 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:51:44,398 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:51:44,847 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:51:45,486 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:51:46 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:51:48,320 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:51:49,324 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:51:49 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:52:28 [worker.py:267] Memory profiling takes 45.34 seconds
INFO 07-05 10:52:28 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:52:28 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:52:28 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:52:28 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:52:36 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.75it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.92it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.93it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.95it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.96it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.93it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:12,  1.91it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.92it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.95it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.96it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.96it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.95it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.96it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.97it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.96it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.88it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.91it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.93it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.94it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.95it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.92it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.93it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.87it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.93it/s]
INFO 07-05 10:52:54 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:52:54 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 71.59 seconds
[INFO|2025-07-05 10:52:55] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:52:55,918 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:52:55,918 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:52:55,919 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:52:55,919 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:52:55,919 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:52:55,920 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:52:55,920 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:52:55,920 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:52:55,920 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:52:57,155 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:52:57,156 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:52:57,156 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:52:57,707 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-378', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it, est. speed input: 253.72 toks/s, output: 32.93 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.15it/s, est. speed input: 6331.37 toks/s, output: 892.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.28it/s, est. speed input: 6753.75 toks/s, output: 1001.51 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:06,  4.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.56 toks/s, output: 42.13 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.24it/s, est. speed input: 7341.14 toks/s, output: 1031.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8205.35 toks/s, output: 1272.70 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:35,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.40 toks/s, output: 42.11 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.44it/s, est. speed input: 6199.25 toks/s, output: 876.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8128.61 toks/s, output: 1386.37 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:05,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.05 toks/s, output: 41.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 24.30it/s, est. speed input: 10049.79 toks/s, output: 1369.28 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:11<02:42,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 321.30 toks/s, output: 41.43 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7669.51 toks/s, output: 1073.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 8213.75 toks/s, output: 1240.05 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:14<02:36,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.51 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.35it/s, est. speed input: 7982.36 toks/s, output: 1121.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 8177.37 toks/s, output: 1179.10 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:16<02:30,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.44 toks/s, output: 41.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.86it/s, est. speed input: 8171.40 toks/s, output: 1143.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 8243.70 toks/s, output: 1183.96 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:19<02:26,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.96 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7681.47 toks/s, output: 1080.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8215.41 toks/s, output: 1237.87 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:21<02:23,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.01 toks/s, output: 41.93 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 25.69it/s, est. speed input: 8101.91 toks/s, output: 1142.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8101.91 toks/s, output: 1142.33 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:23<02:19,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.56 toks/s, output: 42.00 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.12it/s, est. speed input: 7966.87 toks/s, output: 1119.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.90it/s, est. speed input: 8225.35 toks/s, output: 1186.06 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:26<02:16,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.90 toks/s, output: 42.04 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.90it/s, est. speed input: 7546.73 toks/s, output: 1055.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6918.49 toks/s, output: 1069.85 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:28<02:18,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.37 toks/s, output: 42.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.07it/s, est. speed input: 8227.90 toks/s, output: 1166.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.99it/s, est. speed input: 8227.90 toks/s, output: 1166.84 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:31<02:13,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.38 toks/s, output: 40.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.16it/s, est. speed input: 6679.66 toks/s, output: 940.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.26it/s, est. speed input: 7982.94 toks/s, output: 1298.18 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:33<02:12,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.67 toks/s, output: 40.85 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.58it/s, est. speed input: 8028.44 toks/s, output: 1119.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 8042.10 toks/s, output: 1150.77 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:36<02:12,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.89 toks/s, output: 40.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.85it/s, est. speed input: 7495.82 toks/s, output: 1050.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 8019.42 toks/s, output: 1212.89 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:39<02:11,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.31 toks/s, output: 40.93 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.19it/s, est. speed input: 7338.93 toks/s, output: 1037.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 8044.38 toks/s, output: 1224.36 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:41<02:11,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.19 toks/s, output: 40.78 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.23it/s, est. speed input: 6990.49 toks/s, output: 991.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.33it/s, est. speed input: 7931.47 toks/s, output: 1240.47 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:44<02:08,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.42 toks/s, output: 40.94 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.88it/s, est. speed input: 7455.02 toks/s, output: 1054.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 7997.30 toks/s, output: 1215.90 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:47<02:06,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 313.98 toks/s, output: 40.76 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.43it/s, est. speed input: 7108.09 toks/s, output: 999.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.31it/s, est. speed input: 8010.48 toks/s, output: 1243.43 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:49<02:04,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 306.68 toks/s, output: 41.04 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.59it/s, est. speed input: 7080.07 toks/s, output: 1004.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.26it/s, est. speed input: 6706.34 toks/s, output: 1074.10 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:52<02:04,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.53 toks/s, output: 40.83 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.62it/s, est. speed input: 7707.79 toks/s, output: 1085.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.38it/s, est. speed input: 7988.96 toks/s, output: 1183.50 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:55<02:00,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.34 toks/s, output: 40.93 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.59it/s, est. speed input: 5888.26 toks/s, output: 830.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.19it/s, est. speed input: 7953.22 toks/s, output: 1373.51 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [00:58<01:57,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.03 toks/s, output: 40.76 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.80it/s, est. speed input: 7496.30 toks/s, output: 1048.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.40it/s, est. speed input: 6801.03 toks/s, output: 1047.29 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:00<01:54,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 310.90 toks/s, output: 40.36 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 23.90it/s, est. speed input: 7522.76 toks/s, output: 1057.81 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 23.90it/s, est. speed input: 7690.66 toks/s, output: 1110.69 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 504.05 toks/s, output: 227.33 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 504.05 toks/s, output: 227.33 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:27<06:57,  9.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.94 toks/s, output: 40.75 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.73it/s, est. speed input: 7122.21 toks/s, output: 1005.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.82it/s, est. speed input: 1981.90 toks/s, output: 432.00 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:34<06:14,  9.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.63 toks/s, output: 40.58 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.07it/s, est. speed input: 6693.48 toks/s, output: 951.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.21it/s, est. speed input: 2876.24 toks/s, output: 565.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s, est. speed input: 2876.24 toks/s, output: 565.62 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:40<05:19,  7.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.33 toks/s, output: 40.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.49it/s, est. speed input: 7981.50 toks/s, output: 1120.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7996.17 toks/s, output: 1152.07 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:42<04:05,  6.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.97 toks/s, output: 40.63 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.82it/s, est. speed input: 7213.27 toks/s, output: 1020.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.31it/s, est. speed input: 7967.38 toks/s, output: 1214.42 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:44<03:13,  5.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.05 toks/s, output: 40.51 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.33it/s, est. speed input: 7007.49 toks/s, output: 995.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.22it/s, est. speed input: 7903.75 toks/s, output: 1238.31 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:47<02:37,  4.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 316.10 toks/s, output: 41.03 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.36it/s, est. speed input: 8336.76 toks/s, output: 1162.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.03it/s, est. speed input: 8336.76 toks/s, output: 1162.60 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:49<02:10,  3.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.88 toks/s, output: 40.87 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.59it/s, est. speed input: 7984.34 toks/s, output: 1121.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 8028.88 toks/s, output: 1156.56 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:51<01:52,  3.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.82 toks/s, output: 40.87 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.07it/s, est. speed input: 6938.78 toks/s, output: 972.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.33it/s, est. speed input: 7988.20 toks/s, output: 1263.10 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:53<01:39,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.01 toks/s, output: 40.63 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 23.63it/s, est. speed input: 7504.89 toks/s, output: 1062.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 8004.02 toks/s, output: 1191.21 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:56<01:30,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.46 toks/s, output: 40.69 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.18it/s, est. speed input: 7048.95 toks/s, output: 993.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.24it/s, est. speed input: 5910.87 toks/s, output: 961.92 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:59<01:29,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.37 toks/s, output: 40.81 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.71it/s, est. speed input: 7737.29 toks/s, output: 1086.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 8012.41 toks/s, output: 1178.77 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:01<01:21,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.38 toks/s, output: 41.46 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.19it/s, est. speed input: 7278.26 toks/s, output: 1022.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.59it/s, est. speed input: 8079.17 toks/s, output: 1252.26 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:03<01:15,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.79 toks/s, output: 41.64 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.08it/s, est. speed input: 7917.04 toks/s, output: 1105.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.02it/s, est. speed input: 8315.41 toks/s, output: 1214.54 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:05<01:10,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.69 toks/s, output: 41.76 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.58it/s, est. speed input: 7174.13 toks/s, output: 1018.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6874.20 toks/s, output: 1100.72 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:08<01:09,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.71 toks/s, output: 41.89 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.23it/s, est. speed input: 5848.45 toks/s, output: 822.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 8111.86 toks/s, output: 1406.88 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:10<01:05,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.28 toks/s, output: 41.96 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.22it/s, est. speed input: 7963.59 toks/s, output: 1119.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 8241.37 toks/s, output: 1219.08 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:12<01:01,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.52 toks/s, output: 41.48 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.18it/s, est. speed input: 7289.84 toks/s, output: 1024.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6833.51 toks/s, output: 1085.50 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:15<01:00,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.46 toks/s, output: 41.99 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.38it/s, est. speed input: 8229.63 toks/s, output: 1156.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.01it/s, est. speed input: 8235.42 toks/s, output: 1186.30 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:17<00:56,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 316.09 toks/s, output: 41.03 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.90it/s, est. speed input: 7491.56 toks/s, output: 1052.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.46it/s, est. speed input: 8011.78 toks/s, output: 1211.52 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:19<00:54,  2.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.52 toks/s, output: 41.73 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.88it/s, est. speed input: 7811.23 toks/s, output: 1092.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8152.18 toks/s, output: 1200.26 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:22<00:51,  2.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.32 toks/s, output: 41.71 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 25.66it/s, est. speed input: 8121.23 toks/s, output: 1142.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 8121.23 toks/s, output: 1142.48 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:24<00:48,  2.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.25 toks/s, output: 41.83 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7094.72 toks/s, output: 997.52 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 22.54it/s, est. speed input: 1147.83 toks/s, output: 324.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.06s/it, est. speed input: 508.11 toks/s, output: 297.00 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 508.11 toks/s, output: 297.00 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:51<03:11,  9.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.71 toks/s, output: 41.76 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.76it/s, est. speed input: 7521.67 toks/s, output: 1062.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8179.45 toks/s, output: 1242.65 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:53<02:19,  7.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.11 toks/s, output: 41.81 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.02it/s, est. speed input: 7901.91 toks/s, output: 1117.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8157.57 toks/s, output: 1183.59 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:55<01:45,  5.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.15 toks/s, output: 41.69 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.47it/s, est. speed input: 7379.85 toks/s, output: 1035.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8116.32 toks/s, output: 1248.13 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:57<01:20,  4.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.86 toks/s, output: 41.78 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.25it/s, est. speed input: 7631.27 toks/s, output: 1069.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.05it/s, est. speed input: 8292.67 toks/s, output: 1245.27 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:59<01:04,  4.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.12 toks/s, output: 41.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.54it/s, est. speed input: 6800.04 toks/s, output: 957.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8123.17 toks/s, output: 1317.15 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [03:02<00:52,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.61 toks/s, output: 41.88 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.17it/s, est. speed input: 7915.19 toks/s, output: 1117.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8193.49 toks/s, output: 1216.32 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [03:04<00:43,  3.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 317.98 toks/s, output: 41.78 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.42it/s, est. speed input: 7077.11 toks/s, output: 995.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8137.60 toks/s, output: 1287.85 toks/s]
Processing batched inference:  80%|████████  | 53/66 [03:06<00:36,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.99 toks/s, output: 41.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.10it/s, est. speed input: 8223.39 toks/s, output: 1146.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 8231.28 toks/s, output: 1178.10 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [03:08<00:31,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.07 toks/s, output: 41.68 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.36it/s, est. speed input: 7051.12 toks/s, output: 990.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.73it/s, est. speed input: 6908.70 toks/s, output: 1119.12 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:11<00:28,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.49 toks/s, output: 41.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.45it/s, est. speed input: 7068.49 toks/s, output: 999.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6867.35 toks/s, output: 1121.53 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:13<00:25,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.91 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.33it/s, est. speed input: 7627.67 toks/s, output: 1069.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8175.33 toks/s, output: 1236.20 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:16<00:22,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.31 toks/s, output: 41.84 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6503.97 toks/s, output: 917.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8081.08 toks/s, output: 1341.52 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:18<00:19,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.94 toks/s, output: 41.92 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.12it/s, est. speed input: 7278.13 toks/s, output: 1025.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:20<00:00, 23.12it/s, est. speed input: 7882.23 toks/s, output: 1194.60 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.08s/it, est. speed input: 504.29 toks/s, output: 231.02 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 504.29 toks/s, output: 231.02 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:45<01:08,  9.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.07 toks/s, output: 41.94 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.51it/s, est. speed input: 7407.35 toks/s, output: 1034.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8184.44 toks/s, output: 1259.37 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:47<00:44,  7.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 317.75 toks/s, output: 42.52 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6816.57 toks/s, output: 967.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8148.50 toks/s, output: 1324.22 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:49<00:29,  5.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.50 toks/s, output: 41.86 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.47it/s, est. speed input: 6482.28 toks/s, output: 919.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8117.13 toks/s, output: 1348.04 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:52<00:19,  4.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.61 toks/s, output: 41.88 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.66it/s, est. speed input: 7800.29 toks/s, output: 1094.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 24.66it/s, est. speed input: 7940.59 toks/s, output: 1144.53 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 506.30 toks/s, output: 227.66 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.30 toks/s, output: 227.66 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [04:18<00:34, 11.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.20 toks/s, output: 41.82 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.15it/s, est. speed input: 7892.48 toks/s, output: 1108.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8173.77 toks/s, output: 1207.62 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [04:21<00:17,  8.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.42 toks/s, output: 41.57 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.46it/s, est. speed input: 6790.78 toks/s, output: 948.95 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.19it/s, est. speed input: 6854.15 toks/s, output: 1130.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6854.15 toks/s, output: 1130.13 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [04:23<00:06,  6.83s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 354.83 toks/s, output: 46.62 toks/s][A
Processed prompts:  93%|█████████▎| 26/28 [00:01<00:00, 23.63it/s, est. speed input: 7463.69 toks/s, output: 1055.08 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.88it/s, est. speed input: 7782.96 toks/s, output: 1165.21 toks/s]
Processing batched inference: 100%|██████████| 66/66 [04:25<00:00,  5.40s/it]Processing batched inference: 100%|██████████| 66/66 [04:25<00:00,  4.03s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-378/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 10:57:22.533933978 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-441
INFO 07-05 10:57:35 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 10:57:37,132 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 10:57:37,177 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,201 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,201 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,201 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,201 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,201 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,201 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,201 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:57:37,599 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:57:37,601 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 10:57:37,607 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:57:37,614 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,616 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,616 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,616 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,616 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,616 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,616 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:37,616 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:57:37,992 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:57:37,995 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:57:38,213 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:57:38,648 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 10:57:38,706 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/config.json
[INFO|configuration_utils.py:696] 2025-07-05 10:57:38,706 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/config.json
[INFO|configuration_utils.py:770] 2025-07-05 10:57:38,708 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 10:57:50 [config.py:689] This model supports multiple tasks: {'embed', 'generate', 'reward', 'classify', 'score'}. Defaulting to 'generate'.
INFO 07-05 10:57:50 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:50,153 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:50,153 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:50,153 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:50,153 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:50,153 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:50,153 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:57:50,153 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:57:50,484 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 10:57:50,584 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 10:57:50,587 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 10:57:51 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 10:57:52 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 10:57:52 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441...
WARNING 07-05 10:57:52 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 10:57:52 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.26s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.26s/it]

INFO 07-05 10:58:00 [loader.py:458] Loading weights took 7.47 seconds
INFO 07-05 10:58:00 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.719699 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:00,571 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:00,571 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:00,571 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:00,571 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:00,571 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:00,571 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:00,571 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:58:00,990 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 10:58:01,086 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:58:01,086 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 10:58:01,087 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:58:01,087 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:01,088 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:01,088 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:01,088 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:01,088 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:01,088 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:01,088 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:58:01,088 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:58:01,839 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:58:01,840 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:58:01,840 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:58:02,293 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 10:58:02,956 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 10:58:03 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 10:58:05,793 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 10:58:06,806 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 10:58:07 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 10:58:46 [worker.py:267] Memory profiling takes 45.47 seconds
INFO 07-05 10:58:46 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 10:58:46 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 10:58:46 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 10:58:46 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 10:58:51 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:21,  1.58it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.78it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.86it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.90it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.90it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.92it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.96it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.96it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.92it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.94it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.95it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.95it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.90it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.92it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.92it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.84it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.87it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.90it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.92it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.93it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.94it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.90it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 10:59:09 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 10:59:09 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.28 seconds
[INFO|2025-07-05 10:59:10] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 10:59:11,039 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 10:59:11,039 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:59:11,040 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:59:11,040 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:59:11,040 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:59:11,040 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:59:11,040 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:59:11,040 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 10:59:11,040 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 10:59:12,225 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 10:59:12,225 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 10:59:12,226 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 10:59:12,789 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-441', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.63s/it, est. speed input: 254.80 toks/s, output: 33.07 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 19.40it/s, est. speed input: 6057.75 toks/s, output: 856.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.27it/s, est. speed input: 6752.50 toks/s, output: 1044.55 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:11,  4.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.01 toks/s, output: 42.19 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.64it/s, est. speed input: 7201.67 toks/s, output: 1013.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.71it/s, est. speed input: 5258.62 toks/s, output: 875.64 toks/s] 
Processing batched inference:   3%|▎         | 2/66 [00:08<04:11,  3.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.72 toks/s, output: 42.15 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6848.79 toks/s, output: 969.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.45it/s, est. speed input: 6923.29 toks/s, output: 1179.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6923.29 toks/s, output: 1179.75 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:10<03:32,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.45 toks/s, output: 42.12 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.82it/s, est. speed input: 8447.36 toks/s, output: 1179.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.42it/s, est. speed input: 8447.36 toks/s, output: 1179.67 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:13<03:04,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.64 toks/s, output: 42.01 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6837.40 toks/s, output: 963.24 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.39it/s, est. speed input: 5500.28 toks/s, output: 945.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.28it/s, est. speed input: 5500.28 toks/s, output: 945.34 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:16<03:07,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.69 toks/s, output: 40.98 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.76it/s, est. speed input: 7731.22 toks/s, output: 1085.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 8009.04 toks/s, output: 1182.21 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:18<02:52,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.07 toks/s, output: 42.20 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.06it/s, est. speed input: 7925.88 toks/s, output: 1109.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 8267.17 toks/s, output: 1217.86 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:21<02:40,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.91 toks/s, output: 42.05 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.12it/s, est. speed input: 8242.93 toks/s, output: 1154.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 8248.58 toks/s, output: 1185.72 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:23<02:31,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.94 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7590.92 toks/s, output: 1067.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8122.95 toks/s, output: 1233.16 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:26<02:23,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.05 toks/s, output: 42.19 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.33it/s, est. speed input: 7960.28 toks/s, output: 1117.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 8241.26 toks/s, output: 1217.02 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:28<02:18,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.13 toks/s, output: 42.07 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6824.67 toks/s, output: 954.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8149.73 toks/s, output: 1318.21 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:30<02:15,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.28 toks/s, output: 42.09 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.31it/s, est. speed input: 7984.98 toks/s, output: 1132.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.03it/s, est. speed input: 8243.59 toks/s, output: 1197.85 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:33<02:10,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.90 toks/s, output: 42.04 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7398.15 toks/s, output: 1040.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8204.12 toks/s, output: 1273.54 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:35<02:06,  2.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.47 toks/s, output: 41.73 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.37it/s, est. speed input: 7654.98 toks/s, output: 1074.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.35it/s, est. speed input: 8418.08 toks/s, output: 1258.63 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:37<02:02,  2.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.06 toks/s, output: 42.06 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.44it/s, est. speed input: 7387.03 toks/s, output: 1037.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.83it/s, est. speed input: 6950.36 toks/s, output: 1098.00 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:40<02:04,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.58 toks/s, output: 42.00 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7660.62 toks/s, output: 1080.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 8206.19 toks/s, output: 1246.51 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:42<02:00,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.96 toks/s, output: 41.92 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.67it/s, est. speed input: 7143.59 toks/s, output: 1013.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.56it/s, est. speed input: 5977.42 toks/s, output: 979.01 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [00:45<02:06,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.19 toks/s, output: 42.08 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.35it/s, est. speed input: 7616.35 toks/s, output: 1078.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8160.98 toks/s, output: 1237.69 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:48<02:00,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.74 toks/s, output: 42.02 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.34it/s, est. speed input: 7681.46 toks/s, output: 1080.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8226.59 toks/s, output: 1244.12 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:50<01:55,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.95 toks/s, output: 42.41 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.50it/s, est. speed input: 7418.25 toks/s, output: 1053.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8102.57 toks/s, output: 1239.41 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:52<01:51,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.88 toks/s, output: 42.04 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7362.35 toks/s, output: 1036.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.85it/s, est. speed input: 6944.55 toks/s, output: 1104.59 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:55<01:51,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.21 toks/s, output: 40.79 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.69it/s, est. speed input: 5611.28 toks/s, output: 791.40 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.10it/s, est. speed input: 6524.55 toks/s, output: 1159.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.25it/s, est. speed input: 6734.78 toks/s, output: 1238.26 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [00:58<01:52,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.12 toks/s, output: 40.78 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.80it/s, est. speed input: 7496.01 toks/s, output: 1048.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6796.00 toks/s, output: 1046.52 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:00<01:50,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.26 toks/s, output: 40.79 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 23.74it/s, est. speed input: 7503.18 toks/s, output: 1055.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  6.19it/s, est. speed input: 2548.08 toks/s, output: 488.73 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:06<02:29,  3.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.61 toks/s, output: 40.84 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 21.99it/s, est. speed input: 6953.50 toks/s, output: 985.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.81it/s, est. speed input: 1978.22 toks/s, output: 437.97 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:13<03:12,  4.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.15 toks/s, output: 40.78 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 22.87it/s, est. speed input: 7241.55 toks/s, output: 1028.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7995.29 toks/s, output: 1223.10 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:16<02:39,  3.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.50 toks/s, output: 40.69 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.76it/s, est. speed input: 7447.11 toks/s, output: 1047.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.34it/s, est. speed input: 7984.13 toks/s, output: 1206.56 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:18<02:15,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.08 toks/s, output: 40.64 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.82it/s, est. speed input: 7151.46 toks/s, output: 1011.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.26it/s, est. speed input: 7945.97 toks/s, output: 1237.04 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:20<02:00,  3.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.53 toks/s, output: 40.70 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.33it/s, est. speed input: 6730.35 toks/s, output: 955.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.25it/s, est. speed input: 7917.20 toks/s, output: 1269.30 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:23<01:47,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.29 toks/s, output: 41.32 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.04it/s, est. speed input: 7909.36 toks/s, output: 1107.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.19it/s, est. speed input: 8403.14 toks/s, output: 1228.03 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:25<01:36,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.41 toks/s, output: 40.94 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.73it/s, est. speed input: 7736.03 toks/s, output: 1085.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8060.49 toks/s, output: 1189.90 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:27<01:29,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.76 toks/s, output: 41.12 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.04it/s, est. speed input: 7241.49 toks/s, output: 1014.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 8038.15 toks/s, output: 1241.82 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:29<01:23,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.65 toks/s, output: 40.71 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.16it/s, est. speed input: 7033.74 toks/s, output: 997.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.27it/s, est. speed input: 7984.35 toks/s, output: 1247.30 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:32<01:19,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.94 toks/s, output: 40.75 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.55it/s, est. speed input: 6841.45 toks/s, output: 964.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.26it/s, est. speed input: 7993.44 toks/s, output: 1270.73 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:34<01:17,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.12 toks/s, output: 41.42 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.18it/s, est. speed input: 7290.33 toks/s, output: 1025.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 8077.90 toks/s, output: 1245.28 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:36<01:13,  2.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.37 toks/s, output: 41.59 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.48it/s, est. speed input: 6748.98 toks/s, output: 951.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8070.43 toks/s, output: 1308.38 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:39<01:09,  2.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.89 toks/s, output: 41.65 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.06it/s, est. speed input: 7913.59 toks/s, output: 1104.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.01it/s, est. speed input: 8311.67 toks/s, output: 1214.00 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:41<01:06,  2.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.32 toks/s, output: 41.71 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.10it/s, est. speed input: 7660.64 toks/s, output: 1086.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6892.90 toks/s, output: 1053.23 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:43<01:06,  2.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.98 toks/s, output: 41.79 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.88it/s, est. speed input: 6002.85 toks/s, output: 842.26 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.06it/s, est. speed input: 6888.80 toks/s, output: 1216.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6888.80 toks/s, output: 1216.52 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:46<01:05,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.25 toks/s, output: 41.70 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.49it/s, est. speed input: 6809.02 toks/s, output: 960.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.19it/s, est. speed input: 6864.21 toks/s, output: 1139.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6864.21 toks/s, output: 1139.38 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:48<01:03,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.15 toks/s, output: 41.69 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.40it/s, est. speed input: 7047.62 toks/s, output: 990.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.23it/s, est. speed input: 4224.53 toks/s, output: 764.69 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:52<01:11,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.57 toks/s, output: 41.48 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.24it/s, est. speed input: 7872.25 toks/s, output: 1107.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8149.97 toks/s, output: 1203.08 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [01:54<01:04,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.80 toks/s, output: 41.51 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.12it/s, est. speed input: 7561.21 toks/s, output: 1060.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8087.40 toks/s, output: 1224.80 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [01:57<00:59,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.67 toks/s, output: 41.76 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.11it/s, est. speed input: 7872.85 toks/s, output: 1102.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8143.20 toks/s, output: 1197.08 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [01:59<00:54,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.17 toks/s, output: 41.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.08it/s, est. speed input: 8167.30 toks/s, output: 1146.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.84it/s, est. speed input: 8175.97 toks/s, output: 1178.08 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:01<00:49,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.30 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.79it/s, est. speed input: 6851.45 toks/s, output: 963.72 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:17<00:00, 21.79it/s, est. speed input: 5586.09 toks/s, output: 909.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.10s/it, est. speed input: 492.09 toks/s, output: 235.20 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 507.20 toks/s, output: 392.76 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:28<03:13,  9.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.40 toks/s, output: 41.07 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.30it/s, est. speed input: 7683.45 toks/s, output: 1083.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.50it/s, est. speed input: 8075.68 toks/s, output: 1198.24 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:30<02:21,  7.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.34 toks/s, output: 42.37 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.32it/s, est. speed input: 7600.16 toks/s, output: 1074.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8139.68 toks/s, output: 1236.61 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:32<01:45,  5.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.39 toks/s, output: 41.85 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6531.04 toks/s, output: 923.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8114.84 toks/s, output: 1334.37 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:35<01:21,  4.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.63 toks/s, output: 41.88 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.40it/s, est. speed input: 7680.44 toks/s, output: 1073.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.93it/s, est. speed input: 8239.81 toks/s, output: 1237.95 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:37<01:04,  4.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.33 toks/s, output: 41.97 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6272.66 toks/s, output: 890.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8116.73 toks/s, output: 1369.43 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:39<00:52,  3.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.05 toks/s, output: 41.80 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.52it/s, est. speed input: 6802.93 toks/s, output: 959.56 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.32it/s, est. speed input: 6867.59 toks/s, output: 1168.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6867.59 toks/s, output: 1168.47 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:42<00:44,  3.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 317.90 toks/s, output: 41.77 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.67it/s, est. speed input: 6529.74 toks/s, output: 919.18 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 20.67it/s, est. speed input: 7857.24 toks/s, output: 1281.47 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.05s/it, est. speed input: 505.45 toks/s, output: 236.20 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.45 toks/s, output: 236.20 toks/s]
Processing batched inference:  80%|████████  | 53/66 [03:09<02:13, 10.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.27 toks/s, output: 41.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.90it/s, est. speed input: 8160.61 toks/s, output: 1137.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8168.13 toks/s, output: 1168.45 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [03:11<01:34,  7.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.20 toks/s, output: 41.69 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.28it/s, est. speed input: 7319.19 toks/s, output: 1029.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8123.21 toks/s, output: 1256.86 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:13<01:08,  6.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.04 toks/s, output: 41.67 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.92it/s, est. speed input: 6936.97 toks/s, output: 982.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.01it/s, est. speed input: 5921.09 toks/s, output: 989.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.32it/s, est. speed input: 5921.09 toks/s, output: 989.83 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:16<00:51,  5.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.02 toks/s, output: 41.67 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.38it/s, est. speed input: 7026.19 toks/s, output: 990.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8096.43 toks/s, output: 1280.09 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:18<00:38,  4.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 312.12 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.50it/s, est. speed input: 6729.35 toks/s, output: 949.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8050.87 toks/s, output: 1306.58 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:20<00:29,  3.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.99 toks/s, output: 41.54 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.51it/s, est. speed input: 7705.80 toks/s, output: 1085.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.32it/s, est. speed input: 7128.03 toks/s, output: 1076.75 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:23<00:23,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.52 toks/s, output: 41.35 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.37it/s, est. speed input: 6760.88 toks/s, output: 946.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 8064.18 toks/s, output: 1298.08 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:25<00:17,  2.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 314.85 toks/s, output: 42.13 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.50it/s, est. speed input: 6764.82 toks/s, output: 958.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8088.45 toks/s, output: 1314.46 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:27<00:13,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.84 toks/s, output: 41.52 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.07it/s, est. speed input: 6979.22 toks/s, output: 987.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.78it/s, est. speed input: 6113.06 toks/s, output: 1012.91 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:30<00:11,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.28 toks/s, output: 41.57 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.00it/s, est. speed input: 7853.69 toks/s, output: 1103.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8129.02 toks/s, output: 1198.96 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:32<00:07,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.82 toks/s, output: 41.90 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.60it/s, est. speed input: 7415.12 toks/s, output: 1041.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.81it/s, est. speed input: 6940.96 toks/s, output: 1098.50 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:35<00:05,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.31 toks/s, output: 41.71 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.65it/s, est. speed input: 6541.00 toks/s, output: 916.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 8121.36 toks/s, output: 1337.85 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:37<00:02,  2.48s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 353.59 toks/s, output: 46.46 toks/s][A
Processed prompts:  93%|█████████▎| 26/28 [00:01<00:00, 23.56it/s, est. speed input: 7440.94 toks/s, output: 1051.86 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.82it/s, est. speed input: 7757.81 toks/s, output: 1161.45 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:39<00:00,  2.36s/it]Processing batched inference: 100%|██████████| 66/66 [03:39<00:00,  3.33s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-441/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:02:51.672275928 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-504
INFO 07-05 11:03:03 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:03:05,764 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:03:05,805 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:05,829 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:05,829 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:05,829 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:05,829 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:05,829 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:05,829 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:05,829 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:03:06,217 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:03:06,219 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:03:06,224 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:03:06,231 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:06,231 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:06,231 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:06,231 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:06,232 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:06,232 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:06,232 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:06,232 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:03:06,605 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:03:06,607 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:03:06,803 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:03:07,242 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:03:07,296 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:03:07,296 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:03:07,298 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:03:18 [config.py:689] This model supports multiple tasks: {'classify', 'reward', 'score', 'generate', 'embed'}. Defaulting to 'generate'.
INFO 07-05 11:03:18 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:18,774 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:18,774 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:18,774 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:18,774 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:18,775 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:18,775 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:18,775 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:03:19,106 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:03:19,209 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:03:19,212 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:03:20 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:03:21 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:03:21 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504...
WARNING 07-05 11:03:21 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:03:21 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.40s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.40s/it]

INFO 07-05 11:03:28 [loader.py:458] Loading weights took 7.61 seconds
INFO 07-05 11:03:29 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.857966 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,356 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,356 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,356 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,356 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,356 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,356 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,356 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:03:29,771 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:03:29,867 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:03:29,868 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:03:29,868 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:03:29,868 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,869 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,869 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,869 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,869 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,869 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,869 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:03:29,870 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:03:30,623 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:03:30,623 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:03:30,624 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:03:31,079 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:03:31,701 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:03:32 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:03:34,563 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:03:35,551 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:03:35 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:04:14 [worker.py:267] Memory profiling takes 45.32 seconds
INFO 07-05 11:04:14 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:04:14 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:04:14 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:04:14 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:04:27 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.76it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.88it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.91it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.92it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.89it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:14,  1.90it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.94it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:12,  1.75it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:11,  1.81it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:10,  1.86it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:09<00:09,  1.86it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:09,  1.88it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:10<00:08,  1.88it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.90it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:11<00:07,  1.91it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.91it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:12<00:06,  1.92it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.94it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:13<00:05,  1.95it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.95it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:14<00:04,  1.95it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.87it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.90it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.92it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.93it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.94it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.90it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.91it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.88it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.90it/s]
INFO 07-05 11:04:45 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:04:45 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 76.42 seconds
[INFO|2025-07-05 11:04:46] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:04:47,058 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:04:47,058 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:04:47,059 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:04:47,059 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:04:47,059 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:04:47,059 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:04:47,059 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:04:47,059 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:04:47,059 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:04:48,272 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:04:48,273 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:04:48,273 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:04:48,862 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-504', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it, est. speed input: 251.75 toks/s, output: 32.68 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.84it/s, est. speed input: 5568.73 toks/s, output: 788.15 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.59it/s, est. speed input: 5794.47 toks/s, output: 960.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.96it/s, est. speed input: 5794.47 toks/s, output: 960.50 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:05<05:29,  5.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.01 toks/s, output: 42.19 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.48it/s, est. speed input: 6798.56 toks/s, output: 958.65 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.69it/s, est. speed input: 6711.04 toks/s, output: 1095.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6924.65 toks/s, output: 1176.07 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:55,  3.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.12 toks/s, output: 42.20 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.38it/s, est. speed input: 6491.47 toks/s, output: 916.78 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.97it/s, est. speed input: 6715.88 toks/s, output: 1125.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s, est. speed input: 857.09 toks/s, output: 292.56 toks/s]  
Processing batched inference:   5%|▍         | 3/66 [00:24<09:56,  9.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.26 toks/s, output: 41.96 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7365.56 toks/s, output: 1035.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8175.78 toks/s, output: 1257.28 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:26<06:54,  6.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.37 toks/s, output: 41.98 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 6280.57 toks/s, output: 887.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.02it/s, est. speed input: 5793.36 toks/s, output: 1008.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  5.29it/s, est. speed input: 2191.05 toks/s, output: 507.01 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:33<06:52,  6.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.01 toks/s, output: 41.93 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7604.79 toks/s, output: 1070.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.36it/s, est. speed input: 7142.80 toks/s, output: 1103.18 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:36<05:22,  5.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.94 toks/s, output: 42.05 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.31it/s, est. speed input: 7073.52 toks/s, output: 991.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8198.45 toks/s, output: 1297.31 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:38<04:19,  4.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.11 toks/s, output: 41.94 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7672.36 toks/s, output: 1079.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8210.24 toks/s, output: 1237.09 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:40<03:38,  3.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.54 toks/s, output: 42.40 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6754.51 toks/s, output: 958.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8077.37 toks/s, output: 1309.30 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:43<03:09,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.83 toks/s, output: 42.04 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.53it/s, est. speed input: 7123.69 toks/s, output: 999.01 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 22.53it/s, est. speed input: 7921.03 toks/s, output: 1230.86 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 506.26 toks/s, output: 233.13 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 506.26 toks/s, output: 233.13 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [01:10<09:54, 10.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.64 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 6260.37 toks/s, output: 880.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8107.78 toks/s, output: 1366.01 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [01:12<07:28,  8.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.06 toks/s, output: 42.06 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.25it/s, est. speed input: 7916.88 toks/s, output: 1120.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.44it/s, est. speed input: 4296.81 toks/s, output: 718.31 toks/s] 
Processing batched inference:  18%|█▊        | 12/66 [01:16<06:09,  6.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.97 toks/s, output: 42.46 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6831.24 toks/s, output: 966.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8158.23 toks/s, output: 1323.61 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:18<04:50,  5.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.58 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.64it/s, est. speed input: 7128.41 toks/s, output: 1003.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6893.37 toks/s, output: 1104.62 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:21<04:00,  4.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.28 toks/s, output: 42.09 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.99it/s, est. speed input: 6023.95 toks/s, output: 849.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.78it/s, est. speed input: 5177.27 toks/s, output: 935.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.90it/s, est. speed input: 2438.97 toks/s, output: 562.08 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:27<04:18,  5.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.20 toks/s, output: 41.95 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7093.78 toks/s, output: 1003.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8161.27 toks/s, output: 1298.87 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:30<03:32,  4.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.59 toks/s, output: 42.41 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.76it/s, est. speed input: 6501.36 toks/s, output: 922.70 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.12it/s, est. speed input: 6693.29 toks/s, output: 1123.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.56it/s, est. speed input: 5975.68 toks/s, output: 1064.26 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:33<03:09,  3.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.45 toks/s, output: 41.99 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7325.29 toks/s, output: 1037.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8137.99 toks/s, output: 1263.88 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:35<02:44,  3.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.10 toks/s, output: 40.77 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.01it/s, est. speed input: 6960.10 toks/s, output: 977.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6899.95 toks/s, output: 1118.35 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:38<02:30,  3.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 305.48 toks/s, output: 41.18 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.54it/s, est. speed input: 7381.97 toks/s, output: 1048.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.41it/s, est. speed input: 6769.60 toks/s, output: 1080.13 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:40<02:21,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.61 toks/s, output: 40.84 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.02it/s, est. speed input: 6916.42 toks/s, output: 979.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6794.13 toks/s, output: 1101.78 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:43<02:16,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.25 toks/s, output: 40.79 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 16.83it/s, est. speed input: 5342.58 toks/s, output: 756.54 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 17.68it/s, est. speed input: 5856.69 toks/s, output: 1015.98 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.97it/s, est. speed input: 4872.26 toks/s, output: 1068.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.76it/s, est. speed input: 4872.26 toks/s, output: 1068.14 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:47<02:21,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.75 toks/s, output: 40.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.05it/s, est. speed input: 6958.62 toks/s, output: 976.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.33it/s, est. speed input: 8013.34 toks/s, output: 1261.16 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:50<02:09,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.45 toks/s, output: 40.82 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.16it/s, est. speed input: 6656.65 toks/s, output: 937.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:04<00:00,  5.84it/s, est. speed input: 2704.16 toks/s, output: 566.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s, est. speed input: 2704.16 toks/s, output: 566.90 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:55<02:40,  3.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.64 toks/s, output: 40.71 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.06it/s, est. speed input: 6902.17 toks/s, output: 975.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 22.06it/s, est. speed input: 5250.00 toks/s, output: 894.47 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 503.28 toks/s, output: 239.91 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.28 toks/s, output: 239.91 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:22<07:22, 10.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.60 toks/s, output: 40.84 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.34it/s, est. speed input: 7357.00 toks/s, output: 1044.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.41it/s, est. speed input: 6773.78 toks/s, output: 1060.33 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:25<05:36,  8.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.26 toks/s, output: 40.79 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.69it/s, est. speed input: 7733.93 toks/s, output: 1088.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.40it/s, est. speed input: 8008.57 toks/s, output: 1181.15 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:28<04:17,  6.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.88 toks/s, output: 40.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.85it/s, est. speed input: 7467.39 toks/s, output: 1054.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 8008.31 toks/s, output: 1218.23 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:30<03:23,  5.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.87 toks/s, output: 40.74 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.19it/s, est. speed input: 7000.62 toks/s, output: 994.09 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 22.19it/s, est. speed input: 7700.51 toks/s, output: 1180.28 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.08s/it, est. speed input: 503.43 toks/s, output: 231.54 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.43 toks/s, output: 231.54 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [02:57<07:18, 11.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.77 toks/s, output: 40.86 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.41it/s, est. speed input: 8339.84 toks/s, output: 1162.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.04it/s, est. speed input: 8339.84 toks/s, output: 1162.41 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:59<05:22,  8.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.62 toks/s, output: 40.84 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.92it/s, est. speed input: 7192.04 toks/s, output: 1010.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6802.14 toks/s, output: 1077.52 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [03:02<04:06,  7.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.83 toks/s, output: 40.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.40it/s, est. speed input: 7379.14 toks/s, output: 1033.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 8022.46 toks/s, output: 1211.49 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [03:04<03:11,  5.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.84 toks/s, output: 40.74 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.49it/s, est. speed input: 6511.99 toks/s, output: 924.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.10it/s, est. speed input: 5855.84 toks/s, output: 1001.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5855.84 toks/s, output: 1001.36 toks/s]
Processing batched inference:  50%|█████     | 33/66 [03:07<02:39,  4.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.94 toks/s, output: 40.62 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.51it/s, est. speed input: 6827.07 toks/s, output: 962.92 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.00it/s, est. speed input: 5898.15 toks/s, output: 981.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.21it/s, est. speed input: 5898.15 toks/s, output: 981.61 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [03:10<02:16,  4.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.36 toks/s, output: 40.68 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.84it/s, est. speed input: 7166.67 toks/s, output: 1008.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.33it/s, est. speed input: 6741.72 toks/s, output: 1065.33 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [03:13<01:56,  3.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.06 toks/s, output: 41.42 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.73it/s, est. speed input: 6218.27 toks/s, output: 878.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.55it/s, est. speed input: 6775.76 toks/s, output: 1169.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.42it/s, est. speed input: 6775.76 toks/s, output: 1169.84 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [03:15<01:41,  3.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.89 toks/s, output: 41.52 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.03it/s, est. speed input: 7899.57 toks/s, output: 1102.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.98it/s, est. speed input: 8297.45 toks/s, output: 1211.30 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [03:17<01:28,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 311.29 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.54it/s, est. speed input: 6490.80 toks/s, output: 923.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.66it/s, est. speed input: 6619.66 toks/s, output: 1111.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.78it/s, est. speed input: 6117.02 toks/s, output: 1084.30 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [03:20<01:23,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 318.95 toks/s, output: 41.40 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.53it/s, est. speed input: 6509.25 toks/s, output: 914.30 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.34it/s, est. speed input: 5937.67 toks/s, output: 1025.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.29it/s, est. speed input: 5937.67 toks/s, output: 1025.78 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:23<01:19,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.60 toks/s, output: 41.49 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.17it/s, est. speed input: 7324.84 toks/s, output: 1034.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 8128.24 toks/s, output: 1259.25 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:25<01:11,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.87 toks/s, output: 40.87 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.44it/s, est. speed input: 6121.50 toks/s, output: 864.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 6717.65 toks/s, output: 1165.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.26it/s, est. speed input: 6717.65 toks/s, output: 1165.16 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [03:28<01:07,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 316.21 toks/s, output: 41.05 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.91it/s, est. speed input: 7492.92 toks/s, output: 1055.81 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00, 23.91it/s, est. speed input: 7889.49 toks/s, output: 1165.88 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.10s/it, est. speed input: 503.90 toks/s, output: 228.97 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.90 toks/s, output: 228.97 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [03:55<03:58,  9.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.66 toks/s, output: 41.23 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.08it/s, est. speed input: 7242.85 toks/s, output: 1019.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.80it/s, est. speed input: 6093.01 toks/s, output: 1006.47 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [03:58<02:59,  7.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.67 toks/s, output: 41.37 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.37it/s, est. speed input: 7017.92 toks/s, output: 988.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.75it/s, est. speed input: 4842.59 toks/s, output: 845.89 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [04:01<02:22,  6.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.67 toks/s, output: 41.49 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.00it/s, est. speed input: 7841.36 toks/s, output: 1100.54 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 25.00it/s, est. speed input: 7866.39 toks/s, output: 1133.86 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.11s/it, est. speed input: 505.10 toks/s, output: 227.54 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 505.10 toks/s, output: 227.54 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [04:28<04:23, 12.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.44 toks/s, output: 41.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.36it/s, est. speed input: 6718.78 toks/s, output: 945.69 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:12<00:00, 21.36it/s, est. speed input: 6366.20 toks/s, output: 1011.48 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00,  1.44it/s, est. speed input: 764.64 toks/s, output: 273.23 toks/s]  [A
Processed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.19s/it, est. speed input: 508.37 toks/s, output: 334.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 508.37 toks/s, output: 334.17 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [04:54<05:35, 16.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.74 toks/s, output: 41.24 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.52it/s, est. speed input: 7441.69 toks/s, output: 1052.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8093.59 toks/s, output: 1230.22 toks/s]
Processing batched inference:  71%|███████   | 47/66 [04:57<03:55, 12.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.16 toks/s, output: 41.30 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.88it/s, est. speed input: 7183.08 toks/s, output: 1016.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.98it/s, est. speed input: 6989.13 toks/s, output: 1113.29 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [04:59<02:49,  9.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.67 toks/s, output: 41.37 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.14it/s, est. speed input: 7285.11 toks/s, output: 1026.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.98it/s, est. speed input: 7020.01 toks/s, output: 1105.01 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [05:02<02:04,  7.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.95 toks/s, output: 40.88 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.12it/s, est. speed input: 7918.00 toks/s, output: 1107.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 8052.56 toks/s, output: 1156.27 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [05:04<01:33,  5.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.71 toks/s, output: 41.11 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.51it/s, est. speed input: 6164.92 toks/s, output: 875.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.29it/s, est. speed input: 7982.30 toks/s, output: 1346.75 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [05:06<01:12,  4.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.84 toks/s, output: 41.26 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.69it/s, est. speed input: 5916.16 toks/s, output: 839.29 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.01it/s, est. speed input: 6578.95 toks/s, output: 1150.04 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 20.01it/s, est. speed input: 6578.95 toks/s, output: 1150.04 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.41s/it, est. speed input: 506.35 toks/s, output: 242.65 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 506.35 toks/s, output: 242.65 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [05:33<02:39, 11.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.63 toks/s, output: 41.97 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.21it/s, est. speed input: 7303.43 toks/s, output: 1027.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.80it/s, est. speed input: 6127.22 toks/s, output: 990.04 toks/s] 
Processing batched inference:  80%|████████  | 53/66 [05:36<01:54,  8.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.22 toks/s, output: 41.57 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.06it/s, est. speed input: 7895.24 toks/s, output: 1103.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8168.95 toks/s, output: 1196.89 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [05:38<01:21,  6.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.97 toks/s, output: 41.66 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.51it/s, est. speed input: 6784.01 toks/s, output: 953.35 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00, 21.51it/s, est. speed input: 5773.69 toks/s, output: 983.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 506.32 toks/s, output: 240.58 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.32 toks/s, output: 240.58 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [06:05<02:21, 12.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 312.22 toks/s, output: 42.44 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.82it/s, est. speed input: 5920.60 toks/s, output: 846.33 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.25it/s, est. speed input: 6365.48 toks/s, output: 1093.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5904.10 toks/s, output: 1133.85 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [06:08<01:38,  9.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.99 toks/s, output: 41.80 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6497.56 toks/s, output: 917.92 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.38it/s, est. speed input: 6767.73 toks/s, output: 1125.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.78it/s, est. speed input: 6921.55 toks/s, output: 1194.48 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [06:10<01:08,  7.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.12 toks/s, output: 42.34 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6498.95 toks/s, output: 919.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.20it/s, est. speed input: 6104.50 toks/s, output: 1055.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.82it/s, est. speed input: 6104.50 toks/s, output: 1055.08 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [06:13<00:49,  6.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 318.89 toks/s, output: 41.39 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.92it/s, est. speed input: 7218.71 toks/s, output: 1015.07 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 22.92it/s, est. speed input: 764.16 toks/s, output: 271.17 toks/s]  [A
Processed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.08s/it, est. speed input: 508.09 toks/s, output: 332.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 508.09 toks/s, output: 332.98 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [06:40<01:26, 12.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.28 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.85it/s, est. speed input: 6596.98 toks/s, output: 925.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.09it/s, est. speed input: 6753.13 toks/s, output: 1114.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6903.99 toks/s, output: 1184.78 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [06:42<00:56,  9.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.59 toks/s, output: 41.49 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.42it/s, est. speed input: 6747.89 toks/s, output: 953.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.51it/s, est. speed input: 8068.19 toks/s, output: 1313.60 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [06:45<00:36,  7.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.20 toks/s, output: 41.82 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.56it/s, est. speed input: 6219.23 toks/s, output: 883.54 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.98it/s, est. speed input: 6839.95 toks/s, output: 1167.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.77it/s, est. speed input: 4867.86 toks/s, output: 910.31 toks/s] 
Processing batched inference:  94%|█████████▍| 62/66 [06:48<00:24,  6.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.11 toks/s, output: 41.55 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.51it/s, est. speed input: 7747.68 toks/s, output: 1088.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 8192.00 toks/s, output: 1210.11 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [06:50<00:14,  4.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.18 toks/s, output: 41.43 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.17it/s, est. speed input: 7291.64 toks/s, output: 1025.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6894.74 toks/s, output: 1091.71 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [06:53<00:08,  4.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.21 toks/s, output: 41.44 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.28it/s, est. speed input: 7046.22 toks/s, output: 989.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6850.59 toks/s, output: 1101.68 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [06:55<00:03,  3.72s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 356.34 toks/s, output: 46.26 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 21.72it/s, est. speed input: 6919.97 toks/s, output: 981.55 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.74it/s, est. speed input: 7726.89 toks/s, output: 1192.30 toks/s]
Processing batched inference: 100%|██████████| 66/66 [06:57<00:00,  3.23s/it]Processing batched inference: 100%|██████████| 66/66 [06:57<00:00,  6.33s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-504/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:11:45.772432530 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-567
INFO 07-05 11:11:58 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:12:00,017 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:12:00,057 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,081 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,081 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,081 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,081 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,081 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,081 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,081 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:12:00,489 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:12:00,491 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:12:00,497 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:12:00,504 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,505 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,505 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,505 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,505 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,505 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,505 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:00,505 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:12:00,880 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:12:00,882 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:12:01,095 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:12:01,531 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:12:01,588 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:12:01,589 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:12:01,594 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:12:13 [config.py:689] This model supports multiple tasks: {'classify', 'score', 'reward', 'embed', 'generate'}. Defaulting to 'generate'.
INFO 07-05 11:12:13 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:13,184 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:13,184 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:13,184 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:13,186 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:13,186 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:13,186 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:13,186 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:12:13,528 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:12:13,620 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:12:13,620 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:12:14 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:12:15 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:12:15 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567...
WARNING 07-05 11:12:15 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:12:15 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.06s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.06s/it]

INFO 07-05 11:12:22 [loader.py:458] Loading weights took 7.27 seconds
INFO 07-05 11:12:23 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.512686 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,396 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,396 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,396 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,396 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,396 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,396 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,396 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:12:23,805 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:12:23,900 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:12:23,901 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:12:23,902 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:12:23,902 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,902 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,902 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,903 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,903 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,903 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,903 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:12:23,903 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:12:24,678 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:12:24,678 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:12:24,679 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:12:25,147 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:12:25,770 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:12:26 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:12:28,582 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:12:29,592 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:12:29 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:13:08 [worker.py:267] Memory profiling takes 45.57 seconds
INFO 07-05 11:13:08 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:13:08 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:13:09 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:13:09 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:13:15 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.75it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.90it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.92it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.94it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.93it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.96it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:11<00:15,  1.05it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:11<00:12,  1.22it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:12<00:10,  1.38it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:12<00:08,  1.52it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:13<00:07,  1.62it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:13<00:06,  1.70it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:14<00:05,  1.74it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:14<00:04,  1.81it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:15<00:04,  1.85it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:15<00:03,  1.81it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:16<00:03,  1.84it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:16<00:02,  1.86it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:17<00:02,  1.88it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:18<00:01,  1.91it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:18<00:01,  1.92it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:19<00:00,  1.89it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:19<00:00,  1.86it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:19<00:00,  1.78it/s]
INFO 07-05 11:13:34 [model_runner.py:1598] Graph capturing finished in 20 secs, took 0.33 GiB
INFO 07-05 11:13:34 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 71.54 seconds
[INFO|2025-07-05 11:13:35] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:13:36,186 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:13:36,187 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,188 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,188 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,188 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,188 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,188 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,188 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:13:36,188 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:13:37,434 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:13:37,434 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:13:37,435 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:13:37,999 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-567', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.63s/it, est. speed input: 255.82 toks/s, output: 33.21 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 17.26it/s, est. speed input: 5414.17 toks/s, output: 765.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.24it/s, est. speed input: 6740.68 toks/s, output: 1116.33 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:06,  4.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.60 toks/s, output: 42.14 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.91it/s, est. speed input: 6657.45 toks/s, output: 936.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.91it/s, est. speed input: 6720.81 toks/s, output: 1098.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6914.68 toks/s, output: 1175.95 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:47,  3.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.75 toks/s, output: 42.15 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.00it/s, est. speed input: 6029.44 toks/s, output: 853.65 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.36it/s, est. speed input: 6460.71 toks/s, output: 1111.67 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.36it/s, est. speed input: 6675.76 toks/s, output: 1192.61 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.39s/it, est. speed input: 506.71 toks/s, output: 244.53 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 506.71 toks/s, output: 244.53 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:34<14:59, 14.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.66 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7375.31 toks/s, output: 1035.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8179.72 toks/s, output: 1258.50 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:36<09:54,  9.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 319.97 toks/s, output: 42.04 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.10it/s, est. speed input: 5744.72 toks/s, output: 812.46 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.55it/s, est. speed input: 6436.50 toks/s, output: 1126.43 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5951.39 toks/s, output: 1153.99 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:39<07:20,  7.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.36 toks/s, output: 42.10 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6547.87 toks/s, output: 922.41 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.53it/s, est. speed input: 6575.05 toks/s, output: 1069.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.86it/s, est. speed input: 5291.27 toks/s, output: 971.18 toks/s] 
Processing batched inference:   9%|▉         | 6/66 [00:43<05:52,  5.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.79 toks/s, output: 42.03 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6845.08 toks/s, output: 960.63 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.27it/s, est. speed input: 7096.93 toks/s, output: 1171.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.11it/s, est. speed input: 7096.93 toks/s, output: 1171.67 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:45<04:45,  4.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.16 toks/s, output: 41.95 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6573.13 toks/s, output: 930.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8157.86 toks/s, output: 1345.92 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:48<03:55,  4.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.19 toks/s, output: 41.82 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.90it/s, est. speed input: 5942.90 toks/s, output: 844.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 8015.01 toks/s, output: 1386.50 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:50<03:21,  3.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.74 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6843.25 toks/s, output: 959.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:14<00:00,  1.70it/s, est. speed input: 891.28 toks/s, output: 290.26 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:14<00:00,  2.16it/s, est. speed input: 891.28 toks/s, output: 290.26 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [01:06<06:48,  7.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.08 toks/s, output: 42.07 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 7097.96 toks/s, output: 992.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8163.47 toks/s, output: 1290.16 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [01:08<05:19,  5.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.87 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6787.98 toks/s, output: 967.34 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.41it/s, est. speed input: 6869.76 toks/s, output: 1171.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6869.76 toks/s, output: 1171.90 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [01:11<04:22,  4.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.02 toks/s, output: 42.06 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6847.16 toks/s, output: 964.98 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.32it/s, est. speed input: 6901.11 toks/s, output: 1148.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6901.11 toks/s, output: 1148.27 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:14<03:41,  4.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.71 toks/s, output: 42.02 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.06it/s, est. speed input: 6327.65 toks/s, output: 892.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8129.31 toks/s, output: 1360.41 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:16<03:08,  3.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.92 toks/s, output: 41.52 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6293.26 toks/s, output: 884.55 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.32it/s, est. speed input: 6740.15 toks/s, output: 1142.62 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 20.32it/s, est. speed input: 6740.15 toks/s, output: 1142.62 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.43s/it, est. speed input: 505.85 toks/s, output: 239.97 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.85 toks/s, output: 239.97 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:43<09:03, 10.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.04 toks/s, output: 41.93 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 6014.14 toks/s, output: 849.25 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.90it/s, est. speed input: 6833.49 toks/s, output: 1211.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6833.49 toks/s, output: 1211.94 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:46<06:53,  8.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 300.90 toks/s, output: 39.05 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.38it/s, est. speed input: 5811.81 toks/s, output: 822.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.18it/s, est. speed input: 5691.37 toks/s, output: 1014.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s, est. speed input: 2690.97 toks/s, output: 595.24 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [01:51<06:06,  7.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.90 toks/s, output: 40.75 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.88it/s, est. speed input: 7146.62 toks/s, output: 1011.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.32it/s, est. speed input: 7945.19 toks/s, output: 1232.73 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:54<04:48,  6.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.21 toks/s, output: 40.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.29it/s, est. speed input: 6415.18 toks/s, output: 905.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.22it/s, est. speed input: 7972.40 toks/s, output: 1321.02 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:57<03:55,  5.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 307.51 toks/s, output: 41.15 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.01it/s, est. speed input: 6294.72 toks/s, output: 897.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.51it/s, est. speed input: 6505.32 toks/s, output: 1092.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5826.77 toks/s, output: 1038.30 toks/s]
Processing batched inference:  30%|███       | 20/66 [02:00<03:24,  4.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.31 toks/s, output: 40.80 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.02it/s, est. speed input: 6912.70 toks/s, output: 976.51 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 22.02it/s, est. speed input: 6617.83 toks/s, output: 1053.92 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 504.57 toks/s, output: 234.65 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 504.57 toks/s, output: 234.65 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [02:27<08:26, 11.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.27 toks/s, output: 40.53 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.10it/s, est. speed input: 4811.26 toks/s, output: 678.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.69it/s, est. speed input: 6474.38 toks/s, output: 1223.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.01it/s, est. speed input: 5804.14 toks/s, output: 1152.06 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [02:30<06:30,  8.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.10 toks/s, output: 40.51 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.90it/s, est. speed input: 6927.46 toks/s, output: 968.45 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 21.90it/s, est. speed input: 7719.75 toks/s, output: 1188.48 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 507.22 toks/s, output: 232.37 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 507.22 toks/s, output: 232.37 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [02:57<10:15, 14.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.65 toks/s, output: 40.71 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.26it/s, est. speed input: 6375.73 toks/s, output: 899.24 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:05<00:00,  5.37it/s, est. speed input: 2506.82 toks/s, output: 520.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s, est. speed input: 1110.38 toks/s, output: 374.12 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [03:10<09:42, 13.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.83 toks/s, output: 40.74 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.22it/s, est. speed input: 6638.25 toks/s, output: 939.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 21.22it/s, est. speed input: 6516.12 toks/s, output: 1064.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 503.07 toks/s, output: 236.41 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.07 toks/s, output: 236.41 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [03:37<12:10, 17.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.10 toks/s, output: 40.64 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.25it/s, est. speed input: 6439.68 toks/s, output: 915.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 15.57it/s, est. speed input: 5681.46 toks/s, output: 979.11 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 15.57it/s, est. speed input: 5681.46 toks/s, output: 979.11 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.46s/it, est. speed input: 505.24 toks/s, output: 241.13 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.24 toks/s, output: 241.13 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [04:04<13:44, 20.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.96 toks/s, output: 40.75 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.00it/s, est. speed input: 6909.60 toks/s, output: 972.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.34it/s, est. speed input: 6743.03 toks/s, output: 1167.57 toks/s]
Processing batched inference:  41%|████      | 27/66 [04:07<09:53, 15.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.76 toks/s, output: 40.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.18it/s, est. speed input: 6642.46 toks/s, output: 940.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.27it/s, est. speed input: 7951.08 toks/s, output: 1297.46 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [04:09<07:11, 11.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 305.90 toks/s, output: 41.24 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.56it/s, est. speed input: 5830.66 toks/s, output: 830.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.04it/s, est. speed input: 6270.83 toks/s, output: 1082.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:19<00:00, 19.04it/s, est. speed input: 6481.84 toks/s, output: 1162.03 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.39s/it, est. speed input: 503.11 toks/s, output: 244.08 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 503.11 toks/s, output: 244.08 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [04:36<09:52, 16.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.89 toks/s, output: 41.13 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.14it/s, est. speed input: 7325.93 toks/s, output: 1025.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6910.03 toks/s, output: 1085.59 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [04:39<07:10, 11.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:42,  1.36s/it, est. speed input: 306.35 toks/s, output: 39.77 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.74it/s, est. speed input: 6490.71 toks/s, output: 917.78 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.03it/s, est. speed input: 6658.18 toks/s, output: 1100.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.19it/s, est. speed input: 6658.18 toks/s, output: 1100.75 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [04:41<05:20,  9.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.55 toks/s, output: 40.70 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.98it/s, est. speed input: 6915.77 toks/s, output: 969.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.25it/s, est. speed input: 7956.26 toks/s, output: 1256.85 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [04:43<04:01,  7.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.48 toks/s, output: 40.69 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.67it/s, est. speed input: 6555.04 toks/s, output: 929.72 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.36it/s, est. speed input: 6555.12 toks/s, output: 1076.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.16it/s, est. speed input: 5867.90 toks/s, output: 1023.79 toks/s]
Processing batched inference:  50%|█████     | 33/66 [04:46<03:13,  5.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.89 toks/s, output: 40.75 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.18it/s, est. speed input: 6089.08 toks/s, output: 860.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.15it/s, est. speed input: 7946.75 toks/s, output: 1347.69 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [04:49<02:33,  4.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.53 toks/s, output: 40.70 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.77it/s, est. speed input: 7446.19 toks/s, output: 1045.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 7985.59 toks/s, output: 1204.45 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [04:51<02:05,  4.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.55 toks/s, output: 41.35 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.50it/s, est. speed input: 6459.13 toks/s, output: 911.90 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.28it/s, est. speed input: 5878.21 toks/s, output: 1016.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.25it/s, est. speed input: 5878.21 toks/s, output: 1016.21 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [04:54<01:50,  3.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.09 toks/s, output: 41.42 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.09it/s, est. speed input: 7609.73 toks/s, output: 1062.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8178.11 toks/s, output: 1224.03 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [04:56<01:34,  3.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.69 toks/s, output: 41.61 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.46it/s, est. speed input: 6783.50 toks/s, output: 960.87 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 21.46it/s, est. speed input: 6660.28 toks/s, output: 1092.85 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.06s/it, est. speed input: 507.12 toks/s, output: 237.56 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 507.12 toks/s, output: 237.56 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [05:23<04:49, 10.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.73 toks/s, output: 41.76 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.13it/s, est. speed input: 5467.15 toks/s, output: 769.92 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.70it/s, est. speed input: 6413.70 toks/s, output: 1146.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.31it/s, est. speed input: 5947.09 toks/s, output: 1179.48 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [05:26<03:38,  8.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.21 toks/s, output: 41.44 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.63it/s, est. speed input: 6232.84 toks/s, output: 882.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 8058.28 toks/s, output: 1364.88 toks/s]
Processing batched inference:  61%|██████    | 40/66 [05:28<02:44,  6.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.89 toks/s, output: 41.65 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.62it/s, est. speed input: 6510.97 toks/s, output: 914.55 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.10it/s, est. speed input: 6469.98 toks/s, output: 1061.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.40it/s, est. speed input: 5949.65 toks/s, output: 1076.06 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [05:31<02:13,  5.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.82 toks/s, output: 41.51 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.54it/s, est. speed input: 6756.43 toks/s, output: 955.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8095.22 toks/s, output: 1311.19 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [05:33<01:45,  4.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.16 toks/s, output: 41.67 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.49it/s, est. speed input: 6759.01 toks/s, output: 953.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.96it/s, est. speed input: 6091.80 toks/s, output: 1028.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.80it/s, est. speed input: 6091.80 toks/s, output: 1028.01 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [05:36<01:30,  3.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.57 toks/s, output: 41.09 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.62it/s, est. speed input: 6174.11 toks/s, output: 873.18 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.36it/s, est. speed input: 4801.81 toks/s, output: 873.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.65it/s, est. speed input: 4801.81 toks/s, output: 873.35 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [05:40<01:22,  3.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.76 toks/s, output: 41.38 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.95it/s, est. speed input: 7822.80 toks/s, output: 1097.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8087.22 toks/s, output: 1194.73 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [05:42<01:09,  3.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.40 toks/s, output: 41.20 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.87it/s, est. speed input: 5947.00 toks/s, output: 841.24 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.21it/s, est. speed input: 6125.40 toks/s, output: 1023.28 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:17<00:00, 18.21it/s, est. speed input: 1174.57 toks/s, output: 348.82 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.36s/it, est. speed input: 507.13 toks/s, output: 303.66 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 507.13 toks/s, output: 303.66 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [06:08<03:26, 10.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.08 toks/s, output: 41.44 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.15it/s, est. speed input: 7297.06 toks/s, output: 1031.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8097.56 toks/s, output: 1258.32 toks/s]
Processing batched inference:  71%|███████   | 47/66 [06:11<02:30,  7.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.54 toks/s, output: 42.40 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6790.20 toks/s, output: 962.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8093.61 toks/s, output: 1315.64 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [06:13<01:51,  6.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.02 toks/s, output: 41.80 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.97it/s, est. speed input: 6295.54 toks/s, output: 890.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.05it/s, est. speed input: 6922.12 toks/s, output: 1188.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.73it/s, est. speed input: 6922.12 toks/s, output: 1188.46 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [06:15<01:26,  5.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.68 toks/s, output: 41.37 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.26it/s, est. speed input: 7026.56 toks/s, output: 986.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.87it/s, est. speed input: 6974.65 toks/s, output: 1121.14 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [06:18<01:09,  4.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.32 toks/s, output: 41.19 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 16.96it/s, est. speed input: 5371.56 toks/s, output: 764.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.23it/s, est. speed input: 7955.69 toks/s, output: 1429.39 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [06:20<00:55,  3.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.91 toks/s, output: 41.14 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.28it/s, est. speed input: 6707.48 toks/s, output: 949.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.08it/s, est. speed input: 6781.85 toks/s, output: 1128.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.40it/s, est. speed input: 6781.85 toks/s, output: 1128.25 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [06:23<00:47,  3.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 314.57 toks/s, output: 41.33 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.86it/s, est. speed input: 5677.76 toks/s, output: 801.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.97it/s, est. speed input: 6765.68 toks/s, output: 1217.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.35it/s, est. speed input: 6765.68 toks/s, output: 1217.34 toks/s]
Processing batched inference:  80%|████████  | 53/66 [06:25<00:40,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 311.44 toks/s, output: 41.68 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.22it/s, est. speed input: 7007.88 toks/s, output: 983.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.44it/s, est. speed input: 8060.99 toks/s, output: 1266.13 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [06:28<00:34,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.52 toks/s, output: 41.09 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.61it/s, est. speed input: 5891.94 toks/s, output: 832.22 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.98it/s, est. speed input: 6500.22 toks/s, output: 1109.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.16it/s, est. speed input: 5848.11 toks/s, output: 1095.10 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [06:31<00:31,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.09 toks/s, output: 41.29 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.70it/s, est. speed input: 5919.29 toks/s, output: 842.40 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.24it/s, est. speed input: 6380.61 toks/s, output: 1096.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.39it/s, est. speed input: 4709.22 toks/s, output: 938.56 toks/s] 
Processing batched inference:  85%|████████▍ | 56/66 [06:34<00:30,  3.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.14 toks/s, output: 40.91 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.58it/s, est. speed input: 5851.90 toks/s, output: 826.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.96it/s, est. speed input: 6768.52 toks/s, output: 1193.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.41it/s, est. speed input: 6768.52 toks/s, output: 1193.20 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [06:37<00:26,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 308.67 toks/s, output: 41.61 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 16.96it/s, est. speed input: 5333.31 toks/s, output: 759.51 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.15it/s, est. speed input: 6697.43 toks/s, output: 1231.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.26it/s, est. speed input: 6697.43 toks/s, output: 1231.24 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [06:39<00:22,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.59 toks/s, output: 41.36 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.31it/s, est. speed input: 6424.05 toks/s, output: 902.96 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 15.35it/s, est. speed input: 5605.42 toks/s, output: 937.63 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:19<00:00, 15.35it/s, est. speed input: 5605.42 toks/s, output: 937.63 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:25<00:01,  1.49s/it, est. speed input: 492.59 toks/s, output: 237.81 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:25<00:00,  1.23it/s, est. speed input: 507.73 toks/s, output: 395.75 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [07:06<01:09,  9.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.63 toks/s, output: 41.49 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.66it/s, est. speed input: 6532.82 toks/s, output: 914.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.94it/s, est. speed input: 6695.69 toks/s, output: 1106.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6845.75 toks/s, output: 1176.86 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [07:08<00:46,  7.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.36 toks/s, output: 42.20 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6773.73 toks/s, output: 960.36 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.55it/s, est. speed input: 6906.44 toks/s, output: 1146.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6906.44 toks/s, output: 1146.89 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [07:11<00:30,  6.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.32 toks/s, output: 41.58 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.40it/s, est. speed input: 5858.49 toks/s, output: 835.42 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 18.39it/s, est. speed input: 6110.63 toks/s, output: 1017.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.40it/s, est. speed input: 6782.86 toks/s, output: 1295.06 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [07:14<00:20,  5.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.04 toks/s, output: 41.41 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.46it/s, est. speed input: 7715.23 toks/s, output: 1084.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.58it/s, est. speed input: 6850.78 toks/s, output: 1037.89 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [07:16<00:13,  4.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.11 toks/s, output: 41.42 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.54it/s, est. speed input: 6474.75 toks/s, output: 911.69 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.66it/s, est. speed input: 6619.20 toks/s, output: 1102.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.43it/s, est. speed input: 4720.48 toks/s, output: 869.27 toks/s] 
Processing batched inference:  97%|█████████▋| 64/66 [07:20<00:08,  4.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.29 toks/s, output: 41.32 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.60it/s, est. speed input: 6211.53 toks/s, output: 871.03 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.42it/s, est. speed input: 5894.60 toks/s, output: 1036.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.21it/s, est. speed input: 5894.60 toks/s, output: 1036.74 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [07:22<00:03,  3.69s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 352.65 toks/s, output: 45.48 toks/s][A
Processed prompts:  79%|███████▊  | 22/28 [00:01<00:00, 19.52it/s, est. speed input: 6206.14 toks/s, output: 880.72 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.53it/s, est. speed input: 7639.70 toks/s, output: 1268.86 toks/s]
Processing batched inference: 100%|██████████| 66/66 [07:25<00:00,  3.22s/it]Processing batched inference: 100%|██████████| 66/66 [07:25<00:00,  6.74s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-567/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:21:01.134947112 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-63
INFO 07-05 11:21:14 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:21:16,400 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:21:16,445 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,465 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,465 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,465 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,465 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,465 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,465 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,465 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:21:16,854 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:21:16,856 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:21:16,860 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:21:16,867 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,868 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,868 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,868 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,868 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,868 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,868 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:16,868 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:21:17,240 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:21:17,241 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:21:17,444 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:21:17,910 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:21:17,960 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:21:17,960 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:21:17,962 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:21:29 [config.py:689] This model supports multiple tasks: {'generate', 'score', 'embed', 'classify', 'reward'}. Defaulting to 'generate'.
INFO 07-05 11:21:29 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:29,568 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:29,568 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:29,569 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:29,569 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:29,569 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:29,569 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:29,569 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:21:29,899 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:21:30,000 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:21:30,002 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:21:31 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:21:31 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:21:31 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63...
WARNING 07-05 11:21:31 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:21:31 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.16s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.17s/it]

INFO 07-05 11:21:39 [loader.py:458] Loading weights took 7.38 seconds
INFO 07-05 11:21:39 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.630425 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:39,927 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:39,927 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:39,927 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:39,927 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:39,927 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:39,927 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:39,927 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:21:40,329 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:21:40,424 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:21:40,424 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:21:40,426 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:21:40,426 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:40,426 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:40,426 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:40,426 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:40,427 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:40,427 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:40,427 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:21:40,427 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:21:41,204 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:21:41,205 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:21:41,205 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:21:41,654 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:21:42,322 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:21:42 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:21:45,194 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:21:46,269 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:21:46 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:22:25 [worker.py:267] Memory profiling takes 45.59 seconds
INFO 07-05 11:22:25 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:22:25 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:22:25 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:22:25 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:22:31 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.76it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.87it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.91it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.94it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.97it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.97it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.97it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.92it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.94it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.95it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.95it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.96it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.85it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.88it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.91it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.93it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.94it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.95it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.96it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.87it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.93it/s]
INFO 07-05 11:22:49 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:22:49 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 70.19 seconds
[INFO|2025-07-05 11:22:50] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:22:51,332 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:22:51,333 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:22:51,333 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:22:51,333 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:22:51,333 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:22:51,333 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:22:51,333 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:22:51,333 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:22:51,333 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:22:52,581 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:22:52,582 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:22:52,583 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:22:53,138 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-63', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.66s/it, est. speed input: 245.58 toks/s, output: 33.10 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 19.23it/s, est. speed input: 5989.96 toks/s, output: 852.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.50it/s, est. speed input: 6847.22 toks/s, output: 1056.11 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:07,  4.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.75 toks/s, output: 42.56 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.39it/s, est. speed input: 7662.44 toks/s, output: 1080.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 8200.87 toks/s, output: 1241.03 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:36,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.94 toks/s, output: 42.59 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.69it/s, est. speed input: 6839.41 toks/s, output: 968.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8165.93 toks/s, output: 1329.85 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:09<03:06,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.42 toks/s, output: 42.52 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.39it/s, est. speed input: 7658.64 toks/s, output: 1077.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.45it/s, est. speed input: 8454.92 toks/s, output: 1266.99 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:12<02:49,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.75 toks/s, output: 42.43 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7372.79 toks/s, output: 1038.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8180.72 toks/s, output: 1262.22 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:14<02:41,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 318.19 toks/s, output: 42.58 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.47it/s, est. speed input: 7335.21 toks/s, output: 1040.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.41it/s, est. speed input: 8395.37 toks/s, output: 1292.81 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:16<02:34,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.18 toks/s, output: 42.49 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.27it/s, est. speed input: 7955.44 toks/s, output: 1117.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.46it/s, est. speed input: 8486.55 toks/s, output: 1244.42 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:19<02:28,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.73 toks/s, output: 42.56 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.45it/s, est. speed input: 7404.05 toks/s, output: 1049.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 8463.50 toks/s, output: 1301.38 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:21<02:22,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.74 toks/s, output: 42.29 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.30it/s, est. speed input: 7562.11 toks/s, output: 1073.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.37it/s, est. speed input: 8355.37 toks/s, output: 1262.08 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:23<02:17,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.62 toks/s, output: 41.99 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.35it/s, est. speed input: 7654.28 toks/s, output: 1080.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.13it/s, est. speed input: 8319.78 toks/s, output: 1252.52 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:26<02:14,  2.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.00 toks/s, output: 42.46 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 7354.37 toks/s, output: 1035.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8158.30 toks/s, output: 1252.93 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:28<02:12,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.65 toks/s, output: 42.55 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.18it/s, est. speed input: 8175.49 toks/s, output: 1160.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.51it/s, est. speed input: 8441.23 toks/s, output: 1224.01 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:31<02:08,  2.39s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.73 toks/s, output: 41.35 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.85it/s, est. speed input: 7497.76 toks/s, output: 1057.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.38it/s, est. speed input: 8035.09 toks/s, output: 1216.40 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:33<02:08,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.44 toks/s, output: 41.31 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.44it/s, est. speed input: 6121.23 toks/s, output: 870.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.19it/s, est. speed input: 7935.90 toks/s, output: 1324.44 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:36<02:09,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 309.00 toks/s, output: 41.35 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.95it/s, est. speed input: 7194.36 toks/s, output: 1019.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.92it/s, est. speed input: 8229.44 toks/s, output: 1265.82 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:38<02:08,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 307.77 toks/s, output: 41.19 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.79it/s, est. speed input: 7462.86 toks/s, output: 1059.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 8238.52 toks/s, output: 1244.58 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:41<02:09,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 305.15 toks/s, output: 41.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.22it/s, est. speed input: 8156.08 toks/s, output: 1153.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 8156.08 toks/s, output: 1153.88 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:44<02:06,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 309.65 toks/s, output: 40.68 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.76it/s, est. speed input: 7417.22 toks/s, output: 1051.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.33it/s, est. speed input: 7951.04 toks/s, output: 1204.64 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:46<02:05,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 307.99 toks/s, output: 41.22 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.55it/s, est. speed input: 8024.36 toks/s, output: 1128.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.97it/s, est. speed input: 8283.20 toks/s, output: 1190.26 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:49<02:03,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 306.75 toks/s, output: 41.05 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 23.66it/s, est. speed input: 7462.33 toks/s, output: 1059.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.31it/s, est. speed input: 7964.75 toks/s, output: 1188.76 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:52<01:59,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 305.87 toks/s, output: 41.23 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.90it/s, est. speed input: 7158.96 toks/s, output: 1018.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 8191.33 toks/s, output: 1264.40 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:54<01:56,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 308.57 toks/s, output: 41.29 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.44it/s, est. speed input: 6135.82 toks/s, output: 870.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.18it/s, est. speed input: 7949.65 toks/s, output: 1339.32 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [00:57<01:55,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 305.94 toks/s, output: 41.24 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.90it/s, est. speed input: 7209.21 toks/s, output: 1015.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.88it/s, est. speed input: 8241.91 toks/s, output: 1261.72 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [00:59<01:51,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 309.06 toks/s, output: 41.26 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.91it/s, est. speed input: 7155.20 toks/s, output: 1014.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.30it/s, est. speed input: 7944.77 toks/s, output: 1227.74 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:02<01:48,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 305.66 toks/s, output: 41.20 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.68it/s, est. speed input: 7681.27 toks/s, output: 1089.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 8198.93 toks/s, output: 1212.41 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:04<01:44,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 305.54 toks/s, output: 41.19 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.64it/s, est. speed input: 7707.85 toks/s, output: 1095.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.30it/s, est. speed input: 7968.11 toks/s, output: 1185.16 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:07<01:39,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 305.48 toks/s, output: 41.18 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.01it/s, est. speed input: 6894.10 toks/s, output: 978.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.24it/s, est. speed input: 7940.98 toks/s, output: 1252.34 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:09<01:34,  2.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 307.89 toks/s, output: 41.20 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.68it/s, est. speed input: 7711.44 toks/s, output: 1092.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 8229.22 toks/s, output: 1216.30 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:11<01:30,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 304.82 toks/s, output: 41.09 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.48it/s, est. speed input: 7934.23 toks/s, output: 1125.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.33it/s, est. speed input: 7949.64 toks/s, output: 1156.10 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:13<01:26,  2.34s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 310.16 toks/s, output: 41.51 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.01it/s, est. speed input: 7275.48 toks/s, output: 1024.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.98it/s, est. speed input: 8313.20 toks/s, output: 1271.70 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:16<01:22,  2.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.83 toks/s, output: 41.36 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.22it/s, est. speed input: 6624.14 toks/s, output: 942.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7967.88 toks/s, output: 1286.40 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:18<01:19,  2.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.50 toks/s, output: 41.32 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.62it/s, est. speed input: 8016.01 toks/s, output: 1123.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.02it/s, est. speed input: 8275.49 toks/s, output: 1185.25 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:20<01:16,  2.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 305.61 toks/s, output: 41.20 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.65it/s, est. speed input: 7737.57 toks/s, output: 1093.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 8017.18 toks/s, output: 1190.75 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:22<01:14,  2.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.20 toks/s, output: 41.28 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 24.70it/s, est. speed input: 7769.10 toks/s, output: 1096.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 8071.84 toks/s, output: 1192.01 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:25<01:13,  2.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 307.78 toks/s, output: 41.49 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.39it/s, est. speed input: 6399.37 toks/s, output: 911.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.30it/s, est. speed input: 7964.54 toks/s, output: 1307.41 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:27<01:10,  2.28s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 311.32 toks/s, output: 41.97 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.59it/s, est. speed input: 6460.18 toks/s, output: 916.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.50it/s, est. speed input: 8042.95 toks/s, output: 1329.52 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:29<01:08,  2.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.66 toks/s, output: 41.97 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7645.83 toks/s, output: 1071.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.24it/s, est. speed input: 8404.70 toks/s, output: 1254.78 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:31<01:04,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 311.13 toks/s, output: 41.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.59it/s, est. speed input: 8354.07 toks/s, output: 1181.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.18it/s, est. speed input: 8354.07 toks/s, output: 1181.26 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:34<01:02,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 312.39 toks/s, output: 42.11 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.39it/s, est. speed input: 7077.01 toks/s, output: 999.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8143.19 toks/s, output: 1282.47 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:36<01:00,  2.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.59 toks/s, output: 42.41 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7382.91 toks/s, output: 1044.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8189.32 toks/s, output: 1267.48 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:38<00:58,  2.26s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.15 toks/s, output: 42.21 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.42it/s, est. speed input: 7042.30 toks/s, output: 997.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8111.80 toks/s, output: 1281.80 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:40<00:56,  2.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.97 toks/s, output: 42.15 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.24it/s, est. speed input: 7566.49 toks/s, output: 1072.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.31it/s, est. speed input: 8357.53 toks/s, output: 1261.02 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [01:43<00:53,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.43 toks/s, output: 42.25 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.12it/s, est. speed input: 7845.35 toks/s, output: 1106.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.34it/s, est. speed input: 8373.04 toks/s, output: 1232.46 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [01:45<00:51,  2.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.96 toks/s, output: 41.79 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.33it/s, est. speed input: 7317.52 toks/s, output: 1031.11 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8120.33 toks/s, output: 1248.51 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [01:47<00:49,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.26 toks/s, output: 42.23 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.17it/s, est. speed input: 7863.78 toks/s, output: 1107.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8139.48 toks/s, output: 1201.22 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [01:49<00:46,  2.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.23 toks/s, output: 42.22 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.41it/s, est. speed input: 7019.07 toks/s, output: 995.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8081.16 toks/s, output: 1273.61 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [01:52<00:44,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.56 toks/s, output: 42.27 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.05it/s, est. speed input: 8179.85 toks/s, output: 1153.06 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8189.12 toks/s, output: 1184.17 toks/s]
Processing batched inference:  71%|███████   | 47/66 [01:54<00:42,  2.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.30 toks/s, output: 42.37 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 26.82it/s, est. speed input: 8381.10 toks/s, output: 1182.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 8381.10 toks/s, output: 1182.29 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [01:56<00:39,  2.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.93 toks/s, output: 42.32 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.37it/s, est. speed input: 7344.99 toks/s, output: 1036.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 8208.97 toks/s, output: 1261.76 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [01:58<00:37,  2.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.20 toks/s, output: 42.22 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.33it/s, est. speed input: 7329.76 toks/s, output: 1031.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8130.07 toks/s, output: 1248.50 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:00<00:35,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.42 toks/s, output: 42.21 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.87it/s, est. speed input: 5956.48 toks/s, output: 850.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 8059.35 toks/s, output: 1386.53 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:03<00:33,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.08 toks/s, output: 42.33 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.08it/s, est. speed input: 8176.94 toks/s, output: 1156.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.42it/s, est. speed input: 8441.51 toks/s, output: 1219.32 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:05<00:30,  2.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.48 toks/s, output: 42.22 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.03it/s, est. speed input: 8169.37 toks/s, output: 1147.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.06it/s, est. speed input: 8303.98 toks/s, output: 1193.80 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:07<00:28,  2.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.84 toks/s, output: 42.40 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.35it/s, est. speed input: 7668.66 toks/s, output: 1073.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8206.23 toks/s, output: 1229.56 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:09<00:26,  2.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.38 toks/s, output: 42.38 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.33it/s, est. speed input: 7629.65 toks/s, output: 1077.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 8423.73 toks/s, output: 1267.03 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:11<00:24,  2.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 314.62 toks/s, output: 42.76 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7611.62 toks/s, output: 1080.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8149.37 toks/s, output: 1235.40 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:14<00:22,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 311.84 toks/s, output: 42.04 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.25it/s, est. speed input: 7282.19 toks/s, output: 1030.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.20it/s, est. speed input: 8331.39 toks/s, output: 1280.63 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:16<00:20,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.59 toks/s, output: 42.27 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7590.03 toks/s, output: 1069.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8134.18 toks/s, output: 1231.23 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:18<00:17,  2.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.20 toks/s, output: 42.22 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.13it/s, est. speed input: 7843.44 toks/s, output: 1105.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8117.46 toks/s, output: 1198.47 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [02:20<00:15,  2.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.79 toks/s, output: 42.30 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7351.01 toks/s, output: 1036.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.30it/s, est. speed input: 8405.33 toks/s, output: 1287.02 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [02:23<00:13,  2.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.33 toks/s, output: 42.33 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.07it/s, est. speed input: 8178.99 toks/s, output: 1156.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.41it/s, est. speed input: 8443.47 toks/s, output: 1219.05 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [02:25<00:11,  2.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.73 toks/s, output: 42.29 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.18it/s, est. speed input: 7900.43 toks/s, output: 1113.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8181.56 toks/s, output: 1212.85 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [02:27<00:08,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.82 toks/s, output: 42.30 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.17it/s, est. speed input: 7891.02 toks/s, output: 1111.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.07it/s, est. speed input: 8290.87 toks/s, output: 1220.95 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [02:29<00:06,  2.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.03 toks/s, output: 42.20 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.54it/s, est. speed input: 6762.37 toks/s, output: 960.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8093.52 toks/s, output: 1306.03 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [02:32<00:04,  2.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.77 toks/s, output: 42.30 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6541.33 toks/s, output: 923.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.60it/s, est. speed input: 8132.89 toks/s, output: 1334.24 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [02:34<00:02,  2.21s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 348.35 toks/s, output: 46.96 toks/s][A
Processed prompts:  96%|█████████▋| 27/28 [00:01<00:00, 24.57it/s, est. speed input: 7737.89 toks/s, output: 1097.45 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 19.47it/s, est. speed input: 8026.22 toks/s, output: 1166.16 toks/s]
Processing batched inference: 100%|██████████| 66/66 [02:36<00:00,  2.16s/it]Processing batched inference: 100%|██████████| 66/66 [02:36<00:00,  2.37s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-63/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:25:28.442055955 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-630
INFO 07-05 11:25:40 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:25:42,716 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:25:42,758 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:42,781 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:42,781 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:42,781 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:42,781 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:42,781 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:42,781 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:42,781 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:25:43,170 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:25:43,171 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:25:43,177 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:25:43,183 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:43,184 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:43,184 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:43,185 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:43,185 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:43,185 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:43,185 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:43,185 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:25:43,561 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:25:43,563 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:25:43,767 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:25:44,223 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:25:44,280 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:25:44,281 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:25:44,283 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:25:55 [config.py:689] This model supports multiple tasks: {'score', 'generate', 'embed', 'classify', 'reward'}. Defaulting to 'generate'.
INFO 07-05 11:25:55 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:55,937 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:55,937 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:55,937 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:55,937 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:55,937 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:55,937 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:25:55,937 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:25:56,282 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:25:56,371 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:25:56,371 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:25:57 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:25:59 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:25:59 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630...
WARNING 07-05 11:25:59 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:25:59 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.54s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.54s/it]

INFO 07-05 11:26:07 [loader.py:458] Loading weights took 7.77 seconds
INFO 07-05 11:26:07 [model_runner.py:1146] Model loading took 4.1513 GiB and 8.032041 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:07,615 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:07,615 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:07,615 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:07,615 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:07,615 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:07,615 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:07,615 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:26:08,018 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:26:08,112 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:26:08,113 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:26:08,114 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:26:08,114 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,115 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,115 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,115 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,115 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,115 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,115 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:26:08,115 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:26:08,907 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:26:08,908 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:26:08,908 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:26:09,383 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:26:10,029 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:26:10 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:26:12,913 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:26:13,948 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:26:14 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:26:53 [worker.py:267] Memory profiling takes 45.62 seconds
INFO 07-05 11:26:53 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:26:53 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:26:53 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:26:53 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:26:58 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.78it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.89it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.90it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.92it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.94it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.96it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.97it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.97it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.96it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.96it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.96it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.96it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.92it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.94it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.95it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.96it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.96it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.89it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.91it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.94it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.95it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.96it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.96it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.97it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.94it/s]
INFO 07-05 11:27:16 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:27:16 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.51 seconds
[INFO|2025-07-05 11:27:17] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:27:18,395 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:27:18,395 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:18,396 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:18,396 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:18,396 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:18,396 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:18,396 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:18,396 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:27:18,396 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:27:19,630 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:27:19,631 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:27:19,631 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:27:20,202 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-630', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.68s/it, est. speed input: 248.29 toks/s, output: 32.23 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 15.50it/s, est. speed input: 4861.13 toks/s, output: 690.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 15.81it/s, est. speed input: 6559.28 toks/s, output: 1130.75 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:11,  4.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.10 toks/s, output: 42.07 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.57it/s, est. speed input: 6514.41 toks/s, output: 918.73 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.82it/s, est. speed input: 6878.40 toks/s, output: 1147.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.67it/s, est. speed input: 6895.73 toks/s, output: 1195.12 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:50,  3.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.56 toks/s, output: 42.26 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.18it/s, est. speed input: 5775.44 toks/s, output: 818.17 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.62it/s, est. speed input: 6466.03 toks/s, output: 1138.06 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 19.62it/s, est. speed input: 6681.17 toks/s, output: 1219.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:14<00:00,  1.35it/s, est. speed input: 908.40 toks/s, output: 312.88 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:14<00:00,  2.19it/s, est. speed input: 908.40 toks/s, output: 312.88 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:23<09:28,  9.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.91 toks/s, output: 42.04 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.25it/s, est. speed input: 7940.75 toks/s, output: 1112.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.02it/s, est. speed input: 8279.25 toks/s, output: 1214.38 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:25<06:37,  6.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.38 toks/s, output: 42.11 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.00it/s, est. speed input: 6036.45 toks/s, output: 850.94 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.23it/s, est. speed input: 6675.49 toks/s, output: 1162.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.83it/s, est. speed input: 2413.09 toks/s, output: 541.46 toks/s] 
Processing batched inference:   8%|▊         | 5/66 [00:31<06:28,  6.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.30 toks/s, output: 42.10 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6533.40 toks/s, output: 922.44 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.45it/s, est. speed input: 6780.25 toks/s, output: 1126.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6865.67 toks/s, output: 1186.08 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:34<05:08,  5.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.63 toks/s, output: 41.49 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.03it/s, est. speed input: 7019.22 toks/s, output: 983.48 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.17it/s, est. speed input: 7113.01 toks/s, output: 1149.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.15it/s, est. speed input: 7113.01 toks/s, output: 1149.13 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:37<04:16,  4.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.54 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6835.96 toks/s, output: 964.88 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8159.79 toks/s, output: 1319.20 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:39<03:38,  3.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.12 toks/s, output: 42.21 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 6180.72 toks/s, output: 882.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 8010.95 toks/s, output: 1355.89 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:42<03:10,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.14 toks/s, output: 42.07 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.55it/s, est. speed input: 7135.29 toks/s, output: 999.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  5.32it/s, est. speed input: 2199.57 toks/s, output: 475.84 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:48<04:07,  4.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.26 toks/s, output: 42.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6831.17 toks/s, output: 956.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.42it/s, est. speed input: 6900.48 toks/s, output: 1163.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6900.48 toks/s, output: 1163.64 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:51<03:34,  3.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.51 toks/s, output: 42.12 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.11it/s, est. speed input: 6314.76 toks/s, output: 898.72 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.00it/s, est. speed input: 6618.77 toks/s, output: 1113.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6852.46 toks/s, output: 1242.82 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:54<03:10,  3.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.48 toks/s, output: 41.99 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6840.83 toks/s, output: 964.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.70it/s, est. speed input: 8167.06 toks/s, output: 1326.28 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:56<02:48,  3.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.36 toks/s, output: 42.10 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.79it/s, est. speed input: 6866.61 toks/s, output: 969.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8171.31 toks/s, output: 1306.93 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:59<02:32,  2.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.90 toks/s, output: 41.52 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.42it/s, est. speed input: 5226.24 toks/s, output: 738.02 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.94it/s, est. speed input: 6421.62 toks/s, output: 1168.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  6.22it/s, est. speed input: 2568.10 toks/s, output: 610.89 toks/s] 
Processing batched inference:  23%|██▎       | 15/66 [01:04<03:14,  3.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.38 toks/s, output: 41.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6546.19 toks/s, output: 925.92 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.50it/s, est. speed input: 6866.45 toks/s, output: 1169.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6866.45 toks/s, output: 1169.55 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:07<02:53,  3.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.22 toks/s, output: 42.49 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.13it/s, est. speed input: 5689.36 toks/s, output: 811.76 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.90it/s, est. speed input: 5122.39 toks/s, output: 955.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.35it/s, est. speed input: 1374.67 toks/s, output: 395.35 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:17<04:31,  5.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.22 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6526.34 toks/s, output: 923.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8091.69 toks/s, output: 1345.84 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:20<03:40,  4.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.36 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.51it/s, est. speed input: 7113.23 toks/s, output: 1001.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8185.37 toks/s, output: 1297.71 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:22<03:04,  3.92s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.58 toks/s, output: 42.36 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.26it/s, est. speed input: 6994.57 toks/s, output: 995.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 8057.33 toks/s, output: 1287.43 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:25<02:37,  3.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.54 toks/s, output: 42.00 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 5981.17 toks/s, output: 852.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.63it/s, est. speed input: 6725.52 toks/s, output: 1168.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  5.06it/s, est. speed input: 2086.74 toks/s, output: 489.96 toks/s] 
Processing batched inference:  32%|███▏      | 21/66 [01:32<03:22,  4.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.74 toks/s, output: 41.89 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.29it/s, est. speed input: 5501.89 toks/s, output: 777.14 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.72it/s, est. speed input: 6418.99 toks/s, output: 1148.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.19it/s, est. speed input: 5467.22 toks/s, output: 1078.59 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:35<03:01,  4.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.01 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.38it/s, est. speed input: 7399.65 toks/s, output: 1033.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.81it/s, est. speed input: 1581.43 toks/s, output: 374.88 toks/s] 
Processing batched inference:  35%|███▍      | 23/66 [01:44<04:02,  5.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.16 toks/s, output: 41.95 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6273.82 toks/s, output: 882.79 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.12it/s, est. speed input: 6432.52 toks/s, output: 1075.28 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00, 19.12it/s, est. speed input: 3520.54 toks/s, output: 691.88 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.41s/it, est. speed input: 504.26 toks/s, output: 252.92 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 504.26 toks/s, output: 252.92 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [02:11<08:24, 12.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.09 toks/s, output: 40.90 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.42it/s, est. speed input: 6406.96 toks/s, output: 906.73 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.57it/s, est. speed input: 6311.04 toks/s, output: 1058.89 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:18<00:00, 18.57it/s, est. speed input: 1440.01 toks/s, output: 381.44 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.42s/it, est. speed input: 504.80 toks/s, output: 286.92 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 504.80 toks/s, output: 286.92 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [02:38<11:13, 16.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.78 toks/s, output: 40.73 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 18.99it/s, est. speed input: 6020.13 toks/s, output: 856.19 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.91it/s, est. speed input: 6306.00 toks/s, output: 1067.68 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 18.91it/s, est. speed input: 6516.45 toks/s, output: 1146.91 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:14<00:00,  1.29it/s, est. speed input: 886.38 toks/s, output: 303.33 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:14<00:00,  2.15it/s, est. speed input: 886.38 toks/s, output: 303.33 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:53<10:48, 16.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.70 toks/s, output: 40.85 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.91it/s, est. speed input: 7195.21 toks/s, output: 1014.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.43it/s, est. speed input: 6780.18 toks/s, output: 1098.54 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:56<07:52, 12.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.79 toks/s, output: 40.73 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.40it/s, est. speed input: 6090.89 toks/s, output: 865.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.16it/s, est. speed input: 7904.67 toks/s, output: 1346.18 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:58<05:48,  9.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.87 toks/s, output: 40.87 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.04it/s, est. speed input: 6023.36 toks/s, output: 857.51 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.94it/s, est. speed input: 6250.60 toks/s, output: 1035.82 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 18.94it/s, est. speed input: 5655.87 toks/s, output: 1036.10 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.39s/it, est. speed input: 502.30 toks/s, output: 245.60 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 502.30 toks/s, output: 245.60 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [03:25<08:56, 14.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.66 toks/s, output: 40.97 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.32it/s, est. speed input: 6761.78 toks/s, output: 950.25 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.41it/s, est. speed input: 6891.64 toks/s, output: 1154.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6891.64 toks/s, output: 1154.64 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [03:28<06:32, 10.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.87 toks/s, output: 41.00 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.50it/s, est. speed input: 6141.26 toks/s, output: 868.71 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.06it/s, est. speed input: 6585.30 toks/s, output: 1118.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6778.46 toks/s, output: 1193.77 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [03:30<04:53,  8.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.36 toks/s, output: 40.81 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.14it/s, est. speed input: 6652.41 toks/s, output: 932.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.24it/s, est. speed input: 7952.45 toks/s, output: 1286.91 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [03:32<03:43,  6.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.38 toks/s, output: 40.81 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.02it/s, est. speed input: 6041.08 toks/s, output: 858.05 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.52it/s, est. speed input: 6731.44 toks/s, output: 1173.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.25it/s, est. speed input: 6731.44 toks/s, output: 1173.94 toks/s]
Processing batched inference:  50%|█████     | 33/66 [03:35<02:57,  5.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.22 toks/s, output: 40.79 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 16.68it/s, est. speed input: 5324.47 toks/s, output: 752.69 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.52it/s, est. speed input: 5721.40 toks/s, output: 1060.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.81it/s, est. speed input: 1994.30 toks/s, output: 496.96 toks/s] 
Processing batched inference:  52%|█████▏    | 34/66 [03:43<03:12,  6.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.41 toks/s, output: 41.20 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.32it/s, est. speed input: 6716.16 toks/s, output: 946.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.43it/s, est. speed input: 8018.81 toks/s, output: 1293.86 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [03:45<02:31,  4.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.47 toks/s, output: 41.60 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.61it/s, est. speed input: 6508.69 toks/s, output: 914.96 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.96it/s, est. speed input: 6872.94 toks/s, output: 1142.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6825.68 toks/s, output: 1179.49 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [03:47<02:05,  4.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.57 toks/s, output: 41.48 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.19it/s, est. speed input: 7339.95 toks/s, output: 1025.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8195.21 toks/s, output: 1253.72 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [03:50<01:44,  3.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.20 toks/s, output: 41.30 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.05it/s, est. speed input: 6375.53 toks/s, output: 906.91 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.28it/s, est. speed input: 6681.72 toks/s, output: 1098.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6873.71 toks/s, output: 1219.99 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [03:52<01:32,  3.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 318.82 toks/s, output: 41.38 toks/s][A
Processed prompts:  50%|█████     | 16/32 [00:01<00:01, 12.74it/s, est. speed input: 4091.01 toks/s, output: 583.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.77it/s, est. speed input: 6104.33 toks/s, output: 1196.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5872.47 toks/s, output: 1287.91 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:55<01:25,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 318.82 toks/s, output: 41.39 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.52it/s, est. speed input: 6499.25 toks/s, output: 918.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 8073.20 toks/s, output: 1340.06 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:57<01:15,  2.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.17 toks/s, output: 41.69 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.98it/s, est. speed input: 5698.49 toks/s, output: 804.84 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.87it/s, est. speed input: 6463.58 toks/s, output: 1134.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.75it/s, est. speed input: 6093.51 toks/s, output: 1163.38 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [04:00<01:11,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.86 toks/s, output: 41.78 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6524.67 toks/s, output: 924.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.02it/s, est. speed input: 6684.43 toks/s, output: 1112.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6879.00 toks/s, output: 1188.89 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [04:03<01:06,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.29 toks/s, output: 41.32 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.49it/s, est. speed input: 6461.57 toks/s, output: 910.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.10it/s, est. speed input: 6058.87 toks/s, output: 1044.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.72it/s, est. speed input: 6058.87 toks/s, output: 1044.99 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [04:05<01:04,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 318.85 toks/s, output: 41.39 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.74it/s, est. speed input: 6216.71 toks/s, output: 878.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5368.31 toks/s, output: 957.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.02it/s, est. speed input: 5368.31 toks/s, output: 957.66 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [04:08<01:03,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.58 toks/s, output: 41.48 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.19it/s, est. speed input: 7302.43 toks/s, output: 1024.54 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 23.19it/s, est. speed input: 4613.75 toks/s, output: 784.40 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:15<00:00,  1.59it/s, est. speed input: 852.88 toks/s, output: 293.39 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s, est. speed input: 852.88 toks/s, output: 293.39 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [04:25<02:23,  6.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.69 toks/s, output: 41.63 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.16it/s, est. speed input: 5766.08 toks/s, output: 811.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.38it/s, est. speed input: 6331.68 toks/s, output: 1080.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 19.38it/s, est. speed input: 2147.72 toks/s, output: 508.22 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.09it/s, est. speed input: 729.89 toks/s, output: 322.18 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.77it/s, est. speed input: 729.89 toks/s, output: 322.18 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [04:43<03:28, 10.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.45 toks/s, output: 41.73 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.82it/s, est. speed input: 7230.56 toks/s, output: 1023.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8146.57 toks/s, output: 1267.17 toks/s]
Processing batched inference:  71%|███████   | 47/66 [04:46<02:31,  7.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.99 toks/s, output: 42.46 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.64it/s, est. speed input: 6782.89 toks/s, output: 962.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8105.25 toks/s, output: 1317.53 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [04:48<01:52,  6.24s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.53 toks/s, output: 41.61 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.15it/s, est. speed input: 5724.65 toks/s, output: 811.40 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.40it/s, est. speed input: 6874.75 toks/s, output: 1230.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6874.75 toks/s, output: 1230.72 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [04:50<01:26,  5.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.01 toks/s, output: 41.15 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.17it/s, est. speed input: 7292.07 toks/s, output: 1020.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.82it/s, est. speed input: 6954.62 toks/s, output: 1092.17 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [04:53<01:10,  4.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.67 toks/s, output: 41.62 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.81it/s, est. speed input: 5948.17 toks/s, output: 843.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.81it/s, est. speed input: 6799.17 toks/s, output: 1197.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.43it/s, est. speed input: 6799.17 toks/s, output: 1197.97 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [04:56<00:57,  3.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.03 toks/s, output: 41.67 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.84it/s, est. speed input: 5969.83 toks/s, output: 847.72 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.54it/s, est. speed input: 6452.42 toks/s, output: 1108.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5904.36 toks/s, output: 1112.14 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [04:59<00:49,  3.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 312.51 toks/s, output: 41.06 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.64it/s, est. speed input: 5901.19 toks/s, output: 832.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.24it/s, est. speed input: 7963.58 toks/s, output: 1375.76 toks/s]
Processing batched inference:  80%|████████  | 53/66 [05:01<00:41,  3.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.40 toks/s, output: 41.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.43it/s, est. speed input: 6764.28 toks/s, output: 951.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 8081.05 toks/s, output: 1297.90 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [05:03<00:34,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.09 toks/s, output: 41.55 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.46it/s, est. speed input: 6766.89 toks/s, output: 951.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:16<00:00, 21.46it/s, est. speed input: 6634.79 toks/s, output: 1104.07 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.33it/s, est. speed input: 705.59 toks/s, output: 268.15 toks/s]  [AProcessed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.71it/s, est. speed input: 705.59 toks/s, output: 268.15 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [05:22<01:26,  7.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 312.61 toks/s, output: 42.49 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.27it/s, est. speed input: 5143.73 toks/s, output: 736.59 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.75it/s, est. speed input: 5722.10 toks/s, output: 1085.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.25it/s, est. speed input: 5891.56 toks/s, output: 1174.21 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [05:25<01:03,  6.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.35 toks/s, output: 41.45 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.78it/s, est. speed input: 5934.19 toks/s, output: 836.48 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.79it/s, est. speed input: 6486.30 toks/s, output: 1107.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  6.20it/s, est. speed input: 2556.95 toks/s, output: 571.44 toks/s] 
Processing batched inference:  86%|████████▋ | 57/66 [05:31<00:55,  6.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.77 toks/s, output: 42.30 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.20it/s, est. speed input: 5435.69 toks/s, output: 769.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.37it/s, est. speed input: 6970.07 toks/s, output: 1280.83 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.92it/s, est. speed input: 6970.07 toks/s, output: 1280.83 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [05:34<00:40,  5.09s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.15 toks/s, output: 41.82 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6536.65 toks/s, output: 920.07 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.43it/s, est. speed input: 5151.34 toks/s, output: 895.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.64it/s, est. speed input: 1908.49 toks/s, output: 462.37 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [05:41<00:40,  5.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 318.54 toks/s, output: 41.38 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.00it/s, est. speed input: 6338.11 toks/s, output: 885.04 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.19it/s, est. speed input: 6727.17 toks/s, output: 1135.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6874.46 toks/s, output: 1205.14 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [05:44<00:28,  4.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.27 toks/s, output: 42.36 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.54it/s, est. speed input: 5226.86 toks/s, output: 744.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.11it/s, est. speed input: 6671.59 toks/s, output: 1237.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6889.08 toks/s, output: 1316.81 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [05:46<00:20,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.12 toks/s, output: 41.81 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.68it/s, est. speed input: 5946.83 toks/s, output: 845.62 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.17it/s, est. speed input: 6816.75 toks/s, output: 1189.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.96it/s, est. speed input: 7014.66 toks/s, output: 1264.06 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [05:49<00:14,  3.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.32 toks/s, output: 41.32 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.87it/s, est. speed input: 7220.53 toks/s, output: 1015.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.68it/s, est. speed input: 3585.67 toks/s, output: 646.56 toks/s] 
Processing batched inference:  95%|█████████▌| 63/66 [05:53<00:11,  3.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.21 toks/s, output: 41.44 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.96it/s, est. speed input: 5995.83 toks/s, output: 844.48 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.11it/s, est. speed input: 6372.51 toks/s, output: 1091.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.71it/s, est. speed input: 4834.45 toks/s, output: 955.39 toks/s] 
Processing batched inference:  97%|█████████▋| 64/66 [05:57<00:07,  3.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.75 toks/s, output: 41.62 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.85it/s, est. speed input: 5981.42 toks/s, output: 840.77 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.85it/s, est. speed input: 6827.88 toks/s, output: 1197.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.46it/s, est. speed input: 6827.88 toks/s, output: 1197.80 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [05:59<00:03,  3.35s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.18s/it, est. speed input: 345.28 toks/s, output: 46.54 toks/s][A
Processed prompts:  71%|███████▏  | 20/28 [00:01<00:00, 17.79it/s, est. speed input: 5624.20 toks/s, output: 806.58 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.45it/s, est. speed input: 7605.00 toks/s, output: 1321.74 toks/s]
Processing batched inference: 100%|██████████| 66/66 [06:01<00:00,  2.98s/it]Processing batched inference: 100%|██████████| 66/66 [06:01<00:00,  5.48s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-630/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:33:20.902853726 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-693
INFO 07-05 11:33:33 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:33:35,100 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:33:35,141 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,164 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,164 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,165 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,165 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,165 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,165 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,165 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:33:35,576 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:33:35,577 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:33:35,583 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:33:35,590 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,590 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,590 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,590 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,591 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,591 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,591 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:35,591 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:33:35,963 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:33:35,966 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:33:36,176 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:33:36,623 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:33:36,673 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:33:36,673 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:33:36,675 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:33:48 [config.py:689] This model supports multiple tasks: {'embed', 'reward', 'generate', 'classify', 'score'}. Defaulting to 'generate'.
INFO 07-05 11:33:48 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:48,940 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:48,940 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:48,940 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:48,940 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:48,940 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:48,940 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:48,940 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:33:49,272 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:33:49,375 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:33:49,378 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:33:50 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:33:51 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:33:51 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693...
WARNING 07-05 11:33:51 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:33:51 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.37s/it]

INFO 07-05 11:33:59 [loader.py:458] Loading weights took 7.58 seconds
INFO 07-05 11:33:59 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.813219 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,468 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,468 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,468 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,468 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,468 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,468 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,468 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:33:59,874 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:33:59,968 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:33:59,968 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:33:59,969 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:33:59,969 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,970 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,970 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,970 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,970 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,970 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,970 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:33:59,970 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:34:00,728 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:34:00,729 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:34:00,729 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:34:01,190 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:34:01,813 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:34:02 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:34:04,680 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:34:05,702 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:34:05 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:34:44 [worker.py:267] Memory profiling takes 45.36 seconds
INFO 07-05 11:34:44 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:34:44 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:34:45 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:34:45 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:34:58 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:20,  1.65it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.80it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.92it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.91it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.93it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.97it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.97it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.96it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.98it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.97it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.97it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.97it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.98it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.97it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.98it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.90it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.92it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.90it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.92it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.93it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.95it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.87it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.94it/s]
INFO 07-05 11:35:16 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:35:16 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 77.66 seconds
[INFO|2025-07-05 11:35:17] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:22, 88.77 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 298.06 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:04, 390.35 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:02<00:02, 548.41 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 748.77 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:02<00:01, 771.55 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:02<00:01, 781.40 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 856.39 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:02<00:00, 922.64 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:03<00:00, 906.58 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 895.11 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 598.87 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:35:24,155 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:35:24,156 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:24,157 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:24,157 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:24,157 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:24,157 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:24,157 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:24,157 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:35:24,157 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:35:24,940 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:35:24,941 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:35:24,941 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:35:25,399 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-693', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.66s/it, est. speed input: 250.60 toks/s, output: 32.53 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.70it/s, est. speed input: 5528.46 toks/s, output: 781.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.00it/s, est. speed input: 6639.58 toks/s, output: 1075.59 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:30,  4.16s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.14 toks/s, output: 41.95 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.48it/s, est. speed input: 7454.71 toks/s, output: 1048.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8196.65 toks/s, output: 1242.87 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:20,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.88 toks/s, output: 42.04 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.70it/s, est. speed input: 6561.28 toks/s, output: 926.82 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:05<00:00,  4.86it/s, est. speed input: 2305.26 toks/s, output: 500.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.57it/s, est. speed input: 2305.26 toks/s, output: 500.91 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:13<04:57,  4.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.43 toks/s, output: 41.98 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7371.86 toks/s, output: 1034.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 8218.48 toks/s, output: 1263.23 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:15<03:57,  3.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.65 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6835.21 toks/s, output: 962.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.50it/s, est. speed input: 5528.73 toks/s, output: 948.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.35it/s, est. speed input: 5528.73 toks/s, output: 948.98 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:18<03:39,  3.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.91 toks/s, output: 42.05 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 7072.13 toks/s, output: 995.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.99it/s, est. speed input: 6987.44 toks/s, output: 1130.68 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:21<03:17,  3.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.83 toks/s, output: 42.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.18it/s, est. speed input: 7341.94 toks/s, output: 1029.41 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8205.82 toks/s, output: 1268.18 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:23<02:57,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.92 toks/s, output: 42.05 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7406.07 toks/s, output: 1045.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8211.76 toks/s, output: 1265.76 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:26<02:42,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.55 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6755.36 toks/s, output: 957.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8071.49 toks/s, output: 1308.97 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:28<02:32,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.72 toks/s, output: 41.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.35it/s, est. speed input: 7424.39 toks/s, output: 1043.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.86it/s, est. speed input: 6966.81 toks/s, output: 1106.78 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:31<02:28,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.93 toks/s, output: 41.92 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6801.13 toks/s, output: 953.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8128.59 toks/s, output: 1312.33 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:33<02:22,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.19 toks/s, output: 41.95 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6774.74 toks/s, output: 965.45 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.21it/s, est. speed input: 7028.37 toks/s, output: 1172.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.07it/s, est. speed input: 7028.37 toks/s, output: 1172.27 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:36<02:19,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.63 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.40it/s, est. speed input: 7393.54 toks/s, output: 1041.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8197.37 toks/s, output: 1271.25 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:38<02:13,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.15 toks/s, output: 41.95 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.76it/s, est. speed input: 7455.74 toks/s, output: 1047.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.37it/s, est. speed input: 8427.29 toks/s, output: 1286.75 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:40<02:07,  2.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 320.62 toks/s, output: 41.34 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 6023.80 toks/s, output: 851.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.54it/s, est. speed input: 8072.53 toks/s, output: 1385.82 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:43<02:03,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.00 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.36it/s, est. speed input: 7360.23 toks/s, output: 1038.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8166.22 toks/s, output: 1270.66 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:45<02:00,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.90 toks/s, output: 42.45 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6489.83 toks/s, output: 920.24 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.06it/s, est. speed input: 6679.17 toks/s, output: 1121.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.53it/s, est. speed input: 5963.19 toks/s, output: 1062.50 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:48<02:05,  2.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.95 toks/s, output: 41.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.31it/s, est. speed input: 7601.22 toks/s, output: 1075.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8144.26 toks/s, output: 1233.91 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:51<02:00,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.30 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.49it/s, est. speed input: 7108.75 toks/s, output: 1001.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8179.42 toks/s, output: 1296.77 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [00:53<01:55,  2.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.74 toks/s, output: 42.25 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.32it/s, est. speed input: 6720.55 toks/s, output: 955.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.40it/s, est. speed input: 6845.93 toks/s, output: 1170.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6845.93 toks/s, output: 1170.63 toks/s]
Processing batched inference:  30%|███       | 20/66 [00:55<01:54,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.92 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 7053.21 toks/s, output: 1000.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.79it/s, est. speed input: 6921.97 toks/s, output: 1123.04 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [00:58<01:54,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.24 toks/s, output: 41.96 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.08it/s, est. speed input: 5741.62 toks/s, output: 812.57 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.73it/s, est. speed input: 6908.88 toks/s, output: 1222.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6859.36 toks/s, output: 1256.51 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:01<01:53,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.45 toks/s, output: 41.99 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 7131.20 toks/s, output: 998.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8188.35 toks/s, output: 1287.46 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:03<01:46,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.39 toks/s, output: 41.98 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6827.11 toks/s, output: 959.23 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.69it/s, est. speed input: 5281.30 toks/s, output: 914.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.83it/s, est. speed input: 5281.30 toks/s, output: 914.75 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:06<01:52,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.01 toks/s, output: 41.93 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.54it/s, est. speed input: 6762.89 toks/s, output: 958.52 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:06<00:00,  4.54it/s, est. speed input: 2181.66 toks/s, output: 489.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:06<00:00,  5.31it/s, est. speed input: 2181.66 toks/s, output: 489.81 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:13<02:39,  3.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.92 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.43it/s, est. speed input: 7135.90 toks/s, output: 1013.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.38it/s, est. speed input: 4286.90 toks/s, output: 749.25 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:17<02:34,  3.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.28 toks/s, output: 41.96 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.32it/s, est. speed input: 7637.36 toks/s, output: 1074.71 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6896.56 toks/s, output: 1067.79 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:19<02:15,  3.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.06 toks/s, output: 41.93 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.57it/s, est. speed input: 6779.47 toks/s, output: 959.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8108.80 toks/s, output: 1323.82 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:22<01:58,  3.12s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.68 toks/s, output: 42.28 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6484.01 toks/s, output: 922.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 8054.38 toks/s, output: 1347.59 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:24<01:45,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.78 toks/s, output: 41.90 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.41it/s, est. speed input: 7720.74 toks/s, output: 1080.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 8298.85 toks/s, output: 1244.57 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:26<01:35,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.81 toks/s, output: 41.90 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 7050.74 toks/s, output: 997.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.85it/s, est. speed input: 8162.78 toks/s, output: 1289.96 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:28<01:28,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 310.53 toks/s, output: 40.31 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.83it/s, est. speed input: 6858.06 toks/s, output: 961.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.11it/s, est. speed input: 7899.47 toks/s, output: 1248.47 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:30<01:23,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.42 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.90it/s, est. speed input: 6652.79 toks/s, output: 943.76 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.26it/s, est. speed input: 5941.44 toks/s, output: 1015.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.34it/s, est. speed input: 5941.44 toks/s, output: 1015.56 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:33<01:25,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.88 toks/s, output: 41.91 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.53it/s, est. speed input: 5910.73 toks/s, output: 836.32 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 8103.98 toks/s, output: 1405.48 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:36<01:20,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.68 toks/s, output: 41.89 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.29it/s, est. speed input: 7640.03 toks/s, output: 1071.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8164.75 toks/s, output: 1230.85 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:38<01:15,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.78 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6789.03 toks/s, output: 958.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8114.41 toks/s, output: 1313.67 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:40<01:10,  2.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.62 toks/s, output: 42.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.41it/s, est. speed input: 7410.81 toks/s, output: 1036.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8215.29 toks/s, output: 1257.41 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:42<01:07,  2.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.40 toks/s, output: 42.38 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.83it/s, est. speed input: 6862.26 toks/s, output: 975.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8133.56 toks/s, output: 1325.09 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:45<01:04,  2.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.41 toks/s, output: 41.33 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.15it/s, est. speed input: 5150.29 toks/s, output: 727.06 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.05it/s, est. speed input: 5856.16 toks/s, output: 1117.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.09it/s, est. speed input: 5856.16 toks/s, output: 1117.84 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:48<01:07,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.46 toks/s, output: 41.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.26it/s, est. speed input: 7667.66 toks/s, output: 1078.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8209.03 toks/s, output: 1240.25 toks/s]
Processing batched inference:  61%|██████    | 40/66 [01:50<01:02,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.12 toks/s, output: 41.81 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 6242.19 toks/s, output: 882.36 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.98it/s, est. speed input: 6642.33 toks/s, output: 1131.86 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s, est. speed input: 6834.64 toks/s, output: 1208.72 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [01:52<01:02,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.23 toks/s, output: 41.83 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.38it/s, est. speed input: 7620.24 toks/s, output: 1075.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.83it/s, est. speed input: 8162.99 toks/s, output: 1234.14 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [01:55<00:57,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.88 toks/s, output: 41.78 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.36it/s, est. speed input: 7633.54 toks/s, output: 1074.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.89it/s, est. speed input: 8188.71 toks/s, output: 1235.17 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [01:57<00:55,  2.40s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.44 toks/s, output: 41.85 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.36it/s, est. speed input: 7337.12 toks/s, output: 1030.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8130.89 toks/s, output: 1250.75 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [01:59<00:51,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.93 toks/s, output: 41.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.99it/s, est. speed input: 8139.95 toks/s, output: 1142.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8149.10 toks/s, output: 1174.21 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:01<00:48,  2.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.93 toks/s, output: 41.79 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6788.48 toks/s, output: 956.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:05<00:00,  5.45it/s, est. speed input: 2560.35 toks/s, output: 535.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:05<00:00,  6.21it/s, est. speed input: 2560.35 toks/s, output: 535.18 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:07<01:06,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.94 toks/s, output: 42.32 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.47it/s, est. speed input: 7075.97 toks/s, output: 1002.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8142.64 toks/s, output: 1294.83 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:09<00:57,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 311.66 toks/s, output: 42.01 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.35it/s, est. speed input: 6996.69 toks/s, output: 991.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8049.39 toks/s, output: 1281.56 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:12<00:49,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.09 toks/s, output: 41.94 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.93it/s, est. speed input: 6005.82 toks/s, output: 850.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 8091.81 toks/s, output: 1388.06 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:14<00:44,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.94 toks/s, output: 41.66 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.21it/s, est. speed input: 7912.39 toks/s, output: 1107.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.03it/s, est. speed input: 8280.74 toks/s, output: 1212.19 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:16<00:40,  2.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.33 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6804.52 toks/s, output: 962.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8133.92 toks/s, output: 1313.36 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:18<00:36,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.46 toks/s, output: 41.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6793.50 toks/s, output: 964.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8116.72 toks/s, output: 1320.26 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:21<00:33,  2.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.30 toks/s, output: 41.43 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.28it/s, est. speed input: 7027.21 toks/s, output: 988.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.77it/s, est. speed input: 6112.08 toks/s, output: 1009.75 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:23<00:32,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.28 toks/s, output: 42.32 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6824.97 toks/s, output: 958.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8142.88 toks/s, output: 1307.84 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:26<00:29,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.56 toks/s, output: 41.87 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.56it/s, est. speed input: 7456.47 toks/s, output: 1047.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5954.94 toks/s, output: 946.60 toks/s] 
Processing batched inference:  83%|████████▎ | 55/66 [02:29<00:28,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.76 toks/s, output: 41.77 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.29it/s, est. speed input: 5188.89 toks/s, output: 740.10 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.89it/s, est. speed input: 6611.91 toks/s, output: 1230.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.46it/s, est. speed input: 6804.72 toks/s, output: 1306.30 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:31<00:25,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.21 toks/s, output: 41.82 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6497.72 toks/s, output: 917.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8090.49 toks/s, output: 1337.99 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:33<00:22,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.10 toks/s, output: 42.34 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6219.04 toks/s, output: 880.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.55it/s, est. speed input: 8054.29 toks/s, output: 1365.19 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:36<00:19,  2.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.35 toks/s, output: 41.84 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.22it/s, est. speed input: 7010.79 toks/s, output: 986.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8099.64 toks/s, output: 1284.42 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [02:38<00:16,  2.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.22 toks/s, output: 41.83 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.89it/s, est. speed input: 6300.88 toks/s, output: 884.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.20it/s, est. speed input: 6715.86 toks/s, output: 1133.25 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6857.51 toks/s, output: 1201.65 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [02:40<00:14,  2.41s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.70 toks/s, output: 41.76 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.65it/s, est. speed input: 6513.70 toks/s, output: 922.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.58it/s, est. speed input: 8099.60 toks/s, output: 1347.48 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [02:43<00:11,  2.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.48 toks/s, output: 41.86 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.70it/s, est. speed input: 5942.18 toks/s, output: 845.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.53it/s, est. speed input: 8077.25 toks/s, output: 1399.40 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [02:45<00:09,  2.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.94 toks/s, output: 41.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.49it/s, est. speed input: 8044.22 toks/s, output: 1130.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8177.54 toks/s, output: 1178.90 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [02:47<00:06,  2.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.53 toks/s, output: 41.87 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7351.98 toks/s, output: 1034.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8145.81 toks/s, output: 1260.83 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [02:50<00:04,  2.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.64 toks/s, output: 41.75 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.77it/s, est. speed input: 6266.44 toks/s, output: 879.71 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.65it/s, est. speed input: 6848.44 toks/s, output: 1178.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6848.44 toks/s, output: 1178.19 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [02:52<00:02,  2.36s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 355.15 toks/s, output: 46.66 toks/s][A
Processed prompts:  89%|████████▉ | 25/28 [00:01<00:00, 22.80it/s, est. speed input: 7194.78 toks/s, output: 1017.03 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.85it/s, est. speed input: 7771.96 toks/s, output: 1195.21 toks/s]
Processing batched inference: 100%|██████████| 66/66 [02:54<00:00,  2.28s/it]Processing batched inference: 100%|██████████| 66/66 [02:54<00:00,  2.65s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-693/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:38:19.718896605 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-756
INFO 07-05 11:38:32 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:38:34,711 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:38:34,765 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:34,792 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:34,792 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:34,793 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:34,793 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:34,793 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:34,793 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:34,793 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:38:35,180 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:38:35,181 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:38:35,188 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:38:35,196 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:35,197 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:35,197 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:35,197 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:35,197 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:35,197 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:35,197 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:35,197 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:38:35,574 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:38:35,577 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:38:35,773 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:38:36,207 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:38:36,262 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:38:36,262 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:38:36,264 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:38:49 [config.py:689] This model supports multiple tasks: {'embed', 'generate', 'classify', 'reward', 'score'}. Defaulting to 'generate'.
INFO 07-05 11:38:49 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:49,233 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:49,233 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:49,233 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:49,233 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:49,233 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:49,233 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:49,233 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:38:49,563 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:38:49,664 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:38:49,667 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:38:51 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:38:51 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:38:51 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756...
WARNING 07-05 11:38:51 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:38:51 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.34s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.34s/it]

INFO 07-05 11:38:59 [loader.py:458] Loading weights took 7.56 seconds
INFO 07-05 11:38:59 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.814025 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:59,802 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:59,802 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:59,802 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:59,802 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:59,802 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:59,802 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:38:59,802 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:39:00,210 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:39:00,306 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:39:00,307 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:39:00,307 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:39:00,307 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:00,309 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:00,309 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:00,309 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:00,309 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:00,309 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:00,309 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:39:00,309 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:39:01,068 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:39:01,069 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:39:01,069 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:39:01,552 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:39:02,217 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:39:02 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:39:05,066 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:39:06,079 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:39:06 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:39:45 [worker.py:267] Memory profiling takes 45.56 seconds
INFO 07-05 11:39:45 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:39:45 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:39:45 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:39:45 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:39:53 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:20,  1.69it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:18,  1.82it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:16,  1.89it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.91it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.93it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.95it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.96it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.97it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.97it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.97it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.98it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.96it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.94it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.90it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.89it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.89it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.91it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.93it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.91it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.86it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.89it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.92it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.87it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.91it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.92it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.94it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.89it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 11:40:12 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:40:12 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 72.44 seconds
[INFO|2025-07-05 11:40:12] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:18, 106.94 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 219.27 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:04, 343.96 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:03, 461.88 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 553.24 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:02, 637.14 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:02<00:01, 730.07 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 790.73 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:02<00:01, 833.67 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:02<00:00, 860.90 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:02<00:00, 891.98 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 940.01 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:02<00:00, 897.95 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 1069.73 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 988.94 examples/s] Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 604.42 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:40:19,328 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:40:19,328 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:40:19,329 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:40:19,329 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:40:19,330 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:40:19,330 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:40:19,330 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:40:19,330 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:40:19,330 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:40:20,113 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:40:20,114 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:40:20,114 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:40:20,566 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-756', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.66s/it, est. speed input: 250.97 toks/s, output: 32.58 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.70it/s, est. speed input: 5542.60 toks/s, output: 782.85 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 18.54it/s, est. speed input: 5962.88 toks/s, output: 985.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5962.88 toks/s, output: 985.72 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:48,  4.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.61 toks/s, output: 42.14 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.61it/s, est. speed input: 6524.40 toks/s, output: 919.69 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.95it/s, est. speed input: 6665.59 toks/s, output: 1090.68 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6907.11 toks/s, output: 1222.15 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:40,  3.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.02 toks/s, output: 42.19 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.96it/s, est. speed input: 5719.30 toks/s, output: 810.84 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.67it/s, est. speed input: 6460.21 toks/s, output: 1137.55 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00, 19.67it/s, est. speed input: 6675.24 toks/s, output: 1218.49 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.52it/s, est. speed input: 1013.42 toks/s, output: 330.77 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.45it/s, est. speed input: 1013.42 toks/s, output: 330.77 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:21<08:37,  8.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.45 toks/s, output: 41.99 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.39it/s, est. speed input: 7379.31 toks/s, output: 1032.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.76it/s, est. speed input: 8173.19 toks/s, output: 1258.73 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:23<06:08,  5.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.03 toks/s, output: 41.93 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.81it/s, est. speed input: 6276.17 toks/s, output: 887.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.54it/s, est. speed input: 5938.36 toks/s, output: 1046.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.34it/s, est. speed input: 5938.36 toks/s, output: 1046.62 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:26<04:58,  4.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.86 toks/s, output: 42.17 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.82it/s, est. speed input: 6557.72 toks/s, output: 923.17 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.16it/s, est. speed input: 5854.52 toks/s, output: 993.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.56it/s, est. speed input: 4755.11 toks/s, output: 890.11 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:30<04:27,  4.46s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.56 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.33it/s, est. speed input: 6474.88 toks/s, output: 909.00 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.98it/s, est. speed input: 6667.27 toks/s, output: 1086.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.42it/s, est. speed input: 5980.11 toks/s, output: 1076.06 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:33<03:55,  4.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.09 toks/s, output: 42.07 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7134.21 toks/s, output: 1005.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.78it/s, est. speed input: 8206.95 toks/s, output: 1296.54 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:35<03:22,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.91 toks/s, output: 41.94 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6509.85 toks/s, output: 920.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.66it/s, est. speed input: 5963.08 toks/s, output: 1031.54 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.53it/s, est. speed input: 5963.08 toks/s, output: 1031.54 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:38<03:08,  3.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.89 toks/s, output: 42.04 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.39it/s, est. speed input: 7378.53 toks/s, output: 1035.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.84it/s, est. speed input: 6961.76 toks/s, output: 1104.40 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:41<02:53,  3.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.78 toks/s, output: 42.03 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.65it/s, est. speed input: 6820.71 toks/s, output: 953.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8148.17 toks/s, output: 1317.34 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:43<02:39,  2.89s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.40 toks/s, output: 41.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6524.96 toks/s, output: 929.95 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.52it/s, est. speed input: 7035.49 toks/s, output: 1197.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.09it/s, est. speed input: 7035.49 toks/s, output: 1197.50 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:46<02:31,  2.81s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.07 toks/s, output: 41.94 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.60it/s, est. speed input: 6828.19 toks/s, output: 962.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8155.27 toks/s, output: 1326.82 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:48<02:21,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.86 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.77it/s, est. speed input: 6861.20 toks/s, output: 964.84 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.85it/s, est. speed input: 7204.02 toks/s, output: 1178.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.41it/s, est. speed input: 7204.02 toks/s, output: 1178.89 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:51<02:16,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 326.24 toks/s, output: 41.56 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.06it/s, est. speed input: 6051.87 toks/s, output: 853.47 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.52it/s, est. speed input: 6734.09 toks/s, output: 1163.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.80it/s, est. speed input: 6939.85 toks/s, output: 1243.88 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:53<02:14,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.93 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7085.58 toks/s, output: 1001.15 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 8154.29 toks/s, output: 1298.37 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:56<02:07,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.62 toks/s, output: 42.41 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 6221.24 toks/s, output: 883.50 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:03<00:00, 10.24it/s, est. speed input: 4175.33 toks/s, output: 778.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.57it/s, est. speed input: 3107.44 toks/s, output: 689.25 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [01:01<02:41,  3.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.53 toks/s, output: 40.83 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.91it/s, est. speed input: 7157.70 toks/s, output: 1014.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.35it/s, est. speed input: 7957.07 toks/s, output: 1236.39 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:03<02:25,  3.03s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.28 toks/s, output: 41.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6564.78 toks/s, output: 925.08 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.70it/s, est. speed input: 6884.43 toks/s, output: 1143.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.46it/s, est. speed input: 3923.35 toks/s, output: 748.54 toks/s] 
Processing batched inference:  29%|██▉       | 19/66 [01:07<02:37,  3.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.70 toks/s, output: 42.38 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.26it/s, est. speed input: 6994.06 toks/s, output: 993.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6879.40 toks/s, output: 1152.38 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:10<02:23,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.72 toks/s, output: 41.89 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.91it/s, est. speed input: 5957.93 toks/s, output: 846.72 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.49it/s, est. speed input: 6690.75 toks/s, output: 1165.92 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.37it/s, est. speed input: 4273.15 toks/s, output: 834.22 toks/s] 
Processing batched inference:  32%|███▏      | 21/66 [01:14<02:29,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.76 toks/s, output: 42.03 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.52it/s, est. speed input: 4955.90 toks/s, output: 701.60 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.23it/s, est. speed input: 6416.78 toks/s, output: 1199.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.79it/s, est. speed input: 6127.20 toks/s, output: 1235.14 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:16<02:20,  3.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.11 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 7126.25 toks/s, output: 997.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6907.01 toks/s, output: 1111.51 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:19<02:09,  3.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.46 toks/s, output: 41.99 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.83it/s, est. speed input: 6277.24 toks/s, output: 886.26 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.31it/s, est. speed input: 5834.72 toks/s, output: 1013.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.96it/s, est. speed input: 1631.47 toks/s, output: 418.67 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:28<03:19,  4.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.17 toks/s, output: 41.82 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.66it/s, est. speed input: 6802.05 toks/s, output: 960.00 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.91it/s, est. speed input: 987.37 toks/s, output: 330.07 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.40it/s, est. speed input: 987.37 toks/s, output: 330.07 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:42<05:09,  7.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.49 toks/s, output: 41.86 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.12it/s, est. speed input: 6694.03 toks/s, output: 950.76 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.65it/s, est. speed input: 6668.97 toks/s, output: 1097.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  7.53it/s, est. speed input: 3107.30 toks/s, output: 622.35 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:47<04:30,  6.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.58 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.59it/s, est. speed input: 6807.60 toks/s, output: 959.74 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.39it/s, est. speed input: 6875.99 toks/s, output: 1190.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6875.99 toks/s, output: 1190.59 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:49<03:34,  5.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.54 toks/s, output: 41.87 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.91it/s, est. speed input: 5966.36 toks/s, output: 847.47 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 22.26it/s, est. speed input: 7077.12 toks/s, output: 1254.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.15it/s, est. speed input: 7077.12 toks/s, output: 1254.03 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:52<02:55,  4.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.88 toks/s, output: 42.31 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.72it/s, est. speed input: 6506.42 toks/s, output: 922.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.76it/s, est. speed input: 6615.35 toks/s, output: 1138.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.37it/s, est. speed input: 5912.10 toks/s, output: 1077.66 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:55<02:31,  4.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.33 toks/s, output: 41.84 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.47it/s, est. speed input: 7430.99 toks/s, output: 1041.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.57it/s, est. speed input: 6062.77 toks/s, output: 973.88 toks/s] 
Processing batched inference:  45%|████▌     | 30/66 [01:58<02:13,  3.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.93 toks/s, output: 41.79 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.37it/s, est. speed input: 7024.77 toks/s, output: 992.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.23it/s, est. speed input: 7088.84 toks/s, output: 1145.02 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [02:00<01:56,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.07 toks/s, output: 41.81 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 7068.41 toks/s, output: 990.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8135.29 toks/s, output: 1286.97 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [02:02<01:41,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.51 toks/s, output: 41.73 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.32it/s, est. speed input: 6147.56 toks/s, output: 872.55 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.34it/s, est. speed input: 5836.00 toks/s, output: 1022.20 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.67it/s, est. speed input: 5250.11 toks/s, output: 991.24 toks/s] 
Processing batched inference:  50%|█████     | 33/66 [02:05<01:41,  3.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.82 toks/s, output: 41.90 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.07it/s, est. speed input: 5743.65 toks/s, output: 813.14 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.38it/s, est. speed input: 6847.52 toks/s, output: 1217.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6911.15 toks/s, output: 1269.91 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [02:08<01:34,  2.94s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.67 toks/s, output: 41.88 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6544.13 toks/s, output: 921.31 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.83it/s, est. speed input: 6911.66 toks/s, output: 1165.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.74it/s, est. speed input: 6911.66 toks/s, output: 1165.45 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:11<01:27,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.76 toks/s, output: 41.90 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.14it/s, est. speed input: 6337.30 toks/s, output: 892.16 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.61it/s, est. speed input: 6830.05 toks/s, output: 1178.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6830.05 toks/s, output: 1178.18 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:13<01:21,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.99 toks/s, output: 41.67 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.21it/s, est. speed input: 7649.43 toks/s, output: 1067.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8188.72 toks/s, output: 1225.62 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:15<01:14,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.37 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.11it/s, est. speed input: 6694.94 toks/s, output: 951.51 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 6861.41 toks/s, output: 1148.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6861.41 toks/s, output: 1148.91 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:18<01:12,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.11 toks/s, output: 41.81 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.59it/s, est. speed input: 4670.34 toks/s, output: 664.06 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 20.43it/s, est. speed input: 6353.33 toks/s, output: 1190.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.64it/s, est. speed input: 5252.49 toks/s, output: 1114.01 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:21<01:14,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.52 toks/s, output: 41.86 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.46it/s, est. speed input: 7107.90 toks/s, output: 1003.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6904.68 toks/s, output: 1120.62 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:24<01:09,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.47 toks/s, output: 41.86 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.04it/s, est. speed input: 5725.51 toks/s, output: 806.24 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.52it/s, est. speed input: 6398.97 toks/s, output: 1122.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.39it/s, est. speed input: 5945.16 toks/s, output: 1139.11 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:27<01:08,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.70 toks/s, output: 41.89 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.60it/s, est. speed input: 7392.17 toks/s, output: 1042.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.57it/s, est. speed input: 5995.79 toks/s, output: 970.23 toks/s] 
Processing batched inference:  64%|██████▎   | 42/66 [02:29<01:06,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.54 toks/s, output: 41.87 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6553.42 toks/s, output: 925.13 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.32it/s, est. speed input: 5399.99 toks/s, output: 947.75 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.12it/s, est. speed input: 5399.99 toks/s, output: 947.75 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:32<01:06,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.19 toks/s, output: 41.82 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.00it/s, est. speed input: 5992.85 toks/s, output: 849.52 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.55it/s, est. speed input: 6096.26 toks/s, output: 1087.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.79it/s, est. speed input: 6096.26 toks/s, output: 1087.52 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:35<01:02,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.03 toks/s, output: 41.80 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.05it/s, est. speed input: 8152.70 toks/s, output: 1144.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8162.80 toks/s, output: 1176.19 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:37<00:55,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.31 toks/s, output: 41.84 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6797.50 toks/s, output: 957.40 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.17it/s, est. speed input: 1115.54 toks/s, output: 379.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:11<00:00,  2.71it/s, est. speed input: 1115.54 toks/s, output: 379.38 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [02:50<01:52,  5.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.03 toks/s, output: 41.93 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.82it/s, est. speed input: 7541.21 toks/s, output: 1065.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8200.27 toks/s, output: 1246.43 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:52<01:27,  4.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.29 toks/s, output: 42.37 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.50it/s, est. speed input: 7040.95 toks/s, output: 996.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6841.90 toks/s, output: 1115.29 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:55<01:11,  3.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.44 toks/s, output: 41.85 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.32it/s, est. speed input: 5172.06 toks/s, output: 737.07 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.83it/s, est. speed input: 6609.30 toks/s, output: 1216.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.50it/s, est. speed input: 6822.62 toks/s, output: 1296.67 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:57<01:00,  3.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.85 toks/s, output: 41.26 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.21it/s, est. speed input: 7298.47 toks/s, output: 1026.51 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.97it/s, est. speed input: 7017.25 toks/s, output: 1100.94 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [03:00<00:51,  3.25s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.59 toks/s, output: 41.10 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 16.93it/s, est. speed input: 5374.13 toks/s, output: 763.84 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.93it/s, est. speed input: 5841.17 toks/s, output: 1092.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.12it/s, est. speed input: 5841.17 toks/s, output: 1092.26 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [03:03<00:47,  3.14s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.80 toks/s, output: 41.12 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.27it/s, est. speed input: 6697.67 toks/s, output: 949.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 8009.92 toks/s, output: 1304.71 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [03:05<00:40,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.34 toks/s, output: 41.43 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.40it/s, est. speed input: 6758.26 toks/s, output: 951.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.16it/s, est. speed input: 6823.00 toks/s, output: 1129.26 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6823.00 toks/s, output: 1129.26 toks/s]
Processing batched inference:  80%|████████  | 53/66 [03:07<00:36,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 310.26 toks/s, output: 41.52 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.03it/s, est. speed input: 7257.01 toks/s, output: 1018.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.41it/s, est. speed input: 8046.12 toks/s, output: 1234.08 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [03:10<00:31,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.48 toks/s, output: 40.95 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.21it/s, est. speed input: 6675.03 toks/s, output: 941.30 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.06it/s, est. speed input: 5867.69 toks/s, output: 1035.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.20it/s, est. speed input: 5867.69 toks/s, output: 1035.29 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [03:13<00:29,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.35s/it, est. speed input: 304.37 toks/s, output: 41.37 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 15.94it/s, est. speed input: 5029.54 toks/s, output: 720.41 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 17.27it/s, est. speed input: 5627.43 toks/s, output: 986.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.83it/s, est. speed input: 5751.63 toks/s, output: 1209.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.91it/s, est. speed input: 5751.63 toks/s, output: 1209.81 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:16<00:28,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.44 toks/s, output: 40.69 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.36it/s, est. speed input: 6098.38 toks/s, output: 860.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.13it/s, est. speed input: 7892.31 toks/s, output: 1333.32 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:18<00:24,  2.67s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.58 toks/s, output: 41.33 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.47it/s, est. speed input: 6392.51 toks/s, output: 902.27 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.22it/s, est. speed input: 6716.42 toks/s, output: 1139.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.31it/s, est. speed input: 6716.42 toks/s, output: 1139.95 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:21<00:21,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.41 toks/s, output: 41.46 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.30it/s, est. speed input: 6718.75 toks/s, output: 946.75 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.45it/s, est. speed input: 5954.90 toks/s, output: 1051.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.47it/s, est. speed input: 5954.90 toks/s, output: 1051.04 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:23<00:18,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.06 toks/s, output: 41.29 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.83it/s, est. speed input: 5969.24 toks/s, output: 836.65 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.34it/s, est. speed input: 5792.99 toks/s, output: 1022.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.60it/s, est. speed input: 5216.91 toks/s, output: 991.72 toks/s] 
Processing batched inference:  91%|█████████ | 60/66 [03:27<00:16,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 311.62 toks/s, output: 41.70 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.72it/s, est. speed input: 5895.62 toks/s, output: 838.05 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.33it/s, est. speed input: 6627.97 toks/s, output: 1156.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.38it/s, est. speed input: 6777.33 toks/s, output: 1225.81 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:29<00:13,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.50 toks/s, output: 40.82 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.22it/s, est. speed input: 6096.89 toks/s, output: 865.54 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.88it/s, est. speed input: 6278.71 toks/s, output: 1037.63 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.84it/s, est. speed input: 5312.47 toks/s, output: 1014.32 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:32<00:11,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.53 toks/s, output: 40.83 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.43it/s, est. speed input: 7099.06 toks/s, output: 998.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.82it/s, est. speed input: 6949.17 toks/s, output: 1100.11 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:35<00:08,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 317.09 toks/s, output: 41.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.18it/s, est. speed input: 6981.71 toks/s, output: 982.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.45it/s, est. speed input: 6790.21 toks/s, output: 1101.37 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:37<00:05,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.90 toks/s, output: 41.24 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.58it/s, est. speed input: 6203.36 toks/s, output: 870.23 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.80it/s, est. speed input: 6602.64 toks/s, output: 1117.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.43it/s, est. speed input: 6816.09 toks/s, output: 1197.28 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:40<00:02,  2.65s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.18s/it, est. speed input: 347.89 toks/s, output: 45.71 toks/s][A
Processed prompts:  71%|███████▏  | 20/28 [00:01<00:00, 17.77it/s, est. speed input: 5628.21 toks/s, output: 805.10 toks/s][A
Processed prompts: 100%|██████████| 28/28 [00:01<00:00, 20.10it/s, est. speed input: 6515.95 toks/s, output: 1157.87 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 15.80it/s, est. speed input: 6515.95 toks/s, output: 1157.87 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:42<00:00,  2.59s/it]Processing batched inference: 100%|██████████| 66/66 [03:42<00:00,  3.38s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-756/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:44:02.098341049 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-819
INFO 07-05 11:44:15 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:44:17,474 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:44:17,520 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,543 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,543 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,543 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,543 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,543 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,543 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,543 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:44:17,936 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:44:17,938 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:44:17,944 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:44:17,950 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,951 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,951 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,951 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,951 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,951 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,951 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:17,952 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:44:18,327 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:44:18,329 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:44:18,525 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:44:18,973 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:44:19,029 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:44:19,029 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:44:19,031 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:44:30 [config.py:689] This model supports multiple tasks: {'score', 'generate', 'reward', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 07-05 11:44:30 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:30,559 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:30,559 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:30,559 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:30,559 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:30,560 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:30,560 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:30,560 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:44:30,904 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:44:31,006 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:44:31,009 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:44:32 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:44:32 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:44:32 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819...
WARNING 07-05 11:44:32 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:44:32 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.27s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.27s/it]

INFO 07-05 11:44:40 [loader.py:458] Loading weights took 7.48 seconds
INFO 07-05 11:44:40 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.725258 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,018 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,018 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,018 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,018 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,018 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,018 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,018 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:44:41,420 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:44:41,516 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:44:41,516 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:44:41,516 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:44:41,517 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,518 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,518 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,518 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,518 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,518 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,518 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:44:41,518 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:44:42,274 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:44:42,274 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:44:42,275 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:44:42,724 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:44:43,343 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:44:43 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:44:46,226 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:44:47,231 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:44:47 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:45:26 [worker.py:267] Memory profiling takes 45.40 seconds
INFO 07-05 11:45:26 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:45:26 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:45:26 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:45:26 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:45:32 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.76it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.86it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.91it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.92it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:15,  1.92it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.92it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:13,  1.92it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.93it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.95it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.95it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.91it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.93it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.94it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.94it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.95it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.92it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.93it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.95it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.94it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.94it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.95it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.88it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:15<00:03,  1.90it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.92it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:16<00:02,  1.92it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.94it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:17<00:01,  1.95it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.95it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.90it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]
INFO 07-05 11:45:51 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:45:51 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 70.36 seconds
[INFO|2025-07-05 11:45:51] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:18, 104.29 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 221.53 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 329.67 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:03, 436.64 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 539.26 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:02<00:02, 597.83 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:02<00:01, 676.48 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 737.89 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:02<00:01, 767.54 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:02<00:01, 756.67 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:02<00:00, 811.10 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 794.95 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:03<00:00, 850.96 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:03<00:00, 900.84 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 897.86 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 839.09 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 560.88 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:45:58,659 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:45:58,660 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:45:58,661 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:45:58,661 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:45:58,661 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:45:58,661 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:45:58,661 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:45:58,661 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:45:58,661 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:45:59,446 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:45:59,446 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:45:59,447 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:45:59,905 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-819', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it, est. speed input: 249.79 toks/s, output: 32.42 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 16.92it/s, est. speed input: 5289.83 toks/s, output: 750.65 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.53it/s, est. speed input: 5088.19 toks/s, output: 879.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.26it/s, est. speed input: 5088.19 toks/s, output: 879.07 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<05:10,  4.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.22 toks/s, output: 42.09 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.75it/s, est. speed input: 6923.02 toks/s, output: 976.23 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.08it/s, est. speed input: 6185.79 toks/s, output: 1048.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.95it/s, est. speed input: 6185.79 toks/s, output: 1048.72 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:59,  3.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.69 toks/s, output: 42.02 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.10it/s, est. speed input: 5747.32 toks/s, output: 814.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.39it/s, est. speed input: 6653.02 toks/s, output: 1188.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.79it/s, est. speed input: 5294.67 toks/s, output: 1016.95 toks/s]
Processing batched inference:   5%|▍         | 3/66 [00:11<03:44,  3.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.09 toks/s, output: 42.48 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.78it/s, est. speed input: 6554.08 toks/s, output: 927.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.82it/s, est. speed input: 8197.91 toks/s, output: 1343.70 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:13<03:12,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.58 toks/s, output: 42.00 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 6281.57 toks/s, output: 886.69 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 17.07it/s, est. speed input: 6038.10 toks/s, output: 1045.62 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.43it/s, est. speed input: 5975.26 toks/s, output: 1094.60 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:16<03:09,  3.11s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.10 toks/s, output: 42.07 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.58it/s, est. speed input: 6785.21 toks/s, output: 956.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8097.33 toks/s, output: 1310.28 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:19<02:53,  2.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.41 toks/s, output: 41.98 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.75it/s, est. speed input: 5963.86 toks/s, output: 839.18 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.37it/s, est. speed input: 6689.81 toks/s, output: 1162.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6883.04 toks/s, output: 1239.57 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:21<02:48,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.70 toks/s, output: 42.15 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6598.70 toks/s, output: 933.58 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.23it/s, est. speed input: 7045.31 toks/s, output: 1187.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.98it/s, est. speed input: 7045.31 toks/s, output: 1187.29 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:24<02:42,  2.80s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.17 toks/s, output: 41.82 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.66it/s, est. speed input: 6486.54 toks/s, output: 919.33 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.59it/s, est. speed input: 5939.40 toks/s, output: 1028.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.48it/s, est. speed input: 5939.40 toks/s, output: 1028.80 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:27<02:42,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.07 toks/s, output: 41.94 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.59it/s, est. speed input: 6892.74 toks/s, output: 967.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00, 21.59it/s, est. speed input: 5131.02 toks/s, output: 914.88 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.07s/it, est. speed input: 506.28 toks/s, output: 244.39 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.28 toks/s, output: 244.39 toks/s]
Processing batched inference:  15%|█▌        | 10/66 [00:54<09:36, 10.30s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.16 toks/s, output: 41.95 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.02it/s, est. speed input: 6968.45 toks/s, output: 976.45 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.53it/s, est. speed input: 7142.98 toks/s, output: 1152.66 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.29it/s, est. speed input: 7142.98 toks/s, output: 1152.66 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:57<07:18,  7.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.72 toks/s, output: 42.02 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6528.37 toks/s, output: 931.08 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.81it/s, est. speed input: 6617.93 toks/s, output: 1087.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6851.01 toks/s, output: 1217.59 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:59<05:43,  6.37s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.47 toks/s, output: 41.99 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6567.08 toks/s, output: 927.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8153.84 toks/s, output: 1354.87 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [01:02<04:33,  5.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.61 toks/s, output: 42.01 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.15it/s, est. speed input: 6352.33 toks/s, output: 899.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8120.71 toks/s, output: 1354.05 toks/s]
Processing batched inference:  21%|██        | 14/66 [01:04<03:43,  4.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 325.52 toks/s, output: 41.47 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.05it/s, est. speed input: 5745.29 toks/s, output: 810.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 8081.45 toks/s, output: 1420.38 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [01:06<03:09,  3.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.55 toks/s, output: 42.00 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.82it/s, est. speed input: 6931.70 toks/s, output: 980.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.73it/s, est. speed input: 8162.77 toks/s, output: 1301.57 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [01:09<02:45,  3.32s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.90 toks/s, output: 42.45 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.97it/s, est. speed input: 5950.74 toks/s, output: 846.67 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.30it/s, est. speed input: 6384.89 toks/s, output: 1100.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.47it/s, est. speed input: 4709.23 toks/s, output: 941.63 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [01:12<02:45,  3.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.74 toks/s, output: 42.02 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7328.39 toks/s, output: 1038.07 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8141.23 toks/s, output: 1264.39 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [01:15<02:27,  3.07s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.92 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7103.72 toks/s, output: 1000.47 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.49it/s, est. speed input: 8083.11 toks/s, output: 1283.32 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:17<02:14,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.08 toks/s, output: 42.30 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.21it/s, est. speed input: 6981.92 toks/s, output: 993.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6865.53 toks/s, output: 1148.50 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:20<02:08,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.55 toks/s, output: 41.87 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.76it/s, est. speed input: 6242.95 toks/s, output: 885.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.25it/s, est. speed input: 3874.74 toks/s, output: 742.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.40it/s, est. speed input: 3874.74 toks/s, output: 742.04 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:24<02:23,  3.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.85 toks/s, output: 41.91 toks/s][A
Processed prompts:  56%|█████▋    | 18/32 [00:01<00:00, 14.57it/s, est. speed input: 4647.53 toks/s, output: 661.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 22.21it/s, est. speed input: 6781.68 toks/s, output: 1304.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.41it/s, est. speed input: 6801.81 toks/s, output: 1347.01 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:27<02:13,  3.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.58 toks/s, output: 41.09 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.27it/s, est. speed input: 6739.08 toks/s, output: 945.33 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.08it/s, est. speed input: 6798.50 toks/s, output: 1118.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.40it/s, est. speed input: 6798.50 toks/s, output: 1118.13 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:29<02:05,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.08 toks/s, output: 40.90 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.33it/s, est. speed input: 6417.93 toks/s, output: 903.18 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.24it/s, est. speed input: 6455.02 toks/s, output: 1052.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.48it/s, est. speed input: 1431.66 toks/s, output: 445.85 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:39<03:30,  5.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.54 toks/s, output: 40.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.06it/s, est. speed input: 6912.67 toks/s, output: 977.19 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 22.06it/s, est. speed input: 5906.71 toks/s, output: 985.99 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:14<00:00,  1.68it/s, est. speed input: 884.11 toks/s, output: 295.42 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:14<00:00,  2.15it/s, est. speed input: 884.11 toks/s, output: 295.42 toks/s]
Processing batched inference:  38%|███▊      | 25/66 [01:55<05:34,  8.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.25 toks/s, output: 40.79 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.72it/s, est. speed input: 6557.64 toks/s, output: 931.39 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 15.51it/s, est. speed input: 5693.68 toks/s, output: 980.33 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00, 15.51it/s, est. speed input: 5693.68 toks/s, output: 980.33 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.46s/it, est. speed input: 505.27 toks/s, output: 241.07 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, est. speed input: 505.27 toks/s, output: 241.07 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [02:22<09:11, 13.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.71 toks/s, output: 40.72 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.25it/s, est. speed input: 6377.62 toks/s, output: 902.43 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.61it/s, est. speed input: 6309.56 toks/s, output: 1028.81 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.31it/s, est. speed input: 6733.11 toks/s, output: 1187.77 toks/s]
Processing batched inference:  41%|████      | 27/66 [02:24<06:47, 10.44s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.10 toks/s, output: 40.77 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.40it/s, est. speed input: 6090.60 toks/s, output: 866.02 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.40it/s, est. speed input: 6702.76 toks/s, output: 1166.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.25it/s, est. speed input: 6702.76 toks/s, output: 1166.37 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [02:27<05:07,  8.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.39 toks/s, output: 40.68 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.30it/s, est. speed input: 5788.42 toks/s, output: 822.72 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.04it/s, est. speed input: 6262.41 toks/s, output: 1083.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.29it/s, est. speed input: 4641.55 toks/s, output: 913.07 toks/s] 
Processing batched inference:  44%|████▍     | 29/66 [02:30<04:07,  6.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.85 toks/s, output: 41.13 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.39it/s, est. speed input: 6781.76 toks/s, output: 953.32 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.02it/s, est. speed input: 7024.71 toks/s, output: 1151.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.88it/s, est. speed input: 7024.71 toks/s, output: 1151.61 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [02:33<03:15,  5.43s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.59 toks/s, output: 40.84 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.42it/s, est. speed input: 6114.02 toks/s, output: 864.59 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.62it/s, est. speed input: 6731.29 toks/s, output: 1162.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.36it/s, est. speed input: 6731.29 toks/s, output: 1162.96 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [02:35<02:39,  4.57s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 311.81 toks/s, output: 40.48 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.04it/s, est. speed input: 6617.04 toks/s, output: 928.02 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.14it/s, est. speed input: 7911.72 toks/s, output: 1279.73 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [02:38<02:12,  3.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.45 toks/s, output: 40.69 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.67it/s, est. speed input: 6553.66 toks/s, output: 928.48 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.36it/s, est. speed input: 6555.18 toks/s, output: 1076.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.34it/s, est. speed input: 6767.54 toks/s, output: 1155.74 toks/s]
Processing batched inference:  50%|█████     | 33/66 [02:40<01:55,  3.51s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.24 toks/s, output: 40.79 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.53it/s, est. speed input: 5888.80 toks/s, output: 830.50 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.01it/s, est. speed input: 6333.64 toks/s, output: 1085.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.09it/s, est. speed input: 1697.90 toks/s, output: 441.51 toks/s] 
Processing batched inference:  52%|█████▏    | 34/66 [02:49<02:40,  5.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.11 toks/s, output: 40.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.16it/s, est. speed input: 6679.56 toks/s, output: 939.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.27it/s, est. speed input: 7954.96 toks/s, output: 1282.95 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [02:51<02:10,  4.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.00 toks/s, output: 41.41 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.18it/s, est. speed input: 5730.82 toks/s, output: 812.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.34it/s, est. speed input: 7979.31 toks/s, output: 1402.42 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [02:53<01:48,  3.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.40 toks/s, output: 41.33 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.04it/s, est. speed input: 7593.48 toks/s, output: 1061.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.87it/s, est. speed input: 8252.16 toks/s, output: 1232.01 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [02:55<01:32,  3.19s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.01 toks/s, output: 41.93 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.90it/s, est. speed input: 7257.13 toks/s, output: 1029.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6896.23 toks/s, output: 1103.72 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:58<01:24,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.05 toks/s, output: 41.93 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.33it/s, est. speed input: 5214.69 toks/s, output: 735.98 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.06it/s, est. speed input: 6688.92 toks/s, output: 1236.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6860.99 toks/s, output: 1308.62 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [03:01<01:17,  2.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.35 toks/s, output: 41.97 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7121.55 toks/s, output: 1006.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.75it/s, est. speed input: 6954.45 toks/s, output: 1127.13 toks/s]
Processing batched inference:  61%|██████    | 40/66 [03:03<01:11,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.17 toks/s, output: 41.82 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.88it/s, est. speed input: 5965.51 toks/s, output: 843.49 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.68it/s, est. speed input: 6481.99 toks/s, output: 1109.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6831.07 toks/s, output: 1257.18 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [03:06<01:07,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.75 toks/s, output: 41.90 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6797.90 toks/s, output: 965.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8151.91 toks/s, output: 1317.89 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [03:08<01:01,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 321.35 toks/s, output: 41.34 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.28it/s, est. speed input: 5172.44 toks/s, output: 735.60 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 21.21it/s, est. speed input: 6604.25 toks/s, output: 1203.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.76it/s, est. speed input: 6077.64 toks/s, output: 1199.10 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [03:11<01:00,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.46 toks/s, output: 41.73 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.74it/s, est. speed input: 6217.78 toks/s, output: 880.42 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.47it/s, est. speed input: 5389.63 toks/s, output: 962.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.07it/s, est. speed input: 5389.63 toks/s, output: 962.28 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [03:14<01:01,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.46 toks/s, output: 41.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 26.07it/s, est. speed input: 8160.74 toks/s, output: 1145.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.71it/s, est. speed input: 6887.64 toks/s, output: 1018.04 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [03:16<00:56,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.96 toks/s, output: 41.79 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.85it/s, est. speed input: 6272.51 toks/s, output: 885.95 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.05it/s, est. speed input: 6418.40 toks/s, output: 1067.40 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00, 19.05it/s, est. speed input: 2675.80 toks/s, output: 563.73 toks/s] [A
Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.40s/it, est. speed input: 506.05 toks/s, output: 260.65 toks/s] [AProcessed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.23it/s, est. speed input: 506.05 toks/s, output: 260.65 toks/s]
Processing batched inference:  70%|██████▉   | 46/66 [03:43<03:18,  9.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 312.06 toks/s, output: 42.07 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.36it/s, est. speed input: 7037.37 toks/s, output: 996.50 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8099.41 toks/s, output: 1288.56 toks/s]
Processing batched inference:  71%|███████   | 47/66 [03:45<02:24,  7.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.06 toks/s, output: 42.34 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.71it/s, est. speed input: 6522.28 toks/s, output: 923.44 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8073.55 toks/s, output: 1341.80 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [03:47<01:47,  5.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.20 toks/s, output: 41.82 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.17it/s, est. speed input: 5438.88 toks/s, output: 773.93 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.91it/s, est. speed input: 6864.54 toks/s, output: 1235.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.49it/s, est. speed input: 6818.47 toks/s, output: 1268.57 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [03:50<01:24,  4.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 321.22 toks/s, output: 41.70 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.85it/s, est. speed input: 5982.90 toks/s, output: 845.81 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.89it/s, est. speed input: 6769.45 toks/s, output: 1165.82 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.31it/s, est. speed input: 5916.14 toks/s, output: 1078.42 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [03:53<01:09,  4.35s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.52 toks/s, output: 41.74 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.85it/s, est. speed input: 5968.13 toks/s, output: 848.90 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.85it/s, est. speed input: 6813.70 toks/s, output: 1197.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.46it/s, est. speed input: 6813.70 toks/s, output: 1197.96 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [03:56<00:57,  3.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.42 toks/s, output: 41.85 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6539.95 toks/s, output: 925.96 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.62it/s, est. speed input: 5995.55 toks/s, output: 1041.40 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.50it/s, est. speed input: 5995.55 toks/s, output: 1041.40 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [03:58<00:49,  3.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 318.17 toks/s, output: 41.80 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.42it/s, est. speed input: 7080.85 toks/s, output: 998.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8134.83 toks/s, output: 1284.95 toks/s]
Processing batched inference:  80%|████████  | 53/66 [04:01<00:40,  3.13s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.81 toks/s, output: 42.39 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6562.29 toks/s, output: 923.09 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8142.50 toks/s, output: 1336.62 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [04:03<00:34,  2.86s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.82 toks/s, output: 41.77 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.66it/s, est. speed input: 6516.80 toks/s, output: 920.86 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.76it/s, est. speed input: 6649.95 toks/s, output: 1104.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6864.96 toks/s, output: 1185.79 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [04:05<00:30,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 315.46 toks/s, output: 42.88 toks/s][A
Processed prompts:  53%|█████▎    | 17/32 [00:01<00:01, 13.81it/s, est. speed input: 4381.24 toks/s, output: 631.51 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.79it/s, est. speed input: 6149.80 toks/s, output: 1186.80 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.40it/s, est. speed input: 4711.23 toks/s, output: 1059.36 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [04:09<00:29,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.32 toks/s, output: 41.84 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.79it/s, est. speed input: 6236.45 toks/s, output: 880.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.57it/s, est. speed input: 8073.09 toks/s, output: 1364.47 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [04:11<00:24,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.20 toks/s, output: 42.35 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.03it/s, est. speed input: 5981.31 toks/s, output: 844.90 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.16it/s, est. speed input: 6606.05 toks/s, output: 1150.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.56it/s, est. speed input: 6820.25 toks/s, output: 1231.57 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [04:14<00:21,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.68 toks/s, output: 41.89 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.34it/s, est. speed input: 6740.03 toks/s, output: 948.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8088.16 toks/s, output: 1312.70 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [04:16<00:17,  2.56s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.10 toks/s, output: 41.81 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.99it/s, est. speed input: 6025.96 toks/s, output: 846.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.52it/s, est. speed input: 8083.42 toks/s, output: 1386.58 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [04:18<00:14,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.64 toks/s, output: 42.28 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.90it/s, est. speed input: 5963.20 toks/s, output: 849.00 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.49it/s, est. speed input: 6687.16 toks/s, output: 1167.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6905.08 toks/s, output: 1246.83 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [04:21<00:12,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.75 toks/s, output: 41.76 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.67it/s, est. speed input: 5941.14 toks/s, output: 842.94 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.93it/s, est. speed input: 6816.05 toks/s, output: 1207.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6816.05 toks/s, output: 1207.16 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [04:23<00:10,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.27 toks/s, output: 41.70 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.37it/s, est. speed input: 7057.93 toks/s, output: 993.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.57it/s, est. speed input: 6844.63 toks/s, output: 1108.92 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [04:26<00:07,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.59 toks/s, output: 41.35 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.59it/s, est. speed input: 6186.72 toks/s, output: 872.38 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.53it/s, est. speed input: 6767.79 toks/s, output: 1172.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6767.79 toks/s, output: 1172.01 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [04:28<00:05,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.19 toks/s, output: 41.56 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.94it/s, est. speed input: 5703.13 toks/s, output: 804.09 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.24it/s, est. speed input: 6848.96 toks/s, output: 1225.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.51it/s, est. speed input: 6848.96 toks/s, output: 1225.23 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [04:31<00:02,  2.55s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.16s/it, est. speed input: 353.15 toks/s, output: 46.40 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.60it/s, est. speed input: 6828.41 toks/s, output: 966.39 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.72it/s, est. speed input: 7718.83 toks/s, output: 1220.48 toks/s]
Processing batched inference: 100%|██████████| 66/66 [04:33<00:00,  2.41s/it]Processing batched inference: 100%|██████████| 66/66 [04:33<00:00,  4.15s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-819/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:50:33.193145813 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-882
INFO 07-05 11:50:46 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:50:48,041 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:50:48,081 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,105 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,105 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,105 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,105 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,105 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,105 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,105 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:50:48,497 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:50:48,499 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:50:48,505 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:50:48,511 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,512 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,513 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,513 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,513 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,513 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,513 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:50:48,513 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:50:48,885 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:50:48,887 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:50:49,083 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:50:49,533 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:50:49,584 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:50:49,584 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:50:49,586 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:51:01 [config.py:689] This model supports multiple tasks: {'score', 'classify', 'embed', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 07-05 11:51:01 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:01,197 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:01,197 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:01,197 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:01,197 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:01,197 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:01,197 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:01,197 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:01,527 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:51:01,628 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:51:01,631 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:51:02 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:51:03 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:51:03 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882...
WARNING 07-05 11:51:03 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:51:03 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.21s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.21s/it]

INFO 07-05 11:51:11 [loader.py:458] Loading weights took 7.43 seconds
INFO 07-05 11:51:11 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.665540 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:11,591 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:11,591 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:11,591 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:11,591 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:11,591 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:11,591 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:11,591 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:11,995 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:51:12,091 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:51:12,091 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:51:12,092 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:51:12,092 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:12,093 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:12,093 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:12,093 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:12,093 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:12,093 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:12,093 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:51:12,093 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:51:12,856 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:51:12,856 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:51:12,856 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:51:13,308 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:51:13,946 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:51:14 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:51:16,756 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:51:17,748 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:51:17 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:51:56 [worker.py:267] Memory profiling takes 45.27 seconds
INFO 07-05 11:51:56 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:51:56 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:51:57 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:51:57 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:52:02 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.71it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:17,  1.85it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:17,  1.88it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:16,  1.89it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.93it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  1.94it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:14,  1.93it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:13,  1.95it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:12,  1.96it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:11,  1.97it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:10,  1.97it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:08<00:09,  1.95it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.96it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:08,  1.97it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:10<00:07,  1.98it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:07,  1.93it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:11<00:06,  1.94it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:06,  1.94it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:12<00:05,  1.96it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:05,  1.97it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:13<00:04,  1.93it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:04,  1.95it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:14<00:03,  1.88it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:03,  1.91it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:15<00:02,  1.93it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:02,  1.95it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:16<00:01,  1.96it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:01,  1.97it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:17<00:00,  1.97it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.92it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.94it/s]
INFO 07-05 11:52:20 [model_runner.py:1598] Graph capturing finished in 18 secs, took 0.33 GiB
INFO 07-05 11:52:20 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 69.45 seconds
[INFO|2025-07-05 11:52:21] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:18, 104.97 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 216.58 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 332.45 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:03, 445.77 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 553.47 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:01<00:02, 642.68 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:02<00:01, 702.59 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 776.11 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1188/2108 [00:02<00:01, 778.31 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1452/2108 [00:02<00:00, 958.86 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 946.14 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1715/2108 [00:02<00:00, 931.21 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:03<00:00, 989.13 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 939.05 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 931.43 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 593.72 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:52:28,152 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:52:28,152 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:52:28,153 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:52:28,153 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:52:28,153 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:52:28,153 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:52:28,153 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:52:28,153 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:52:28,153 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:52:28,936 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:52:28,936 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:52:28,937 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:52:29,393 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-882', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:52,  1.68s/it, est. speed input: 247.32 toks/s, output: 32.10 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 17.58it/s, est. speed input: 5482.12 toks/s, output: 774.87 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 17.37it/s, est. speed input: 5712.18 toks/s, output: 946.00 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.76it/s, est. speed input: 5712.18 toks/s, output: 946.00 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:54,  4.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.83 toks/s, output: 42.16 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.08it/s, est. speed input: 6402.08 toks/s, output: 905.02 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.03it/s, est. speed input: 6891.62 toks/s, output: 1151.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.19it/s, est. speed input: 7112.36 toks/s, output: 1230.52 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:07<03:41,  3.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.87 toks/s, output: 42.17 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.49it/s, est. speed input: 6212.72 toks/s, output: 878.69 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.30it/s, est. speed input: 6478.83 toks/s, output: 1091.34 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.26it/s, est. speed input: 1347.29 toks/s, output: 376.37 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:17<07:05,  6.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.46 toks/s, output: 42.52 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6821.73 toks/s, output: 963.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8154.95 toks/s, output: 1310.16 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:20<05:13,  5.05s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 319.81 toks/s, output: 42.02 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.10it/s, est. speed input: 5744.92 toks/s, output: 813.66 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.66it/s, est. speed input: 5104.07 toks/s, output: 945.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.99it/s, est. speed input: 4965.39 toks/s, output: 995.77 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:23<04:34,  4.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.93 toks/s, output: 42.05 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.77it/s, est. speed input: 6541.55 toks/s, output: 921.52 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.68it/s, est. speed input: 5987.01 toks/s, output: 1034.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.55it/s, est. speed input: 5987.01 toks/s, output: 1034.29 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:26<03:59,  3.99s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.20 toks/s, output: 42.08 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.58it/s, est. speed input: 6527.68 toks/s, output: 915.85 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.56it/s, est. speed input: 6889.08 toks/s, output: 1165.91 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6889.08 toks/s, output: 1165.91 toks/s]
Processing batched inference:  11%|█         | 7/66 [00:29<03:31,  3.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.69 toks/s, output: 42.15 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.57it/s, est. speed input: 7142.29 toks/s, output: 1006.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.80it/s, est. speed input: 8217.78 toks/s, output: 1298.87 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:32<03:06,  3.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 315.23 toks/s, output: 42.49 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.12it/s, est. speed input: 5688.24 toks/s, output: 811.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8025.78 toks/s, output: 1415.88 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:34<02:48,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.43 toks/s, output: 41.98 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.42it/s, est. speed input: 7382.45 toks/s, output: 1035.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.87it/s, est. speed input: 5317.07 toks/s, output: 959.68 toks/s] 
Processing batched inference:  15%|█▌        | 10/66 [00:37<02:51,  3.06s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.20 toks/s, output: 42.08 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6830.86 toks/s, output: 955.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.75it/s, est. speed input: 8157.15 toks/s, output: 1316.32 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:40<02:38,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.72 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.16it/s, est. speed input: 6675.60 toks/s, output: 951.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.86it/s, est. speed input: 6686.12 toks/s, output: 1122.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.66it/s, est. speed input: 6859.73 toks/s, output: 1196.23 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:42<02:32,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.03 toks/s, output: 42.06 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.86it/s, est. speed input: 6296.46 toks/s, output: 889.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8142.17 toks/s, output: 1383.01 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:45<02:22,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.39 toks/s, output: 41.85 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.80it/s, est. speed input: 6558.91 toks/s, output: 925.19 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8121.99 toks/s, output: 1330.34 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:47<02:14,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.21 toks/s, output: 41.95 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.07it/s, est. speed input: 5739.82 toks/s, output: 809.79 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.16it/s, est. speed input: 6823.35 toks/s, output: 1226.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.52it/s, est. speed input: 6823.35 toks/s, output: 1226.61 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:50<02:13,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.71 toks/s, output: 42.02 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 7100.60 toks/s, output: 1002.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.74it/s, est. speed input: 8168.60 toks/s, output: 1301.27 toks/s]
Processing batched inference:  24%|██▍       | 16/66 [00:52<02:07,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.78 toks/s, output: 42.43 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.24it/s, est. speed input: 5408.87 toks/s, output: 772.51 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.86it/s, est. speed input: 5786.25 toks/s, output: 1078.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.82it/s, est. speed input: 5261.98 toks/s, output: 1051.35 toks/s]
Processing batched inference:  26%|██▌       | 17/66 [00:55<02:14,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.66 toks/s, output: 42.01 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.52it/s, est. speed input: 7052.63 toks/s, output: 1001.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.16it/s, est. speed input: 7058.18 toks/s, output: 1146.05 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:58<02:10,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.77 toks/s, output: 41.90 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.92it/s, est. speed input: 6013.24 toks/s, output: 847.68 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.97it/s, est. speed input: 5996.35 toks/s, output: 1081.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.46it/s, est. speed input: 5996.35 toks/s, output: 1081.69 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:01<02:10,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.17 toks/s, output: 42.44 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.11it/s, est. speed input: 7567.82 toks/s, output: 1072.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6885.70 toks/s, output: 1075.70 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:04<02:05,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.14 toks/s, output: 41.95 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.02it/s, est. speed input: 6287.87 toks/s, output: 891.71 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.97it/s, est. speed input: 6891.98 toks/s, output: 1193.42 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.72it/s, est. speed input: 6891.98 toks/s, output: 1193.42 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:06<02:01,  2.70s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.84 toks/s, output: 40.87 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.06it/s, est. speed input: 5399.94 toks/s, output: 761.03 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.41it/s, est. speed input: 6309.76 toks/s, output: 1131.30 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5853.24 toks/s, output: 1159.16 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:09<02:04,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.01 toks/s, output: 40.63 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.06it/s, est. speed input: 6668.38 toks/s, output: 932.14 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.95it/s, est. speed input: 6743.28 toks/s, output: 1111.08 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.26it/s, est. speed input: 6743.28 toks/s, output: 1111.08 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:12<02:01,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.89 toks/s, output: 40.75 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.39it/s, est. speed input: 6124.29 toks/s, output: 865.45 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.10it/s, est. speed input: 5732.78 toks/s, output: 994.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.40it/s, est. speed input: 3869.49 toks/s, output: 766.55 toks/s]
Processing batched inference:  36%|███▋      | 24/66 [01:16<02:17,  3.27s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.86 toks/s, output: 40.61 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.33it/s, est. speed input: 6375.21 toks/s, output: 901.53 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.49it/s, est. speed input: 6272.50 toks/s, output: 1058.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s, est. speed input: 2865.99 toks/s, output: 622.96 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:22<02:38,  3.88s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.32s/it, est. speed input: 314.30 toks/s, output: 40.80 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.73it/s, est. speed input: 6558.88 toks/s, output: 931.56 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.31it/s, est. speed input: 6540.90 toks/s, output: 1126.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.34it/s, est. speed input: 4680.49 toks/s, output: 887.13 toks/s] 
Processing batched inference:  39%|███▉      | 26/66 [01:25<02:30,  3.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.57 toks/s, output: 40.70 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.12it/s, est. speed input: 6649.22 toks/s, output: 938.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.09it/s, est. speed input: 6749.47 toks/s, output: 1143.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.35it/s, est. speed input: 6749.47 toks/s, output: 1143.13 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:28<02:13,  3.42s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.65 toks/s, output: 40.84 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.04it/s, est. speed input: 6909.87 toks/s, output: 976.90 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.34it/s, est. speed input: 6742.29 toks/s, output: 1100.72 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:31<02:00,  3.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.84 toks/s, output: 40.61 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.02it/s, est. speed input: 6290.72 toks/s, output: 895.52 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.62it/s, est. speed input: 6282.65 toks/s, output: 1037.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5871.70 toks/s, output: 1069.40 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:33<01:54,  3.08s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.92 toks/s, output: 41.01 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.09it/s, est. speed input: 7306.01 toks/s, output: 1021.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.40it/s, est. speed input: 8073.97 toks/s, output: 1241.16 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:36<01:41,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.82 toks/s, output: 40.74 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.28it/s, est. speed input: 6358.80 toks/s, output: 901.67 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.43it/s, est. speed input: 6741.81 toks/s, output: 1138.14 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s, est. speed input: 6741.81 toks/s, output: 1138.14 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:38<01:35,  2.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 306.48 toks/s, output: 41.31 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.35it/s, est. speed input: 6391.50 toks/s, output: 898.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.24it/s, est. speed input: 7951.52 toks/s, output: 1313.22 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:40<01:28,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.64 toks/s, output: 40.71 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.83it/s, est. speed input: 6294.97 toks/s, output: 893.36 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.72it/s, est. speed input: 6331.25 toks/s, output: 1044.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.52it/s, est. speed input: 5188.18 toks/s, output: 979.94 toks/s] 
Processing batched inference:  50%|█████     | 33/66 [01:44<01:31,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.82 toks/s, output: 40.87 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.56it/s, est. speed input: 5890.73 toks/s, output: 834.73 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.83it/s, est. speed input: 6781.00 toks/s, output: 1197.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.34it/s, est. speed input: 6781.00 toks/s, output: 1197.99 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:46<01:28,  2.75s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 316.82 toks/s, output: 41.13 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.16it/s, est. speed input: 6976.31 toks/s, output: 982.67 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 8017.31 toks/s, output: 1263.87 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:49<01:20,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.39 toks/s, output: 41.46 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.76it/s, est. speed input: 6226.42 toks/s, output: 879.15 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.70it/s, est. speed input: 6956.58 toks/s, output: 1176.38 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6797.01 toks/s, output: 1193.59 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:51<01:17,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.49 toks/s, output: 41.47 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.13it/s, est. speed input: 7619.11 toks/s, output: 1063.21 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.65it/s, est. speed input: 8158.86 toks/s, output: 1221.15 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:53<01:11,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.36 toks/s, output: 41.45 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.96it/s, est. speed input: 6644.82 toks/s, output: 944.39 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.24it/s, est. speed input: 6813.83 toks/s, output: 1140.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.46it/s, est. speed input: 6813.83 toks/s, output: 1140.95 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [01:56<01:10,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 320.91 toks/s, output: 41.66 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.11it/s, est. speed input: 5449.92 toks/s, output: 767.56 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.66it/s, est. speed input: 6401.22 toks/s, output: 1145.45 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.28it/s, est. speed input: 5933.82 toks/s, output: 1155.87 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [01:59<01:11,  2.64s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 318.84 toks/s, output: 41.39 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.38it/s, est. speed input: 6766.02 toks/s, output: 955.72 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.48it/s, est. speed input: 8084.95 toks/s, output: 1310.36 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:01<01:05,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.98 toks/s, output: 41.79 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.76it/s, est. speed input: 6233.45 toks/s, output: 884.54 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.26it/s, est. speed input: 6203.39 toks/s, output: 1027.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6828.21 toks/s, output: 1265.95 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:04<01:03,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.00 toks/s, output: 41.41 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.39it/s, est. speed input: 7013.57 toks/s, output: 990.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6835.65 toks/s, output: 1133.13 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:06<01:01,  2.54s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 318.32 toks/s, output: 41.72 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.29it/s, est. speed input: 7312.01 toks/s, output: 1031.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.10it/s, est. speed input: 7040.79 toks/s, output: 1110.65 toks/s]
Processing batched inference:  65%|██████▌   | 43/66 [02:09<00:58,  2.55s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.56 toks/s, output: 41.87 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.91it/s, est. speed input: 6271.24 toks/s, output: 886.28 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.44it/s, est. speed input: 4846.80 toks/s, output: 881.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.76it/s, est. speed input: 4846.80 toks/s, output: 881.16 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:12<01:01,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.62 toks/s, output: 41.75 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.99it/s, est. speed input: 8137.03 toks/s, output: 1142.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.68it/s, est. speed input: 6873.40 toks/s, output: 1015.94 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:15<00:56,  2.69s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.82 toks/s, output: 41.90 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 20.01it/s, est. speed input: 6314.06 toks/s, output: 891.18 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.06it/s, est. speed input: 6433.95 toks/s, output: 1068.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.36it/s, est. speed input: 970.68 toks/s, output: 354.41 toks/s]  
Processing batched inference:  70%|██████▉   | 46/66 [02:29<02:03,  6.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.94 toks/s, output: 41.79 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 21.97it/s, est. speed input: 6966.33 toks/s, output: 986.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8140.44 toks/s, output: 1297.55 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:31<01:34,  4.97s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 308.74 toks/s, output: 41.62 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.20it/s, est. speed input: 6937.67 toks/s, output: 982.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6803.23 toks/s, output: 1108.47 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:34<01:16,  4.23s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.18 toks/s, output: 41.82 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.36it/s, est. speed input: 5482.41 toks/s, output: 776.68 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.66it/s, est. speed input: 6885.18 toks/s, output: 1258.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6885.18 toks/s, output: 1258.61 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:36<01:03,  3.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.05 toks/s, output: 41.80 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.26it/s, est. speed input: 7643.36 toks/s, output: 1068.98 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.91it/s, est. speed input: 8232.08 toks/s, output: 1238.04 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:38<00:53,  3.31s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.19 toks/s, output: 41.82 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.88it/s, est. speed input: 5976.36 toks/s, output: 848.46 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.51it/s, est. speed input: 8073.95 toks/s, output: 1391.48 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:41<00:44,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.44 toks/s, output: 41.85 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.52it/s, est. speed input: 6801.76 toks/s, output: 960.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.62it/s, est. speed input: 8111.39 toks/s, output: 1320.01 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:43<00:38,  2.76s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 318.56 toks/s, output: 41.85 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.69it/s, est. speed input: 6542.34 toks/s, output: 921.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.63it/s, est. speed input: 8122.81 toks/s, output: 1344.39 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:45<00:33,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.82 toks/s, output: 42.26 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.35it/s, est. speed input: 7364.59 toks/s, output: 1033.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8161.17 toks/s, output: 1251.72 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:47<00:29,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.08 toks/s, output: 41.81 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.68it/s, est. speed input: 6517.27 toks/s, output: 919.83 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 18.89it/s, est. speed input: 6431.47 toks/s, output: 1050.36 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.61it/s, est. speed input: 6861.75 toks/s, output: 1212.24 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:50<00:27,  2.50s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.45 toks/s, output: 41.86 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.18it/s, est. speed input: 5447.23 toks/s, output: 775.74 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.03it/s, est. speed input: 6451.16 toks/s, output: 1161.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.50it/s, est. speed input: 6819.66 toks/s, output: 1311.75 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [02:53<00:25,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.98 toks/s, output: 41.92 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.61it/s, est. speed input: 6804.70 toks/s, output: 957.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8123.73 toks/s, output: 1314.56 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [02:55<00:22,  2.45s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 313.44 toks/s, output: 42.25 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 19.11it/s, est. speed input: 5980.03 toks/s, output: 845.95 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.83it/s, est. speed input: 6788.21 toks/s, output: 1200.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6788.21 toks/s, output: 1200.03 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [02:57<00:19,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.54 toks/s, output: 41.87 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.36it/s, est. speed input: 6757.10 toks/s, output: 950.20 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.70it/s, est. speed input: 7103.29 toks/s, output: 1176.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.26it/s, est. speed input: 7103.29 toks/s, output: 1176.05 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:00<00:17,  2.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.88 toks/s, output: 41.78 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.09it/s, est. speed input: 5741.64 toks/s, output: 807.17 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.06it/s, est. speed input: 6817.74 toks/s, output: 1219.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.46it/s, est. speed input: 6817.74 toks/s, output: 1219.89 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:02<00:14,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.96 toks/s, output: 41.92 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.80it/s, est. speed input: 6252.19 toks/s, output: 885.58 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.01it/s, est. speed input: 6909.22 toks/s, output: 1200.60 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.70it/s, est. speed input: 6909.22 toks/s, output: 1200.60 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:05<00:12,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.76 toks/s, output: 41.77 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.66it/s, est. speed input: 5936.17 toks/s, output: 842.85 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.32it/s, est. speed input: 6405.73 toks/s, output: 1105.64 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.74it/s, est. speed input: 6096.96 toks/s, output: 1165.49 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:08<00:10,  2.61s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.95 toks/s, output: 41.79 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.29it/s, est. speed input: 7342.18 toks/s, output: 1031.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.68it/s, est. speed input: 8132.18 toks/s, output: 1259.09 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:10<00:07,  2.52s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.26 toks/s, output: 41.83 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.63it/s, est. speed input: 6517.11 toks/s, output: 919.46 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.46it/s, est. speed input: 6831.92 toks/s, output: 1156.74 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6831.92 toks/s, output: 1156.74 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:13<00:05,  2.53s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 315.52 toks/s, output: 41.46 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.55it/s, est. speed input: 6506.44 toks/s, output: 912.44 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.40it/s, est. speed input: 6836.03 toks/s, output: 1150.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6836.03 toks/s, output: 1150.31 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:15<00:02,  2.53s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.17s/it, est. speed input: 355.69 toks/s, output: 46.17 toks/s][A
Processed prompts:  86%|████████▌ | 24/28 [00:01<00:00, 21.52it/s, est. speed input: 6802.46 toks/s, output: 963.41 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.66it/s, est. speed input: 7690.49 toks/s, output: 1215.33 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:17<00:00,  2.40s/it]Processing batched inference: 100%|██████████| 66/66 [03:17<00:00,  3.00s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-882/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 11:55:46.846836331 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Running inference on checkpoint: checkpoint-945
INFO 07-05 11:55:59 [__init__.py:239] Automatically detected platform cuda.
[INFO|training_args.py:2135] 2025-07-05 11:56:01,400 >> PyTorch: setting up devices
[INFO|training_args.py:1812] 2025-07-05 11:56:01,441 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,465 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,465 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,465 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,465 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,465 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,465 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,465 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:56:01,858 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:56:01,860 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-07-05 11:56:01,866 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:56:01,872 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,873 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,873 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,873 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,873 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,873 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,873 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:01,873 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:56:02,245 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:56:02,248 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:56:02,444 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:56:02,884 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|configuration_utils.py:696] 2025-07-05 11:56:02,941 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/config.json
[INFO|configuration_utils.py:696] 2025-07-05 11:56:02,941 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/config.json
[INFO|configuration_utils.py:770] 2025-07-05 11:56:02,943 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "float32",
    "use_cache": false,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": false,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "torch_dtype": "float32"
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

INFO 07-05 11:56:14 [config.py:689] This model supports multiple tasks: {'score', 'reward', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.
INFO 07-05 11:56:14 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945', speculative_config=None, tokenizer='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=6144, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:14,494 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:14,494 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:14,494 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:14,494 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:14,494 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:14,494 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:14,494 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:56:14,841 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:1088] 2025-07-05 11:56:14,929 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-05 11:56:14,930 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

INFO 07-05 11:56:16 [cuda.py:292] Using Flash Attention backend.
INFO 07-05 11:56:16 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-05 11:56:16 [model_runner.py:1110] Starting to load model saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945...
WARNING 07-05 11:56:16 [vision.py:93] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.
INFO 07-05 11:56:16 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.24s/it]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:07<00:00,  7.24s/it]

INFO 07-05 11:56:24 [loader.py:458] Loading weights took 7.47 seconds
INFO 07-05 11:56:24 [model_runner.py:1146] Model loading took 4.1513 GiB and 7.713530 seconds
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:24,926 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:24,927 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:24,927 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:24,927 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:24,927 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:24,927 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:24,927 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:56:25,320 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-07-05 11:56:25,411 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:56:25,411 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|image_processing_base.py:378] 2025-07-05 11:56:25,412 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:56:25,412 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:25,413 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:25,413 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:25,413 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:25,413 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:25,413 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:25,413 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:56:25,413 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:56:26,192 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:56:26,193 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:56:26,193 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:56:26,666 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[WARNING|image_utils.py:939] 2025-07-05 11:56:27,305 >> Unused or unrecognized kwargs: return_tensors.
WARNING 07-05 11:56:27 [model_runner.py:1311] Computed max_num_seqs (min(256, 6144 // 98304)) to be less than 1. Setting it to the minimum value of 1.
[WARNING|image_utils.py:939] 2025-07-05 11:56:30,158 >> Unused or unrecognized kwargs: return_tensors.
[WARNING|tokenization_utils_base.py:3934] 2025-07-05 11:56:31,160 >> Token indices sequence length is longer than the specified maximum sequence length for this model (98304 > 32768). Running this sequence through the model will result in indexing errors
WARNING 07-05 11:56:31 [profiling.py:245] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 6144) is too short to hold the multi-modal embeddings in the worst case (98304 tokens in total, out of which {'image': 65536, 'video': 32768} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.
INFO 07-05 11:57:10 [worker.py:267] Memory profiling takes 45.54 seconds
INFO 07-05 11:57:10 [worker.py:267] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.90) = 35.45GiB
INFO 07-05 11:57:10 [worker.py:267] model weights take 4.15GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 14.59GiB; the rest of the memory reserved for KV Cache is 16.62GiB.
INFO 07-05 11:57:10 [executor_base.py:112] # cuda blocks: 38908, # CPU blocks: 9362
INFO 07-05 11:57:10 [executor_base.py:117] Maximum concurrency for 6144 tokens per request: 101.32x
INFO 07-05 11:57:15 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:18,  1.84it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:16,  1.96it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:15,  2.00it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:15,  1.99it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:15,  1.99it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:14,  2.01it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:03<00:13,  2.02it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:13,  2.02it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:04<00:12,  2.02it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:04<00:12,  2.03it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:05<00:11,  2.04it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:05<00:11,  2.01it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:06<00:10,  2.01it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:06<00:10,  2.03it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:07<00:09,  2.04it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:07<00:09,  2.03it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:08<00:09,  1.98it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:08<00:08,  2.00it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:09<00:07,  2.02it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:09<00:07,  2.03it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:10<00:06,  2.03it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:10<00:06,  2.03it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:11<00:05,  2.03it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:11<00:05,  2.02it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:12<00:04,  2.03it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:12<00:04,  2.04it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:13<00:03,  2.00it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:13<00:03,  2.00it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:14<00:02,  2.01it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:14<00:02,  2.02it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:15<00:01,  2.03it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:15<00:01,  2.03it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:16<00:00,  2.03it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:16<00:00,  2.04it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.03it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:17<00:00,  2.02it/s]
INFO 07-05 11:57:33 [model_runner.py:1598] Graph capturing finished in 17 secs, took 0.33 GiB
INFO 07-05 11:57:33 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 68.54 seconds
[INFO|2025-07-05 11:57:33] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_definition_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [00:01<00:19, 100.87 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [00:01<00:08, 210.63 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [00:01<00:05, 323.26 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [00:01<00:03, 450.56 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [00:01<00:02, 549.16 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [00:02<00:02, 637.75 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 924/2108 [00:02<00:01, 709.11 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [00:02<00:01, 789.48 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1320/2108 [00:02<00:00, 900.10 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1584/2108 [00:02<00:00, 988.19 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1846/2108 [00:03<00:00, 1018.43 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [00:03<00:00, 1004.62 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 1023.52 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [00:03<00:00, 605.65 examples/s] 
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 13874, 19324, 9112, 25, 393, 811, 372, 8767, 269, 706, 3363, 6553, 30591, 304, 279, 7100, 4176, 3550, 6825, 264, 12929, 476, 19265, 315, 20622, 19847, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```

Note: Pneumothorax means Air trapped in the pleural space creating a gap or absence of lung tissue.<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

Processing batched inference:   0%|          | 0/66 [00:00<?, ?it/s][INFO|image_processing_base.py:378] 2025-07-05 11:57:40,089 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-07-05 11:57:40,089 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:57:40,090 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:57:40,090 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:57:40,090 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:57:40,090 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:57:40,090 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:57:40,090 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-07-05 11:57:40,090 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-07-05 11:57:40,894 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:627] 2025-07-05 11:57:40,894 >> loading configuration file saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945/video_preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-07-05 11:57:40,895 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-07-05 11:57:41,349 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: CachedQwen2TokenizerFast(name_or_path='saves/qwen2_vl-3b/vindr_sft_def/checkpoint-945', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}


Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:50,  1.63s/it, est. speed input: 255.37 toks/s, output: 33.15 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 18.01it/s, est. speed input: 5628.48 toks/s, output: 797.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.23it/s, est. speed input: 6733.68 toks/s, output: 1088.30 toks/s]
Processing batched inference:   2%|▏         | 1/66 [00:04<04:31,  4.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.71 toks/s, output: 42.02 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.41it/s, est. speed input: 6787.95 toks/s, output: 955.19 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.36it/s, est. speed input: 6878.68 toks/s, output: 1141.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s, est. speed input: 6878.68 toks/s, output: 1141.76 toks/s]
Processing batched inference:   3%|▎         | 2/66 [00:06<03:35,  3.36s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.61 toks/s, output: 42.14 toks/s][A
Processed prompts:  72%|███████▏  | 23/32 [00:01<00:00, 18.60it/s, est. speed input: 5933.69 toks/s, output: 839.92 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 18.59it/s, est. speed input: 6235.78 toks/s, output: 1056.58 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.69it/s, est. speed input: 1526.52 toks/s, output: 415.60 toks/s] 
Processing batched inference:   5%|▍         | 3/66 [00:16<06:28,  6.17s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.81 toks/s, output: 42.03 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.43it/s, est. speed input: 7376.74 toks/s, output: 1036.59 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8177.42 toks/s, output: 1257.53 toks/s]
Processing batched inference:   6%|▌         | 4/66 [00:18<04:50,  4.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.40 toks/s, output: 40.94 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.75it/s, est. speed input: 5621.23 toks/s, output: 796.58 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.27it/s, est. speed input: 6324.04 toks/s, output: 1110.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.11it/s, est. speed input: 5431.35 toks/s, output: 1069.13 toks/s]
Processing batched inference:   8%|▊         | 5/66 [00:22<04:14,  4.18s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.57 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.63it/s, est. speed input: 6793.83 toks/s, output: 958.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 8108.11 toks/s, output: 1312.02 toks/s]
Processing batched inference:   9%|▉         | 6/66 [00:24<03:35,  3.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.92 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.30it/s, est. speed input: 6464.80 toks/s, output: 908.21 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.90it/s, est. speed input: 6692.41 toks/s, output: 1115.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.16it/s, est. speed input: 5459.11 toks/s, output: 980.26 toks/s] 
Processing batched inference:  11%|█         | 7/66 [00:27<03:25,  3.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.84 toks/s, output: 41.91 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7114.09 toks/s, output: 1002.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8182.17 toks/s, output: 1292.01 toks/s]
Processing batched inference:  12%|█▏        | 8/66 [00:30<03:02,  3.15s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.97 toks/s, output: 41.92 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6502.34 toks/s, output: 919.93 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8070.26 toks/s, output: 1340.12 toks/s]
Processing batched inference:  14%|█▎        | 9/66 [00:32<02:45,  2.90s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 320.64 toks/s, output: 41.35 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.32it/s, est. speed input: 7364.94 toks/s, output: 1032.77 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.72it/s, est. speed input: 5258.57 toks/s, output: 930.43 toks/s] 
Processing batched inference:  15%|█▌        | 10/66 [00:36<02:50,  3.04s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.22 toks/s, output: 41.96 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.48it/s, est. speed input: 7076.83 toks/s, output: 988.73 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.71it/s, est. speed input: 8142.33 toks/s, output: 1286.82 toks/s]
Processing batched inference:  17%|█▋        | 11/66 [00:38<02:37,  2.87s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.66 toks/s, output: 42.01 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.74it/s, est. speed input: 6510.85 toks/s, output: 928.75 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.51it/s, est. speed input: 6834.59 toks/s, output: 1166.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6834.59 toks/s, output: 1166.94 toks/s]
Processing batched inference:  18%|█▊        | 12/66 [00:41<02:32,  2.82s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.55 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.75it/s, est. speed input: 6568.08 toks/s, output: 926.87 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.67it/s, est. speed input: 8154.64 toks/s, output: 1354.39 toks/s]
Processing batched inference:  20%|█▉        | 13/66 [00:43<02:22,  2.68s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.24 toks/s, output: 41.96 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.85it/s, est. speed input: 6572.39 toks/s, output: 928.17 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8142.69 toks/s, output: 1333.12 toks/s]
Processing batched inference:  21%|██        | 14/66 [00:45<02:14,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.63 toks/s, output: 41.88 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.05it/s, est. speed input: 5731.16 toks/s, output: 810.01 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.45it/s, est. speed input: 6877.62 toks/s, output: 1234.29 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6877.62 toks/s, output: 1234.29 toks/s]
Processing batched inference:  23%|██▎       | 15/66 [00:48<02:12,  2.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.91 toks/s, output: 41.39 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.64it/s, est. speed input: 7135.20 toks/s, output: 1006.24 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.49it/s, est. speed input: 5995.91 toks/s, output: 997.27 toks/s] 
Processing batched inference:  24%|██▍       | 16/66 [00:51<02:15,  2.72s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.32 toks/s, output: 42.37 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.84it/s, est. speed input: 6231.17 toks/s, output: 882.58 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.39it/s, est. speed input: 6455.44 toks/s, output: 1088.53 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.74it/s, est. speed input: 3588.85 toks/s, output: 770.62 toks/s] 
Processing batched inference:  26%|██▌       | 17/66 [00:55<02:37,  3.22s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.86 toks/s, output: 42.04 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.62it/s, est. speed input: 6791.62 toks/s, output: 963.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.72it/s, est. speed input: 8109.63 toks/s, output: 1317.40 toks/s]
Processing batched inference:  27%|██▋       | 18/66 [00:58<02:22,  2.96s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.55 toks/s, output: 42.00 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6825.79 toks/s, output: 960.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.66it/s, est. speed input: 8153.92 toks/s, output: 1322.22 toks/s]
Processing batched inference:  29%|██▉       | 19/66 [01:00<02:10,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 316.67 toks/s, output: 42.38 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.50it/s, est. speed input: 6473.92 toks/s, output: 947.10 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.99it/s, est. speed input: 6183.66 toks/s, output: 1029.28 toks/s]
Processing batched inference:  30%|███       | 20/66 [01:03<02:08,  2.79s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.24 toks/s, output: 41.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.56it/s, est. speed input: 6783.28 toks/s, output: 961.25 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.44it/s, est. speed input: 5984.62 toks/s, output: 1014.52 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.52it/s, est. speed input: 5984.62 toks/s, output: 1014.52 toks/s]
Processing batched inference:  32%|███▏      | 21/66 [01:06<02:07,  2.83s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 319.79 toks/s, output: 41.51 toks/s][A
Processed prompts:  59%|█████▉    | 19/32 [00:01<00:00, 15.38it/s, est. speed input: 4894.56 toks/s, output: 694.24 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 19.18it/s, est. speed input: 6135.42 toks/s, output: 1132.23 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.72it/s, est. speed input: 6099.52 toks/s, output: 1251.64 toks/s]
Processing batched inference:  33%|███▎      | 22/66 [01:09<02:05,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.78 toks/s, output: 41.90 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.32it/s, est. speed input: 7382.44 toks/s, output: 1030.76 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.64it/s, est. speed input: 6897.43 toks/s, output: 1086.57 toks/s]
Processing batched inference:  35%|███▍      | 23/66 [01:11<01:59,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.83 toks/s, output: 41.91 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 18.07it/s, est. speed input: 5729.90 toks/s, output: 813.24 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.65it/s, est. speed input: 5811.87 toks/s, output: 1050.33 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.07it/s, est. speed input: 3322.02 toks/s, output: 705.75 toks/s] 
Processing batched inference:  36%|███▋      | 24/66 [01:16<02:19,  3.33s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.18 toks/s, output: 40.52 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.17it/s, est. speed input: 6333.21 toks/s, output: 895.06 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 19.59it/s, est. speed input: 6480.67 toks/s, output: 1063.04 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.41it/s, est. speed input: 1812.86 toks/s, output: 440.77 toks/s] 
Processing batched inference:  38%|███▊      | 25/66 [01:24<03:14,  4.74s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.63 toks/s, output: 40.71 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 20.69it/s, est. speed input: 6546.36 toks/s, output: 929.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 15.49it/s, est. speed input: 5684.73 toks/s, output: 978.79 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00,  8.64it/s, est. speed input: 3567.50 toks/s, output: 715.06 toks/s]
Processing batched inference:  39%|███▉      | 26/66 [01:28<03:05,  4.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.81 toks/s, output: 40.60 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.08it/s, est. speed input: 6634.79 toks/s, output: 935.64 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 6711.85 toks/s, output: 1111.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.26it/s, est. speed input: 6711.85 toks/s, output: 1111.35 toks/s]
Processing batched inference:  41%|████      | 27/66 [01:31<02:36,  4.02s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.24 toks/s, output: 40.66 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.20it/s, est. speed input: 6353.93 toks/s, output: 898.79 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 19.70it/s, est. speed input: 6563.77 toks/s, output: 1100.37 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.28it/s, est. speed input: 6713.62 toks/s, output: 1169.28 toks/s]
Processing batched inference:  42%|████▏     | 28/66 [01:34<02:16,  3.60s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.34s/it, est. speed input: 304.64 toks/s, output: 41.07 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.37it/s, est. speed input: 6077.21 toks/s, output: 863.86 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 17.92it/s, est. speed input: 6046.17 toks/s, output: 1003.13 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 12.60it/s, est. speed input: 5183.65 toks/s, output: 1020.10 toks/s]
Processing batched inference:  44%|████▍     | 29/66 [01:37<02:08,  3.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 316.30 toks/s, output: 41.06 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 23.11it/s, est. speed input: 7314.95 toks/s, output: 1021.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.42it/s, est. speed input: 8080.73 toks/s, output: 1242.81 toks/s]
Processing batched inference:  45%|████▌     | 30/66 [01:39<01:51,  3.10s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.70 toks/s, output: 40.98 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.37it/s, est. speed input: 6389.67 toks/s, output: 906.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.45it/s, est. speed input: 8000.96 toks/s, output: 1321.53 toks/s]
Processing batched inference:  47%|████▋     | 31/66 [01:41<01:39,  2.84s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 314.56 toks/s, output: 40.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.18it/s, est. speed input: 6663.54 toks/s, output: 934.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.28it/s, est. speed input: 7967.25 toks/s, output: 1289.31 toks/s]
Processing batched inference:  48%|████▊     | 32/66 [01:44<01:30,  2.66s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 312.90 toks/s, output: 40.62 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 19.90it/s, est. speed input: 6304.58 toks/s, output: 894.46 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 13.31it/s, est. speed input: 5093.02 toks/s, output: 891.27 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 11.22it/s, est. speed input: 4646.44 toks/s, output: 893.74 toks/s]
Processing batched inference:  50%|█████     | 33/66 [01:47<01:36,  2.91s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.47 toks/s, output: 40.69 toks/s][A
Processed prompts:  69%|██████▉   | 22/32 [00:01<00:00, 17.48it/s, est. speed input: 5559.27 toks/s, output: 786.16 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.11it/s, est. speed input: 6517.86 toks/s, output: 1160.96 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.15it/s, est. speed input: 5870.47 toks/s, output: 1102.56 toks/s]
Processing batched inference:  52%|█████▏    | 34/66 [01:50<01:33,  2.93s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.23 toks/s, output: 40.92 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 22.95it/s, est. speed input: 7203.67 toks/s, output: 1013.85 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.37it/s, est. speed input: 7995.03 toks/s, output: 1229.48 toks/s]
Processing batched inference:  53%|█████▎    | 35/66 [01:52<01:24,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.28 toks/s, output: 41.32 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.71it/s, est. speed input: 6208.30 toks/s, output: 877.22 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.38it/s, est. speed input: 5855.08 toks/s, output: 1032.61 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.19it/s, est. speed input: 5855.08 toks/s, output: 1032.61 toks/s]
Processing batched inference:  55%|█████▍    | 36/66 [01:55<01:23,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 313.71 toks/s, output: 41.22 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 23.99it/s, est. speed input: 7577.18 toks/s, output: 1056.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.61it/s, est. speed input: 8143.49 toks/s, output: 1217.62 toks/s]
Processing batched inference:  56%|█████▌    | 37/66 [01:57<01:16,  2.62s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.32s/it, est. speed input: 315.19 toks/s, output: 40.91 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.09it/s, est. speed input: 6360.40 toks/s, output: 906.95 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 20.90it/s, est. speed input: 6828.04 toks/s, output: 1141.99 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.33it/s, est. speed input: 6760.58 toks/s, output: 1174.90 toks/s]
Processing batched inference:  58%|█████▊    | 38/66 [02:00<01:13,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.31s/it, est. speed input: 318.40 toks/s, output: 41.33 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.00it/s, est. speed input: 5415.42 toks/s, output: 764.30 toks/s][A
Processed prompts:  88%|████████▊ | 28/32 [00:01<00:00, 18.66it/s, est. speed input: 6092.24 toks/s, output: 1052.91 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.38it/s, est. speed input: 5869.94 toks/s, output: 1184.05 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.13it/s, est. speed input: 5869.94 toks/s, output: 1184.05 toks/s]
Processing batched inference:  59%|█████▉    | 39/66 [02:03<01:13,  2.71s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.82 toks/s, output: 41.77 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.39it/s, est. speed input: 7088.68 toks/s, output: 1001.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.62it/s, est. speed input: 6901.28 toks/s, output: 1145.53 toks/s]
Processing batched inference:  61%|██████    | 40/66 [02:05<01:08,  2.65s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.10 toks/s, output: 41.81 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.16it/s, est. speed input: 5454.11 toks/s, output: 769.29 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.00it/s, est. speed input: 6439.45 toks/s, output: 1152.94 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6807.30 toks/s, output: 1302.75 toks/s]
Processing batched inference:  62%|██████▏   | 41/66 [02:08<01:05,  2.63s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.26 toks/s, output: 41.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.67it/s, est. speed input: 6799.66 toks/s, output: 962.29 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.24it/s, est. speed input: 4266.28 toks/s, output: 798.89 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.37it/s, est. speed input: 4266.28 toks/s, output: 798.89 toks/s]
Processing batched inference:  64%|██████▎   | 42/66 [02:12<01:10,  2.95s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 319.03 toks/s, output: 41.04 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.09it/s, est. speed input: 7570.05 toks/s, output: 1064.69 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.16it/s, est. speed input: 5416.95 toks/s, output: 893.16 toks/s] 
Processing batched inference:  65%|██████▌   | 43/66 [02:15<01:09,  3.00s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.15 toks/s, output: 41.82 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.27it/s, est. speed input: 5449.23 toks/s, output: 775.39 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 21.56it/s, est. speed input: 6788.68 toks/s, output: 1221.55 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 13.08it/s, est. speed input: 5390.18 toks/s, output: 1037.57 toks/s]
Processing batched inference:  67%|██████▋   | 44/66 [02:18<01:06,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.81 toks/s, output: 41.77 toks/s][A
Processed prompts:  91%|█████████ | 29/32 [00:01<00:00, 24.22it/s, est. speed input: 7601.49 toks/s, output: 1068.03 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.65it/s, est. speed input: 6859.73 toks/s, output: 1064.38 toks/s]
Processing batched inference:  68%|██████▊   | 45/66 [02:20<00:59,  2.85s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.55 toks/s, output: 41.87 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.79it/s, est. speed input: 6557.89 toks/s, output: 924.58 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:02<00:00, 12.57it/s, est. speed input: 4926.52 toks/s, output: 839.56 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:14<00:00,  2.25it/s, est. speed input: 927.55 toks/s, output: 359.27 toks/s] 
Processing batched inference:  70%|██████▉   | 46/66 [02:35<02:09,  6.48s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 316.05 toks/s, output: 41.83 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.55it/s, est. speed input: 6804.16 toks/s, output: 964.78 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.64it/s, est. speed input: 8133.45 toks/s, output: 1322.22 toks/s]
Processing batched inference:  71%|███████   | 47/66 [02:38<01:38,  5.20s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 314.61 toks/s, output: 42.41 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.73it/s, est. speed input: 6528.52 toks/s, output: 923.87 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.50it/s, est. speed input: 7019.95 toks/s, output: 1192.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 17.05it/s, est. speed input: 7019.95 toks/s, output: 1192.28 toks/s]
Processing batched inference:  73%|███████▎  | 48/66 [02:40<01:18,  4.38s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it, est. speed input: 326.33 toks/s, output: 40.79 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.11it/s, est. speed input: 5439.27 toks/s, output: 770.57 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.47it/s, est. speed input: 8053.36 toks/s, output: 1442.33 toks/s]
Processing batched inference:  74%|███████▍  | 49/66 [02:42<01:03,  3.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.75 toks/s, output: 41.76 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:01<00:00, 25.49it/s, est. speed input: 8062.29 toks/s, output: 1125.28 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.94it/s, est. speed input: 8244.12 toks/s, output: 1181.90 toks/s]
Processing batched inference:  76%|███████▌  | 50/66 [02:44<00:52,  3.29s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 322.23 toks/s, output: 41.83 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.78it/s, est. speed input: 6255.29 toks/s, output: 884.95 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.56it/s, est. speed input: 8092.50 toks/s, output: 1367.18 toks/s]
Processing batched inference:  77%|███████▋  | 51/66 [02:47<00:44,  2.98s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:41,  1.33s/it, est. speed input: 313.31 toks/s, output: 40.67 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.07it/s, est. speed input: 6643.85 toks/s, output: 939.49 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:03<00:00,  9.97it/s, est. speed input: 4173.11 toks/s, output: 772.16 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:03<00:00, 10.09it/s, est. speed input: 4173.11 toks/s, output: 772.16 toks/s]
Processing batched inference:  79%|███████▉  | 52/66 [02:50<00:44,  3.21s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 317.92 toks/s, output: 41.77 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.53it/s, est. speed input: 6803.63 toks/s, output: 958.03 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.30it/s, est. speed input: 6871.55 toks/s, output: 1160.12 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6871.55 toks/s, output: 1160.12 toks/s]
Processing batched inference:  80%|████████  | 53/66 [02:53<00:39,  3.01s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 322.48 toks/s, output: 41.86 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 25.16it/s, est. speed input: 7933.71 toks/s, output: 1109.49 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.79it/s, est. speed input: 8204.55 toks/s, output: 1202.72 toks/s]
Processing batched inference:  82%|████████▏ | 54/66 [02:55<00:33,  2.77s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.56 toks/s, output: 42.13 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.88it/s, est. speed input: 6278.92 toks/s, output: 887.83 toks/s][A
Processed prompts:  97%|█████████▋| 31/32 [00:02<00:00, 16.01it/s, est. speed input: 5778.57 toks/s, output: 1004.31 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.44it/s, est. speed input: 5965.26 toks/s, output: 1096.73 toks/s]
Processing batched inference:  83%|████████▎ | 55/66 [02:58<00:30,  2.78s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.30s/it, est. speed input: 317.15 toks/s, output: 43.11 toks/s][A
Processed prompts:  62%|██████▎   | 20/32 [00:01<00:00, 16.45it/s, est. speed input: 5190.46 toks/s, output: 743.38 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.64it/s, est. speed input: 6813.88 toks/s, output: 1284.35 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.48it/s, est. speed input: 6813.88 toks/s, output: 1284.35 toks/s]
Processing batched inference:  85%|████████▍ | 56/66 [03:01<00:27,  2.73s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.79 toks/s, output: 42.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.59it/s, est. speed input: 7094.09 toks/s, output: 998.48 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.81it/s, est. speed input: 8171.94 toks/s, output: 1293.26 toks/s]
Processing batched inference:  86%|████████▋ | 57/66 [03:03<00:23,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 316.53 toks/s, output: 42.67 toks/s][A
Processed prompts:  66%|██████▌   | 21/32 [00:01<00:00, 17.29it/s, est. speed input: 5459.30 toks/s, output: 775.38 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 21.43it/s, est. speed input: 6809.83 toks/s, output: 1251.39 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.53it/s, est. speed input: 6809.83 toks/s, output: 1251.39 toks/s]
Processing batched inference:  88%|████████▊ | 58/66 [03:05<00:20,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.75 toks/s, output: 42.15 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.46it/s, est. speed input: 6790.67 toks/s, output: 952.74 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.72it/s, est. speed input: 6924.78 toks/s, output: 1150.18 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.83it/s, est. speed input: 6924.78 toks/s, output: 1150.18 toks/s]
Processing batched inference:  89%|████████▉ | 59/66 [03:08<00:18,  2.58s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.56 toks/s, output: 42.00 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.86it/s, est. speed input: 6603.26 toks/s, output: 923.84 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.69it/s, est. speed input: 8151.85 toks/s, output: 1341.72 toks/s]
Processing batched inference:  91%|█████████ | 60/66 [03:10<00:14,  2.47s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:40,  1.29s/it, est. speed input: 321.90 toks/s, output: 41.79 toks/s][A
Processed prompts:  78%|███████▊  | 25/32 [00:01<00:00, 20.66it/s, est. speed input: 6514.70 toks/s, output: 922.81 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:02<00:00, 16.59it/s, est. speed input: 5988.19 toks/s, output: 1039.65 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:02<00:00, 14.48it/s, est. speed input: 5988.19 toks/s, output: 1039.65 toks/s]
Processing batched inference:  92%|█████████▏| 61/66 [03:13<00:12,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 323.82 toks/s, output: 42.03 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.63it/s, est. speed input: 6244.10 toks/s, output: 885.19 toks/s][A
Processed prompts:  94%|█████████▍| 30/32 [00:01<00:00, 20.08it/s, est. speed input: 6627.65 toks/s, output: 1112.97 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.60it/s, est. speed input: 6864.83 toks/s, output: 1238.10 toks/s]
Processing batched inference:  94%|█████████▍| 62/66 [03:16<00:10,  2.59s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.79 toks/s, output: 42.16 toks/s][A
Processed prompts:  84%|████████▍ | 27/32 [00:01<00:00, 22.54it/s, est. speed input: 7117.39 toks/s, output: 1002.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 19.77it/s, est. speed input: 8170.14 toks/s, output: 1293.39 toks/s]
Processing batched inference:  95%|█████████▌| 63/66 [03:18<00:07,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.28s/it, est. speed input: 324.62 toks/s, output: 42.14 toks/s][A
Processed prompts:  81%|████████▏ | 26/32 [00:01<00:00, 21.68it/s, est. speed input: 6837.93 toks/s, output: 962.55 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.37it/s, est. speed input: 6890.34 toks/s, output: 1217.22 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.69it/s, est. speed input: 6890.34 toks/s, output: 1217.22 toks/s]
Processing batched inference:  97%|█████████▋| 64/66 [03:20<00:04,  2.49s/it]
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.29s/it, est. speed input: 323.01 toks/s, output: 41.93 toks/s][A
Processed prompts:  75%|███████▌  | 24/32 [00:01<00:00, 19.82it/s, est. speed input: 6288.33 toks/s, output: 884.15 toks/s][A
Processed prompts: 100%|██████████| 32/32 [00:01<00:00, 20.70it/s, est. speed input: 6867.99 toks/s, output: 1180.01 toks/s][AProcessed prompts: 100%|██████████| 32/32 [00:01<00:00, 16.55it/s, est. speed input: 6867.99 toks/s, output: 1180.01 toks/s]
Processing batched inference:  98%|█████████▊| 65/66 [03:23<00:02,  2.49s/it]
Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   4%|▎         | 1/28 [00:01<00:31,  1.15s/it, est. speed input: 357.15 toks/s, output: 46.92 toks/s][A
Processed prompts:  82%|████████▏ | 23/28 [00:01<00:00, 20.80it/s, est. speed input: 6586.94 toks/s, output: 936.31 toks/s][AProcessed prompts: 100%|██████████| 28/28 [00:01<00:00, 18.85it/s, est. speed input: 7770.35 toks/s, output: 1258.92 toks/s]
Processing batched inference: 100%|██████████| 66/66 [03:25<00:00,  2.37s/it]Processing batched inference: 100%|██████████| 66/66 [03:25<00:00,  3.11s/it]
**********************************************************************
2108 total generated results have been saved at ./evaluate_outputs/new_results/vindr_sft_def_qwen2_vl-3b/checkpoint-945/generated_predictions.jsonl.
**********************************************************************
[rank0]:[W705 12:01:06.568113153 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
