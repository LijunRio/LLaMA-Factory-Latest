Container llamafactory already exists.

=============
== PyTorch ==
=============

NVIDIA Release 24.07 (build 100464919)
PyTorch Version 2.4.0a0+3bcc3cd
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

ERROR: This container was built for NVIDIA Driver Release 555.42 or later, but
       version 535.247.01 was detected and compatibility mode is UNAVAILABLE.

       [[]]

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.

Sat Jun 28 16:57:06 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.5     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:E3:00.0 Off |                    0 |
| N/A   41C    P0              66W / 500W |      0MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
[2025-06-28 16:57:25,426] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-28 16:57:30 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-28 16:57:34] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,229 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,229 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,229 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,230 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,230 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,231 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,231 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 16:57:34,668 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|processing_utils.py:928] 2025-06-28 16:57:34,670 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/processor_config.json
[INFO|image_processing_base.py:378] 2025-06-28 16:57:34,672 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-28 16:57:34,679 >> Image processor GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,680 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,680 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,680 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,680 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,681 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,681 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 16:57:34,681 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 16:57:35,100 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-28 16:57:35,102 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-28 16:57:35,102 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-28 16:57:35,102 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-28 16:57:35,105 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

[INFO|video_processing_utils.py:627] 2025-06-28 16:57:35,106 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-28 16:57:35,106 >> Video processor InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-06-28 16:57:35,107 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/processor_config.json
[INFO|processing_utils.py:990] 2025-06-28 16:57:35,613 >> Processor InternVLProcessor:
- image_processor: GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf', vocab_size=151643, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>', '<img>', '</img>', '<IMG_CONTEXT>', '<quad>', '</quad>', '<ref>', '</ref>', '<box>', '</box>'], 'context_image_token': '<IMG_CONTEXT>', 'end_image_token': '</img>', 'start_image_token': '<img>', 'video_token': '<video>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151665: AddedToken("<img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151666: AddedToken("</img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151667: AddedToken("<IMG_CONTEXT>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151668: AddedToken("<quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151669: AddedToken("</quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151670: AddedToken("<ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151671: AddedToken("</ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151672: AddedToken("<box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151673: AddedToken("</box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151674: AddedToken("<video>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}


{
  "image_seq_length": 256,
  "processor_class": "InternVLProcessor"
}

[INFO|2025-06-28 16:57:35] llamafactory.data.template:143 >> Add <|im_end|> to stop words.
[INFO|2025-06-28 16:57:35] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
[INFO|configuration_utils.py:696] 2025-06-28 16:57:36,307 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-28 16:57:36,309 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

eval example:
input_ids:
[151644, 8948, 198, 105043, 90286, 21287, 13935, 116669, 3837, 105205, 13072, 20412, 67916, 30698, 3837, 104625, 100633, 104455, 104800, 5373, 109065, 81217, 104581, 99721, 75317, 101101, 100013, 9370, 42140, 53772, 35243, 26288, 102064, 104949, 1773, 151645, 198, 151644, 872, 198, 151665, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151666, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
你是书生·万象，英文名是InternVL，是由上海人工智能实验室、清华大学及多家合作单位联合开发的多模态大语言模型。<|im_end|>
<|im_start|>user
<img><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT></img>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-28 16:57:36] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-28 16:57:36,395 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-06-28 16:57:36,397 >> Instantiating InternVLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-28 16:57:36,400 >> Generate config GenerationConfig {}

[INFO|modeling_utils.py:2241] 2025-06-28 16:57:36,990 >> Instantiating InternVLVisionModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-28 16:57:37,047 >> Instantiating Qwen2Model model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.33s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]
[INFO|modeling_utils.py:5131] 2025-06-28 16:57:44,457 >> All model checkpoint weights were used when initializing InternVLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-28 16:57:44,457 >> All the weights of InternVLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use InternVLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-28 16:57:44,463 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-8B-hf/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-28 16:57:44,463 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|2025-06-28 16:57:44] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-28 16:57:44] llamafactory.model.loader:143 >> all params: 7,944,373,760
[WARNING|2025-06-28 16:57:44] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-28 16:57:44,536 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-28 16:57:44,537 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-28 16:57:44,537 >>   Batch size = 8
  0%|          | 0/264 [00:00<?, ?it/s]  1%|          | 2/264 [00:02<05:54,  1.35s/it]  1%|          | 3/264 [00:05<07:48,  1.79s/it]  2%|▏         | 4/264 [00:10<13:06,  3.02s/it]  2%|▏         | 5/264 [00:14<14:35,  3.38s/it]  2%|▏         | 6/264 [00:19<17:38,  4.10s/it]  3%|▎         | 7/264 [00:24<18:02,  4.21s/it]  3%|▎         | 8/264 [00:31<22:28,  5.27s/it]  3%|▎         | 9/264 [00:37<22:38,  5.33s/it]  4%|▍         | 10/264 [00:39<18:21,  4.34s/it]  4%|▍         | 11/264 [00:43<17:29,  4.15s/it]  5%|▍         | 12/264 [00:45<15:40,  3.73s/it]  5%|▍         | 13/264 [00:50<16:19,  3.90s/it]  5%|▌         | 14/264 [00:52<14:47,  3.55s/it]  6%|▌         | 15/264 [00:58<17:02,  4.11s/it]  6%|▌         | 16/264 [01:03<18:49,  4.55s/it]  6%|▋         | 17/264 [01:08<18:13,  4.43s/it]  7%|▋         | 18/264 [01:10<16:07,  3.93s/it]  7%|▋         | 19/264 [01:15<16:58,  4.16s/it]  8%|▊         | 20/264 [01:19<17:10,  4.22s/it]  8%|▊         | 21/264 [01:23<16:31,  4.08s/it]  8%|▊         | 22/264 [01:26<14:31,  3.60s/it]  9%|▊         | 23/264 [01:30<15:16,  3.80s/it]  9%|▉         | 24/264 [01:33<14:08,  3.53s/it]  9%|▉         | 25/264 [01:37<15:07,  3.80s/it] 10%|▉         | 26/264 [01:39<13:12,  3.33s/it] 10%|█         | 27/264 [01:42<12:02,  3.05s/it] 11%|█         | 28/264 [01:48<15:09,  3.86s/it] 11%|█         | 29/264 [01:52<15:42,  4.01s/it] 11%|█▏        | 30/264 [01:57<17:17,  4.43s/it] 12%|█▏        | 31/264 [02:02<17:06,  4.41s/it] 12%|█▏        | 32/264 [02:07<17:46,  4.60s/it] 12%|█▎        | 33/264 [02:12<17:59,  4.67s/it] 13%|█▎        | 34/264 [02:16<17:28,  4.56s/it] 13%|█▎        | 35/264 [02:20<16:55,  4.43s/it] 14%|█▎        | 36/264 [02:27<20:18,  5.34s/it] 14%|█▍        | 37/264 [02:31<18:41,  4.94s/it] 14%|█▍        | 38/264 [02:36<18:40,  4.96s/it] 15%|█▍        | 39/264 [02:42<19:26,  5.18s/it] 15%|█▌        | 40/264 [02:50<21:59,  5.89s/it] 16%|█▌        | 41/264 [02:53<18:27,  4.97s/it] 16%|█▌        | 42/264 [02:55<15:41,  4.24s/it] 16%|█▋        | 43/264 [02:59<15:29,  4.21s/it] 17%|█▋        | 44/264 [03:02<13:39,  3.72s/it] 17%|█▋        | 45/264 [03:05<12:42,  3.48s/it] 17%|█▋        | 46/264 [03:08<12:52,  3.54s/it] 18%|█▊        | 47/264 [03:15<15:40,  4.33s/it] 18%|█▊        | 48/264 [03:19<15:41,  4.36s/it] 19%|█▊        | 49/264 [03:25<17:11,  4.80s/it] 19%|█▉        | 50/264 [03:28<15:19,  4.30s/it] 19%|█▉        | 51/264 [03:33<16:06,  4.54s/it] 20%|█▉        | 52/264 [03:38<16:05,  4.55s/it] 20%|██        | 53/264 [03:41<14:36,  4.15s/it] 20%|██        | 54/264 [03:47<16:19,  4.66s/it] 21%|██        | 55/264 [03:49<13:52,  3.98s/it] 21%|██        | 56/264 [03:52<12:55,  3.73s/it] 22%|██▏       | 57/264 [03:55<11:29,  3.33s/it] 22%|██▏       | 58/264 [03:57<10:33,  3.08s/it] 22%|██▏       | 59/264 [04:02<12:36,  3.69s/it] 23%|██▎       | 60/264 [04:06<12:44,  3.75s/it] 23%|██▎       | 61/264 [04:11<13:22,  3.96s/it] 23%|██▎       | 62/264 [04:16<14:59,  4.45s/it] 24%|██▍       | 63/264 [04:21<15:33,  4.64s/it] 24%|██▍       | 64/264 [04:25<14:56,  4.48s/it] 25%|██▍       | 65/264 [04:28<12:46,  3.85s/it] 25%|██▌       | 66/264 [04:30<11:10,  3.39s/it] 25%|██▌       | 67/264 [04:36<13:19,  4.06s/it] 26%|██▌       | 68/264 [04:40<13:13,  4.05s/it] 26%|██▌       | 69/264 [04:45<14:10,  4.36s/it] 27%|██▋       | 70/264 [04:49<14:08,  4.37s/it] 27%|██▋       | 71/264 [04:53<13:58,  4.34s/it] 27%|██▋       | 72/264 [04:59<14:36,  4.57s/it] 28%|██▊       | 73/264 [05:02<13:13,  4.15s/it] 28%|██▊       | 74/264 [05:04<11:33,  3.65s/it] 28%|██▊       | 75/264 [05:08<11:47,  3.75s/it] 29%|██▉       | 76/264 [05:12<11:54,  3.80s/it] 29%|██▉       | 77/264 [05:16<12:17,  3.95s/it] 30%|██▉       | 78/264 [05:19<11:11,  3.61s/it] 30%|██▉       | 79/264 [05:22<10:20,  3.36s/it] 30%|███       | 80/264 [05:27<11:32,  3.76s/it] 31%|███       | 81/264 [05:34<14:43,  4.83s/it] 31%|███       | 82/264 [05:40<15:39,  5.16s/it] 31%|███▏      | 83/264 [05:44<14:57,  4.96s/it] 32%|███▏      | 84/264 [05:52<17:31,  5.84s/it] 32%|███▏      | 85/264 [05:56<15:45,  5.28s/it] 33%|███▎      | 86/264 [05:59<13:13,  4.46s/it] 33%|███▎      | 87/264 [06:04<13:20,  4.53s/it] 33%|███▎      | 88/264 [06:06<11:35,  3.95s/it] 34%|███▎      | 89/264 [06:10<11:05,  3.80s/it] 34%|███▍      | 90/264 [06:15<12:26,  4.29s/it] 34%|███▍      | 91/264 [06:18<11:15,  3.91s/it] 35%|███▍      | 92/264 [06:21<10:25,  3.64s/it] 35%|███▌      | 93/264 [06:25<10:15,  3.60s/it] 36%|███▌      | 94/264 [06:29<10:56,  3.86s/it] 36%|███▌      | 95/264 [06:34<11:59,  4.26s/it] 36%|███▋      | 96/264 [06:39<12:31,  4.47s/it] 37%|███▋      | 97/264 [06:42<11:08,  4.00s/it] 37%|███▋      | 98/264 [06:47<11:22,  4.11s/it] 38%|███▊      | 99/264 [06:51<11:29,  4.18s/it] 38%|███▊      | 100/264 [06:56<12:04,  4.42s/it] 38%|███▊      | 101/264 [07:00<12:01,  4.43s/it] 39%|███▊      | 102/264 [07:05<12:21,  4.58s/it] 39%|███▉      | 103/264 [07:11<13:36,  5.07s/it] 39%|███▉      | 104/264 [07:17<14:00,  5.25s/it] 40%|███▉      | 105/264 [07:22<13:27,  5.08s/it] 40%|████      | 106/264 [07:25<11:39,  4.43s/it] 41%|████      | 107/264 [07:29<11:44,  4.48s/it] 41%|████      | 108/264 [07:33<11:00,  4.24s/it] 41%|████▏     | 109/264 [07:39<12:37,  4.89s/it] 42%|████▏     | 110/264 [07:42<11:05,  4.32s/it] 42%|████▏     | 111/264 [07:47<11:05,  4.35s/it] 42%|████▏     | 112/264 [07:51<10:46,  4.26s/it] 43%|████▎     | 113/264 [07:56<11:43,  4.66s/it] 43%|████▎     | 114/264 [08:03<13:22,  5.35s/it] 44%|████▎     | 115/264 [08:06<11:12,  4.51s/it] 44%|████▍     | 116/264 [08:11<11:49,  4.79s/it] 44%|████▍     | 117/264 [08:15<10:34,  4.31s/it] 45%|████▍     | 118/264 [08:19<10:47,  4.43s/it] 45%|████▌     | 119/264 [08:26<12:29,  5.17s/it] 45%|████▌     | 120/264 [08:35<14:59,  6.25s/it] 46%|████▌     | 121/264 [08:42<15:14,  6.40s/it] 46%|████▌     | 122/264 [08:47<14:12,  6.00s/it] 47%|████▋     | 123/264 [08:49<11:21,  4.83s/it] 47%|████▋     | 124/264 [08:53<10:53,  4.67s/it] 47%|████▋     | 125/264 [08:59<11:18,  4.88s/it] 48%|████▊     | 126/264 [09:01<09:25,  4.10s/it] 48%|████▊     | 127/264 [09:05<09:32,  4.18s/it] 48%|████▊     | 128/264 [09:10<09:51,  4.35s/it] 49%|████▉     | 129/264 [09:14<09:49,  4.37s/it] 49%|████▉     | 130/264 [09:19<09:55,  4.45s/it] 50%|████▉     | 131/264 [09:21<08:33,  3.86s/it] 50%|█████     | 132/264 [09:26<09:00,  4.10s/it] 50%|█████     | 133/264 [09:29<08:18,  3.81s/it] 51%|█████     | 134/264 [09:34<09:04,  4.19s/it] 51%|█████     | 135/264 [09:39<09:07,  4.24s/it] 52%|█████▏    | 136/264 [09:42<08:38,  4.05s/it] 52%|█████▏    | 137/264 [09:46<08:14,  3.89s/it] 52%|█████▏    | 138/264 [09:51<08:43,  4.16s/it] 53%|█████▎    | 139/264 [09:53<07:35,  3.64s/it] 53%|█████▎    | 140/264 [09:57<08:02,  3.89s/it] 53%|█████▎    | 141/264 [10:02<08:04,  3.94s/it] 54%|█████▍    | 142/264 [10:06<08:23,  4.13s/it] 54%|█████▍    | 143/264 [10:13<10:15,  5.09s/it] 55%|█████▍    | 144/264 [10:18<09:41,  4.85s/it] 55%|█████▍    | 145/264 [10:21<08:27,  4.27s/it] 55%|█████▌    | 146/264 [10:25<08:24,  4.27s/it] 56%|█████▌    | 147/264 [10:27<07:20,  3.76s/it] 56%|█████▌    | 148/264 [10:34<08:41,  4.49s/it] 56%|█████▋    | 149/264 [10:38<08:45,  4.57s/it] 57%|█████▋    | 150/264 [10:43<08:46,  4.62s/it] 57%|█████▋    | 151/264 [10:49<09:07,  4.84s/it] 58%|█████▊    | 152/264 [10:51<07:38,  4.10s/it] 58%|█████▊    | 153/264 [10:56<08:07,  4.39s/it] 58%|█████▊    | 154/264 [11:03<09:43,  5.31s/it] 59%|█████▊    | 155/264 [11:08<09:29,  5.23s/it] 59%|█████▉    | 156/264 [11:12<08:44,  4.86s/it] 59%|█████▉    | 157/264 [11:15<07:26,  4.17s/it] 60%|█████▉    | 158/264 [11:21<08:07,  4.60s/it] 60%|██████    | 159/264 [11:24<07:26,  4.25s/it] 61%|██████    | 160/264 [11:28<07:13,  4.17s/it] 61%|██████    | 161/264 [11:32<06:57,  4.05s/it] 61%|██████▏   | 162/264 [11:36<07:00,  4.12s/it] 62%|██████▏   | 163/264 [11:38<06:00,  3.57s/it] 62%|██████▏   | 164/264 [11:41<05:39,  3.39s/it] 62%|██████▎   | 165/264 [11:45<05:43,  3.47s/it] 63%|██████▎   | 166/264 [11:50<06:36,  4.05s/it] 63%|██████▎   | 167/264 [11:55<06:42,  4.14s/it] 64%|██████▎   | 168/264 [11:59<06:51,  4.29s/it] 64%|██████▍   | 169/264 [12:02<05:58,  3.77s/it] 64%|██████▍   | 170/264 [12:06<06:11,  3.95s/it] 65%|██████▍   | 171/264 [12:11<06:26,  4.15s/it] 65%|██████▌   | 172/264 [12:13<05:33,  3.62s/it] 66%|██████▌   | 173/264 [12:20<06:49,  4.50s/it] 66%|██████▌   | 174/264 [12:25<06:50,  4.56s/it] 66%|██████▋   | 175/264 [12:27<05:48,  3.92s/it] 67%|██████▋   | 176/264 [12:31<05:53,  4.02s/it] 67%|██████▋   | 177/264 [12:34<05:20,  3.69s/it] 67%|██████▋   | 178/264 [12:37<04:49,  3.36s/it] 68%|██████▊   | 179/264 [12:40<04:42,  3.32s/it] 68%|██████▊   | 180/264 [12:44<05:07,  3.66s/it] 69%|██████▊   | 181/264 [12:50<05:48,  4.20s/it] 69%|██████▉   | 182/264 [12:54<05:45,  4.21s/it] 69%|██████▉   | 183/264 [13:02<07:01,  5.21s/it] 70%|██████▉   | 184/264 [13:06<06:36,  4.96s/it] 70%|███████   | 185/264 [13:09<05:43,  4.34s/it] 70%|███████   | 186/264 [13:13<05:42,  4.39s/it] 71%|███████   | 187/264 [13:19<05:53,  4.59s/it] 71%|███████   | 188/264 [13:21<05:06,  4.04s/it] 72%|███████▏  | 189/264 [13:27<05:33,  4.44s/it] 72%|███████▏  | 190/264 [13:30<04:52,  3.96s/it] 72%|███████▏  | 191/264 [13:32<04:13,  3.48s/it] 73%|███████▎  | 192/264 [13:36<04:14,  3.54s/it] 73%|███████▎  | 193/264 [13:41<04:51,  4.11s/it] 73%|███████▎  | 194/264 [13:44<04:27,  3.82s/it] 74%|███████▍  | 195/264 [13:49<04:51,  4.23s/it] 74%|███████▍  | 196/264 [13:53<04:32,  4.00s/it] 75%|███████▍  | 197/264 [14:00<05:31,  4.95s/it] 75%|███████▌  | 198/264 [14:04<05:15,  4.78s/it] 75%|███████▌  | 199/264 [14:09<05:09,  4.76s/it] 76%|███████▌  | 200/264 [14:14<05:15,  4.92s/it] 76%|███████▌  | 201/264 [14:19<05:00,  4.77s/it] 77%|███████▋  | 202/264 [14:23<04:46,  4.62s/it] 77%|███████▋  | 203/264 [14:26<04:20,  4.27s/it] 77%|███████▋  | 204/264 [14:31<04:18,  4.31s/it] 78%|███████▊  | 205/264 [14:36<04:33,  4.64s/it] 78%|███████▊  | 206/264 [14:39<03:53,  4.03s/it] 78%|███████▊  | 207/264 [14:44<04:13,  4.44s/it] 79%|███████▉  | 208/264 [14:50<04:23,  4.71s/it] 79%|███████▉  | 209/264 [14:52<03:40,  4.01s/it] 80%|███████▉  | 210/264 [14:55<03:22,  3.74s/it] 80%|███████▉  | 211/264 [15:03<04:16,  4.84s/it] 80%|████████  | 212/264 [15:09<04:43,  5.44s/it] 81%|████████  | 213/264 [15:14<04:20,  5.11s/it] 81%|████████  | 214/264 [15:28<06:29,  7.80s/it] 81%|████████▏ | 215/264 [15:35<06:07,  7.49s/it] 82%|████████▏ | 216/264 [15:38<05:05,  6.37s/it] 82%|████████▏ | 217/264 [15:43<04:31,  5.78s/it] 83%|████████▎ | 218/264 [15:47<04:03,  5.29s/it] 83%|████████▎ | 219/264 [15:53<04:13,  5.63s/it] 83%|████████▎ | 220/264 [15:58<03:50,  5.25s/it] 84%|████████▎ | 221/264 [16:00<03:09,  4.41s/it] 84%|████████▍ | 222/264 [16:02<02:36,  3.73s/it] 84%|████████▍ | 223/264 [16:10<03:27,  5.05s/it] 85%|████████▍ | 224/264 [16:16<03:26,  5.16s/it] 85%|████████▌ | 225/264 [16:18<02:47,  4.30s/it] 86%|████████▌ | 226/264 [16:22<02:41,  4.26s/it] 86%|████████▌ | 227/264 [16:27<02:39,  4.31s/it] 86%|████████▋ | 228/264 [16:31<02:37,  4.39s/it] 87%|████████▋ | 229/264 [16:36<02:36,  4.49s/it] 87%|████████▋ | 230/264 [16:41<02:39,  4.69s/it] 88%|████████▊ | 231/264 [16:45<02:30,  4.57s/it] 88%|████████▊ | 232/264 [16:48<02:03,  3.85s/it] 88%|████████▊ | 233/264 [16:52<02:05,  4.04s/it] 89%|████████▊ | 234/264 [16:57<02:12,  4.40s/it] 89%|████████▉ | 235/264 [17:00<01:54,  3.96s/it] 89%|████████▉ | 236/264 [17:03<01:40,  3.61s/it] 90%|████████▉ | 237/264 [17:10<02:00,  4.48s/it] 90%|█████████ | 238/264 [17:12<01:41,  3.91s/it] 91%|█████████ | 239/264 [17:19<01:56,  4.66s/it] 91%|█████████ | 240/264 [17:25<02:02,  5.12s/it] 91%|█████████▏| 241/264 [17:27<01:39,  4.32s/it] 92%|█████████▏| 242/264 [17:30<01:21,  3.72s/it] 92%|█████████▏| 243/264 [17:38<01:51,  5.30s/it] 92%|█████████▏| 244/264 [17:43<01:40,  5.02s/it] 93%|█████████▎| 245/264 [17:47<01:31,  4.83s/it] 93%|█████████▎| 246/264 [17:52<01:26,  4.83s/it] 94%|█████████▎| 247/264 [17:58<01:28,  5.21s/it] 94%|█████████▍| 248/264 [18:00<01:09,  4.34s/it] 94%|█████████▍| 249/264 [18:04<01:03,  4.22s/it] 95%|█████████▍| 250/264 [18:11<01:08,  4.91s/it] 95%|█████████▌| 251/264 [18:23<01:30,  6.93s/it] 95%|█████████▌| 252/264 [18:26<01:09,  5.76s/it] 96%|█████████▌| 253/264 [18:32<01:06,  6.01s/it] 96%|█████████▌| 254/264 [18:35<00:49,  4.91s/it] 97%|█████████▋| 255/264 [18:40<00:45,  5.04s/it] 97%|█████████▋| 256/264 [18:43<00:35,  4.47s/it] 97%|█████████▋| 257/264 [18:47<00:31,  4.44s/it] 98%|█████████▊| 258/264 [18:51<00:24,  4.05s/it] 98%|█████████▊| 259/264 [18:53<00:17,  3.46s/it] 98%|█████████▊| 260/264 [18:58<00:16,  4.09s/it] 99%|█████████▉| 261/264 [19:03<00:12,  4.20s/it] 99%|█████████▉| 262/264 [19:07<00:08,  4.29s/it]100%|█████████▉| 263/264 [19:11<00:04,  4.27s/it]100%|██████████| 264/264 [19:18<00:00,  4.92s/it]Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 0.684 seconds.
Prefix dict has been built successfully.
100%|██████████| 264/264 [19:26<00:00,  4.42s/it]
***** predict metrics *****
  predict_bleu-4                 =     8.8972
  predict_model_preparation_time =     0.0095
  predict_rouge-1                =     8.9402
  predict_rouge-2                =     4.7635
  predict_rouge-l                =     9.4068
  predict_runtime                = 0:19:30.97
  predict_samples_per_second     =        1.8
  predict_steps_per_second       =      0.225
[INFO|2025-06-28 17:17:15] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/InternVL3-8B-hf/vindr_test_set/generated_predictions.jsonl
[2025-06-28 17:17:35,444] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-28 17:17:40 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-28 17:17:43] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,510 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,510 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,510 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,510 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,510 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,511 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,511 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 17:17:43,842 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-06-28 17:17:43,844 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-06-28 17:17:43,869 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-28 17:17:43,898 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,899 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,899 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,899 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,899 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,899 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,899 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:17:43,899 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 17:17:44,214 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-28 17:17:44,215 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-28 17:17:44,216 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-28 17:17:44,216 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-28 17:17:44,219 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 152064
  },
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 3584,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 152064
}

[INFO|video_processing_utils.py:627] 2025-06-28 17:17:44,222 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-28 17:17:44,222 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-06-28 17:17:44,734 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|2025-06-28 17:17:44] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Converting format of dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   6%|▋         | 132/2108 [00:00<00:01, 1059.26 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 2108/2108 [00:00<00:00, 6521.83 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [03:16<48:59,  1.49s/ examples]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [03:18<19:09,  1.60 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [03:38<19:09,  1.60 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [04:11<14:53,  1.92 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [04:18<08:53,  2.96 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [04:22<05:25,  4.45 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 791/2108 [04:24<03:24,  6.43 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 923/2108 [04:25<02:06,  9.38 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1055/2108 [04:27<01:22, 12.83 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1186/2108 [04:28<00:49, 18.55 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1450/2108 [04:28<00:19, 34.50 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1582/2108 [04:28<00:11, 44.21 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1714/2108 [04:28<00:06, 58.85 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 1845/2108 [04:29<00:03, 76.58 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [04:29<00:01, 99.75 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [04:29<00:00,  7.81 examples/s]
[INFO|configuration_utils.py:696] 2025-06-28 17:22:16,267 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-28 17:22:16,274 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 152064
  },
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 3584,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 152064
}

eval example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-28 17:22:16] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-28 17:22:16,401 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-06-28 17:22:16,403 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-28 17:22:16,407 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|modeling_utils.py:2241] 2025-06-28 17:22:16,409 >> Instantiating Qwen2VisionTransformerPretrainedModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-28 17:22:16,497 >> Instantiating Qwen2VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:04<00:19,  4.88s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.66s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:09,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.61s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.41s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.97s/it]
[INFO|modeling_utils.py:5131] 2025-06-28 17:22:36,406 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-28 17:22:36,406 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-28 17:22:36,413 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-7B-Instruct/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-28 17:22:36,413 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

[INFO|2025-06-28 17:22:36] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-28 17:22:36] llamafactory.model.loader:143 >> all params: 8,291,375,616
[WARNING|2025-06-28 17:22:36] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-28 17:22:36,489 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-28 17:22:36,489 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-28 17:22:36,489 >>   Batch size = 8
  0%|          | 0/264 [00:00<?, ?it/s]  1%|          | 2/264 [00:03<08:12,  1.88s/it]  1%|          | 3/264 [00:07<11:03,  2.54s/it]  2%|▏         | 4/264 [00:09<10:52,  2.51s/it]  2%|▏         | 5/264 [00:12<10:41,  2.48s/it]  2%|▏         | 6/264 [00:14<10:33,  2.46s/it]  3%|▎         | 7/264 [00:16<10:27,  2.44s/it]  3%|▎         | 8/264 [00:19<10:22,  2.43s/it]  3%|▎         | 9/264 [00:21<10:18,  2.43s/it]  4%|▍         | 10/264 [00:24<10:46,  2.55s/it]  4%|▍         | 11/264 [00:26<10:33,  2.51s/it]  5%|▍         | 12/264 [00:30<12:01,  2.86s/it]  5%|▍         | 13/264 [00:33<11:24,  2.73s/it]  5%|▌         | 14/264 [00:36<12:33,  3.02s/it]  6%|▌         | 15/264 [00:39<11:45,  2.83s/it]  6%|▌         | 16/264 [00:41<11:12,  2.71s/it]  6%|▋         | 17/264 [00:45<12:29,  3.03s/it]  7%|▋         | 18/264 [00:47<11:40,  2.85s/it]  7%|▋         | 19/264 [00:51<12:39,  3.10s/it]  8%|▊         | 20/264 [00:53<11:46,  2.89s/it]  8%|▊         | 21/264 [00:56<11:08,  2.75s/it]  8%|▊         | 22/264 [00:59<12:08,  3.01s/it]  9%|▊         | 23/264 [01:02<11:22,  2.83s/it]  9%|▉         | 24/264 [01:04<10:49,  2.71s/it]  9%|▉         | 25/264 [01:08<12:02,  3.02s/it] 10%|▉         | 26/264 [01:10<11:13,  2.83s/it] 10%|█         | 27/264 [01:14<12:11,  3.09s/it] 11%|█         | 28/264 [01:18<12:45,  3.25s/it] 11%|█         | 29/264 [01:20<11:44,  3.00s/it] 11%|█▏        | 30/264 [01:23<11:00,  2.82s/it] 12%|█▏        | 31/264 [01:25<10:29,  2.70s/it] 12%|█▏        | 32/264 [01:27<10:13,  2.64s/it] 12%|█▎        | 33/264 [01:30<09:55,  2.58s/it] 13%|█▎        | 34/264 [01:32<09:41,  2.53s/it] 13%|█▎        | 35/264 [01:35<09:31,  2.49s/it] 14%|█▎        | 36/264 [01:44<17:42,  4.66s/it] 14%|█▍        | 37/264 [01:48<16:23,  4.33s/it] 14%|█▍        | 38/264 [01:52<15:34,  4.13s/it] 15%|█▍        | 39/264 [01:55<15:04,  4.02s/it] 15%|█▌        | 40/264 [01:59<14:42,  3.94s/it] 16%|█▌        | 41/264 [02:02<12:56,  3.48s/it] 16%|█▌        | 42/264 [02:05<13:06,  3.54s/it] 16%|█▋        | 43/264 [02:09<13:12,  3.58s/it] 17%|█▋        | 44/264 [02:11<11:51,  3.23s/it] 17%|█▋        | 45/264 [02:14<10:54,  2.99s/it] 17%|█▋        | 46/264 [02:18<11:41,  3.22s/it] 18%|█▊        | 47/264 [02:20<10:46,  2.98s/it] 18%|█▊        | 48/264 [02:22<10:06,  2.81s/it] 19%|█▊        | 49/264 [02:26<10:47,  3.01s/it] 19%|█▉        | 50/264 [02:28<10:06,  2.83s/it] 19%|█▉        | 51/264 [02:31<10:00,  2.82s/it] 20%|█▉        | 52/264 [02:33<09:32,  2.70s/it] 20%|██        | 53/264 [02:36<09:11,  2.61s/it] 20%|██        | 54/264 [02:38<08:56,  2.55s/it] 21%|██        | 55/264 [02:41<08:45,  2.51s/it] 21%|██        | 56/264 [02:43<08:36,  2.48s/it] 22%|██▏       | 57/264 [02:46<08:29,  2.46s/it] 22%|██▏       | 58/264 [02:48<08:24,  2.45s/it] 22%|██▏       | 59/264 [02:50<08:19,  2.44s/it] 23%|██▎       | 60/264 [02:53<08:15,  2.43s/it] 23%|██▎       | 61/264 [02:55<08:12,  2.43s/it] 23%|██▎       | 62/264 [02:58<08:09,  2.42s/it] 24%|██▍       | 63/264 [03:00<08:06,  2.42s/it] 24%|██▍       | 64/264 [03:02<08:03,  2.42s/it] 25%|██▍       | 65/264 [03:05<08:00,  2.42s/it] 25%|██▌       | 66/264 [03:09<09:17,  2.82s/it] 25%|██▌       | 67/264 [03:12<10:09,  3.10s/it] 26%|██▌       | 68/264 [03:15<09:26,  2.89s/it] 26%|██▌       | 69/264 [03:26<17:13,  5.30s/it] 27%|██▋       | 70/264 [03:28<14:20,  4.44s/it] 27%|██▋       | 71/264 [03:31<12:19,  3.83s/it] 27%|██▋       | 72/264 [03:33<10:55,  3.41s/it] 28%|██▊       | 73/264 [03:35<09:55,  3.12s/it] 28%|██▊       | 74/264 [03:39<10:24,  3.28s/it] 28%|██▊       | 75/264 [03:43<10:43,  3.40s/it] 29%|██▉       | 76/264 [03:46<10:57,  3.50s/it] 29%|██▉       | 77/264 [03:49<09:53,  3.17s/it] 30%|██▉       | 78/264 [03:51<09:08,  2.95s/it] 30%|██▉       | 79/264 [03:55<09:49,  3.19s/it] 30%|███       | 80/264 [03:59<10:17,  3.35s/it] 31%|███       | 81/264 [04:01<09:24,  3.08s/it] 31%|███       | 82/264 [04:04<08:44,  2.88s/it] 31%|███▏      | 83/264 [04:07<09:24,  3.12s/it] 32%|███▏      | 84/264 [04:10<08:43,  2.91s/it] 32%|███▏      | 85/264 [04:12<08:14,  2.76s/it] 33%|███▎      | 86/264 [04:15<08:16,  2.79s/it] 33%|███▎      | 87/264 [04:19<08:53,  3.02s/it] 33%|███▎      | 88/264 [04:21<08:19,  2.84s/it] 34%|███▎      | 89/264 [04:26<10:08,  3.48s/it] 34%|███▍      | 90/264 [04:30<10:09,  3.50s/it] 34%|███▍      | 91/264 [04:32<09:12,  3.20s/it] 35%|███▍      | 92/264 [04:34<08:29,  2.96s/it] 35%|███▌      | 93/264 [04:37<07:58,  2.80s/it] 36%|███▌      | 94/264 [04:39<07:36,  2.68s/it] 36%|███▌      | 95/264 [04:42<07:19,  2.60s/it] 36%|███▋      | 96/264 [04:44<07:07,  2.55s/it] 37%|███▋      | 97/264 [04:48<08:01,  2.89s/it] 37%|███▋      | 98/264 [04:50<07:39,  2.77s/it] 38%|███▊      | 99/264 [04:54<08:23,  3.05s/it] 38%|███▊      | 100/264 [04:58<08:54,  3.26s/it] 38%|███▊      | 101/264 [05:01<09:11,  3.38s/it] 39%|███▊      | 102/264 [05:05<09:19,  3.45s/it] 39%|███▉      | 103/264 [05:07<08:25,  3.14s/it] 39%|███▉      | 104/264 [05:10<07:48,  2.93s/it] 40%|███▉      | 105/264 [05:16<10:12,  3.85s/it] 40%|████      | 106/264 [05:18<09:00,  3.42s/it] 41%|████      | 107/264 [05:21<08:09,  3.12s/it] 41%|████      | 108/264 [05:23<07:35,  2.92s/it] 41%|████▏     | 109/264 [05:26<07:08,  2.77s/it] 42%|████▏     | 110/264 [05:35<12:15,  4.78s/it] 42%|████▏     | 111/264 [05:37<10:22,  4.07s/it] 42%|████▏     | 112/264 [05:40<09:02,  3.57s/it] 43%|████▎     | 113/264 [05:42<08:06,  3.22s/it] 43%|████▎     | 114/264 [05:45<07:27,  2.98s/it] 44%|████▎     | 115/264 [05:47<06:59,  2.82s/it] 44%|████▍     | 116/264 [05:50<06:39,  2.70s/it] 44%|████▍     | 117/264 [05:52<06:23,  2.61s/it] 45%|████▍     | 118/264 [05:56<07:08,  2.93s/it] 45%|████▌     | 119/264 [05:58<06:44,  2.79s/it] 45%|████▌     | 120/264 [06:02<07:20,  3.06s/it] 46%|████▌     | 121/264 [06:04<06:49,  2.87s/it] 46%|████▌     | 122/264 [06:08<07:18,  3.09s/it] 47%|████▋     | 123/264 [06:10<06:47,  2.89s/it] 47%|████▋     | 124/264 [06:13<06:24,  2.75s/it] 47%|████▋     | 125/264 [06:16<07:00,  3.03s/it] 48%|████▊     | 126/264 [06:19<06:32,  2.84s/it] 48%|████▊     | 127/264 [06:22<06:27,  2.83s/it] 48%|████▊     | 128/264 [06:24<06:07,  2.70s/it] 49%|████▉     | 129/264 [06:26<05:53,  2.62s/it] 49%|████▉     | 130/264 [06:30<06:30,  2.92s/it] 50%|████▉     | 131/264 [06:32<06:07,  2.77s/it] 50%|█████     | 132/264 [06:36<06:42,  3.05s/it] 50%|█████     | 133/264 [06:41<07:58,  3.66s/it] 51%|█████     | 134/264 [06:44<07:06,  3.28s/it] 51%|█████     | 135/264 [06:55<11:59,  5.58s/it] 52%|█████▏    | 136/264 [06:58<10:42,  5.02s/it] 52%|█████▏    | 137/264 [07:01<08:58,  4.24s/it] 52%|█████▏    | 138/264 [07:03<07:46,  3.70s/it] 53%|█████▎    | 139/264 [07:07<07:41,  3.70s/it] 53%|█████▎    | 140/264 [07:09<06:50,  3.31s/it] 53%|█████▎    | 141/264 [07:12<06:14,  3.04s/it] 54%|█████▍    | 142/264 [07:14<05:48,  2.86s/it] 54%|█████▍    | 143/264 [07:18<06:12,  3.08s/it] 55%|█████▍    | 144/264 [07:20<05:45,  2.88s/it] 55%|█████▍    | 145/264 [07:22<05:26,  2.74s/it] 55%|█████▌    | 146/264 [07:26<05:59,  3.04s/it] 56%|█████▌    | 147/264 [07:30<06:20,  3.25s/it] 56%|█████▌    | 148/264 [07:32<05:48,  3.00s/it] 56%|█████▋    | 149/264 [07:35<05:25,  2.83s/it] 57%|█████▋    | 150/264 [07:37<05:08,  2.70s/it] 57%|█████▋    | 151/264 [07:41<05:38,  3.00s/it] 58%|█████▊    | 152/264 [07:45<05:58,  3.20s/it] 58%|█████▊    | 153/264 [07:48<06:13,  3.37s/it] 58%|█████▊    | 154/264 [07:51<05:38,  3.08s/it] 59%|█████▊    | 155/264 [07:54<05:55,  3.26s/it] 59%|█████▉    | 156/264 [07:58<06:07,  3.40s/it] 59%|█████▉    | 157/264 [08:02<06:14,  3.50s/it] 60%|█████▉    | 158/264 [08:04<05:36,  3.17s/it] 60%|██████    | 159/264 [08:07<05:08,  2.94s/it] 61%|██████    | 160/264 [08:09<04:50,  2.79s/it] 61%|██████    | 161/264 [08:12<04:35,  2.68s/it] 61%|██████▏   | 162/264 [08:14<04:25,  2.60s/it] 62%|██████▏   | 163/264 [08:16<04:16,  2.54s/it] 62%|██████▏   | 164/264 [08:19<04:10,  2.50s/it] 62%|██████▎   | 165/264 [08:25<05:59,  3.64s/it] 63%|██████▎   | 166/264 [08:27<05:20,  3.27s/it] 63%|██████▎   | 167/264 [08:30<05:03,  3.13s/it] 64%|██████▎   | 168/264 [08:33<04:39,  2.91s/it] 64%|██████▍   | 169/264 [08:35<04:22,  2.76s/it] 64%|██████▍   | 170/264 [08:38<04:10,  2.66s/it] 65%|██████▍   | 171/264 [08:40<04:00,  2.59s/it] 65%|██████▌   | 172/264 [08:42<03:51,  2.52s/it] 66%|██████▌   | 173/264 [08:45<03:46,  2.49s/it] 66%|██████▌   | 174/264 [08:47<03:41,  2.47s/it] 66%|██████▋   | 175/264 [08:50<03:38,  2.45s/it] 67%|██████▋   | 176/264 [08:52<03:34,  2.44s/it] 67%|██████▋   | 177/264 [08:54<03:31,  2.43s/it] 67%|██████▋   | 178/264 [08:57<03:28,  2.43s/it] 68%|██████▊   | 179/264 [09:00<03:58,  2.80s/it] 68%|██████▊   | 180/264 [09:03<03:45,  2.69s/it] 69%|██████▊   | 181/264 [09:05<03:36,  2.60s/it] 69%|██████▉   | 182/264 [09:09<03:56,  2.89s/it] 69%|██████▉   | 183/264 [09:11<03:42,  2.75s/it] 70%|██████▉   | 184/264 [09:14<03:31,  2.65s/it] 70%|███████   | 185/264 [09:16<03:23,  2.58s/it] 70%|███████   | 186/264 [09:20<03:47,  2.92s/it] 71%|███████   | 187/264 [09:23<04:02,  3.15s/it] 71%|███████   | 188/264 [09:28<04:38,  3.67s/it] 72%|███████▏  | 189/264 [09:31<04:06,  3.29s/it] 72%|███████▏  | 190/264 [09:34<04:12,  3.41s/it] 72%|███████▏  | 191/264 [09:37<03:47,  3.11s/it] 73%|███████▎  | 192/264 [09:41<03:56,  3.28s/it] 73%|███████▎  | 193/264 [09:44<04:02,  3.42s/it] 73%|███████▎  | 194/264 [09:47<03:39,  3.14s/it] 74%|███████▍  | 195/264 [09:50<03:46,  3.28s/it] 74%|███████▍  | 196/264 [09:54<03:51,  3.40s/it] 75%|███████▍  | 197/264 [09:56<03:28,  3.11s/it] 75%|███████▌  | 198/264 [10:00<03:37,  3.30s/it] 75%|███████▌  | 199/264 [10:03<03:17,  3.03s/it] 76%|███████▌  | 200/264 [10:06<03:26,  3.23s/it] 76%|███████▌  | 201/264 [10:10<03:38,  3.48s/it] 77%|███████▋  | 202/264 [10:14<03:39,  3.54s/it] 77%|███████▋  | 203/264 [10:16<03:15,  3.20s/it] 77%|███████▋  | 204/264 [10:19<02:57,  2.97s/it] 78%|███████▊  | 205/264 [10:23<03:07,  3.18s/it] 78%|███████▊  | 206/264 [10:25<02:51,  2.95s/it] 78%|███████▊  | 207/264 [10:27<02:38,  2.79s/it] 79%|███████▉  | 208/264 [10:30<02:29,  2.68s/it] 79%|███████▉  | 209/264 [10:32<02:22,  2.60s/it] 80%|███████▉  | 210/264 [10:35<02:17,  2.54s/it] 80%|███████▉  | 211/264 [10:37<02:12,  2.51s/it] 80%|████████  | 212/264 [10:39<02:08,  2.48s/it] 81%|████████  | 213/264 [10:42<02:05,  2.46s/it] 81%|████████  | 214/264 [10:46<02:21,  2.83s/it] 81%|████████▏ | 215/264 [10:49<02:30,  3.06s/it] 82%|████████▏ | 216/264 [10:52<02:17,  2.87s/it] 82%|████████▏ | 217/264 [10:54<02:08,  2.73s/it] 83%|████████▎ | 218/264 [10:58<02:19,  3.04s/it] 83%|████████▎ | 219/264 [11:00<02:07,  2.84s/it] 83%|████████▎ | 220/264 [11:04<02:16,  3.09s/it] 84%|████████▎ | 221/264 [11:06<02:04,  2.89s/it] 84%|████████▍ | 222/264 [11:09<01:57,  2.79s/it] 84%|████████▍ | 223/264 [11:13<02:06,  3.07s/it] 85%|████████▍ | 224/264 [11:15<01:55,  2.88s/it] 85%|████████▌ | 225/264 [11:19<02:02,  3.14s/it] 86%|████████▌ | 226/264 [11:21<01:51,  2.92s/it] 86%|████████▌ | 227/264 [11:25<01:56,  3.15s/it] 86%|████████▋ | 228/264 [11:27<01:45,  2.94s/it] 87%|████████▋ | 229/264 [11:30<01:37,  2.78s/it] 87%|████████▋ | 230/264 [11:32<01:31,  2.68s/it] 88%|████████▊ | 231/264 [11:37<01:52,  3.40s/it] 88%|████████▊ | 232/264 [11:41<01:52,  3.50s/it] 88%|████████▊ | 233/264 [11:43<01:38,  3.18s/it] 89%|████████▊ | 234/264 [11:46<01:28,  2.95s/it] 89%|████████▉ | 235/264 [11:48<01:20,  2.79s/it] 89%|████████▉ | 236/264 [11:51<01:14,  2.68s/it] 90%|████████▉ | 237/264 [11:53<01:10,  2.60s/it] 90%|█████████ | 238/264 [11:57<01:16,  2.92s/it] 91%|█████████ | 239/264 [12:00<01:12,  2.89s/it] 91%|█████████ | 240/264 [12:03<01:14,  3.11s/it] 91%|█████████▏| 241/264 [12:07<01:15,  3.30s/it] 92%|█████████▏| 242/264 [12:09<01:06,  3.03s/it] 92%|█████████▏| 243/264 [12:12<00:59,  2.85s/it] 92%|█████████▏| 244/264 [12:15<01:01,  3.10s/it] 93%|█████████▎| 245/264 [12:18<00:54,  2.89s/it] 93%|█████████▎| 246/264 [12:20<00:49,  2.75s/it] 94%|█████████▎| 247/264 [12:24<00:51,  3.06s/it] 94%|█████████▍| 248/264 [12:28<00:51,  3.25s/it] 94%|█████████▍| 249/264 [12:30<00:44,  3.00s/it] 95%|█████████▍| 250/264 [12:34<00:44,  3.18s/it] 95%|█████████▌| 251/264 [12:36<00:38,  2.95s/it] 95%|█████████▌| 252/264 [12:39<00:33,  2.79s/it] 96%|█████████▌| 253/264 [12:41<00:29,  2.68s/it] 96%|█████████▌| 254/264 [12:43<00:25,  2.60s/it] 97%|█████████▋| 255/264 [12:46<00:22,  2.54s/it] 97%|█████████▋| 256/264 [12:48<00:20,  2.50s/it] 97%|█████████▋| 257/264 [12:51<00:17,  2.48s/it] 98%|█████████▊| 258/264 [12:53<00:14,  2.43s/it] 98%|█████████▊| 259/264 [12:55<00:12,  2.42s/it] 98%|█████████▊| 260/264 [12:58<00:09,  2.42s/it] 99%|█████████▉| 261/264 [13:00<00:07,  2.42s/it] 99%|█████████▉| 262/264 [13:04<00:05,  2.82s/it]100%|█████████▉| 263/264 [13:08<00:03,  3.07s/it]100%|██████████| 264/264 [13:09<00:00,  2.69s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.789 seconds.
Prefix dict has been built successfully.
100%|██████████| 264/264 [13:14<00:00,  3.01s/it]
***** predict metrics *****
  predict_bleu-4                 =     25.812
  predict_model_preparation_time =     0.0095
  predict_rouge-1                =    56.5131
  predict_rouge-2                =    47.8077
  predict_rouge-l                =    55.2726
  predict_runtime                = 0:13:20.22
  predict_samples_per_second     =      2.634
  predict_steps_per_second       =       0.33
[INFO|2025-06-28 17:35:56] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/Qwen2-VL-7B-Instruct/vindr_test_set/generated_predictions.jsonl
[2025-06-28 17:36:12,204] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-28 17:36:16 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-28 17:36:19] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,212 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,213 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,213 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,213 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,213 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,213 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,213 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 17:36:19,636 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|processing_utils.py:928] 2025-06-28 17:36:19,637 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/processor_config.json
[INFO|image_processing_base.py:378] 2025-06-28 17:36:19,638 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-28 17:36:19,645 >> Image processor GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,646 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,646 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,646 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,646 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,646 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,646 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:36:19,646 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 17:36:20,067 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-28 17:36:20,069 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-28 17:36:20,069 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-28 17:36:20,069 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-28 17:36:20,072 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

[INFO|video_processing_utils.py:627] 2025-06-28 17:36:20,073 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-28 17:36:20,073 >> Video processor InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}

[INFO|processing_utils.py:928] 2025-06-28 17:36:20,074 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/processor_config.json
[INFO|processing_utils.py:990] 2025-06-28 17:36:20,583 >> Processor InternVLProcessor:
- image_processor: GotOcr2ImageProcessorFast {
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  }
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf', vocab_size=151643, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>', '<img>', '</img>', '<IMG_CONTEXT>', '<quad>', '</quad>', '<ref>', '</ref>', '<box>', '</box>'], 'context_image_token': '<IMG_CONTEXT>', 'end_image_token': '</img>', 'start_image_token': '<img>', 'video_token': '<video>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151665: AddedToken("<img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151666: AddedToken("</img>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151667: AddedToken("<IMG_CONTEXT>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151668: AddedToken("<quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151669: AddedToken("</quad>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151670: AddedToken("<ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151671: AddedToken("</ref>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151672: AddedToken("<box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151673: AddedToken("</box>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151674: AddedToken("<video>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: InternVLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "crop_size": null,
  "crop_to_patches": false,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "GotOcr2ImageProcessorFast",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "input_data_format": null,
  "max_patches": 12,
  "min_patches": 1,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device"
  ],
  "processor_class": "InternVLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "height": 448,
    "width": 448
  },
  "size_divisor": null,
  "video_processor_type": "InternVLVideoProcessor"
}


{
  "image_seq_length": 256,
  "processor_class": "InternVLProcessor"
}

[INFO|2025-06-28 17:36:20] llamafactory.data.template:143 >> Add <|im_end|> to stop words.
[INFO|2025-06-28 17:36:20] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [01:53<28:18,  1.16 examples/s]Running tokenizer on dataset (num_proc=16):  12%|█▏        | 263/2108 [02:57<19:47,  1.55 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▊        | 395/2108 [03:03<10:30,  2.72 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 527/2108 [03:04<05:57,  4.42 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 791/2108 [03:05<02:21,  9.32 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1055/2108 [03:06<01:06, 15.72 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1187/2108 [03:07<00:45, 20.25 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1318/2108 [03:07<00:29, 26.81 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▊   | 1449/2108 [03:07<00:18, 35.03 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1581/2108 [03:08<00:11, 45.35 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1713/2108 [03:08<00:06, 61.35 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 1844/2108 [03:08<00:03, 83.18 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [03:08<00:00, 147.23 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [03:09<00:00, 11.15 examples/s] 
[INFO|configuration_utils.py:696] 2025-06-28 17:39:30,775 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/config.json
[INFO|configuration_utils.py:770] 2025-06-28 17:39:30,782 >> Model config InternVLConfig {
  "architectures": [
    "InternVLForConditionalGeneration"
  ],
  "downsample_ratio": 0.5,
  "image_seq_length": 256,
  "image_token_id": 151667,
  "model_type": "internvl",
  "projector_hidden_act": "gelu",
  "text_config": {
    "architectures": [
      "Qwen2ForCausalLM"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 70,
    "model_type": "qwen2",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "factor": 2.0,
      "rope_type": "dynamic",
      "type": "dynamic"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "vocab_size": 151674
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "vision_config": {
    "architectures": [
      "InternVisionModel"
    ],
    "attention_bias": true,
    "attention_dropout": 0.0,
    "dropout": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.0,
    "hidden_size": 1024,
    "image_size": [
      448,
      448
    ],
    "initializer_factor": 0.1,
    "initializer_range": 1e-10,
    "intermediate_size": 4096,
    "layer_norm_eps": 1e-06,
    "layer_scale_init_value": 0.1,
    "model_type": "internvl_vision",
    "norm_type": "layer_norm",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 24,
    "patch_size": [
      14,
      14
    ],
    "projection_dropout": 0.0,
    "torch_dtype": "bfloat16",
    "use_absolute_position_embeddings": true,
    "use_mask_token": false,
    "use_mean_pooling": true,
    "use_qk_norm": false
  },
  "vision_feature_layer": -1,
  "vision_feature_select_strategy": "default"
}

eval example:
input_ids:
[151644, 8948, 198, 105043, 90286, 21287, 13935, 116669, 3837, 105205, 13072, 20412, 67916, 30698, 3837, 104625, 100633, 104455, 104800, 5373, 109065, 81217, 104581, 99721, 75317, 101101, 100013, 9370, 42140, 53772, 35243, 26288, 102064, 104949, 1773, 151645, 198, 151644, 872, 198, 151665, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151667, 151666, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
你是书生·万象，英文名是InternVL，是由上海人工智能实验室、清华大学及多家合作单位联合开发的多模态大语言模型。<|im_end|>
<|im_start|>user
<img><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT><IMG_CONTEXT></img>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-28 17:39:30] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-28 17:39:30,895 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/model.safetensors
[INFO|modeling_utils.py:2241] 2025-06-28 17:39:30,906 >> Instantiating InternVLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-28 17:39:30,908 >> Generate config GenerationConfig {}

[INFO|modeling_utils.py:2241] 2025-06-28 17:39:31,503 >> Instantiating InternVLVisionModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-28 17:39:31,562 >> Instantiating Qwen2Model model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:5131] 2025-06-28 17:39:37,264 >> All model checkpoint weights were used when initializing InternVLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-28 17:39:37,265 >> All the weights of InternVLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use InternVLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-28 17:39:37,270 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/InternVL3-2B-hf/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-28 17:39:37,270 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|2025-06-28 17:39:37] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-28 17:39:37] llamafactory.model.loader:143 >> all params: 2,088,957,440
[WARNING|2025-06-28 17:39:37] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-28 17:39:37,326 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-28 17:39:37,326 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-28 17:39:37,326 >>   Batch size = 16
  0%|          | 0/132 [00:00<?, ?it/s]  2%|▏         | 2/132 [00:01<02:04,  1.04it/s]  2%|▏         | 3/132 [00:04<03:51,  1.80s/it]  3%|▎         | 4/132 [00:09<05:43,  2.68s/it]  4%|▍         | 5/132 [00:12<05:59,  2.83s/it]  5%|▍         | 6/132 [00:14<05:16,  2.51s/it]  5%|▌         | 7/132 [00:15<04:47,  2.30s/it]  6%|▌         | 8/132 [00:17<04:28,  2.16s/it]  7%|▋         | 9/132 [00:20<05:01,  2.45s/it]  8%|▊         | 10/132 [00:22<04:37,  2.28s/it]  8%|▊         | 11/132 [00:25<05:03,  2.51s/it]  9%|▉         | 12/132 [00:27<04:37,  2.31s/it] 10%|▉         | 13/132 [00:29<04:20,  2.18s/it] 11%|█         | 14/132 [00:33<05:09,  2.62s/it] 11%|█▏        | 15/132 [00:36<05:21,  2.75s/it] 12%|█▏        | 16/132 [00:38<04:47,  2.48s/it] 13%|█▎        | 17/132 [00:39<04:23,  2.29s/it] 14%|█▎        | 18/132 [00:42<04:44,  2.50s/it] 14%|█▍        | 19/132 [00:44<04:20,  2.30s/it] 15%|█▌        | 20/132 [00:47<04:44,  2.54s/it] 16%|█▌        | 21/132 [00:50<04:58,  2.69s/it] 17%|█▋        | 22/132 [00:52<04:27,  2.44s/it] 17%|█▋        | 23/132 [00:54<04:07,  2.27s/it] 18%|█▊        | 24/132 [00:56<03:51,  2.15s/it] 19%|█▉        | 25/132 [00:58<03:40,  2.06s/it] 20%|█▉        | 26/132 [01:00<03:32,  2.00s/it] 20%|██        | 27/132 [01:02<03:25,  1.96s/it] 21%|██        | 28/132 [01:03<03:20,  1.93s/it] 22%|██▏       | 29/132 [01:05<03:16,  1.91s/it] 23%|██▎       | 30/132 [01:08<03:48,  2.24s/it] 23%|██▎       | 31/132 [01:11<04:10,  2.48s/it] 24%|██▍       | 32/132 [01:13<03:49,  2.29s/it] 25%|██▌       | 33/132 [01:16<04:10,  2.53s/it] 26%|██▌       | 34/132 [01:18<03:48,  2.33s/it] 27%|██▋       | 35/132 [01:21<04:06,  2.54s/it] 27%|██▋       | 36/132 [01:24<04:15,  2.67s/it] 28%|██▊       | 37/132 [01:27<04:25,  2.79s/it] 29%|██▉       | 38/132 [01:30<04:31,  2.89s/it] 30%|██▉       | 39/132 [01:35<05:24,  3.49s/it] 30%|███       | 40/132 [01:37<04:36,  3.00s/it] 31%|███       | 41/132 [01:39<04:02,  2.67s/it] 32%|███▏      | 42/132 [01:41<03:38,  2.42s/it] 33%|███▎      | 43/132 [01:43<03:20,  2.25s/it] 33%|███▎      | 44/132 [01:45<03:07,  2.13s/it] 34%|███▍      | 45/132 [01:48<03:30,  2.42s/it] 35%|███▍      | 46/132 [01:49<03:14,  2.26s/it] 36%|███▌      | 47/132 [01:51<03:02,  2.14s/it] 36%|███▋      | 48/132 [01:53<02:52,  2.06s/it] 37%|███▋      | 49/132 [01:56<03:16,  2.37s/it] 38%|███▊      | 50/132 [01:59<03:31,  2.58s/it] 39%|███▊      | 51/132 [02:02<03:39,  2.71s/it] 39%|███▉      | 52/132 [02:07<04:20,  3.25s/it] 40%|████      | 53/132 [02:10<04:09,  3.16s/it] 41%|████      | 54/132 [02:12<03:35,  2.77s/it] 42%|████▏     | 55/132 [02:14<03:11,  2.49s/it] 42%|████▏     | 56/132 [02:15<02:54,  2.30s/it] 43%|████▎     | 57/132 [02:17<02:42,  2.16s/it] 44%|████▍     | 58/132 [02:19<02:33,  2.07s/it] 45%|████▍     | 59/132 [02:21<02:26,  2.00s/it] 45%|████▌     | 60/132 [02:24<02:47,  2.32s/it] 46%|████▌     | 61/132 [02:26<02:34,  2.18s/it] 47%|████▋     | 62/132 [02:28<02:25,  2.08s/it] 48%|████▊     | 63/132 [02:30<02:18,  2.01s/it] 48%|████▊     | 64/132 [02:31<02:13,  1.96s/it] 49%|████▉     | 65/132 [02:33<02:09,  1.93s/it] 50%|█████     | 66/132 [02:36<02:28,  2.25s/it] 51%|█████     | 67/132 [02:38<02:19,  2.14s/it] 52%|█████▏    | 68/132 [02:41<02:33,  2.40s/it] 52%|█████▏    | 69/132 [02:43<02:20,  2.24s/it] 53%|█████▎    | 70/132 [02:46<02:33,  2.47s/it] 54%|█████▍    | 71/132 [02:49<02:40,  2.63s/it] 55%|█████▍    | 72/132 [02:52<02:44,  2.74s/it] 55%|█████▌    | 73/132 [02:55<02:46,  2.82s/it] 56%|█████▌    | 74/132 [02:58<02:46,  2.88s/it] 57%|█████▋    | 75/132 [03:00<02:26,  2.58s/it] 58%|█████▊    | 76/132 [03:02<02:12,  2.37s/it] 58%|█████▊    | 77/132 [03:04<02:01,  2.21s/it] 59%|█████▉    | 78/132 [03:08<02:42,  3.01s/it] 60%|█████▉    | 79/132 [03:10<02:20,  2.66s/it] 61%|██████    | 80/132 [03:12<02:05,  2.42s/it] 61%|██████▏   | 81/132 [03:14<01:54,  2.25s/it] 62%|██████▏   | 82/132 [03:16<01:46,  2.13s/it] 63%|██████▎   | 83/132 [03:20<02:09,  2.65s/it] 64%|██████▎   | 84/132 [03:23<02:09,  2.69s/it] 64%|██████▍   | 85/132 [03:26<02:11,  2.79s/it] 65%|██████▌   | 86/132 [03:31<02:45,  3.60s/it] 66%|██████▌   | 87/132 [03:34<02:33,  3.40s/it] 67%|██████▋   | 88/132 [03:36<02:09,  2.93s/it] 67%|██████▋   | 89/132 [03:38<01:52,  2.61s/it] 68%|██████▊   | 90/132 [03:40<01:40,  2.39s/it] 69%|██████▉   | 91/132 [03:42<01:44,  2.56s/it] 70%|██████▉   | 92/132 [03:45<01:47,  2.69s/it] 70%|███████   | 93/132 [03:48<01:47,  2.76s/it] 71%|███████   | 94/132 [03:50<01:34,  2.49s/it] 72%|███████▏  | 95/132 [03:53<01:38,  2.66s/it] 73%|███████▎  | 96/132 [03:55<01:26,  2.42s/it] 73%|███████▎  | 97/132 [03:57<01:18,  2.24s/it] 74%|███████▍  | 98/132 [04:00<01:24,  2.49s/it] 75%|███████▌  | 99/132 [04:03<01:27,  2.65s/it] 76%|███████▌  | 100/132 [04:06<01:28,  2.78s/it] 77%|███████▋  | 101/132 [04:09<01:28,  2.85s/it] 77%|███████▋  | 102/132 [04:13<01:33,  3.12s/it] 78%|███████▊  | 103/132 [04:15<01:19,  2.74s/it] 79%|███████▉  | 104/132 [04:18<01:18,  2.82s/it] 80%|███████▉  | 105/132 [04:21<01:18,  2.89s/it] 80%|████████  | 106/132 [04:23<01:07,  2.58s/it] 81%|████████  | 107/132 [04:26<01:07,  2.71s/it] 82%|████████▏ | 108/132 [04:28<00:58,  2.45s/it] 83%|████████▎ | 109/132 [04:29<00:52,  2.27s/it] 83%|████████▎ | 110/132 [04:32<00:55,  2.51s/it] 84%|████████▍ | 111/132 [04:35<00:55,  2.65s/it] 85%|████████▍ | 112/132 [04:39<00:55,  2.78s/it] 86%|████████▌ | 113/132 [04:40<00:47,  2.50s/it] 86%|████████▋ | 114/132 [04:42<00:41,  2.30s/it] 87%|████████▋ | 115/132 [04:45<00:42,  2.50s/it] 88%|████████▊ | 116/132 [04:48<00:42,  2.63s/it] 89%|████████▊ | 117/132 [04:50<00:35,  2.40s/it] 89%|████████▉ | 118/132 [04:53<00:35,  2.56s/it] 90%|█████████ | 119/132 [04:56<00:34,  2.68s/it] 91%|█████████ | 120/132 [04:59<00:33,  2.77s/it] 92%|█████████▏| 121/132 [05:01<00:27,  2.50s/it] 92%|█████████▏| 122/132 [05:04<00:26,  2.63s/it] 93%|█████████▎| 123/132 [05:07<00:24,  2.75s/it] 94%|█████████▍| 124/132 [05:09<00:19,  2.48s/it] 95%|█████████▍| 125/132 [05:12<00:18,  2.63s/it] 95%|█████████▌| 126/132 [05:13<00:14,  2.40s/it] 96%|█████████▌| 127/132 [05:16<00:12,  2.58s/it] 97%|█████████▋| 128/132 [05:19<00:10,  2.71s/it] 98%|█████████▊| 129/132 [05:21<00:07,  2.45s/it] 98%|█████████▊| 130/132 [05:23<00:04,  2.27s/it] 99%|█████████▉| 131/132 [05:28<00:03,  3.07s/it]100%|██████████| 132/132 [05:30<00:00,  2.62s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.793 seconds.
Prefix dict has been built successfully.
100%|██████████| 132/132 [05:34<00:00,  2.54s/it]
***** predict metrics *****
  predict_bleu-4                 =      47.89
  predict_model_preparation_time =     0.0094
  predict_rouge-1                =    63.0148
  predict_rouge-2                =    54.9188
  predict_rouge-l                =     62.597
  predict_runtime                = 0:05:38.97
  predict_samples_per_second     =      6.219
  predict_steps_per_second       =      0.389
[INFO|2025-06-28 17:45:16] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/Qwen2-VL-2B-Instruct/InternVL3-2B-hf/generated_predictions.jsonl
[2025-06-28 17:45:28,047] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 06-28 17:45:31 [__init__.py:239] Automatically detected platform cuda.
[INFO|2025-06-28 17:45:34] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,583 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,583 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,583 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,583 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,583 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,583 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,583 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 17:45:34,918 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-06-28 17:45:34,920 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-06-28 17:45:34,924 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-06-28 17:45:34,931 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,932 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,932 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,932 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,932 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,932 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,932 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-06-28 17:45:34,932 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2299] 2025-06-28 17:45:35,235 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:328] 2025-06-28 17:45:35,236 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-06-28 17:45:35,236 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|configuration_utils.py:696] 2025-06-28 17:45:35,236 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-28 17:45:35,239 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

[INFO|video_processing_utils.py:627] 2025-06-28 17:45:35,240 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-06-28 17:45:35,240 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:990] 2025-06-28 17:45:35,747 >> Processor Qwen2VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "patch_size": 14,
  "processor_class": "Qwen2VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2VLProcessor"
}

[INFO|2025-06-28 17:45:35] llamafactory.data.loader:143 >> Loading dataset ./0_my_dataset/vindr/qwen2_vindr_input_test_len_2108.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2108 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 132/2108 [02:32<37:56,  1.15s/ examples]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 264/2108 [04:18<29:08,  1.05 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 396/2108 [04:18<14:44,  1.94 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 528/2108 [04:23<08:35,  3.06 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███▏      | 660/2108 [04:23<05:02,  4.78 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 792/2108 [04:26<03:12,  6.85 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 1056/2108 [04:27<01:18, 13.33 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 1187/2108 [04:29<00:56, 16.36 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1319/2108 [04:30<00:35, 22.26 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 1451/2108 [04:30<00:22, 29.63 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 1583/2108 [04:30<00:12, 40.95 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 1977/2108 [04:31<00:01, 89.59 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 2108/2108 [04:31<00:00,  7.77 examples/s]
[INFO|configuration_utils.py:696] 2025-06-28 17:50:08,210 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/config.json
[INFO|configuration_utils.py:770] 2025-06-28 17:50:08,218 >> Model config Qwen2VLConfig {
  "architectures": [
    "Qwen2VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2_vl",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "architectures": [
      "Qwen2VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 1536,
    "image_token_id": null,
    "initializer_range": 0.02,
    "intermediate_size": 8960,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_vl_text",
    "num_attention_heads": 12,
    "num_hidden_layers": 28,
    "num_key_value_heads": 2,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": 32768,
    "tie_word_embeddings": true,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_id": null,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654,
    "vocab_size": 151936
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "embed_dim": 1280,
    "hidden_act": "quick_gelu",
    "hidden_size": 1536,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "mlp_ratio": 4,
    "model_type": "qwen2_vl",
    "num_heads": 16,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

eval example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 198, 5598, 30618, 14697, 315, 364, 47, 811, 372, 8767, 269, 706, 6, 5671, 438, 4718, 3561, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 330, 1502, 788, 330, 1502, 7115, 9338, 921, 73594, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>
Return bounding boxes of 'Pneumothorax' areas as JSON format:
```json
[
{"bbox_2d": [x1, y1, x2, y2], "label": "label"},
...
]
```<|im_end|>
<|im_start|>assistant

label_ids:
[27, 9217, 397, 9640, 220, 341, 262, 330, 58456, 62, 17, 67, 788, 2278, 414, 220, 16, 22, 20, 345, 414, 220, 17, 22, 24, 345, 414, 220, 18, 15, 17, 345, 414, 220, 21, 23, 16, 198, 262, 3211, 262, 330, 1502, 788, 330, 47, 811, 372, 8767, 269, 706, 698, 220, 456, 921, 522, 9217, 29, 151645, 198]
labels:
<answer>
[
  {
    "bbox_2d": [
      175,
      279,
      302,
      681
    ],
    "label": "Pneumothorax"
  }
]
</answer><|im_end|>

[INFO|2025-06-28 17:50:08] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.
[INFO|modeling_utils.py:1148] 2025-06-28 17:50:08,315 >> loading weights file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-06-28 17:50:08,318 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-06-28 17:50:08,320 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|modeling_utils.py:2241] 2025-06-28 17:50:08,321 >> Instantiating Qwen2VisionTransformerPretrainedModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2241] 2025-06-28 17:50:08,343 >> Instantiating Qwen2VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.87s/it]
[INFO|modeling_utils.py:5131] 2025-06-28 17:50:14,160 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.

[INFO|modeling_utils.py:5139] 2025-06-28 17:50:14,160 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-06-28 17:50:14,166 >> loading configuration file /home/june/Code/new_llamafactory/saves/huggingface_origin/Qwen2-VL-2B-Instruct/generation_config.json
[INFO|configuration_utils.py:1135] 2025-06-28 17:50:14,167 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.01,
  "top_k": 1,
  "top_p": 0.001
}

[INFO|2025-06-28 17:50:14] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
[INFO|2025-06-28 17:50:14] llamafactory.model.loader:143 >> all params: 2,208,985,600
[WARNING|2025-06-28 17:50:14] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
[INFO|trainer.py:4327] 2025-06-28 17:50:14,219 >> 
***** Running Prediction *****
[INFO|trainer.py:4329] 2025-06-28 17:50:14,219 >>   Num examples = 2108
[INFO|trainer.py:4332] 2025-06-28 17:50:14,220 >>   Batch size = 16
  0%|          | 0/132 [00:00<?, ?it/s]  2%|▏         | 2/132 [00:03<03:59,  1.84s/it]  2%|▏         | 3/132 [00:40<34:55, 16.24s/it]  3%|▎         | 4/132 [00:43<24:39, 11.56s/it]  4%|▍         | 5/132 [00:48<19:36,  9.26s/it]  5%|▍         | 6/132 [01:02<22:17, 10.62s/it]  5%|▌         | 7/132 [01:05<17:27,  8.38s/it]  6%|▌         | 8/132 [01:09<14:17,  6.92s/it]  7%|▋         | 9/132 [01:13<12:06,  5.90s/it]  8%|▊         | 10/132 [01:17<11:16,  5.54s/it]  8%|▊         | 11/132 [01:54<30:09, 14.95s/it]  9%|▉         | 12/132 [01:57<23:03, 11.53s/it] 10%|▉         | 13/132 [02:01<18:06,  9.13s/it] 11%|█         | 14/132 [02:08<16:32,  8.41s/it] 11%|█▏        | 15/132 [02:11<13:37,  6.99s/it] 12%|█▏        | 16/132 [02:15<11:35,  5.99s/it] 13%|█▎        | 17/132 [02:52<28:59, 15.13s/it] 14%|█▎        | 18/132 [02:55<22:12, 11.69s/it] 14%|█▍        | 19/132 [03:00<18:10,  9.65s/it] 15%|█▌        | 20/132 [03:04<14:39,  7.86s/it] 16%|█▌        | 21/132 [03:07<12:12,  6.60s/it] 17%|█▋        | 22/132 [03:11<10:29,  5.72s/it] 17%|█▋        | 23/132 [03:15<09:18,  5.12s/it] 18%|█▊        | 24/132 [03:19<08:26,  4.69s/it] 19%|█▉        | 25/132 [03:55<25:18, 14.19s/it] 20%|█▉        | 26/132 [03:59<19:29, 11.03s/it] 20%|██        | 27/132 [04:02<15:26,  8.82s/it] 21%|██        | 28/132 [04:06<12:37,  7.28s/it] 22%|██▏       | 29/132 [04:10<10:38,  6.19s/it] 23%|██▎       | 30/132 [04:13<09:13,  5.43s/it] 23%|██▎       | 31/132 [04:17<08:16,  4.91s/it] 24%|██▍       | 32/132 [04:21<07:33,  4.54s/it] 25%|██▌       | 33/132 [04:57<23:27, 14.21s/it] 26%|██▌       | 34/132 [05:01<18:03, 11.06s/it] 27%|██▋       | 35/132 [05:05<14:17,  8.84s/it] 27%|██▋       | 36/132 [05:08<11:38,  7.28s/it] 28%|██▊       | 37/132 [05:12<09:49,  6.21s/it] 29%|██▉       | 38/132 [05:17<08:55,  5.70s/it] 30%|██▉       | 39/132 [05:20<07:54,  5.10s/it] 30%|███       | 40/132 [05:56<22:08, 14.43s/it] 31%|███       | 41/132 [06:00<17:00, 11.22s/it] 32%|███▏      | 42/132 [06:04<13:25,  8.94s/it] 33%|███▎      | 43/132 [06:40<25:29, 17.18s/it] 33%|███▎      | 44/132 [06:44<19:15, 13.13s/it] 34%|███▍      | 45/132 [06:55<18:15, 12.59s/it] 35%|███▍      | 46/132 [06:59<14:11,  9.90s/it] 36%|███▌      | 47/132 [07:03<11:32,  8.15s/it] 36%|███▋      | 48/132 [07:07<09:31,  6.81s/it] 37%|███▋      | 49/132 [07:43<21:41, 15.69s/it] 38%|███▊      | 50/132 [07:56<20:29, 14.99s/it] 39%|███▊      | 51/132 [08:00<15:41, 11.62s/it] 39%|███▉      | 52/132 [08:04<12:18,  9.23s/it] 40%|████      | 53/132 [08:07<09:57,  7.57s/it] 41%|████      | 54/132 [08:11<08:19,  6.40s/it] 42%|████▏     | 55/132 [08:21<09:39,  7.52s/it] 42%|████▏     | 56/132 [08:58<20:29, 16.18s/it] 43%|████▎     | 57/132 [09:01<15:33, 12.44s/it] 44%|████▍     | 58/132 [09:05<12:05,  9.80s/it] 45%|████▍     | 59/132 [09:10<09:58,  8.21s/it] 45%|████▌     | 60/132 [09:13<08:12,  6.85s/it] 46%|████▌     | 61/132 [09:18<07:23,  6.25s/it] 47%|████▋     | 62/132 [09:22<06:23,  5.48s/it] 48%|████▊     | 63/132 [09:25<05:40,  4.93s/it] 48%|████▊     | 64/132 [09:29<05:09,  4.55s/it] 49%|████▉     | 65/132 [09:33<04:46,  4.27s/it] 50%|█████     | 66/132 [09:36<04:31,  4.11s/it] 51%|█████     | 67/132 [10:13<14:57, 13.81s/it] 52%|█████▏    | 68/132 [10:17<11:46, 11.04s/it] 52%|█████▏    | 69/132 [10:22<09:34,  9.11s/it] 53%|█████▎    | 70/132 [10:27<08:01,  7.76s/it] 54%|█████▍    | 71/132 [10:30<06:38,  6.54s/it] 55%|█████▍    | 72/132 [11:07<15:28, 15.48s/it] 55%|█████▌    | 73/132 [11:10<11:44, 11.94s/it] 56%|█████▌    | 74/132 [11:15<09:24,  9.73s/it] 57%|█████▋    | 75/132 [11:19<07:31,  7.93s/it] 58%|█████▊    | 76/132 [11:23<06:19,  6.78s/it] 58%|█████▊    | 77/132 [11:52<12:27, 13.60s/it] 59%|█████▉    | 78/132 [11:56<09:33, 10.62s/it] 60%|█████▉    | 79/132 [12:00<07:32,  8.54s/it] 61%|██████    | 80/132 [12:03<06:07,  7.08s/it] 61%|██████▏   | 81/132 [12:07<05:08,  6.06s/it] 62%|██████▏   | 82/132 [12:11<04:27,  5.34s/it] 63%|██████▎   | 83/132 [12:23<05:58,  7.32s/it] 64%|██████▎   | 84/132 [12:43<09:02, 11.31s/it] 64%|██████▍   | 85/132 [13:20<14:44, 18.83s/it] 65%|██████▌   | 86/132 [13:24<11:10, 14.57s/it] 66%|██████▌   | 87/132 [13:28<08:28, 11.30s/it] 67%|██████▋   | 88/132 [13:32<06:36,  9.01s/it] 67%|██████▋   | 89/132 [13:35<05:18,  7.41s/it] 68%|██████▊   | 90/132 [13:39<04:23,  6.28s/it] 69%|██████▉   | 91/132 [13:44<04:00,  5.87s/it] 70%|██████▉   | 92/132 [13:47<03:28,  5.21s/it] 70%|███████   | 93/132 [13:51<03:04,  4.74s/it] 71%|███████   | 94/132 [13:55<02:48,  4.42s/it] 72%|███████▏  | 95/132 [13:58<02:35,  4.20s/it] 73%|███████▎  | 96/132 [14:03<02:35,  4.32s/it] 73%|███████▎  | 97/132 [14:07<02:24,  4.13s/it] 74%|███████▍  | 98/132 [14:10<02:15,  3.99s/it] 75%|███████▌  | 99/132 [14:14<02:08,  3.91s/it] 76%|███████▌  | 100/132 [14:50<07:16, 13.63s/it] 77%|███████▋  | 101/132 [15:01<06:37, 12.81s/it] 77%|███████▋  | 102/132 [15:05<05:02, 10.08s/it] 78%|███████▊  | 103/132 [15:09<03:56,  8.16s/it] 79%|███████▉  | 104/132 [15:13<03:18,  7.07s/it] 80%|███████▉  | 105/132 [15:17<02:43,  6.04s/it] 80%|████████  | 106/132 [15:21<02:21,  5.44s/it] 81%|████████  | 107/132 [15:25<02:02,  4.90s/it] 82%|████████▏ | 108/132 [16:01<05:44, 14.35s/it] 83%|████████▎ | 109/132 [16:05<04:16, 11.15s/it] 83%|████████▎ | 110/132 [16:09<03:21,  9.17s/it] 84%|████████▍ | 111/132 [16:13<02:37,  7.52s/it] 85%|████████▍ | 112/132 [16:17<02:07,  6.37s/it] 86%|████████▌ | 113/132 [16:29<02:33,  8.06s/it] 86%|████████▋ | 114/132 [16:32<02:01,  6.74s/it] 87%|████████▋ | 115/132 [16:36<01:39,  5.83s/it] 88%|████████▊ | 116/132 [16:40<01:23,  5.19s/it] 89%|████████▊ | 117/132 [16:43<01:11,  4.74s/it] 89%|████████▉ | 118/132 [16:47<01:01,  4.41s/it] 90%|█████████ | 119/132 [16:51<00:54,  4.20s/it] 91%|█████████ | 120/132 [16:55<00:51,  4.30s/it] 92%|█████████▏| 121/132 [16:59<00:46,  4.23s/it] 92%|█████████▏| 122/132 [17:03<00:40,  4.06s/it] 93%|█████████▎| 123/132 [17:07<00:35,  3.95s/it] 94%|█████████▍| 124/132 [17:10<00:30,  3.86s/it] 95%|█████████▍| 125/132 [17:14<00:26,  3.80s/it] 95%|█████████▌| 126/132 [17:18<00:22,  3.76s/it] 96%|█████████▌| 127/132 [17:33<00:36,  7.32s/it] 97%|█████████▋| 128/132 [17:37<00:24,  6.23s/it] 98%|█████████▊| 129/132 [17:41<00:16,  5.46s/it] 98%|█████████▊| 130/132 [17:44<00:09,  4.91s/it] 99%|█████████▉| 131/132 [17:48<00:04,  4.52s/it]100%|██████████| 132/132 [17:51<00:00,  4.27s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.809 seconds.
Prefix dict has been built successfully.
100%|██████████| 132/132 [17:57<00:00,  8.16s/it]
***** predict metrics *****
  predict_bleu-4                 =    24.0633
  predict_model_preparation_time =     0.0089
  predict_rouge-1                =    62.8609
  predict_rouge-2                =    54.2706
  predict_rouge-l                =    61.4964
  predict_runtime                = 0:18:02.71
  predict_samples_per_second     =      1.947
  predict_steps_per_second       =      0.122
[INFO|2025-06-28 18:08:16] llamafactory.train.sft.trainer:143 >> Saving prediction results to evaluate_outputs/Qwen2-VL-2B-Instruct/vindr_test_set/generated_predictions.jsonl
